{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba7bac1e",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Transfer Learning<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Data-preparation\" data-toc-modified-id=\"Data-preparation-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Data preparation</a></span></li><li><span><a href=\"#Models-training\" data-toc-modified-id=\"Models-training-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Models training</a></span><ul class=\"toc-item\"><li><span><a href=\"#Option-1-(model-not-learned-and-change-only-last-layer)\" data-toc-modified-id=\"Option-1-(model-not-learned-and-change-only-last-layer)-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Option 1 (model not learned and change only last layer)</a></span></li><li><span><a href=\"#Option-2-(model-not-learned-and-change-all-classifier)\" data-toc-modified-id=\"Option-2-(model-not-learned-and-change-all-classifier)-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Option 2 (model not learned and change all classifier)</a></span></li></ul></li><li><span><a href=\"#Models-training-with-Transfer-Learning\" data-toc-modified-id=\"Models-training-with-Transfer-Learning-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Models training with Transfer Learning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Option-1-(model-pre-trained,-no-frozen-pre-trained-parameters,-change-last-layer)\" data-toc-modified-id=\"Option-1-(model-pre-trained,-no-frozen-pre-trained-parameters,-change-last-layer)-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Option 1 (model pre-trained, no frozen pre-trained parameters, change last layer)</a></span></li><li><span><a href=\"#Option-2-(model-pre-trained,-no-frozen-pre-trained-parameters,-change-all-classifier)\" data-toc-modified-id=\"Option-2-(model-pre-trained,-no-frozen-pre-trained-parameters,-change-all-classifier)-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Option 2 (model pre-trained, no frozen pre-trained parameters, change all classifier)</a></span></li><li><span><a href=\"#Option-3-(model-pre-trained,-frozen-pre-trained-parameters,-change-all-classifier)\" data-toc-modified-id=\"Option-3-(model-pre-trained,-frozen-pre-trained-parameters,-change-all-classifier)-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Option 3 (model pre-trained, frozen pre-trained parameters, change all classifier)</a></span></li><li><span><a href=\"#Finetuning\" data-toc-modified-id=\"Finetuning-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Finetuning</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "654008e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import requests\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1e08ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94bcd95",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95120e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_URL = 'https://download.pytorch.org/tutorial/hymenoptera_data.zip'\n",
    "DATA_PATH = os.path.join('.', 'TRANSFER')\n",
    "FILE_NAME = os.path.join(DATA_PATH, 'hymenoptera_data.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbfed016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./TRANSFER/hymenoptera_data.zip'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILE_NAME "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "322873b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./TRANSFER/hymenoptera_data.zip already exists, skipping download\n",
      "Unzipping process...\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile(FILE_NAME):\n",
    "    print('Downloading the data...')\n",
    "    os.makedirs('TRANSFER', exist_ok=True)\n",
    "    with requests.get(DATA_URL) as req:\n",
    "        with open(FILE_NAME, 'wb') as f:\n",
    "            f.write(req.content)\n",
    "    if 200 <= req.status_code < 300:\n",
    "        print('Download complited')\n",
    "    else:\n",
    "        print('Download failed!!!')\n",
    "else:\n",
    "    print(FILE_NAME, 'already exists, skipping download')\n",
    "    \n",
    "with zipfile.ZipFile(FILE_NAME, 'r') as zip_ref:\n",
    "    print('Unzipping process...')\n",
    "    zip_ref.extractall('TRANSFER')\n",
    "\n",
    "DATA_PATH = os.path.join(DATA_PATH, 'hymenoptera_data.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65901c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./TRANSFER/hymenoptera_data.zip'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "908ee26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: wget\n",
      "zsh:1: command not found: uzip\n"
     ]
    }
   ],
   "source": [
    "!wget https://download.pytorch.org/tutorial/hymenoptera_data.zip\n",
    "!uzip hymenoptera_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1728f27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f59409f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_val = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6601cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.ImageFolder(\n",
    "    '/Users/alexeyfilichkin/Desktop/PyTorch/MNIST/TRANSFER/hymenoptera_data/train',\n",
    "    transform=transforms_train)\n",
    "\n",
    "val_data = datasets.ImageFolder(\n",
    "    '/Users/alexeyfilichkin/Desktop/PyTorch/MNIST/TRANSFER/hymenoptera_data/val',\n",
    "    transform=transforms_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ad6ab79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ants', 'bees']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_name = train_data.classes\n",
    "class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bde110d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244\n",
      "153\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b3aad71",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee305b73",
   "metadata": {},
   "source": [
    "### Models training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54db9dc",
   "metadata": {},
   "source": [
    "#### Option 1 (model not learned and change only last layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "143f1d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1 = models.vgg11()\n",
    "model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "361ee829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.classifier[6] = nn.Linear(4096, 2)\n",
    "model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8bd9413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = model_1.to(device)\n",
    "\n",
    "loss_model_1 = nn.CrossEntropyLoss()\n",
    "opt_1 = torch.optim.Adam(model_1.parameters(), lr=0.001)\n",
    "lr_scheduler_1 = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56eeb082",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "lr_list = []\n",
    "best_loss = None\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c4134f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1 / 10], train_loss=1.5851,train_acc=0.5000, val_loss=0.6896,val_acc=0.5425, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2 / 10], train_loss=0.6937,train_acc=0.4795, val_loss=0.6943,val_acc=0.4575, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3 / 10], train_loss=0.6949,train_acc=0.5041, val_loss=0.6975,val_acc=0.4575, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4 / 10], train_loss=0.6930,train_acc=0.5041, val_loss=0.6953,val_acc=0.4575, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5 / 10], train_loss=0.6925,train_acc=0.5041, val_loss=0.6947,val_acc=0.4575, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6 / 10], train_loss=0.6952,train_acc=0.4877, val_loss=0.6964,val_acc=0.4575, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7 / 10], train_loss=0.6943,train_acc=0.5000, val_loss=0.6950,val_acc=0.4575, lr=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8 / 10], train_loss=0.6928,train_acc=0.4959, val_loss=0.6946,val_acc=0.4575, lr=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9 / 10], train_loss=0.6935,train_acc=0.4918, val_loss=0.6948,val_acc=0.4575, lr=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10 / 10], train_loss=0.6934,train_acc=0.5000, val_loss=0.6948,val_acc=0.4575, lr=0.0001\n",
      "Time of model training 10 epochs: 0m 59s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    \n",
    "    model_1.train()\n",
    "    running_train_loss = []\n",
    "    true_answer = 0\n",
    "    \n",
    "    train_loop = tqdm(train_loader, leave=False)\n",
    "    for x, targets in train_loop:\n",
    "        x = x.to(device)\n",
    "        targets = targets.reshape(-1).to(torch.int32)\n",
    "        targets = torch.eye(2)[targets].to(device)\n",
    "        \n",
    "        pred = model_1(x)\n",
    "        loss = loss_model_1(pred, targets)\n",
    "        \n",
    "        opt_1.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        opt_1.step()\n",
    "        \n",
    "        running_train_loss.append(loss.item())\n",
    "        mean_train_loss = sum(running_train_loss) / len(running_train_loss)\n",
    "        \n",
    "        true_answer += (pred.argmax(dim=1) == targets.argmax(dim=1)).sum().item()\n",
    "        train_loop.set_description(f'Epoch [{epoch} / {EPOCHS}], train_loss={mean_train_loss:.4f}')\n",
    "    \n",
    "    running_train_acc = true_answer / len(train_data)\n",
    "    \n",
    "    train_loss.append(mean_train_loss)\n",
    "    train_acc.append(running_train_acc)\n",
    "    \n",
    "    model_1.eval()\n",
    "    with torch.no_grad():\n",
    "        running_val_loss = []\n",
    "        true_answer = 0\n",
    "        \n",
    "        for x, targets in val_loader:\n",
    "#            x = x.reshape(-1, 64*64).to(device)\n",
    "            x = x.to(device)\n",
    "            targets = targets.reshape(-1).to(torch.int32)\n",
    "            targets = torch.eye(2)[targets].to(device)\n",
    "            \n",
    "            pred = model_1(x)\n",
    "            loss = loss_model_1(pred, targets)\n",
    "            \n",
    "            running_val_loss.append(loss.item())\n",
    "            mean_val_loss = sum(running_val_loss) / len(running_val_loss)\n",
    "            \n",
    "            true_answer += (pred.argmax(dim=1) == targets.argmax(dim=1)).sum().item()\n",
    "            \n",
    "        running_val_acc = true_answer / len(val_data)\n",
    "        \n",
    "        val_loss.append(mean_val_loss)\n",
    "        val_acc.append(running_val_acc)\n",
    "        \n",
    "        \n",
    "    \n",
    "    lr_scheduler_1.step(mean_val_loss)\n",
    "    lr = lr_scheduler_1._last_lr[0]\n",
    "    lr_list.append(lr)\n",
    "    \n",
    "#    if epoch == 1 or epoch % 5 == 0:\n",
    "    print(f'Epoch [{epoch} / {EPOCHS}], train_loss={mean_train_loss:.4f},'\n",
    "          f'train_acc={running_train_acc:.4f}, val_loss={mean_val_loss:.4f},'\n",
    "          f'val_acc={running_val_acc:.4f}, lr={lr:.4f}'\n",
    "          )\n",
    "        \n",
    "#    if best_loss == None:\n",
    "#        best_loss = mean_val_loss\n",
    "        \n",
    "#    if mean_val_loss < best_loss:\n",
    "#        best_loss = mean_val_loss\n",
    "        \n",
    "#        checkpoint = {\n",
    "#            'state_model': model_reg.state_dict(),\n",
    "#            'state_opt': opt_reg.state_dict(),\n",
    "#            'state_lr_scheduler': lr_scheduler.state_dict(),\n",
    "#            'loss': {\n",
    "#                'train_loss': train_loss,\n",
    "#                'val_loss': val_loss,\n",
    "#                'best_loss': best_loss\n",
    "#            },\n",
    "#           'metric': {\n",
    "#                'train_acc': train_acc,\n",
    "#                'val_acc': val_acc\n",
    "#            },\n",
    "#            'lr': lr_list,\n",
    "#            'epoch': {\n",
    "#                'EPOCHS': EPOCHS,\n",
    "#                'save_epoch': epoch\n",
    "#            }\n",
    "#        }\n",
    "        \n",
    "#        torch.save(checkpoint,\n",
    "#                   f'/Users/alexeyfilichkin/Desktop/PyTorch/MNIST/mnist/model_saved/model_state_dict_epoch_{epoch}.pt')\n",
    "#        print(f'On epoch {epoch},'\n",
    "#              f' model was saved with validation los function data: {mean_val_loss:.4f}', end='\\n\\n')\n",
    "    \n",
    "#    if earlystopping(mean_val_loss):\n",
    "#        print(f'\\33[31mTraining was stopped on {epoch+1} epoch\\033[0m')\n",
    "#        break\n",
    "\n",
    "time_model = time.time() - start\n",
    "print(f'Time of model training {EPOCHS} epochs: {time_model // 60:.0f}m {time_model % 60:.0f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9521bea",
   "metadata": {},
   "source": [
    "#### Option 2 (model not learned and change all classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "79260866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Linear(in_features=25088, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = models.vgg11()\n",
    "model_2.classifier = nn.Linear(512*7*7, 2)\n",
    "model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1d97c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = model_2.to(device)\n",
    "\n",
    "loss_model_2 = nn.CrossEntropyLoss()\n",
    "opt_2 = torch.optim.Adam(model_2.parameters(), lr=0.001)\n",
    "lr_scheduler_2 = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_2, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fdd5e2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "lr_list = []\n",
    "best_loss = None\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c240d7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1 / 10], train_loss=0.9716,train_acc=0.5123, val_loss=0.6830,val_acc=0.5817, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2 / 10], train_loss=0.6600,train_acc=0.6066, val_loss=0.7218,val_acc=0.4575, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3 / 10], train_loss=0.7017,train_acc=0.5041, val_loss=0.6970,val_acc=0.4575, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4 / 10], train_loss=0.6981,train_acc=0.4344, val_loss=0.6935,val_acc=0.4575, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5 / 10], train_loss=0.6932,train_acc=0.5041, val_loss=0.6940,val_acc=0.4575, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6 / 10], train_loss=0.6937,train_acc=0.5041, val_loss=0.6960,val_acc=0.4575, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7 / 10], train_loss=0.6938,train_acc=0.5041, val_loss=0.6959,val_acc=0.4575, lr=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8 / 10], train_loss=0.6937,train_acc=0.5041, val_loss=0.6958,val_acc=0.4575, lr=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9 / 10], train_loss=0.6927,train_acc=0.5041, val_loss=0.6956,val_acc=0.4575, lr=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10 / 10], train_loss=0.6932,train_acc=0.5041, val_loss=0.6956,val_acc=0.4575, lr=0.0001\n",
      "Time of model training 10 epochs: 0m 45s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    \n",
    "    model_2.train()\n",
    "    running_train_loss = []\n",
    "    true_answer = 0\n",
    "    \n",
    "    train_loop = tqdm(train_loader, leave=False)\n",
    "    for x, targets in train_loop:\n",
    "        x = x.to(device)\n",
    "        targets = targets.reshape(-1).to(torch.int32)\n",
    "        targets = torch.eye(2)[targets].to(device)\n",
    "        \n",
    "        pred = model_2(x)\n",
    "        loss = loss_model_2(pred, targets)\n",
    "        \n",
    "        opt_2.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        opt_2.step()\n",
    "        \n",
    "        running_train_loss.append(loss.item())\n",
    "        mean_train_loss = sum(running_train_loss) / len(running_train_loss)\n",
    "        \n",
    "        true_answer += (pred.argmax(dim=1) == targets.argmax(dim=1)).sum().item()\n",
    "        train_loop.set_description(f'Epoch [{epoch} / {EPOCHS}], train_loss={mean_train_loss:.4f}')\n",
    "    \n",
    "    running_train_acc = true_answer / len(train_data)\n",
    "    \n",
    "    train_loss.append(mean_train_loss)\n",
    "    train_acc.append(running_train_acc)\n",
    "    \n",
    "    model_2.eval()\n",
    "    with torch.no_grad():\n",
    "        running_val_loss = []\n",
    "        true_answer = 0\n",
    "        \n",
    "        for x, targets in val_loader:\n",
    "            x = x.to(device)\n",
    "            targets = targets.reshape(-1).to(torch.int32)\n",
    "            targets = torch.eye(2)[targets].to(device)\n",
    "            \n",
    "            pred = model_2(x)\n",
    "            loss = loss_model_2(pred, targets)\n",
    "            \n",
    "            running_val_loss.append(loss.item())\n",
    "            mean_val_loss = sum(running_val_loss) / len(running_val_loss)\n",
    "            \n",
    "            true_answer += (pred.argmax(dim=1) == targets.argmax(dim=1)).sum().item()\n",
    "            \n",
    "        running_val_acc = true_answer / len(val_data)\n",
    "        \n",
    "        val_loss.append(mean_val_loss)\n",
    "        val_acc.append(running_val_acc)\n",
    "        \n",
    "        \n",
    "    \n",
    "    lr_scheduler_2.step(mean_val_loss)\n",
    "    lr = lr_scheduler_2._last_lr[0]\n",
    "    lr_list.append(lr)\n",
    "    \n",
    "#    if epoch == 1 or epoch % 5 == 0:\n",
    "    print(f'Epoch [{epoch} / {EPOCHS}], train_loss={mean_train_loss:.4f},'\n",
    "          f'train_acc={running_train_acc:.4f}, val_loss={mean_val_loss:.4f},'\n",
    "          f'val_acc={running_val_acc:.4f}, lr={lr:.4f}'\n",
    "          )\n",
    "time_model = time.time() - start\n",
    "print(f'Time of model training {EPOCHS} epochs: {time_model // 60:.0f}m {time_model % 60:.0f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89881c66",
   "metadata": {},
   "source": [
    "### Models training with Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fa3211",
   "metadata": {},
   "source": [
    "#### Option 1 (model pre-trained, no frozen pre-trained parameters, change last layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d95045d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg11-8a719046.pth\" to /Users/alexeyfilichkin/.cache/torch/hub/checkpoints/vgg11-8a719046.pth\n",
      "100%|████████████████████████████████████████| 507M/507M [00:27<00:00, 19.5MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3 = models.vgg11(weights='DEFAULT')\n",
    "model_3.classifier[6] = nn.Linear(4096, 2)\n",
    "model_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f576f303",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = model_3.to(device)\n",
    "\n",
    "loss_model_3 = nn.CrossEntropyLoss()\n",
    "opt_3 = torch.optim.Adam(model_3.parameters(), lr=0.001)\n",
    "lr_scheduler_3 = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_3, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9e4eb8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "lr_list = []\n",
    "best_loss = None\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0c84a7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1 / 10], train_loss=1.2145,train_acc=0.4836, val_loss=0.7439,val_acc=0.5425, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2 / 10], train_loss=0.8365,train_acc=0.5574, val_loss=0.6344,val_acc=0.6405, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3 / 10], train_loss=0.9568,train_acc=0.5738, val_loss=0.7445,val_acc=0.3987, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4 / 10], train_loss=0.7177,train_acc=0.4754, val_loss=0.7004,val_acc=0.4771, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5 / 10], train_loss=0.7035,train_acc=0.4508, val_loss=0.7053,val_acc=0.4575, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6 / 10], train_loss=0.7107,train_acc=0.5123, val_loss=0.7010,val_acc=0.4575, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7 / 10], train_loss=0.6936,train_acc=0.4713, val_loss=0.6661,val_acc=0.5752, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8 / 10], train_loss=0.6708,train_acc=0.6107, val_loss=0.6262,val_acc=0.6209, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9 / 10], train_loss=0.6315,train_acc=0.6639, val_loss=0.6642,val_acc=0.6667, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10 / 10], train_loss=0.8155,train_acc=0.6352, val_loss=0.6615,val_acc=0.5817, lr=0.0010\n",
      "Time of model training 10 epochs: 0m 58s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    \n",
    "    model_3.train()\n",
    "    running_train_loss = []\n",
    "    true_answer = 0\n",
    "    \n",
    "    train_loop = tqdm(train_loader, leave=False)\n",
    "    for x, targets in train_loop:\n",
    "        x = x.to(device)\n",
    "        targets = targets.reshape(-1).to(torch.int32)\n",
    "        targets = torch.eye(2)[targets].to(device)\n",
    "        \n",
    "        pred = model_3(x)\n",
    "        loss = loss_model_3(pred, targets)\n",
    "        \n",
    "        opt_3.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        opt_3.step()\n",
    "        \n",
    "        running_train_loss.append(loss.item())\n",
    "        mean_train_loss = sum(running_train_loss) / len(running_train_loss)\n",
    "        \n",
    "        true_answer += (pred.argmax(dim=1) == targets.argmax(dim=1)).sum().item()\n",
    "        train_loop.set_description(f'Epoch [{epoch} / {EPOCHS}], train_loss={mean_train_loss:.4f}')\n",
    "    \n",
    "    running_train_acc = true_answer / len(train_data)\n",
    "    \n",
    "    train_loss.append(mean_train_loss)\n",
    "    train_acc.append(running_train_acc)\n",
    "    \n",
    "    model_3.eval()\n",
    "    with torch.no_grad():\n",
    "        running_val_loss = []\n",
    "        true_answer = 0\n",
    "        \n",
    "        for x, targets in val_loader:\n",
    "            x = x.to(device)\n",
    "            targets = targets.reshape(-1).to(torch.int32)\n",
    "            targets = torch.eye(2)[targets].to(device)\n",
    "            \n",
    "            pred = model_3(x)\n",
    "            loss = loss_model_3(pred, targets)\n",
    "            \n",
    "            running_val_loss.append(loss.item())\n",
    "            mean_val_loss = sum(running_val_loss) / len(running_val_loss)\n",
    "            \n",
    "            true_answer += (pred.argmax(dim=1) == targets.argmax(dim=1)).sum().item()\n",
    "            \n",
    "        running_val_acc = true_answer / len(val_data)\n",
    "        \n",
    "        val_loss.append(mean_val_loss)\n",
    "        val_acc.append(running_val_acc)\n",
    "        \n",
    "        \n",
    "    \n",
    "    lr_scheduler_3.step(mean_val_loss)\n",
    "    lr = lr_scheduler_3._last_lr[0]\n",
    "    lr_list.append(lr)\n",
    "    \n",
    "#    if epoch == 1 or epoch % 5 == 0:\n",
    "    print(f'Epoch [{epoch} / {EPOCHS}], train_loss={mean_train_loss:.4f},'\n",
    "          f'train_acc={running_train_acc:.4f}, val_loss={mean_val_loss:.4f},'\n",
    "          f'val_acc={running_val_acc:.4f}, lr={lr:.4f}'\n",
    "          )\n",
    "time_model = time.time() - start\n",
    "print(f'Time of model training {EPOCHS} epochs: {time_model // 60:.0f}m {time_model % 60:.0f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604afe59",
   "metadata": {},
   "source": [
    "#### Option 2 (model pre-trained, no frozen pre-trained parameters, change all classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "52999b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Linear(in_features=25088, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4 = models.vgg11(weights='DEFAULT')\n",
    "model_4.classifier = nn.Linear(512*7*7, 2)\n",
    "model_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "11b037de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = model_4.to(device)\n",
    "\n",
    "loss_model_4 = nn.CrossEntropyLoss()\n",
    "opt_4 = torch.optim.Adam(model_4.parameters(), lr=0.001)\n",
    "lr_scheduler_4 = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_4, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9de096d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "lr_list = []\n",
    "best_loss = None\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "180ffeec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1 / 10], train_loss=1.0428,train_acc=0.4098, val_loss=0.7025,val_acc=0.4902, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2 / 10], train_loss=0.6954,train_acc=0.5451, val_loss=0.6927,val_acc=0.5359, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3 / 10], train_loss=0.6954,train_acc=0.4795, val_loss=0.6796,val_acc=0.5425, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4 / 10], train_loss=0.6897,train_acc=0.4959, val_loss=0.6843,val_acc=0.5425, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5 / 10], train_loss=0.6838,train_acc=0.5287, val_loss=0.6509,val_acc=0.5425, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6 / 10], train_loss=0.6674,train_acc=0.5615, val_loss=0.6326,val_acc=0.5425, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7 / 10], train_loss=0.6764,train_acc=0.5328, val_loss=0.6415,val_acc=0.6078, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8 / 10], train_loss=0.6751,train_acc=0.5861, val_loss=0.6470,val_acc=0.6601, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9 / 10], train_loss=0.6392,train_acc=0.5943, val_loss=1.4628,val_acc=0.4575, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10 / 10], train_loss=0.7054,train_acc=0.5779, val_loss=0.6248,val_acc=0.5621, lr=0.0010\n",
      "Time of model training 10 epochs: 0m 44s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    \n",
    "    model_4.train()\n",
    "    running_train_loss = []\n",
    "    true_answer = 0\n",
    "    \n",
    "    train_loop = tqdm(train_loader, leave=False)\n",
    "    for x, targets in train_loop:\n",
    "        x = x.to(device)\n",
    "        targets = targets.reshape(-1).to(torch.int32)\n",
    "        targets = torch.eye(2)[targets].to(device)\n",
    "        \n",
    "        pred = model_4(x)\n",
    "        loss = loss_model_4(pred, targets)\n",
    "        \n",
    "        opt_4.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        opt_4.step()\n",
    "        \n",
    "        running_train_loss.append(loss.item())\n",
    "        mean_train_loss = sum(running_train_loss) / len(running_train_loss)\n",
    "        \n",
    "        true_answer += (pred.argmax(dim=1) == targets.argmax(dim=1)).sum().item()\n",
    "        train_loop.set_description(f'Epoch [{epoch} / {EPOCHS}], train_loss={mean_train_loss:.4f}')\n",
    "    \n",
    "    running_train_acc = true_answer / len(train_data)\n",
    "    \n",
    "    train_loss.append(mean_train_loss)\n",
    "    train_acc.append(running_train_acc)\n",
    "    \n",
    "    model_4.eval()\n",
    "    with torch.no_grad():\n",
    "        running_val_loss = []\n",
    "        true_answer = 0\n",
    "        \n",
    "        for x, targets in val_loader:\n",
    "            x = x.to(device)\n",
    "            targets = targets.reshape(-1).to(torch.int32)\n",
    "            targets = torch.eye(2)[targets].to(device)\n",
    "            \n",
    "            pred = model_4(x)\n",
    "            loss = loss_model_4(pred, targets)\n",
    "            \n",
    "            running_val_loss.append(loss.item())\n",
    "            mean_val_loss = sum(running_val_loss) / len(running_val_loss)\n",
    "            \n",
    "            true_answer += (pred.argmax(dim=1) == targets.argmax(dim=1)).sum().item()\n",
    "            \n",
    "        running_val_acc = true_answer / len(val_data)\n",
    "        \n",
    "        val_loss.append(mean_val_loss)\n",
    "        val_acc.append(running_val_acc)\n",
    "        \n",
    "        \n",
    "    \n",
    "    lr_scheduler_4.step(mean_val_loss)\n",
    "    lr = lr_scheduler_4._last_lr[0]\n",
    "    lr_list.append(lr)\n",
    "    \n",
    "#    if epoch == 1 or epoch % 5 == 0:\n",
    "    print(f'Epoch [{epoch} / {EPOCHS}], train_loss={mean_train_loss:.4f},'\n",
    "          f'train_acc={running_train_acc:.4f}, val_loss={mean_val_loss:.4f},'\n",
    "          f'val_acc={running_val_acc:.4f}, lr={lr:.4f}'\n",
    "          )\n",
    "time_model = time.time() - start\n",
    "print(f'Time of model training {EPOCHS} epochs: {time_model // 60:.0f}m {time_model % 60:.0f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7abe1d",
   "metadata": {},
   "source": [
    "#### Option 3 (model pre-trained, frozen pre-trained parameters, change all classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9422350d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Linear(in_features=25088, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5 = models.vgg11(weights='DEFAULT')\n",
    "\n",
    "for param in model_5.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model_5.classifier = nn.Linear(512*7*7, 2)\n",
    "model_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7a155198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0\n",
      "    weights.requires_grad = False\n",
      "    bias.requires_grad = False\n",
      "\n",
      "features.3\n",
      "    weights.requires_grad = False\n",
      "    bias.requires_grad = False\n",
      "\n",
      "features.6\n",
      "    weights.requires_grad = False\n",
      "    bias.requires_grad = False\n",
      "\n",
      "features.8\n",
      "    weights.requires_grad = False\n",
      "    bias.requires_grad = False\n",
      "\n",
      "features.11\n",
      "    weights.requires_grad = False\n",
      "    bias.requires_grad = False\n",
      "\n",
      "features.13\n",
      "    weights.requires_grad = False\n",
      "    bias.requires_grad = False\n",
      "\n",
      "features.16\n",
      "    weights.requires_grad = False\n",
      "    bias.requires_grad = False\n",
      "\n",
      "features.18\n",
      "    weights.requires_grad = False\n",
      "    bias.requires_grad = False\n",
      "\n",
      "classifier\n",
      "    weights.requires_grad = True\n",
      "    bias.requires_grad = True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, layer in model_5.named_modules():\n",
    "    if isinstance(layer, (nn.Conv2d, nn.Linear)):\n",
    "        print(name)\n",
    "        for i, param in enumerate(layer.parameters()):\n",
    "            if i == 0:\n",
    "                print(f'    weights.requires_grad = {param.requires_grad}')\n",
    "            else:\n",
    "                print(f'    bias.requires_grad = {param.requires_grad}', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7d1fd999",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = model_5.to(device)\n",
    "\n",
    "loss_model_5 = nn.CrossEntropyLoss()\n",
    "opt_5 = torch.optim.Adam(model_5.classifier.parameters(), lr=0.001)\n",
    "lr_scheduler_5 = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_5, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a456ab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "lr_list = []\n",
    "best_loss = None\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "08a7bcf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1 / 10], train_loss=0.5447,train_acc=0.8197, val_loss=0.5968,val_acc=0.9150, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2 / 10], train_loss=0.2827,train_acc=0.9303, val_loss=0.6538,val_acc=0.9216, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3 / 10], train_loss=0.2485,train_acc=0.9549, val_loss=0.5857,val_acc=0.9085, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4 / 10], train_loss=0.2861,train_acc=0.9139, val_loss=1.1071,val_acc=0.8954, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5 / 10], train_loss=0.1329,train_acc=0.9467, val_loss=0.7886,val_acc=0.9216, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6 / 10], train_loss=0.0462,train_acc=0.9877, val_loss=0.6676,val_acc=0.9281, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7 / 10], train_loss=0.1124,train_acc=0.9836, val_loss=0.8134,val_acc=0.9216, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8 / 10], train_loss=0.0265,train_acc=0.9877, val_loss=0.7006,val_acc=0.9150, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9 / 10], train_loss=0.0211,train_acc=0.9959, val_loss=0.7063,val_acc=0.9281, lr=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10 / 10], train_loss=0.0244,train_acc=0.9795, val_loss=0.7154,val_acc=0.9150, lr=0.0001\n",
      "Time of model training 10 epochs: 0m 25s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    \n",
    "    model_5.train()\n",
    "    running_train_loss = []\n",
    "    true_answer = 0\n",
    "    \n",
    "    train_loop = tqdm(train_loader, leave=False)\n",
    "    for x, targets in train_loop:\n",
    "        x = x.to(device)\n",
    "        targets = targets.reshape(-1).to(torch.int32)\n",
    "        targets = torch.eye(2)[targets].to(device)\n",
    "        \n",
    "        pred = model_5(x)\n",
    "        loss = loss_model_5(pred, targets)\n",
    "        \n",
    "        opt_5.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        opt_5.step()\n",
    "        \n",
    "        running_train_loss.append(loss.item())\n",
    "        mean_train_loss = sum(running_train_loss) / len(running_train_loss)\n",
    "        \n",
    "        true_answer += (pred.argmax(dim=1) == targets.argmax(dim=1)).sum().item()\n",
    "        train_loop.set_description(f'Epoch [{epoch} / {EPOCHS}], train_loss={mean_train_loss:.4f}')\n",
    "    \n",
    "    running_train_acc = true_answer / len(train_data)\n",
    "    \n",
    "    train_loss.append(mean_train_loss)\n",
    "    train_acc.append(running_train_acc)\n",
    "    \n",
    "    model_5.eval()\n",
    "    with torch.no_grad():\n",
    "        running_val_loss = []\n",
    "        true_answer = 0\n",
    "        \n",
    "        for x, targets in val_loader:\n",
    "            x = x.to(device)\n",
    "            targets = targets.reshape(-1).to(torch.int32)\n",
    "            targets = torch.eye(2)[targets].to(device)\n",
    "            \n",
    "            pred = model_5(x)\n",
    "            loss = loss_model_5(pred, targets)\n",
    "            \n",
    "            running_val_loss.append(loss.item())\n",
    "            mean_val_loss = sum(running_val_loss) / len(running_val_loss)\n",
    "            \n",
    "            true_answer += (pred.argmax(dim=1) == targets.argmax(dim=1)).sum().item()\n",
    "            \n",
    "        running_val_acc = true_answer / len(val_data)\n",
    "        \n",
    "        val_loss.append(mean_val_loss)\n",
    "        val_acc.append(running_val_acc)\n",
    "        \n",
    "        \n",
    "    \n",
    "    lr_scheduler_5.step(mean_val_loss)\n",
    "    lr = lr_scheduler_5._last_lr[0]\n",
    "    lr_list.append(lr)\n",
    "    \n",
    "#    if epoch == 1 or epoch % 5 == 0:\n",
    "    print(f'Epoch [{epoch} / {EPOCHS}], train_loss={mean_train_loss:.4f},'\n",
    "          f'train_acc={running_train_acc:.4f}, val_loss={mean_val_loss:.4f},'\n",
    "          f'val_acc={running_val_acc:.4f}, lr={lr:.4f}'\n",
    "          )\n",
    "time_model = time.time() - start\n",
    "print(f'Time of model training {EPOCHS} epochs: {time_model // 60:.0f}m {time_model % 60:.0f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee718c6",
   "metadata": {},
   "source": [
    "####  Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ff557535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (14): ReLU(inplace=True)\n",
       "  (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (17): ReLU(inplace=True)\n",
       "  (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (19): ReLU(inplace=True)\n",
       "  (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5.features[13:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c4e5e716",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model_5.features[13:].parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "85228ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0\n",
      "    weights.requires_grad = False\n",
      "    bias.requires_grad = False\n",
      "\n",
      "features.3\n",
      "    weights.requires_grad = False\n",
      "    bias.requires_grad = False\n",
      "\n",
      "features.6\n",
      "    weights.requires_grad = False\n",
      "    bias.requires_grad = False\n",
      "\n",
      "features.8\n",
      "    weights.requires_grad = False\n",
      "    bias.requires_grad = False\n",
      "\n",
      "features.11\n",
      "    weights.requires_grad = False\n",
      "    bias.requires_grad = False\n",
      "\n",
      "features.13\n",
      "    weights.requires_grad = True\n",
      "    bias.requires_grad = True\n",
      "\n",
      "features.16\n",
      "    weights.requires_grad = True\n",
      "    bias.requires_grad = True\n",
      "\n",
      "features.18\n",
      "    weights.requires_grad = True\n",
      "    bias.requires_grad = True\n",
      "\n",
      "classifier\n",
      "    weights.requires_grad = True\n",
      "    bias.requires_grad = True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, layer in model_5.named_modules():\n",
    "    if isinstance(layer, (nn.Conv2d, nn.Linear)):\n",
    "        print(name)\n",
    "        for i, param in enumerate(layer.parameters()):\n",
    "            if i == 0:\n",
    "                print(f'    weights.requires_grad = {param.requires_grad}')\n",
    "            else:\n",
    "                print(f'    bias.requires_grad = {param.requires_grad}', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "74c6458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = model_5.to(device)\n",
    "\n",
    "loss_model_5 = nn.CrossEntropyLoss()\n",
    "opt_5 = torch.optim.Adam(\n",
    "    [\n",
    "        {'params': model_5.features[13:].parameters(), 'lr': 0.000001},\n",
    "        {'params': model_5.classifier.parameters()},\n",
    "    ],\n",
    "    lr=0.0001\n",
    ")\n",
    "lr_scheduler_5 = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_5, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c8ec8258",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1 / 10], train_loss=0.0485,train_acc=0.9836, val_loss=0.7463,val_acc=0.9216, lr=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2 / 10], train_loss=0.0209,train_acc=0.9918, val_loss=0.6431,val_acc=0.9216, lr=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3 / 10], train_loss=0.0034,train_acc=1.0000, val_loss=0.6834,val_acc=0.9412, lr=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4 / 10], train_loss=0.0056,train_acc=1.0000, val_loss=0.6421,val_acc=0.9281, lr=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5 / 10], train_loss=0.0088,train_acc=1.0000, val_loss=0.7654,val_acc=0.9150, lr=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6 / 10], train_loss=0.0040,train_acc=0.9959, val_loss=0.6987,val_acc=0.9281, lr=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7 / 10], train_loss=0.0029,train_acc=1.0000, val_loss=0.7642,val_acc=0.9346, lr=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8 / 10], train_loss=0.0084,train_acc=0.9959, val_loss=0.8380,val_acc=0.9216, lr=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9 / 10], train_loss=0.0062,train_acc=0.9959, val_loss=0.6270,val_acc=0.9477, lr=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10 / 10], train_loss=0.0019,train_acc=1.0000, val_loss=0.7194,val_acc=0.9412, lr=0.0000\n",
      "Time of model training 10 epochs: 0m 30s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    \n",
    "    model_5.train()\n",
    "    running_train_loss = []\n",
    "    true_answer = 0\n",
    "    \n",
    "    train_loop = tqdm(train_loader, leave=False)\n",
    "    for x, targets in train_loop:\n",
    "        x = x.to(device)\n",
    "        targets = targets.reshape(-1).to(torch.int32)\n",
    "        targets = torch.eye(2)[targets].to(device)\n",
    "        \n",
    "        pred = model_5(x)\n",
    "        loss = loss_model_5(pred, targets)\n",
    "        \n",
    "        opt_5.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        opt_5.step()\n",
    "        \n",
    "        running_train_loss.append(loss.item())\n",
    "        mean_train_loss = sum(running_train_loss) / len(running_train_loss)\n",
    "        \n",
    "        true_answer += (pred.argmax(dim=1) == targets.argmax(dim=1)).sum().item()\n",
    "        train_loop.set_description(f'Epoch [{epoch} / {EPOCHS}], train_loss={mean_train_loss:.4f}')\n",
    "    \n",
    "    running_train_acc = true_answer / len(train_data)\n",
    "    \n",
    "    train_loss.append(mean_train_loss)\n",
    "    train_acc.append(running_train_acc)\n",
    "    \n",
    "    model_5.eval()\n",
    "    with torch.no_grad():\n",
    "        running_val_loss = []\n",
    "        true_answer = 0\n",
    "        \n",
    "        for x, targets in val_loader:\n",
    "            x = x.to(device)\n",
    "            targets = targets.reshape(-1).to(torch.int32)\n",
    "            targets = torch.eye(2)[targets].to(device)\n",
    "            \n",
    "            pred = model_5(x)\n",
    "            loss = loss_model_5(pred, targets)\n",
    "            \n",
    "            running_val_loss.append(loss.item())\n",
    "            mean_val_loss = sum(running_val_loss) / len(running_val_loss)\n",
    "            \n",
    "            true_answer += (pred.argmax(dim=1) == targets.argmax(dim=1)).sum().item()\n",
    "            \n",
    "        running_val_acc = true_answer / len(val_data)\n",
    "        \n",
    "        val_loss.append(mean_val_loss)\n",
    "        val_acc.append(running_val_acc)\n",
    "        \n",
    "        \n",
    "    \n",
    "    lr_scheduler_5.step(mean_val_loss)\n",
    "    lr = lr_scheduler_5._last_lr[0]\n",
    "    lr_list.append(lr)\n",
    "    \n",
    "#    if epoch == 1 or epoch % 5 == 0:\n",
    "    print(f'Epoch [{epoch} / {EPOCHS}], train_loss={mean_train_loss:.4f},'\n",
    "          f'train_acc={running_train_acc:.4f}, val_loss={mean_val_loss:.4f},'\n",
    "          f'val_acc={running_val_acc:.4f}, lr={lr:.4f}'\n",
    "          )\n",
    "time_model = time.time() - start\n",
    "print(f'Time of model training {EPOCHS} epochs: {time_model // 60:.0f}m {time_model % 60:.0f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40576f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Transfer Learning",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "685px",
    "left": "24px",
    "top": "110px",
    "width": "302.390625px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
