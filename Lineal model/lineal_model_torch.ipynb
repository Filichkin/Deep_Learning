{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcc0b751",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Цикл-обучения\" data-toc-modified-id=\"Цикл-обучения-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Цикл обучения</a></span></li><li><span><a href=\"#Нормализация-входных-параметров\" data-toc-modified-id=\"Нормализация-входных-параметров-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Нормализация входных параметров</a></span></li><li><span><a href=\"#Использование-autograd\" data-toc-modified-id=\"Использование-autograd-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Использование autograd</a></span></li><li><span><a href=\"#Оптимизатор-на-основе-градиентного-спуска\" data-toc-modified-id=\"Оптимизатор-на-основе-градиентного-спуска-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Оптимизатор на основе градиентного спуска</a></span></li><li><span><a href=\"#Разбиение-набора-данных\" data-toc-modified-id=\"Разбиение-набора-данных-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Разбиение набора данных</a></span></li><li><span><a href=\"#Упражнение\" data-toc-modified-id=\"Упражнение-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Упражнение</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d1d0a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ea9dfbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_c = [0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, 4.0, 6.0, 13.0, 21.0]\n",
    "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "17b2a0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_c = torch.tensor(t_c) # температура в градусах по цельсию\n",
    "t_u = torch.tensor(t_u) # температура в неизвестных величинах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "431d6fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(t_u, w, b):\n",
    "    return w * t_u + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50c742b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(t_p, t_c):\n",
    "    squared_diffs = (t_p - t_c)**2\n",
    "    return squared_diffs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fb27e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.ones(())\n",
    "b = torch.zeros(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "756da67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([35.7000, 55.9000, 58.2000, 81.9000, 56.3000, 48.9000, 33.9000, 21.8000,\n",
       "        48.4000, 60.4000, 68.4000])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_p = model(t_u, w, b)\n",
    "t_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ace3f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1732.1757)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = loss_fn(t_p, t_c)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29095381",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(())\n",
    "y = torch.ones(3, 1)\n",
    "z = torch.ones(1, 3)\n",
    "a = torch.ones(2, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50b9a5cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.]],\n",
       "\n",
       "        [[1.]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f86f21f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes: x: torch.Size([]), y: torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "print(f'shapes: x: {x.shape}, y: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "becc1e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z: torch.Size([1, 3]), a: torch.Size([2, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(f'z: {z.shape}, a: {a.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e62d2a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x * y: torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "print('x * y:', (x * y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee92f3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y * z: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "print('y * z:', (y * z).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a127caaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y * z * a: torch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print('y * z * a:', (y * z * a).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0170e819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y * z * a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cbf3d0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 0.1\n",
    "loss_rate_of_change_w = \\\n",
    "    (loss_fn(model(t_u, w + delta, b), t_c) -\n",
    "     loss_fn(model(t_u, w - delta, b), t_c)) / (2.0 * delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de2c3fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4485.5889)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_rate_of_change_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4464597d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "27f57938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(44.8559)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate * loss_rate_of_change_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "528ff0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-2\n",
    "w = w - learning_rate * loss_rate_of_change_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3b0d4845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-43.8559)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "175e466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_rate_of_change_b = \\\n",
    "    (loss_fn(model(t_u, w, b + delta), t_c) -\n",
    "     loss_fn(model(t_u, w, b - delta), t_c)) / (2.0 * delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "53cd95ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-4570.)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_rate_of_change_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e182d906",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = b - learning_rate * loss_rate_of_change_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ed4175af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(45.7000)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a643d144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_p.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4bd5829b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# производная функции потерь\n",
    "def dloss_fn(t_p, t_c):\n",
    "    dsq_diffs = 2 * (t_p - t_c) / t_p.size(0)\n",
    "    return dsq_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "317beea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dmodel_dw(t_u, w, b):\n",
    "    return t_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "561cb5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dmodel_db(t_u, w, b):\n",
    "    return 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "860b4e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# обратный проход\n",
    "def grad_fn(t_u, t_c, t_p, w, b):\n",
    "    dloss_dtp = dloss_fn(t_p, t_c)\n",
    "    dloss_dw = dloss_dtp * dmodel_dw(t_u, w, b)\n",
    "    dloss_db = dloss_dtp * dmodel_db(t_u, w, b)\n",
    "    return torch.stack([dloss_dw.sum(), dloss_db.sum()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a30b65",
   "metadata": {},
   "source": [
    "### Цикл обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "63c66182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, learning_rate, params, t_u, t_c):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        w, b = params\n",
    "        t_p = model(t_u, w, b) # прямой проход \n",
    "        loss = loss_fn(t_p, t_c) \n",
    "        grad = grad_fn(t_u, t_c, t_p, w, b) # обратный проход\n",
    "        params = params - learning_rate * grad\n",
    "        print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "        print('Params:', params)\n",
    "        print('Grad:  ', grad)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f801c65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 1732.175659\n",
      "Params: tensor([-43.8559,  -0.8115])\n",
      "Grad:   tensor([4485.5874,   81.1455])\n",
      "Epoch 2, Loss 5721265.000000\n",
      "Params: tensor([2550.3701,   44.8640])\n",
      "Grad:   tensor([-259422.6094,   -4567.5464])\n",
      "Epoch 3, Loss 19136387072.000000\n",
      "Params: tensor([-147484.6094,   -2597.9922])\n",
      "Grad:   tensor([15003499.0000,   264285.6250])\n",
      "Epoch 4, Loss 64007297826816.000000\n",
      "Params: tensor([8529670.0000,  150248.2188])\n",
      "Grad:   tensor([-8.6772e+08, -1.5285e+07])\n",
      "Epoch 5, Loss 214091389422534656.000000\n",
      "Params: tensor([-4.9331e+08, -8.6895e+06])\n",
      "Grad:   tensor([5.0184e+10, 8.8397e+08])\n",
      "Epoch 6, Loss 716091973631534432256.000000\n",
      "Params: tensor([2.8530e+10, 5.0255e+08])\n",
      "Grad:   tensor([-2.9023e+12, -5.1124e+10])\n",
      "Epoch 7, Loss 2395181887799361993179136.000000\n",
      "Params: tensor([-1.6500e+12, -2.9065e+10])\n",
      "Grad:   tensor([1.6785e+14, 2.9567e+12])\n",
      "Epoch 8, Loss 8011396158788023201191428096.000000\n",
      "Params: tensor([9.5427e+13, 1.6809e+12])\n",
      "Grad:   tensor([-9.7077e+15, -1.7100e+14])\n",
      "Epoch 9, Loss 26796486358145929869341684137984.000000\n",
      "Params: tensor([-5.5189e+15, -9.7215e+13])\n",
      "Grad:   tensor([5.6144e+17, 9.8896e+15])\n",
      "Epoch 10, Loss 89628780127202502812883237258395648.000000\n",
      "Params: tensor([3.1918e+17, 5.6224e+15])\n",
      "Grad:   tensor([-3.2470e+19, -5.7196e+17])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([3.1918e+17, 5.6224e+15])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(n_epochs = 10,\n",
    "              learning_rate = 1e-2,\n",
    "              params = torch.tensor([1.0, 0.0]),\n",
    "              t_u = t_u,\n",
    "              t_c = t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d5b9206a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 1732.175659\n",
      "Params: tensor([ 0.5514, -0.0081])\n",
      "Grad:   tensor([4485.5874,   81.1455])\n",
      "Epoch 2, Loss 311.548065\n",
      "Params: tensor([ 0.3668, -0.0116])\n",
      "Grad:   tensor([1846.5056,   34.6586])\n",
      "Epoch 3, Loss 70.804909\n",
      "Params: tensor([ 0.2908, -0.0131])\n",
      "Grad:   tensor([760.1066,  15.5218])\n",
      "Epoch 4, Loss 30.007658\n",
      "Params: tensor([ 0.2595, -0.0139])\n",
      "Grad:   tensor([312.8818,   7.6440])\n",
      "Epoch 5, Loss 23.093687\n",
      "Params: tensor([ 0.2466, -0.0143])\n",
      "Grad:   tensor([128.7781,   4.4010])\n",
      "Epoch 6, Loss 21.921654\n",
      "Params: tensor([ 0.2413, -0.0146])\n",
      "Grad:   tensor([52.9904,  3.0660])\n",
      "Epoch 7, Loss 21.722664\n",
      "Params: tensor([ 0.2391, -0.0149])\n",
      "Grad:   tensor([21.7918,  2.5164])\n",
      "Epoch 8, Loss 21.688560\n",
      "Params: tensor([ 0.2382, -0.0151])\n",
      "Grad:   tensor([8.9488, 2.2901])\n",
      "Epoch 9, Loss 21.682405\n",
      "Params: tensor([ 0.2379, -0.0153])\n",
      "Grad:   tensor([3.6617, 2.1970])\n",
      "Epoch 10, Loss 21.680990\n",
      "Params: tensor([ 0.2377, -0.0156])\n",
      "Grad:   tensor([1.4853, 2.1586])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2377, -0.0156])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(n_epochs = 10,\n",
    "              learning_rate = 1e-4,\n",
    "              params = torch.tensor([1.0, 0.0]),\n",
    "              t_u = t_u,\n",
    "              t_c = t_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f7c3e0",
   "metadata": {},
   "source": [
    "### Нормализация входных параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1e1f44d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_un = t_u * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "56028c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 77.193428\n",
      "Params: tensor([1.8078, 0.1209])\n",
      "Grad:   tensor([-80.7850, -12.0945])\n",
      "Epoch 2, Loss 30.687700\n",
      "Params: tensor([2.1280, 0.1558])\n",
      "Grad:   tensor([-32.0175,  -3.4833])\n",
      "Epoch 3, Loss 23.446587\n",
      "Params: tensor([2.2563, 0.1567])\n",
      "Grad:   tensor([-12.8252,  -0.0967])\n",
      "Epoch 4, Loss 22.286634\n",
      "Params: tensor([2.3090, 0.1444])\n",
      "Grad:   tensor([-5.2719,  1.2340])\n",
      "Epoch 5, Loss 22.068619\n",
      "Params: tensor([2.3320, 0.1269])\n",
      "Grad:   tensor([-2.2990,  1.7555])\n",
      "Epoch 6, Loss 21.996622\n",
      "Params: tensor([2.3433, 0.1073])\n",
      "Grad:   tensor([-1.1287,  1.9585])\n",
      "Epoch 7, Loss 21.947363\n",
      "Params: tensor([2.3500, 0.0869])\n",
      "Grad:   tensor([-0.6678,  2.0363])\n",
      "Epoch 8, Loss 21.901756\n",
      "Params: tensor([2.3548, 0.0663])\n",
      "Grad:   tensor([-0.4860,  2.0648])\n",
      "Epoch 9, Loss 21.856840\n",
      "Params: tensor([2.3590, 0.0455])\n",
      "Grad:   tensor([-0.4141,  2.0738])\n",
      "Epoch 10, Loss 21.812168\n",
      "Params: tensor([2.3628, 0.0248])\n",
      "Grad:   tensor([-0.3854,  2.0752])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([2.3628, 0.0248])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(n_epochs = 10,\n",
    "              learning_rate = 1e-2,\n",
    "              params = torch.tensor([1.0, 0.0]),\n",
    "              t_u = t_un,\n",
    "              t_c = t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a4aedbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 77.193428\n",
      "Params: tensor([1.8078, 0.1209])\n",
      "Grad:   tensor([-80.7850, -12.0945])\n",
      "Epoch 2, Loss 30.687700\n",
      "Params: tensor([2.1280, 0.1558])\n",
      "Grad:   tensor([-32.0175,  -3.4833])\n",
      "Epoch 3, Loss 23.446587\n",
      "Params: tensor([2.2563, 0.1567])\n",
      "Grad:   tensor([-12.8252,  -0.0967])\n",
      "Epoch 4, Loss 22.286634\n",
      "Params: tensor([2.3090, 0.1444])\n",
      "Grad:   tensor([-5.2719,  1.2340])\n",
      "Epoch 5, Loss 22.068619\n",
      "Params: tensor([2.3320, 0.1269])\n",
      "Grad:   tensor([-2.2990,  1.7555])\n",
      "Epoch 6, Loss 21.996622\n",
      "Params: tensor([2.3433, 0.1073])\n",
      "Grad:   tensor([-1.1287,  1.9585])\n",
      "Epoch 7, Loss 21.947363\n",
      "Params: tensor([2.3500, 0.0869])\n",
      "Grad:   tensor([-0.6678,  2.0363])\n",
      "Epoch 8, Loss 21.901756\n",
      "Params: tensor([2.3548, 0.0663])\n",
      "Grad:   tensor([-0.4860,  2.0648])\n",
      "Epoch 9, Loss 21.856840\n",
      "Params: tensor([2.3590, 0.0455])\n",
      "Grad:   tensor([-0.4141,  2.0738])\n",
      "Epoch 10, Loss 21.812168\n",
      "Params: tensor([2.3628, 0.0248])\n",
      "Grad:   tensor([-0.3854,  2.0752])\n",
      "Epoch 11, Loss 21.767653\n",
      "Params: tensor([2.3665, 0.0040])\n",
      "Grad:   tensor([-0.3737,  2.0736])\n",
      "Epoch 12, Loss 21.723295\n",
      "Params: tensor([ 2.3702, -0.0167])\n",
      "Grad:   tensor([-0.3687,  2.0709])\n",
      "Epoch 13, Loss 21.679087\n",
      "Params: tensor([ 2.3739, -0.0374])\n",
      "Grad:   tensor([-0.3664,  2.0677])\n",
      "Epoch 14, Loss 21.635029\n",
      "Params: tensor([ 2.3775, -0.0580])\n",
      "Grad:   tensor([-0.3651,  2.0643])\n",
      "Epoch 15, Loss 21.591125\n",
      "Params: tensor([ 2.3812, -0.0786])\n",
      "Grad:   tensor([-0.3642,  2.0608])\n",
      "Epoch 16, Loss 21.547365\n",
      "Params: tensor([ 2.3848, -0.0992])\n",
      "Grad:   tensor([-0.3635,  2.0573])\n",
      "Epoch 17, Loss 21.503756\n",
      "Params: tensor([ 2.3884, -0.1197])\n",
      "Grad:   tensor([-0.3629,  2.0538])\n",
      "Epoch 18, Loss 21.460295\n",
      "Params: tensor([ 2.3921, -0.1402])\n",
      "Grad:   tensor([-0.3622,  2.0504])\n",
      "Epoch 19, Loss 21.416977\n",
      "Params: tensor([ 2.3957, -0.1607])\n",
      "Grad:   tensor([-0.3616,  2.0469])\n",
      "Epoch 20, Loss 21.373812\n",
      "Params: tensor([ 2.3993, -0.1811])\n",
      "Grad:   tensor([-0.3610,  2.0434])\n",
      "Epoch 21, Loss 21.330788\n",
      "Params: tensor([ 2.4029, -0.2015])\n",
      "Grad:   tensor([-0.3604,  2.0399])\n",
      "Epoch 22, Loss 21.287910\n",
      "Params: tensor([ 2.4065, -0.2219])\n",
      "Grad:   tensor([-0.3598,  2.0365])\n",
      "Epoch 23, Loss 21.245180\n",
      "Params: tensor([ 2.4101, -0.2422])\n",
      "Grad:   tensor([-0.3591,  2.0330])\n",
      "Epoch 24, Loss 21.202597\n",
      "Params: tensor([ 2.4137, -0.2625])\n",
      "Grad:   tensor([-0.3585,  2.0296])\n",
      "Epoch 25, Loss 21.160164\n",
      "Params: tensor([ 2.4173, -0.2828])\n",
      "Grad:   tensor([-0.3579,  2.0261])\n",
      "Epoch 26, Loss 21.117859\n",
      "Params: tensor([ 2.4208, -0.3030])\n",
      "Grad:   tensor([-0.3573,  2.0227])\n",
      "Epoch 27, Loss 21.075706\n",
      "Params: tensor([ 2.4244, -0.3232])\n",
      "Grad:   tensor([-0.3567,  2.0192])\n",
      "Epoch 28, Loss 21.033697\n",
      "Params: tensor([ 2.4280, -0.3434])\n",
      "Grad:   tensor([-0.3561,  2.0158])\n",
      "Epoch 29, Loss 20.991831\n",
      "Params: tensor([ 2.4315, -0.3635])\n",
      "Grad:   tensor([-0.3555,  2.0124])\n",
      "Epoch 30, Loss 20.950109\n",
      "Params: tensor([ 2.4351, -0.3836])\n",
      "Grad:   tensor([-0.3549,  2.0090])\n",
      "Epoch 31, Loss 20.908525\n",
      "Params: tensor([ 2.4386, -0.4036])\n",
      "Grad:   tensor([-0.3543,  2.0055])\n",
      "Epoch 32, Loss 20.867085\n",
      "Params: tensor([ 2.4421, -0.4236])\n",
      "Grad:   tensor([-0.3537,  2.0021])\n",
      "Epoch 33, Loss 20.825783\n",
      "Params: tensor([ 2.4457, -0.4436])\n",
      "Grad:   tensor([-0.3531,  1.9987])\n",
      "Epoch 34, Loss 20.784624\n",
      "Params: tensor([ 2.4492, -0.4636])\n",
      "Grad:   tensor([-0.3525,  1.9953])\n",
      "Epoch 35, Loss 20.743599\n",
      "Params: tensor([ 2.4527, -0.4835])\n",
      "Grad:   tensor([-0.3519,  1.9919])\n",
      "Epoch 36, Loss 20.702721\n",
      "Params: tensor([ 2.4562, -0.5034])\n",
      "Grad:   tensor([-0.3513,  1.9886])\n",
      "Epoch 37, Loss 20.661974\n",
      "Params: tensor([ 2.4597, -0.5232])\n",
      "Grad:   tensor([-0.3507,  1.9852])\n",
      "Epoch 38, Loss 20.621372\n",
      "Params: tensor([ 2.4632, -0.5431])\n",
      "Grad:   tensor([-0.3501,  1.9818])\n",
      "Epoch 39, Loss 20.580902\n",
      "Params: tensor([ 2.4667, -0.5628])\n",
      "Grad:   tensor([-0.3495,  1.9784])\n",
      "Epoch 40, Loss 20.540575\n",
      "Params: tensor([ 2.4702, -0.5826])\n",
      "Grad:   tensor([-0.3489,  1.9751])\n",
      "Epoch 41, Loss 20.500380\n",
      "Params: tensor([ 2.4737, -0.6023])\n",
      "Grad:   tensor([-0.3483,  1.9717])\n",
      "Epoch 42, Loss 20.460327\n",
      "Params: tensor([ 2.4772, -0.6220])\n",
      "Grad:   tensor([-0.3477,  1.9684])\n",
      "Epoch 43, Loss 20.420410\n",
      "Params: tensor([ 2.4806, -0.6416])\n",
      "Grad:   tensor([-0.3471,  1.9650])\n",
      "Epoch 44, Loss 20.380623\n",
      "Params: tensor([ 2.4841, -0.6613])\n",
      "Grad:   tensor([-0.3465,  1.9617])\n",
      "Epoch 45, Loss 20.340971\n",
      "Params: tensor([ 2.4876, -0.6808])\n",
      "Grad:   tensor([-0.3459,  1.9584])\n",
      "Epoch 46, Loss 20.301453\n",
      "Params: tensor([ 2.4910, -0.7004])\n",
      "Grad:   tensor([-0.3454,  1.9550])\n",
      "Epoch 47, Loss 20.262072\n",
      "Params: tensor([ 2.4945, -0.7199])\n",
      "Grad:   tensor([-0.3448,  1.9517])\n",
      "Epoch 48, Loss 20.222826\n",
      "Params: tensor([ 2.4979, -0.7394])\n",
      "Grad:   tensor([-0.3442,  1.9484])\n",
      "Epoch 49, Loss 20.183710\n",
      "Params: tensor([ 2.5014, -0.7588])\n",
      "Grad:   tensor([-0.3436,  1.9451])\n",
      "Epoch 50, Loss 20.144735\n",
      "Params: tensor([ 2.5048, -0.7783])\n",
      "Grad:   tensor([-0.3430,  1.9418])\n",
      "Epoch 51, Loss 20.105883\n",
      "Params: tensor([ 2.5082, -0.7977])\n",
      "Grad:   tensor([-0.3424,  1.9385])\n",
      "Epoch 52, Loss 20.067167\n",
      "Params: tensor([ 2.5116, -0.8170])\n",
      "Grad:   tensor([-0.3419,  1.9352])\n",
      "Epoch 53, Loss 20.028578\n",
      "Params: tensor([ 2.5150, -0.8363])\n",
      "Grad:   tensor([-0.3413,  1.9319])\n",
      "Epoch 54, Loss 19.990126\n",
      "Params: tensor([ 2.5184, -0.8556])\n",
      "Grad:   tensor([-0.3407,  1.9286])\n",
      "Epoch 55, Loss 19.951799\n",
      "Params: tensor([ 2.5218, -0.8749])\n",
      "Grad:   tensor([-0.3401,  1.9253])\n",
      "Epoch 56, Loss 19.913609\n",
      "Params: tensor([ 2.5252, -0.8941])\n",
      "Grad:   tensor([-0.3395,  1.9221])\n",
      "Epoch 57, Loss 19.875542\n",
      "Params: tensor([ 2.5286, -0.9133])\n",
      "Grad:   tensor([-0.3390,  1.9188])\n",
      "Epoch 58, Loss 19.837605\n",
      "Params: tensor([ 2.5320, -0.9324])\n",
      "Grad:   tensor([-0.3384,  1.9156])\n",
      "Epoch 59, Loss 19.799801\n",
      "Params: tensor([ 2.5354, -0.9515])\n",
      "Grad:   tensor([-0.3378,  1.9123])\n",
      "Epoch 60, Loss 19.762123\n",
      "Params: tensor([ 2.5388, -0.9706])\n",
      "Grad:   tensor([-0.3372,  1.9091])\n",
      "Epoch 61, Loss 19.724575\n",
      "Params: tensor([ 2.5421, -0.9897])\n",
      "Grad:   tensor([-0.3367,  1.9058])\n",
      "Epoch 62, Loss 19.687147\n",
      "Params: tensor([ 2.5455, -1.0087])\n",
      "Grad:   tensor([-0.3361,  1.9026])\n",
      "Epoch 63, Loss 19.649855\n",
      "Params: tensor([ 2.5489, -1.0277])\n",
      "Grad:   tensor([-0.3355,  1.8993])\n",
      "Epoch 64, Loss 19.612684\n",
      "Params: tensor([ 2.5522, -1.0467])\n",
      "Grad:   tensor([-0.3350,  1.8961])\n",
      "Epoch 65, Loss 19.575645\n",
      "Params: tensor([ 2.5555, -1.0656])\n",
      "Grad:   tensor([-0.3344,  1.8929])\n",
      "Epoch 66, Loss 19.538723\n",
      "Params: tensor([ 2.5589, -1.0845])\n",
      "Grad:   tensor([-0.3338,  1.8897])\n",
      "Epoch 67, Loss 19.501932\n",
      "Params: tensor([ 2.5622, -1.1034])\n",
      "Grad:   tensor([-0.3333,  1.8865])\n",
      "Epoch 68, Loss 19.465265\n",
      "Params: tensor([ 2.5655, -1.1222])\n",
      "Grad:   tensor([-0.3327,  1.8833])\n",
      "Epoch 69, Loss 19.428728\n",
      "Params: tensor([ 2.5689, -1.1410])\n",
      "Grad:   tensor([-0.3321,  1.8801])\n",
      "Epoch 70, Loss 19.392309\n",
      "Params: tensor([ 2.5722, -1.1598])\n",
      "Grad:   tensor([-0.3315,  1.8769])\n",
      "Epoch 71, Loss 19.356010\n",
      "Params: tensor([ 2.5755, -1.1785])\n",
      "Grad:   tensor([-0.3310,  1.8737])\n",
      "Epoch 72, Loss 19.319839\n",
      "Params: tensor([ 2.5788, -1.1972])\n",
      "Grad:   tensor([-0.3304,  1.8705])\n",
      "Epoch 73, Loss 19.283792\n",
      "Params: tensor([ 2.5821, -1.2159])\n",
      "Grad:   tensor([-0.3299,  1.8673])\n",
      "Epoch 74, Loss 19.247864\n",
      "Params: tensor([ 2.5854, -1.2345])\n",
      "Grad:   tensor([-0.3293,  1.8641])\n",
      "Epoch 75, Loss 19.212063\n",
      "Params: tensor([ 2.5887, -1.2531])\n",
      "Grad:   tensor([-0.3287,  1.8610])\n",
      "Epoch 76, Loss 19.176378\n",
      "Params: tensor([ 2.5920, -1.2717])\n",
      "Grad:   tensor([-0.3282,  1.8578])\n",
      "Epoch 77, Loss 19.140818\n",
      "Params: tensor([ 2.5952, -1.2903])\n",
      "Grad:   tensor([-0.3276,  1.8547])\n",
      "Epoch 78, Loss 19.105375\n",
      "Params: tensor([ 2.5985, -1.3088])\n",
      "Grad:   tensor([-0.3271,  1.8515])\n",
      "Epoch 79, Loss 19.070053\n",
      "Params: tensor([ 2.6018, -1.3273])\n",
      "Grad:   tensor([-0.3265,  1.8484])\n",
      "Epoch 80, Loss 19.034855\n",
      "Params: tensor([ 2.6050, -1.3457])\n",
      "Grad:   tensor([-0.3260,  1.8452])\n",
      "Epoch 81, Loss 18.999773\n",
      "Params: tensor([ 2.6083, -1.3641])\n",
      "Grad:   tensor([-0.3254,  1.8421])\n",
      "Epoch 82, Loss 18.964808\n",
      "Params: tensor([ 2.6115, -1.3825])\n",
      "Grad:   tensor([-0.3249,  1.8390])\n",
      "Epoch 83, Loss 18.929966\n",
      "Params: tensor([ 2.6148, -1.4009])\n",
      "Grad:   tensor([-0.3243,  1.8358])\n",
      "Epoch 84, Loss 18.895241\n",
      "Params: tensor([ 2.6180, -1.4192])\n",
      "Grad:   tensor([-0.3238,  1.8327])\n",
      "Epoch 85, Loss 18.860636\n",
      "Params: tensor([ 2.6212, -1.4375])\n",
      "Grad:   tensor([-0.3232,  1.8296])\n",
      "Epoch 86, Loss 18.826141\n",
      "Params: tensor([ 2.6245, -1.4558])\n",
      "Grad:   tensor([-0.3227,  1.8265])\n",
      "Epoch 87, Loss 18.791773\n",
      "Params: tensor([ 2.6277, -1.4740])\n",
      "Grad:   tensor([-0.3221,  1.8234])\n",
      "Epoch 88, Loss 18.757515\n",
      "Params: tensor([ 2.6309, -1.4922])\n",
      "Grad:   tensor([-0.3216,  1.8203])\n",
      "Epoch 89, Loss 18.723375\n",
      "Params: tensor([ 2.6341, -1.5104])\n",
      "Grad:   tensor([-0.3210,  1.8172])\n",
      "Epoch 90, Loss 18.689352\n",
      "Params: tensor([ 2.6373, -1.5285])\n",
      "Grad:   tensor([-0.3205,  1.8141])\n",
      "Epoch 91, Loss 18.655443\n",
      "Params: tensor([ 2.6405, -1.5466])\n",
      "Grad:   tensor([-0.3199,  1.8110])\n",
      "Epoch 92, Loss 18.621651\n",
      "Params: tensor([ 2.6437, -1.5647])\n",
      "Grad:   tensor([-0.3194,  1.8080])\n",
      "Epoch 93, Loss 18.587971\n",
      "Params: tensor([ 2.6469, -1.5828])\n",
      "Grad:   tensor([-0.3188,  1.8049])\n",
      "Epoch 94, Loss 18.554407\n",
      "Params: tensor([ 2.6501, -1.6008])\n",
      "Grad:   tensor([-0.3183,  1.8018])\n",
      "Epoch 95, Loss 18.520954\n",
      "Params: tensor([ 2.6533, -1.6188])\n",
      "Grad:   tensor([-0.3178,  1.7988])\n",
      "Epoch 96, Loss 18.487617\n",
      "Params: tensor([ 2.6564, -1.6367])\n",
      "Grad:   tensor([-0.3172,  1.7957])\n",
      "Epoch 97, Loss 18.454395\n",
      "Params: tensor([ 2.6596, -1.6546])\n",
      "Grad:   tensor([-0.3167,  1.7927])\n",
      "Epoch 98, Loss 18.421282\n",
      "Params: tensor([ 2.6628, -1.6725])\n",
      "Grad:   tensor([-0.3161,  1.7896])\n",
      "Epoch 99, Loss 18.388285\n",
      "Params: tensor([ 2.6659, -1.6904])\n",
      "Grad:   tensor([-0.3156,  1.7866])\n",
      "Epoch 100, Loss 18.355400\n",
      "Params: tensor([ 2.6691, -1.7082])\n",
      "Grad:   tensor([-0.3151,  1.7835])\n",
      "Epoch 101, Loss 18.322628\n",
      "Params: tensor([ 2.6722, -1.7261])\n",
      "Grad:   tensor([-0.3145,  1.7805])\n",
      "Epoch 102, Loss 18.289961\n",
      "Params: tensor([ 2.6754, -1.7438])\n",
      "Grad:   tensor([-0.3140,  1.7775])\n",
      "Epoch 103, Loss 18.257408\n",
      "Params: tensor([ 2.6785, -1.7616])\n",
      "Grad:   tensor([-0.3135,  1.7745])\n",
      "Epoch 104, Loss 18.224962\n",
      "Params: tensor([ 2.6816, -1.7793])\n",
      "Grad:   tensor([-0.3129,  1.7714])\n",
      "Epoch 105, Loss 18.192635\n",
      "Params: tensor([ 2.6847, -1.7970])\n",
      "Grad:   tensor([-0.3124,  1.7684])\n",
      "Epoch 106, Loss 18.160410\n",
      "Params: tensor([ 2.6879, -1.8146])\n",
      "Grad:   tensor([-0.3119,  1.7654])\n",
      "Epoch 107, Loss 18.128294\n",
      "Params: tensor([ 2.6910, -1.8322])\n",
      "Grad:   tensor([-0.3113,  1.7624])\n",
      "Epoch 108, Loss 18.096298\n",
      "Params: tensor([ 2.6941, -1.8498])\n",
      "Grad:   tensor([-0.3108,  1.7594])\n",
      "Epoch 109, Loss 18.064396\n",
      "Params: tensor([ 2.6972, -1.8674])\n",
      "Grad:   tensor([-0.3103,  1.7565])\n",
      "Epoch 110, Loss 18.032612\n",
      "Params: tensor([ 2.7003, -1.8849])\n",
      "Grad:   tensor([-0.3098,  1.7535])\n",
      "Epoch 111, Loss 18.000929\n",
      "Params: tensor([ 2.7034, -1.9024])\n",
      "Grad:   tensor([-0.3092,  1.7505])\n",
      "Epoch 112, Loss 17.969358\n",
      "Params: tensor([ 2.7065, -1.9199])\n",
      "Grad:   tensor([-0.3087,  1.7475])\n",
      "Epoch 113, Loss 17.937897\n",
      "Params: tensor([ 2.7095, -1.9374])\n",
      "Grad:   tensor([-0.3082,  1.7445])\n",
      "Epoch 114, Loss 17.906536\n",
      "Params: tensor([ 2.7126, -1.9548])\n",
      "Grad:   tensor([-0.3077,  1.7416])\n",
      "Epoch 115, Loss 17.875288\n",
      "Params: tensor([ 2.7157, -1.9722])\n",
      "Grad:   tensor([-0.3071,  1.7386])\n",
      "Epoch 116, Loss 17.844141\n",
      "Params: tensor([ 2.7188, -1.9895])\n",
      "Grad:   tensor([-0.3066,  1.7357])\n",
      "Epoch 117, Loss 17.813105\n",
      "Params: tensor([ 2.7218, -2.0069])\n",
      "Grad:   tensor([-0.3061,  1.7327])\n",
      "Epoch 118, Loss 17.782167\n",
      "Params: tensor([ 2.7249, -2.0242])\n",
      "Grad:   tensor([-0.3056,  1.7298])\n",
      "Epoch 119, Loss 17.751343\n",
      "Params: tensor([ 2.7279, -2.0414])\n",
      "Grad:   tensor([-0.3051,  1.7268])\n",
      "Epoch 120, Loss 17.720615\n",
      "Params: tensor([ 2.7310, -2.0587])\n",
      "Grad:   tensor([-0.3045,  1.7239])\n",
      "Epoch 121, Loss 17.689999\n",
      "Params: tensor([ 2.7340, -2.0759])\n",
      "Grad:   tensor([-0.3040,  1.7210])\n",
      "Epoch 122, Loss 17.659481\n",
      "Params: tensor([ 2.7370, -2.0930])\n",
      "Grad:   tensor([-0.3035,  1.7181])\n",
      "Epoch 123, Loss 17.629061\n",
      "Params: tensor([ 2.7401, -2.1102])\n",
      "Grad:   tensor([-0.3030,  1.7151])\n",
      "Epoch 124, Loss 17.598759\n",
      "Params: tensor([ 2.7431, -2.1273])\n",
      "Grad:   tensor([-0.3025,  1.7122])\n",
      "Epoch 125, Loss 17.568552\n",
      "Params: tensor([ 2.7461, -2.1444])\n",
      "Grad:   tensor([-0.3020,  1.7093])\n",
      "Epoch 126, Loss 17.538446\n",
      "Params: tensor([ 2.7491, -2.1615])\n",
      "Grad:   tensor([-0.3014,  1.7064])\n",
      "Epoch 127, Loss 17.508448\n",
      "Params: tensor([ 2.7521, -2.1785])\n",
      "Grad:   tensor([-0.3009,  1.7035])\n",
      "Epoch 128, Loss 17.478544\n",
      "Params: tensor([ 2.7551, -2.1955])\n",
      "Grad:   tensor([-0.3004,  1.7006])\n",
      "Epoch 129, Loss 17.448744\n",
      "Params: tensor([ 2.7581, -2.2125])\n",
      "Grad:   tensor([-0.2999,  1.6977])\n",
      "Epoch 130, Loss 17.419050\n",
      "Params: tensor([ 2.7611, -2.2294])\n",
      "Grad:   tensor([-0.2994,  1.6948])\n",
      "Epoch 131, Loss 17.389454\n",
      "Params: tensor([ 2.7641, -2.2464])\n",
      "Grad:   tensor([-0.2989,  1.6920])\n",
      "Epoch 132, Loss 17.359957\n",
      "Params: tensor([ 2.7671, -2.2633])\n",
      "Grad:   tensor([-0.2984,  1.6891])\n",
      "Epoch 133, Loss 17.330564\n",
      "Params: tensor([ 2.7701, -2.2801])\n",
      "Grad:   tensor([-0.2979,  1.6862])\n",
      "Epoch 134, Loss 17.301264\n",
      "Params: tensor([ 2.7731, -2.2970])\n",
      "Grad:   tensor([-0.2974,  1.6834])\n",
      "Epoch 135, Loss 17.272072\n",
      "Params: tensor([ 2.7760, -2.3138])\n",
      "Grad:   tensor([-0.2969,  1.6805])\n",
      "Epoch 136, Loss 17.242973\n",
      "Params: tensor([ 2.7790, -2.3305])\n",
      "Grad:   tensor([-0.2964,  1.6776])\n",
      "Epoch 137, Loss 17.213972\n",
      "Params: tensor([ 2.7820, -2.3473])\n",
      "Grad:   tensor([-0.2959,  1.6748])\n",
      "Epoch 138, Loss 17.185080\n",
      "Params: tensor([ 2.7849, -2.3640])\n",
      "Grad:   tensor([-0.2954,  1.6719])\n",
      "Epoch 139, Loss 17.156271\n",
      "Params: tensor([ 2.7879, -2.3807])\n",
      "Grad:   tensor([-0.2949,  1.6691])\n",
      "Epoch 140, Loss 17.127569\n",
      "Params: tensor([ 2.7908, -2.3974])\n",
      "Grad:   tensor([-0.2944,  1.6663])\n",
      "Epoch 141, Loss 17.098961\n",
      "Params: tensor([ 2.7937, -2.4140])\n",
      "Grad:   tensor([-0.2939,  1.6634])\n",
      "Epoch 142, Loss 17.070450\n",
      "Params: tensor([ 2.7967, -2.4306])\n",
      "Grad:   tensor([-0.2934,  1.6606])\n",
      "Epoch 143, Loss 17.042040\n",
      "Params: tensor([ 2.7996, -2.4472])\n",
      "Grad:   tensor([-0.2929,  1.6578])\n",
      "Epoch 144, Loss 17.013721\n",
      "Params: tensor([ 2.8025, -2.4637])\n",
      "Grad:   tensor([-0.2924,  1.6550])\n",
      "Epoch 145, Loss 16.985498\n",
      "Params: tensor([ 2.8054, -2.4802])\n",
      "Grad:   tensor([-0.2919,  1.6522])\n",
      "Epoch 146, Loss 16.957375\n",
      "Params: tensor([ 2.8084, -2.4967])\n",
      "Grad:   tensor([-0.2914,  1.6494])\n",
      "Epoch 147, Loss 16.929350\n",
      "Params: tensor([ 2.8113, -2.5132])\n",
      "Grad:   tensor([-0.2909,  1.6466])\n",
      "Epoch 148, Loss 16.901415\n",
      "Params: tensor([ 2.8142, -2.5296])\n",
      "Grad:   tensor([-0.2904,  1.6438])\n",
      "Epoch 149, Loss 16.873573\n",
      "Params: tensor([ 2.8171, -2.5461])\n",
      "Grad:   tensor([-0.2899,  1.6410])\n",
      "Epoch 150, Loss 16.845833\n",
      "Params: tensor([ 2.8200, -2.5624])\n",
      "Grad:   tensor([-0.2894,  1.6382])\n",
      "Epoch 151, Loss 16.818182\n",
      "Params: tensor([ 2.8229, -2.5788])\n",
      "Grad:   tensor([-0.2889,  1.6354])\n",
      "Epoch 152, Loss 16.790625\n",
      "Params: tensor([ 2.8257, -2.5951])\n",
      "Grad:   tensor([-0.2884,  1.6326])\n",
      "Epoch 153, Loss 16.763161\n",
      "Params: tensor([ 2.8286, -2.6114])\n",
      "Grad:   tensor([-0.2879,  1.6298])\n",
      "Epoch 154, Loss 16.735796\n",
      "Params: tensor([ 2.8315, -2.6277])\n",
      "Grad:   tensor([-0.2874,  1.6271])\n",
      "Epoch 155, Loss 16.708513\n",
      "Params: tensor([ 2.8344, -2.6439])\n",
      "Grad:   tensor([-0.2869,  1.6243])\n",
      "Epoch 156, Loss 16.681326\n",
      "Params: tensor([ 2.8372, -2.6601])\n",
      "Grad:   tensor([-0.2865,  1.6216])\n",
      "Epoch 157, Loss 16.654236\n",
      "Params: tensor([ 2.8401, -2.6763])\n",
      "Grad:   tensor([-0.2860,  1.6188])\n",
      "Epoch 158, Loss 16.627237\n",
      "Params: tensor([ 2.8429, -2.6925])\n",
      "Grad:   tensor([-0.2855,  1.6161])\n",
      "Epoch 159, Loss 16.600328\n",
      "Params: tensor([ 2.8458, -2.7086])\n",
      "Grad:   tensor([-0.2850,  1.6133])\n",
      "Epoch 160, Loss 16.573513\n",
      "Params: tensor([ 2.8486, -2.7247])\n",
      "Grad:   tensor([-0.2845,  1.6106])\n",
      "Epoch 161, Loss 16.546783\n",
      "Params: tensor([ 2.8515, -2.7408])\n",
      "Grad:   tensor([-0.2840,  1.6078])\n",
      "Epoch 162, Loss 16.520155\n",
      "Params: tensor([ 2.8543, -2.7569])\n",
      "Grad:   tensor([-0.2835,  1.6051])\n",
      "Epoch 163, Loss 16.493605\n",
      "Params: tensor([ 2.8571, -2.7729])\n",
      "Grad:   tensor([-0.2831,  1.6024])\n",
      "Epoch 164, Loss 16.467150\n",
      "Params: tensor([ 2.8600, -2.7889])\n",
      "Grad:   tensor([-0.2826,  1.5997])\n",
      "Epoch 165, Loss 16.440790\n",
      "Params: tensor([ 2.8628, -2.8048])\n",
      "Grad:   tensor([-0.2821,  1.5969])\n",
      "Epoch 166, Loss 16.414516\n",
      "Params: tensor([ 2.8656, -2.8208])\n",
      "Grad:   tensor([-0.2816,  1.5942])\n",
      "Epoch 167, Loss 16.388325\n",
      "Params: tensor([ 2.8684, -2.8367])\n",
      "Grad:   tensor([-0.2812,  1.5915])\n",
      "Epoch 168, Loss 16.362228\n",
      "Params: tensor([ 2.8712, -2.8526])\n",
      "Grad:   tensor([-0.2807,  1.5888])\n",
      "Epoch 169, Loss 16.336220\n",
      "Params: tensor([ 2.8740, -2.8685])\n",
      "Grad:   tensor([-0.2802,  1.5861])\n",
      "Epoch 170, Loss 16.310303\n",
      "Params: tensor([ 2.8768, -2.8843])\n",
      "Grad:   tensor([-0.2797,  1.5834])\n",
      "Epoch 171, Loss 16.284466\n",
      "Params: tensor([ 2.8796, -2.9001])\n",
      "Grad:   tensor([-0.2792,  1.5807])\n",
      "Epoch 172, Loss 16.258722\n",
      "Params: tensor([ 2.8824, -2.9159])\n",
      "Grad:   tensor([-0.2788,  1.5780])\n",
      "Epoch 173, Loss 16.233065\n",
      "Params: tensor([ 2.8852, -2.9316])\n",
      "Grad:   tensor([-0.2783,  1.5754])\n",
      "Epoch 174, Loss 16.207500\n",
      "Params: tensor([ 2.8880, -2.9474])\n",
      "Grad:   tensor([-0.2778,  1.5727])\n",
      "Epoch 175, Loss 16.182011\n",
      "Params: tensor([ 2.8907, -2.9631])\n",
      "Grad:   tensor([-0.2773,  1.5700])\n",
      "Epoch 176, Loss 16.156610\n",
      "Params: tensor([ 2.8935, -2.9787])\n",
      "Grad:   tensor([-0.2769,  1.5673])\n",
      "Epoch 177, Loss 16.131304\n",
      "Params: tensor([ 2.8963, -2.9944])\n",
      "Grad:   tensor([-0.2764,  1.5647])\n",
      "Epoch 178, Loss 16.106079\n",
      "Params: tensor([ 2.8990, -3.0100])\n",
      "Grad:   tensor([-0.2759,  1.5620])\n",
      "Epoch 179, Loss 16.080942\n",
      "Params: tensor([ 2.9018, -3.0256])\n",
      "Grad:   tensor([-0.2755,  1.5594])\n",
      "Epoch 180, Loss 16.055883\n",
      "Params: tensor([ 2.9045, -3.0412])\n",
      "Grad:   tensor([-0.2750,  1.5567])\n",
      "Epoch 181, Loss 16.030914\n",
      "Params: tensor([ 2.9073, -3.0567])\n",
      "Grad:   tensor([-0.2745,  1.5541])\n",
      "Epoch 182, Loss 16.006033\n",
      "Params: tensor([ 2.9100, -3.0722])\n",
      "Grad:   tensor([-0.2741,  1.5514])\n",
      "Epoch 183, Loss 15.981235\n",
      "Params: tensor([ 2.9128, -3.0877])\n",
      "Grad:   tensor([-0.2736,  1.5488])\n",
      "Epoch 184, Loss 15.956518\n",
      "Params: tensor([ 2.9155, -3.1032])\n",
      "Grad:   tensor([-0.2731,  1.5462])\n",
      "Epoch 185, Loss 15.931886\n",
      "Params: tensor([ 2.9182, -3.1186])\n",
      "Grad:   tensor([-0.2727,  1.5435])\n",
      "Epoch 186, Loss 15.907337\n",
      "Params: tensor([ 2.9209, -3.1340])\n",
      "Grad:   tensor([-0.2722,  1.5409])\n",
      "Epoch 187, Loss 15.882873\n",
      "Params: tensor([ 2.9237, -3.1494])\n",
      "Grad:   tensor([-0.2718,  1.5383])\n",
      "Epoch 188, Loss 15.858494\n",
      "Params: tensor([ 2.9264, -3.1647])\n",
      "Grad:   tensor([-0.2713,  1.5357])\n",
      "Epoch 189, Loss 15.834195\n",
      "Params: tensor([ 2.9291, -3.1801])\n",
      "Grad:   tensor([-0.2708,  1.5331])\n",
      "Epoch 190, Loss 15.809974\n",
      "Params: tensor([ 2.9318, -3.1954])\n",
      "Grad:   tensor([-0.2704,  1.5305])\n",
      "Epoch 191, Loss 15.785839\n",
      "Params: tensor([ 2.9345, -3.2107])\n",
      "Grad:   tensor([-0.2699,  1.5279])\n",
      "Epoch 192, Loss 15.761791\n",
      "Params: tensor([ 2.9372, -3.2259])\n",
      "Grad:   tensor([-0.2694,  1.5253])\n",
      "Epoch 193, Loss 15.737820\n",
      "Params: tensor([ 2.9399, -3.2411])\n",
      "Grad:   tensor([-0.2690,  1.5227])\n",
      "Epoch 194, Loss 15.713932\n",
      "Params: tensor([ 2.9425, -3.2563])\n",
      "Grad:   tensor([-0.2685,  1.5201])\n",
      "Epoch 195, Loss 15.690124\n",
      "Params: tensor([ 2.9452, -3.2715])\n",
      "Grad:   tensor([-0.2681,  1.5175])\n",
      "Epoch 196, Loss 15.666393\n",
      "Params: tensor([ 2.9479, -3.2867])\n",
      "Grad:   tensor([-0.2676,  1.5149])\n",
      "Epoch 197, Loss 15.642755\n",
      "Params: tensor([ 2.9506, -3.3018])\n",
      "Grad:   tensor([-0.2672,  1.5124])\n",
      "Epoch 198, Loss 15.619185\n",
      "Params: tensor([ 2.9532, -3.3169])\n",
      "Grad:   tensor([-0.2667,  1.5098])\n",
      "Epoch 199, Loss 15.595695\n",
      "Params: tensor([ 2.9559, -3.3320])\n",
      "Grad:   tensor([-0.2663,  1.5072])\n",
      "Epoch 200, Loss 15.572292\n",
      "Params: tensor([ 2.9586, -3.3470])\n",
      "Grad:   tensor([-0.2658,  1.5047])\n",
      "Epoch 201, Loss 15.548965\n",
      "Params: tensor([ 2.9612, -3.3620])\n",
      "Grad:   tensor([-0.2654,  1.5021])\n",
      "Epoch 202, Loss 15.525717\n",
      "Params: tensor([ 2.9639, -3.3770])\n",
      "Grad:   tensor([-0.2649,  1.4996])\n",
      "Epoch 203, Loss 15.502548\n",
      "Params: tensor([ 2.9665, -3.3920])\n",
      "Grad:   tensor([-0.2644,  1.4970])\n",
      "Epoch 204, Loss 15.479455\n",
      "Params: tensor([ 2.9691, -3.4069])\n",
      "Grad:   tensor([-0.2640,  1.4945])\n",
      "Epoch 205, Loss 15.456445\n",
      "Params: tensor([ 2.9718, -3.4219])\n",
      "Grad:   tensor([-0.2635,  1.4919])\n",
      "Epoch 206, Loss 15.433511\n",
      "Params: tensor([ 2.9744, -3.4368])\n",
      "Grad:   tensor([-0.2631,  1.4894])\n",
      "Epoch 207, Loss 15.410654\n",
      "Params: tensor([ 2.9770, -3.4516])\n",
      "Grad:   tensor([-0.2627,  1.4869])\n",
      "Epoch 208, Loss 15.387876\n",
      "Params: tensor([ 2.9797, -3.4665])\n",
      "Grad:   tensor([-0.2622,  1.4843])\n",
      "Epoch 209, Loss 15.365173\n",
      "Params: tensor([ 2.9823, -3.4813])\n",
      "Grad:   tensor([-0.2618,  1.4818])\n",
      "Epoch 210, Loss 15.342548\n",
      "Params: tensor([ 2.9849, -3.4961])\n",
      "Grad:   tensor([-0.2613,  1.4793])\n",
      "Epoch 211, Loss 15.320004\n",
      "Params: tensor([ 2.9875, -3.5108])\n",
      "Grad:   tensor([-0.2609,  1.4768])\n",
      "Epoch 212, Loss 15.297531\n",
      "Params: tensor([ 2.9901, -3.5256])\n",
      "Grad:   tensor([-0.2604,  1.4743])\n",
      "Epoch 213, Loss 15.275138\n",
      "Params: tensor([ 2.9927, -3.5403])\n",
      "Grad:   tensor([-0.2600,  1.4718])\n",
      "Epoch 214, Loss 15.252819\n",
      "Params: tensor([ 2.9953, -3.5550])\n",
      "Grad:   tensor([-0.2596,  1.4693])\n",
      "Epoch 215, Loss 15.230575\n",
      "Params: tensor([ 2.9979, -3.5697])\n",
      "Grad:   tensor([-0.2591,  1.4668])\n",
      "Epoch 216, Loss 15.208410\n",
      "Params: tensor([ 3.0005, -3.5843])\n",
      "Grad:   tensor([-0.2587,  1.4643])\n",
      "Epoch 217, Loss 15.186318\n",
      "Params: tensor([ 3.0031, -3.5989])\n",
      "Grad:   tensor([-0.2582,  1.4618])\n",
      "Epoch 218, Loss 15.164303\n",
      "Params: tensor([ 3.0056, -3.6135])\n",
      "Grad:   tensor([-0.2578,  1.4593])\n",
      "Epoch 219, Loss 15.142358\n",
      "Params: tensor([ 3.0082, -3.6281])\n",
      "Grad:   tensor([-0.2574,  1.4568])\n",
      "Epoch 220, Loss 15.120489\n",
      "Params: tensor([ 3.0108, -3.6426])\n",
      "Grad:   tensor([-0.2569,  1.4544])\n",
      "Epoch 221, Loss 15.098701\n",
      "Params: tensor([ 3.0133, -3.6572])\n",
      "Grad:   tensor([-0.2565,  1.4519])\n",
      "Epoch 222, Loss 15.076977\n",
      "Params: tensor([ 3.0159, -3.6716])\n",
      "Grad:   tensor([-0.2560,  1.4494])\n",
      "Epoch 223, Loss 15.055331\n",
      "Params: tensor([ 3.0185, -3.6861])\n",
      "Grad:   tensor([-0.2556,  1.4470])\n",
      "Epoch 224, Loss 15.033758\n",
      "Params: tensor([ 3.0210, -3.7006])\n",
      "Grad:   tensor([-0.2552,  1.4445])\n",
      "Epoch 225, Loss 15.012259\n",
      "Params: tensor([ 3.0236, -3.7150])\n",
      "Grad:   tensor([-0.2547,  1.4421])\n",
      "Epoch 226, Loss 14.990836\n",
      "Params: tensor([ 3.0261, -3.7294])\n",
      "Grad:   tensor([-0.2543,  1.4396])\n",
      "Epoch 227, Loss 14.969476\n",
      "Params: tensor([ 3.0286, -3.7438])\n",
      "Grad:   tensor([-0.2539,  1.4372])\n",
      "Epoch 228, Loss 14.948199\n",
      "Params: tensor([ 3.0312, -3.7581])\n",
      "Grad:   tensor([-0.2534,  1.4347])\n",
      "Epoch 229, Loss 14.926988\n",
      "Params: tensor([ 3.0337, -3.7724])\n",
      "Grad:   tensor([-0.2530,  1.4323])\n",
      "Epoch 230, Loss 14.905856\n",
      "Params: tensor([ 3.0362, -3.7867])\n",
      "Grad:   tensor([-0.2526,  1.4299])\n",
      "Epoch 231, Loss 14.884789\n",
      "Params: tensor([ 3.0388, -3.8010])\n",
      "Grad:   tensor([-0.2522,  1.4274])\n",
      "Epoch 232, Loss 14.863797\n",
      "Params: tensor([ 3.0413, -3.8152])\n",
      "Grad:   tensor([-0.2517,  1.4250])\n",
      "Epoch 233, Loss 14.842874\n",
      "Params: tensor([ 3.0438, -3.8295])\n",
      "Grad:   tensor([-0.2513,  1.4226])\n",
      "Epoch 234, Loss 14.822024\n",
      "Params: tensor([ 3.0463, -3.8437])\n",
      "Grad:   tensor([-0.2509,  1.4202])\n",
      "Epoch 235, Loss 14.801243\n",
      "Params: tensor([ 3.0488, -3.8578])\n",
      "Grad:   tensor([-0.2504,  1.4178])\n",
      "Epoch 236, Loss 14.780532\n",
      "Params: tensor([ 3.0513, -3.8720])\n",
      "Grad:   tensor([-0.2500,  1.4153])\n",
      "Epoch 237, Loss 14.759893\n",
      "Params: tensor([ 3.0538, -3.8861])\n",
      "Grad:   tensor([-0.2496,  1.4129])\n",
      "Epoch 238, Loss 14.739325\n",
      "Params: tensor([ 3.0563, -3.9002])\n",
      "Grad:   tensor([-0.2492,  1.4105])\n",
      "Epoch 239, Loss 14.718823\n",
      "Params: tensor([ 3.0588, -3.9143])\n",
      "Grad:   tensor([-0.2488,  1.4081])\n",
      "Epoch 240, Loss 14.698395\n",
      "Params: tensor([ 3.0613, -3.9284])\n",
      "Grad:   tensor([-0.2483,  1.4057])\n",
      "Epoch 241, Loss 14.678034\n",
      "Params: tensor([ 3.0637, -3.9424])\n",
      "Grad:   tensor([-0.2479,  1.4034])\n",
      "Epoch 242, Loss 14.657742\n",
      "Params: tensor([ 3.0662, -3.9564])\n",
      "Grad:   tensor([-0.2475,  1.4010])\n",
      "Epoch 243, Loss 14.637525\n",
      "Params: tensor([ 3.0687, -3.9704])\n",
      "Grad:   tensor([-0.2471,  1.3986])\n",
      "Epoch 244, Loss 14.617365\n",
      "Params: tensor([ 3.0712, -3.9844])\n",
      "Grad:   tensor([-0.2466,  1.3962])\n",
      "Epoch 245, Loss 14.597278\n",
      "Params: tensor([ 3.0736, -3.9983])\n",
      "Grad:   tensor([-0.2462,  1.3938])\n",
      "Epoch 246, Loss 14.577262\n",
      "Params: tensor([ 3.0761, -4.0122])\n",
      "Grad:   tensor([-0.2458,  1.3915])\n",
      "Epoch 247, Loss 14.557311\n",
      "Params: tensor([ 3.0785, -4.0261])\n",
      "Grad:   tensor([-0.2454,  1.3891])\n",
      "Epoch 248, Loss 14.537434\n",
      "Params: tensor([ 3.0810, -4.0400])\n",
      "Grad:   tensor([-0.2450,  1.3868])\n",
      "Epoch 249, Loss 14.517618\n",
      "Params: tensor([ 3.0834, -4.0538])\n",
      "Grad:   tensor([-0.2446,  1.3844])\n",
      "Epoch 250, Loss 14.497868\n",
      "Params: tensor([ 3.0859, -4.0676])\n",
      "Grad:   tensor([-0.2441,  1.3821])\n",
      "Epoch 251, Loss 14.478189\n",
      "Params: tensor([ 3.0883, -4.0814])\n",
      "Grad:   tensor([-0.2437,  1.3797])\n",
      "Epoch 252, Loss 14.458575\n",
      "Params: tensor([ 3.0907, -4.0952])\n",
      "Grad:   tensor([-0.2433,  1.3774])\n",
      "Epoch 253, Loss 14.439032\n",
      "Params: tensor([ 3.0932, -4.1090])\n",
      "Grad:   tensor([-0.2429,  1.3750])\n",
      "Epoch 254, Loss 14.419550\n",
      "Params: tensor([ 3.0956, -4.1227])\n",
      "Grad:   tensor([-0.2425,  1.3727])\n",
      "Epoch 255, Loss 14.400138\n",
      "Params: tensor([ 3.0980, -4.1364])\n",
      "Grad:   tensor([-0.2421,  1.3704])\n",
      "Epoch 256, Loss 14.380787\n",
      "Params: tensor([ 3.1004, -4.1501])\n",
      "Grad:   tensor([-0.2417,  1.3680])\n",
      "Epoch 257, Loss 14.361507\n",
      "Params: tensor([ 3.1028, -4.1637])\n",
      "Grad:   tensor([-0.2413,  1.3657])\n",
      "Epoch 258, Loss 14.342288\n",
      "Params: tensor([ 3.1052, -4.1774])\n",
      "Grad:   tensor([-0.2409,  1.3634])\n",
      "Epoch 259, Loss 14.323135\n",
      "Params: tensor([ 3.1076, -4.1910])\n",
      "Grad:   tensor([-0.2404,  1.3611])\n",
      "Epoch 260, Loss 14.304052\n",
      "Params: tensor([ 3.1100, -4.2046])\n",
      "Grad:   tensor([-0.2400,  1.3588])\n",
      "Epoch 261, Loss 14.285031\n",
      "Params: tensor([ 3.1124, -4.2181])\n",
      "Grad:   tensor([-0.2396,  1.3564])\n",
      "Epoch 262, Loss 14.266070\n",
      "Params: tensor([ 3.1148, -4.2317])\n",
      "Grad:   tensor([-0.2392,  1.3541])\n",
      "Epoch 263, Loss 14.247177\n",
      "Params: tensor([ 3.1172, -4.2452])\n",
      "Grad:   tensor([-0.2388,  1.3518])\n",
      "Epoch 264, Loss 14.228349\n",
      "Params: tensor([ 3.1196, -4.2587])\n",
      "Grad:   tensor([-0.2384,  1.3495])\n",
      "Epoch 265, Loss 14.209583\n",
      "Params: tensor([ 3.1220, -4.2722])\n",
      "Grad:   tensor([-0.2380,  1.3472])\n",
      "Epoch 266, Loss 14.190884\n",
      "Params: tensor([ 3.1244, -4.2856])\n",
      "Grad:   tensor([-0.2376,  1.3450])\n",
      "Epoch 267, Loss 14.172245\n",
      "Params: tensor([ 3.1267, -4.2990])\n",
      "Grad:   tensor([-0.2372,  1.3427])\n",
      "Epoch 268, Loss 14.153670\n",
      "Params: tensor([ 3.1291, -4.3124])\n",
      "Grad:   tensor([-0.2368,  1.3404])\n",
      "Epoch 269, Loss 14.135159\n",
      "Params: tensor([ 3.1315, -4.3258])\n",
      "Grad:   tensor([-0.2364,  1.3381])\n",
      "Epoch 270, Loss 14.116711\n",
      "Params: tensor([ 3.1338, -4.3392])\n",
      "Grad:   tensor([-0.2360,  1.3358])\n",
      "Epoch 271, Loss 14.098324\n",
      "Params: tensor([ 3.1362, -4.3525])\n",
      "Grad:   tensor([-0.2356,  1.3336])\n",
      "Epoch 272, Loss 14.079999\n",
      "Params: tensor([ 3.1385, -4.3658])\n",
      "Grad:   tensor([-0.2352,  1.3313])\n",
      "Epoch 273, Loss 14.061738\n",
      "Params: tensor([ 3.1409, -4.3791])\n",
      "Grad:   tensor([-0.2348,  1.3290])\n",
      "Epoch 274, Loss 14.043539\n",
      "Params: tensor([ 3.1432, -4.3924])\n",
      "Grad:   tensor([-0.2344,  1.3268])\n",
      "Epoch 275, Loss 14.025399\n",
      "Params: tensor([ 3.1456, -4.4056])\n",
      "Grad:   tensor([-0.2340,  1.3245])\n",
      "Epoch 276, Loss 14.007325\n",
      "Params: tensor([ 3.1479, -4.4189])\n",
      "Grad:   tensor([-0.2336,  1.3223])\n",
      "Epoch 277, Loss 13.989310\n",
      "Params: tensor([ 3.1502, -4.4321])\n",
      "Grad:   tensor([-0.2332,  1.3200])\n",
      "Epoch 278, Loss 13.971358\n",
      "Params: tensor([ 3.1526, -4.4452])\n",
      "Grad:   tensor([-0.2328,  1.3178])\n",
      "Epoch 279, Loss 13.953464\n",
      "Params: tensor([ 3.1549, -4.4584])\n",
      "Grad:   tensor([-0.2324,  1.3156])\n",
      "Epoch 280, Loss 13.935635\n",
      "Params: tensor([ 3.1572, -4.4715])\n",
      "Grad:   tensor([-0.2320,  1.3133])\n",
      "Epoch 281, Loss 13.917865\n",
      "Params: tensor([ 3.1595, -4.4846])\n",
      "Grad:   tensor([-0.2316,  1.3111])\n",
      "Epoch 282, Loss 13.900150\n",
      "Params: tensor([ 3.1618, -4.4977])\n",
      "Grad:   tensor([-0.2312,  1.3089])\n",
      "Epoch 283, Loss 13.882499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: tensor([ 3.1641, -4.5108])\n",
      "Grad:   tensor([-0.2308,  1.3066])\n",
      "Epoch 284, Loss 13.864911\n",
      "Params: tensor([ 3.1664, -4.5238])\n",
      "Grad:   tensor([-0.2304,  1.3044])\n",
      "Epoch 285, Loss 13.847381\n",
      "Params: tensor([ 3.1687, -4.5368])\n",
      "Grad:   tensor([-0.2300,  1.3022])\n",
      "Epoch 286, Loss 13.829907\n",
      "Params: tensor([ 3.1710, -4.5498])\n",
      "Grad:   tensor([-0.2296,  1.3000])\n",
      "Epoch 287, Loss 13.812490\n",
      "Params: tensor([ 3.1733, -4.5628])\n",
      "Grad:   tensor([-0.2293,  1.2978])\n",
      "Epoch 288, Loss 13.795141\n",
      "Params: tensor([ 3.1756, -4.5758])\n",
      "Grad:   tensor([-0.2289,  1.2956])\n",
      "Epoch 289, Loss 13.777846\n",
      "Params: tensor([ 3.1779, -4.5887])\n",
      "Grad:   tensor([-0.2285,  1.2934])\n",
      "Epoch 290, Loss 13.760611\n",
      "Params: tensor([ 3.1802, -4.6016])\n",
      "Grad:   tensor([-0.2281,  1.2912])\n",
      "Epoch 291, Loss 13.743435\n",
      "Params: tensor([ 3.1825, -4.6145])\n",
      "Grad:   tensor([-0.2277,  1.2890])\n",
      "Epoch 292, Loss 13.726313\n",
      "Params: tensor([ 3.1847, -4.6274])\n",
      "Grad:   tensor([-0.2273,  1.2868])\n",
      "Epoch 293, Loss 13.709253\n",
      "Params: tensor([ 3.1870, -4.6402])\n",
      "Grad:   tensor([-0.2269,  1.2846])\n",
      "Epoch 294, Loss 13.692251\n",
      "Params: tensor([ 3.1893, -4.6531])\n",
      "Grad:   tensor([-0.2265,  1.2824])\n",
      "Epoch 295, Loss 13.675305\n",
      "Params: tensor([ 3.1915, -4.6659])\n",
      "Grad:   tensor([-0.2262,  1.2803])\n",
      "Epoch 296, Loss 13.658418\n",
      "Params: tensor([ 3.1938, -4.6786])\n",
      "Grad:   tensor([-0.2258,  1.2781])\n",
      "Epoch 297, Loss 13.641589\n",
      "Params: tensor([ 3.1961, -4.6914])\n",
      "Grad:   tensor([-0.2254,  1.2759])\n",
      "Epoch 298, Loss 13.624816\n",
      "Params: tensor([ 3.1983, -4.7041])\n",
      "Grad:   tensor([-0.2250,  1.2737])\n",
      "Epoch 299, Loss 13.608096\n",
      "Params: tensor([ 3.2005, -4.7169])\n",
      "Grad:   tensor([-0.2246,  1.2716])\n",
      "Epoch 300, Loss 13.591437\n",
      "Params: tensor([ 3.2028, -4.7295])\n",
      "Grad:   tensor([-0.2243,  1.2694])\n",
      "Epoch 301, Loss 13.574836\n",
      "Params: tensor([ 3.2050, -4.7422])\n",
      "Grad:   tensor([-0.2239,  1.2673])\n",
      "Epoch 302, Loss 13.558291\n",
      "Params: tensor([ 3.2073, -4.7549])\n",
      "Grad:   tensor([-0.2235,  1.2651])\n",
      "Epoch 303, Loss 13.541798\n",
      "Params: tensor([ 3.2095, -4.7675])\n",
      "Grad:   tensor([-0.2231,  1.2630])\n",
      "Epoch 304, Loss 13.525363\n",
      "Params: tensor([ 3.2117, -4.7801])\n",
      "Grad:   tensor([-0.2227,  1.2608])\n",
      "Epoch 305, Loss 13.508985\n",
      "Params: tensor([ 3.2139, -4.7927])\n",
      "Grad:   tensor([-0.2223,  1.2587])\n",
      "Epoch 306, Loss 13.492661\n",
      "Params: tensor([ 3.2162, -4.8053])\n",
      "Grad:   tensor([-0.2220,  1.2565])\n",
      "Epoch 307, Loss 13.476396\n",
      "Params: tensor([ 3.2184, -4.8178])\n",
      "Grad:   tensor([-0.2216,  1.2544])\n",
      "Epoch 308, Loss 13.460183\n",
      "Params: tensor([ 3.2206, -4.8303])\n",
      "Grad:   tensor([-0.2212,  1.2523])\n",
      "Epoch 309, Loss 13.444025\n",
      "Params: tensor([ 3.2228, -4.8428])\n",
      "Grad:   tensor([-0.2208,  1.2501])\n",
      "Epoch 310, Loss 13.427924\n",
      "Params: tensor([ 3.2250, -4.8553])\n",
      "Grad:   tensor([-0.2205,  1.2480])\n",
      "Epoch 311, Loss 13.411875\n",
      "Params: tensor([ 3.2272, -4.8678])\n",
      "Grad:   tensor([-0.2201,  1.2459])\n",
      "Epoch 312, Loss 13.395883\n",
      "Params: tensor([ 3.2294, -4.8802])\n",
      "Grad:   tensor([-0.2197,  1.2438])\n",
      "Epoch 313, Loss 13.379944\n",
      "Params: tensor([ 3.2316, -4.8926])\n",
      "Grad:   tensor([-0.2193,  1.2417])\n",
      "Epoch 314, Loss 13.364057\n",
      "Params: tensor([ 3.2338, -4.9050])\n",
      "Grad:   tensor([-0.2190,  1.2396])\n",
      "Epoch 315, Loss 13.348227\n",
      "Params: tensor([ 3.2360, -4.9174])\n",
      "Grad:   tensor([-0.2186,  1.2375])\n",
      "Epoch 316, Loss 13.332450\n",
      "Params: tensor([ 3.2382, -4.9297])\n",
      "Grad:   tensor([-0.2182,  1.2354])\n",
      "Epoch 317, Loss 13.316727\n",
      "Params: tensor([ 3.2403, -4.9421])\n",
      "Grad:   tensor([-0.2179,  1.2333])\n",
      "Epoch 318, Loss 13.301056\n",
      "Params: tensor([ 3.2425, -4.9544])\n",
      "Grad:   tensor([-0.2175,  1.2312])\n",
      "Epoch 319, Loss 13.285438\n",
      "Params: tensor([ 3.2447, -4.9667])\n",
      "Grad:   tensor([-0.2171,  1.2291])\n",
      "Epoch 320, Loss 13.269876\n",
      "Params: tensor([ 3.2468, -4.9789])\n",
      "Grad:   tensor([-0.2167,  1.2270])\n",
      "Epoch 321, Loss 13.254363\n",
      "Params: tensor([ 3.2490, -4.9912])\n",
      "Grad:   tensor([-0.2164,  1.2249])\n",
      "Epoch 322, Loss 13.238903\n",
      "Params: tensor([ 3.2512, -5.0034])\n",
      "Grad:   tensor([-0.2160,  1.2228])\n",
      "Epoch 323, Loss 13.223501\n",
      "Params: tensor([ 3.2533, -5.0156])\n",
      "Grad:   tensor([-0.2156,  1.2207])\n",
      "Epoch 324, Loss 13.208144\n",
      "Params: tensor([ 3.2555, -5.0278])\n",
      "Grad:   tensor([-0.2153,  1.2187])\n",
      "Epoch 325, Loss 13.192842\n",
      "Params: tensor([ 3.2576, -5.0400])\n",
      "Grad:   tensor([-0.2149,  1.2166])\n",
      "Epoch 326, Loss 13.177590\n",
      "Params: tensor([ 3.2598, -5.0521])\n",
      "Grad:   tensor([-0.2145,  1.2145])\n",
      "Epoch 327, Loss 13.162396\n",
      "Params: tensor([ 3.2619, -5.0643])\n",
      "Grad:   tensor([-0.2142,  1.2125])\n",
      "Epoch 328, Loss 13.147248\n",
      "Params: tensor([ 3.2641, -5.0764])\n",
      "Grad:   tensor([-0.2138,  1.2104])\n",
      "Epoch 329, Loss 13.132156\n",
      "Params: tensor([ 3.2662, -5.0884])\n",
      "Grad:   tensor([-0.2135,  1.2083])\n",
      "Epoch 330, Loss 13.117111\n",
      "Params: tensor([ 3.2683, -5.1005])\n",
      "Grad:   tensor([-0.2131,  1.2063])\n",
      "Epoch 331, Loss 13.102113\n",
      "Params: tensor([ 3.2704, -5.1125])\n",
      "Grad:   tensor([-0.2127,  1.2042])\n",
      "Epoch 332, Loss 13.087173\n",
      "Params: tensor([ 3.2726, -5.1246])\n",
      "Grad:   tensor([-0.2124,  1.2022])\n",
      "Epoch 333, Loss 13.072282\n",
      "Params: tensor([ 3.2747, -5.1366])\n",
      "Grad:   tensor([-0.2120,  1.2002])\n",
      "Epoch 334, Loss 13.057443\n",
      "Params: tensor([ 3.2768, -5.1486])\n",
      "Grad:   tensor([-0.2116,  1.1981])\n",
      "Epoch 335, Loss 13.042655\n",
      "Params: tensor([ 3.2789, -5.1605])\n",
      "Grad:   tensor([-0.2113,  1.1961])\n",
      "Epoch 336, Loss 13.027912\n",
      "Params: tensor([ 3.2810, -5.1725])\n",
      "Grad:   tensor([-0.2109,  1.1940])\n",
      "Epoch 337, Loss 13.013223\n",
      "Params: tensor([ 3.2831, -5.1844])\n",
      "Grad:   tensor([-0.2106,  1.1920])\n",
      "Epoch 338, Loss 12.998585\n",
      "Params: tensor([ 3.2852, -5.1963])\n",
      "Grad:   tensor([-0.2102,  1.1900])\n",
      "Epoch 339, Loss 12.983993\n",
      "Params: tensor([ 3.2873, -5.2082])\n",
      "Grad:   tensor([-0.2099,  1.1880])\n",
      "Epoch 340, Loss 12.969452\n",
      "Params: tensor([ 3.2894, -5.2200])\n",
      "Grad:   tensor([-0.2095,  1.1860])\n",
      "Epoch 341, Loss 12.954962\n",
      "Params: tensor([ 3.2915, -5.2319])\n",
      "Grad:   tensor([-0.2092,  1.1839])\n",
      "Epoch 342, Loss 12.940518\n",
      "Params: tensor([ 3.2936, -5.2437])\n",
      "Grad:   tensor([-0.2088,  1.1819])\n",
      "Epoch 343, Loss 12.926126\n",
      "Params: tensor([ 3.2957, -5.2555])\n",
      "Grad:   tensor([-0.2085,  1.1799])\n",
      "Epoch 344, Loss 12.911777\n",
      "Params: tensor([ 3.2978, -5.2673])\n",
      "Grad:   tensor([-0.2081,  1.1779])\n",
      "Epoch 345, Loss 12.897485\n",
      "Params: tensor([ 3.2999, -5.2790])\n",
      "Grad:   tensor([-0.2077,  1.1759])\n",
      "Epoch 346, Loss 12.883236\n",
      "Params: tensor([ 3.3019, -5.2908])\n",
      "Grad:   tensor([-0.2074,  1.1739])\n",
      "Epoch 347, Loss 12.869038\n",
      "Params: tensor([ 3.3040, -5.3025])\n",
      "Grad:   tensor([-0.2070,  1.1719])\n",
      "Epoch 348, Loss 12.854888\n",
      "Params: tensor([ 3.3061, -5.3142])\n",
      "Grad:   tensor([-0.2067,  1.1699])\n",
      "Epoch 349, Loss 12.840783\n",
      "Params: tensor([ 3.3081, -5.3258])\n",
      "Grad:   tensor([-0.2063,  1.1679])\n",
      "Epoch 350, Loss 12.826731\n",
      "Params: tensor([ 3.3102, -5.3375])\n",
      "Grad:   tensor([-0.2060,  1.1660])\n",
      "Epoch 351, Loss 12.812722\n",
      "Params: tensor([ 3.3122, -5.3491])\n",
      "Grad:   tensor([-0.2056,  1.1640])\n",
      "Epoch 352, Loss 12.798763\n",
      "Params: tensor([ 3.3143, -5.3608])\n",
      "Grad:   tensor([-0.2053,  1.1620])\n",
      "Epoch 353, Loss 12.784851\n",
      "Params: tensor([ 3.3163, -5.3724])\n",
      "Grad:   tensor([-0.2049,  1.1600])\n",
      "Epoch 354, Loss 12.770987\n",
      "Params: tensor([ 3.3184, -5.3839])\n",
      "Grad:   tensor([-0.2046,  1.1581])\n",
      "Epoch 355, Loss 12.757168\n",
      "Params: tensor([ 3.3204, -5.3955])\n",
      "Grad:   tensor([-0.2042,  1.1561])\n",
      "Epoch 356, Loss 12.743399\n",
      "Params: tensor([ 3.3225, -5.4071])\n",
      "Grad:   tensor([-0.2039,  1.1541])\n",
      "Epoch 357, Loss 12.729672\n",
      "Params: tensor([ 3.3245, -5.4186])\n",
      "Grad:   tensor([-0.2035,  1.1522])\n",
      "Epoch 358, Loss 12.715998\n",
      "Params: tensor([ 3.3265, -5.4301])\n",
      "Grad:   tensor([-0.2032,  1.1502])\n",
      "Epoch 359, Loss 12.702366\n",
      "Params: tensor([ 3.3286, -5.4416])\n",
      "Grad:   tensor([-0.2028,  1.1483])\n",
      "Epoch 360, Loss 12.688779\n",
      "Params: tensor([ 3.3306, -5.4530])\n",
      "Grad:   tensor([-0.2025,  1.1463])\n",
      "Epoch 361, Loss 12.675241\n",
      "Params: tensor([ 3.3326, -5.4645])\n",
      "Grad:   tensor([-0.2022,  1.1444])\n",
      "Epoch 362, Loss 12.661749\n",
      "Params: tensor([ 3.3346, -5.4759])\n",
      "Grad:   tensor([-0.2018,  1.1424])\n",
      "Epoch 363, Loss 12.648300\n",
      "Params: tensor([ 3.3366, -5.4873])\n",
      "Grad:   tensor([-0.2015,  1.1405])\n",
      "Epoch 364, Loss 12.634899\n",
      "Params: tensor([ 3.3387, -5.4987])\n",
      "Grad:   tensor([-0.2011,  1.1385])\n",
      "Epoch 365, Loss 12.621546\n",
      "Params: tensor([ 3.3407, -5.5100])\n",
      "Grad:   tensor([-0.2008,  1.1366])\n",
      "Epoch 366, Loss 12.608236\n",
      "Params: tensor([ 3.3427, -5.5214])\n",
      "Grad:   tensor([-0.2004,  1.1347])\n",
      "Epoch 367, Loss 12.594968\n",
      "Params: tensor([ 3.3447, -5.5327])\n",
      "Grad:   tensor([-0.2001,  1.1327])\n",
      "Epoch 368, Loss 12.581751\n",
      "Params: tensor([ 3.3467, -5.5440])\n",
      "Grad:   tensor([-0.1998,  1.1308])\n",
      "Epoch 369, Loss 12.568573\n",
      "Params: tensor([ 3.3487, -5.5553])\n",
      "Grad:   tensor([-0.1994,  1.1289])\n",
      "Epoch 370, Loss 12.555442\n",
      "Params: tensor([ 3.3507, -5.5666])\n",
      "Grad:   tensor([-0.1991,  1.1270])\n",
      "Epoch 371, Loss 12.542358\n",
      "Params: tensor([ 3.3526, -5.5778])\n",
      "Grad:   tensor([-0.1987,  1.1251])\n",
      "Epoch 372, Loss 12.529316\n",
      "Params: tensor([ 3.3546, -5.5891])\n",
      "Grad:   tensor([-0.1984,  1.1232])\n",
      "Epoch 373, Loss 12.516317\n",
      "Params: tensor([ 3.3566, -5.6003])\n",
      "Grad:   tensor([-0.1981,  1.1212])\n",
      "Epoch 374, Loss 12.503366\n",
      "Params: tensor([ 3.3586, -5.6115])\n",
      "Grad:   tensor([-0.1977,  1.1193])\n",
      "Epoch 375, Loss 12.490457\n",
      "Params: tensor([ 3.3606, -5.6226])\n",
      "Grad:   tensor([-0.1974,  1.1174])\n",
      "Epoch 376, Loss 12.477586\n",
      "Params: tensor([ 3.3625, -5.6338])\n",
      "Grad:   tensor([-0.1971,  1.1155])\n",
      "Epoch 377, Loss 12.464768\n",
      "Params: tensor([ 3.3645, -5.6449])\n",
      "Grad:   tensor([-0.1967,  1.1136])\n",
      "Epoch 378, Loss 12.451990\n",
      "Params: tensor([ 3.3665, -5.6561])\n",
      "Grad:   tensor([-0.1964,  1.1118])\n",
      "Epoch 379, Loss 12.439254\n",
      "Params: tensor([ 3.3684, -5.6672])\n",
      "Grad:   tensor([-0.1961,  1.1099])\n",
      "Epoch 380, Loss 12.426565\n",
      "Params: tensor([ 3.3704, -5.6782])\n",
      "Grad:   tensor([-0.1957,  1.1080])\n",
      "Epoch 381, Loss 12.413913\n",
      "Params: tensor([ 3.3723, -5.6893])\n",
      "Grad:   tensor([-0.1954,  1.1061])\n",
      "Epoch 382, Loss 12.401307\n",
      "Params: tensor([ 3.3743, -5.7003])\n",
      "Grad:   tensor([-0.1951,  1.1042])\n",
      "Epoch 383, Loss 12.388745\n",
      "Params: tensor([ 3.3762, -5.7114])\n",
      "Grad:   tensor([-0.1947,  1.1023])\n",
      "Epoch 384, Loss 12.376225\n",
      "Params: tensor([ 3.3782, -5.7224])\n",
      "Grad:   tensor([-0.1944,  1.1005])\n",
      "Epoch 385, Loss 12.363750\n",
      "Params: tensor([ 3.3801, -5.7334])\n",
      "Grad:   tensor([-0.1941,  1.0986])\n",
      "Epoch 386, Loss 12.351313\n",
      "Params: tensor([ 3.3821, -5.7443])\n",
      "Grad:   tensor([-0.1937,  1.0967])\n",
      "Epoch 387, Loss 12.338919\n",
      "Params: tensor([ 3.3840, -5.7553])\n",
      "Grad:   tensor([-0.1934,  1.0949])\n",
      "Epoch 388, Loss 12.326565\n",
      "Params: tensor([ 3.3859, -5.7662])\n",
      "Grad:   tensor([-0.1931,  1.0930])\n",
      "Epoch 389, Loss 12.314258\n",
      "Params: tensor([ 3.3878, -5.7771])\n",
      "Grad:   tensor([-0.1928,  1.0912])\n",
      "Epoch 390, Loss 12.301991\n",
      "Params: tensor([ 3.3898, -5.7880])\n",
      "Grad:   tensor([-0.1924,  1.0893])\n",
      "Epoch 391, Loss 12.289765\n",
      "Params: tensor([ 3.3917, -5.7989])\n",
      "Grad:   tensor([-0.1921,  1.0875])\n",
      "Epoch 392, Loss 12.277581\n",
      "Params: tensor([ 3.3936, -5.8097])\n",
      "Grad:   tensor([-0.1918,  1.0856])\n",
      "Epoch 393, Loss 12.265439\n",
      "Params: tensor([ 3.3955, -5.8206])\n",
      "Grad:   tensor([-0.1914,  1.0838])\n",
      "Epoch 394, Loss 12.253341\n",
      "Params: tensor([ 3.3974, -5.8314])\n",
      "Grad:   tensor([-0.1911,  1.0819])\n",
      "Epoch 395, Loss 12.241281\n",
      "Params: tensor([ 3.3993, -5.8422])\n",
      "Grad:   tensor([-0.1908,  1.0801])\n",
      "Epoch 396, Loss 12.229257\n",
      "Params: tensor([ 3.4012, -5.8530])\n",
      "Grad:   tensor([-0.1905,  1.0782])\n",
      "Epoch 397, Loss 12.217279\n",
      "Params: tensor([ 3.4031, -5.8637])\n",
      "Grad:   tensor([-0.1902,  1.0764])\n",
      "Epoch 398, Loss 12.205338\n",
      "Params: tensor([ 3.4050, -5.8745])\n",
      "Grad:   tensor([-0.1898,  1.0746])\n",
      "Epoch 399, Loss 12.193441\n",
      "Params: tensor([ 3.4069, -5.8852])\n",
      "Grad:   tensor([-0.1895,  1.0728])\n",
      "Epoch 400, Loss 12.181586\n",
      "Params: tensor([ 3.4088, -5.8959])\n",
      "Grad:   tensor([-0.1892,  1.0709])\n",
      "Epoch 401, Loss 12.169768\n",
      "Params: tensor([ 3.4107, -5.9066])\n",
      "Grad:   tensor([-0.1889,  1.0691])\n",
      "Epoch 402, Loss 12.157990\n",
      "Params: tensor([ 3.4126, -5.9173])\n",
      "Grad:   tensor([-0.1885,  1.0673])\n",
      "Epoch 403, Loss 12.146255\n",
      "Params: tensor([ 3.4145, -5.9279])\n",
      "Grad:   tensor([-0.1882,  1.0655])\n",
      "Epoch 404, Loss 12.134558\n",
      "Params: tensor([ 3.4164, -5.9386])\n",
      "Grad:   tensor([-0.1879,  1.0637])\n",
      "Epoch 405, Loss 12.122900\n",
      "Params: tensor([ 3.4182, -5.9492])\n",
      "Grad:   tensor([-0.1876,  1.0619])\n",
      "Epoch 406, Loss 12.111283\n",
      "Params: tensor([ 3.4201, -5.9598])\n",
      "Grad:   tensor([-0.1873,  1.0601])\n",
      "Epoch 407, Loss 12.099705\n",
      "Params: tensor([ 3.4220, -5.9704])\n",
      "Grad:   tensor([-0.1870,  1.0583])\n",
      "Epoch 408, Loss 12.088164\n",
      "Params: tensor([ 3.4239, -5.9809])\n",
      "Grad:   tensor([-0.1866,  1.0565])\n",
      "Epoch 409, Loss 12.076666\n",
      "Params: tensor([ 3.4257, -5.9915])\n",
      "Grad:   tensor([-0.1863,  1.0547])\n",
      "Epoch 410, Loss 12.065204\n",
      "Params: tensor([ 3.4276, -6.0020])\n",
      "Grad:   tensor([-0.1860,  1.0529])\n",
      "Epoch 411, Loss 12.053782\n",
      "Params: tensor([ 3.4294, -6.0125])\n",
      "Grad:   tensor([-0.1857,  1.0511])\n",
      "Epoch 412, Loss 12.042398\n",
      "Params: tensor([ 3.4313, -6.0230])\n",
      "Grad:   tensor([-0.1854,  1.0493])\n",
      "Epoch 413, Loss 12.031053\n",
      "Params: tensor([ 3.4331, -6.0335])\n",
      "Grad:   tensor([-0.1850,  1.0475])\n",
      "Epoch 414, Loss 12.019748\n",
      "Params: tensor([ 3.4350, -6.0440])\n",
      "Grad:   tensor([-0.1847,  1.0457])\n",
      "Epoch 415, Loss 12.008480\n",
      "Params: tensor([ 3.4368, -6.0544])\n",
      "Grad:   tensor([-0.1844,  1.0440])\n",
      "Epoch 416, Loss 11.997250\n",
      "Params: tensor([ 3.4387, -6.0648])\n",
      "Grad:   tensor([-0.1841,  1.0422])\n",
      "Epoch 417, Loss 11.986060\n",
      "Params: tensor([ 3.4405, -6.0752])\n",
      "Grad:   tensor([-0.1838,  1.0404])\n",
      "Epoch 418, Loss 11.974906\n",
      "Params: tensor([ 3.4423, -6.0856])\n",
      "Grad:   tensor([-0.1835,  1.0387])\n",
      "Epoch 419, Loss 11.963791\n",
      "Params: tensor([ 3.4442, -6.0960])\n",
      "Grad:   tensor([-0.1832,  1.0369])\n",
      "Epoch 420, Loss 11.952716\n",
      "Params: tensor([ 3.4460, -6.1063])\n",
      "Grad:   tensor([-0.1828,  1.0351])\n",
      "Epoch 421, Loss 11.941675\n",
      "Params: tensor([ 3.4478, -6.1167])\n",
      "Grad:   tensor([-0.1825,  1.0334])\n",
      "Epoch 422, Loss 11.930673\n",
      "Params: tensor([ 3.4496, -6.1270])\n",
      "Grad:   tensor([-0.1822,  1.0316])\n",
      "Epoch 423, Loss 11.919707\n",
      "Params: tensor([ 3.4515, -6.1373])\n",
      "Grad:   tensor([-0.1819,  1.0299])\n",
      "Epoch 424, Loss 11.908777\n",
      "Params: tensor([ 3.4533, -6.1476])\n",
      "Grad:   tensor([-0.1816,  1.0281])\n",
      "Epoch 425, Loss 11.897885\n",
      "Params: tensor([ 3.4551, -6.1578])\n",
      "Grad:   tensor([-0.1813,  1.0264])\n",
      "Epoch 426, Loss 11.887033\n",
      "Params: tensor([ 3.4569, -6.1681])\n",
      "Grad:   tensor([-0.1810,  1.0246])\n",
      "Epoch 427, Loss 11.876218\n",
      "Params: tensor([ 3.4587, -6.1783])\n",
      "Grad:   tensor([-0.1807,  1.0229])\n",
      "Epoch 428, Loss 11.865436\n",
      "Params: tensor([ 3.4605, -6.1885])\n",
      "Grad:   tensor([-0.1804,  1.0212])\n",
      "Epoch 429, Loss 11.854692\n",
      "Params: tensor([ 3.4623, -6.1987])\n",
      "Grad:   tensor([-0.1801,  1.0194])\n",
      "Epoch 430, Loss 11.843986\n",
      "Params: tensor([ 3.4641, -6.2089])\n",
      "Grad:   tensor([-0.1798,  1.0177])\n",
      "Epoch 431, Loss 11.833314\n",
      "Params: tensor([ 3.4659, -6.2190])\n",
      "Grad:   tensor([-0.1795,  1.0160])\n",
      "Epoch 432, Loss 11.822680\n",
      "Params: tensor([ 3.4677, -6.2292])\n",
      "Grad:   tensor([-0.1792,  1.0142])\n",
      "Epoch 433, Loss 11.812082\n",
      "Params: tensor([ 3.4695, -6.2393])\n",
      "Grad:   tensor([-0.1789,  1.0125])\n",
      "Epoch 434, Loss 11.801519\n",
      "Params: tensor([ 3.4713, -6.2494])\n",
      "Grad:   tensor([-0.1786,  1.0108])\n",
      "Epoch 435, Loss 11.790992\n",
      "Params: tensor([ 3.4731, -6.2595])\n",
      "Grad:   tensor([-0.1783,  1.0091])\n",
      "Epoch 436, Loss 11.780499\n",
      "Params: tensor([ 3.4748, -6.2696])\n",
      "Grad:   tensor([-0.1779,  1.0074])\n",
      "Epoch 437, Loss 11.770046\n",
      "Params: tensor([ 3.4766, -6.2796])\n",
      "Grad:   tensor([-0.1776,  1.0056])\n",
      "Epoch 438, Loss 11.759624\n",
      "Params: tensor([ 3.4784, -6.2897])\n",
      "Grad:   tensor([-0.1773,  1.0039])\n",
      "Epoch 439, Loss 11.749238\n",
      "Params: tensor([ 3.4802, -6.2997])\n",
      "Grad:   tensor([-0.1771,  1.0022])\n",
      "Epoch 440, Loss 11.738891\n",
      "Params: tensor([ 3.4819, -6.3097])\n",
      "Grad:   tensor([-0.1767,  1.0005])\n",
      "Epoch 441, Loss 11.728577\n",
      "Params: tensor([ 3.4837, -6.3197])\n",
      "Grad:   tensor([-0.1764,  0.9988])\n",
      "Epoch 442, Loss 11.718298\n",
      "Params: tensor([ 3.4855, -6.3297])\n",
      "Grad:   tensor([-0.1761,  0.9971])\n",
      "Epoch 443, Loss 11.708051\n",
      "Params: tensor([ 3.4872, -6.3396])\n",
      "Grad:   tensor([-0.1758,  0.9954])\n",
      "Epoch 444, Loss 11.697845\n",
      "Params: tensor([ 3.4890, -6.3496])\n",
      "Grad:   tensor([-0.1755,  0.9937])\n",
      "Epoch 445, Loss 11.687668\n",
      "Params: tensor([ 3.4907, -6.3595])\n",
      "Grad:   tensor([-0.1752,  0.9921])\n",
      "Epoch 446, Loss 11.677530\n",
      "Params: tensor([ 3.4925, -6.3694])\n",
      "Grad:   tensor([-0.1750,  0.9904])\n",
      "Epoch 447, Loss 11.667420\n",
      "Params: tensor([ 3.4942, -6.3793])\n",
      "Grad:   tensor([-0.1747,  0.9887])\n",
      "Epoch 448, Loss 11.657352\n",
      "Params: tensor([ 3.4960, -6.3891])\n",
      "Grad:   tensor([-0.1744,  0.9870])\n",
      "Epoch 449, Loss 11.647312\n",
      "Params: tensor([ 3.4977, -6.3990])\n",
      "Grad:   tensor([-0.1741,  0.9853])\n",
      "Epoch 450, Loss 11.637310\n",
      "Params: tensor([ 3.4994, -6.4088])\n",
      "Grad:   tensor([-0.1738,  0.9837])\n",
      "Epoch 451, Loss 11.627338\n",
      "Params: tensor([ 3.5012, -6.4186])\n",
      "Grad:   tensor([-0.1735,  0.9820])\n",
      "Epoch 452, Loss 11.617408\n",
      "Params: tensor([ 3.5029, -6.4285])\n",
      "Grad:   tensor([-0.1732,  0.9803])\n",
      "Epoch 453, Loss 11.607502\n",
      "Params: tensor([ 3.5046, -6.4382])\n",
      "Grad:   tensor([-0.1729,  0.9787])\n",
      "Epoch 454, Loss 11.597635\n",
      "Params: tensor([ 3.5064, -6.4480])\n",
      "Grad:   tensor([-0.1726,  0.9770])\n",
      "Epoch 455, Loss 11.587800\n",
      "Params: tensor([ 3.5081, -6.4578])\n",
      "Grad:   tensor([-0.1723,  0.9753])\n",
      "Epoch 456, Loss 11.577999\n",
      "Params: tensor([ 3.5098, -6.4675])\n",
      "Grad:   tensor([-0.1720,  0.9737])\n",
      "Epoch 457, Loss 11.568232\n",
      "Params: tensor([ 3.5115, -6.4772])\n",
      "Grad:   tensor([-0.1717,  0.9720])\n",
      "Epoch 458, Loss 11.558496\n",
      "Params: tensor([ 3.5132, -6.4869])\n",
      "Grad:   tensor([-0.1714,  0.9704])\n",
      "Epoch 459, Loss 11.548796\n",
      "Params: tensor([ 3.5149, -6.4966])\n",
      "Grad:   tensor([-0.1711,  0.9687])\n",
      "Epoch 460, Loss 11.539128\n",
      "Params: tensor([ 3.5167, -6.5063])\n",
      "Grad:   tensor([-0.1708,  0.9671])\n",
      "Epoch 461, Loss 11.529491\n",
      "Params: tensor([ 3.5184, -6.5159])\n",
      "Grad:   tensor([-0.1706,  0.9654])\n",
      "Epoch 462, Loss 11.519887\n",
      "Params: tensor([ 3.5201, -6.5256])\n",
      "Grad:   tensor([-0.1702,  0.9638])\n",
      "Epoch 463, Loss 11.510315\n",
      "Params: tensor([ 3.5218, -6.5352])\n",
      "Grad:   tensor([-0.1700,  0.9622])\n",
      "Epoch 464, Loss 11.500778\n",
      "Params: tensor([ 3.5235, -6.5448])\n",
      "Grad:   tensor([-0.1697,  0.9605])\n",
      "Epoch 465, Loss 11.491272\n",
      "Params: tensor([ 3.5252, -6.5544])\n",
      "Grad:   tensor([-0.1694,  0.9589])\n",
      "Epoch 466, Loss 11.481797\n",
      "Params: tensor([ 3.5268, -6.5640])\n",
      "Grad:   tensor([-0.1691,  0.9573])\n",
      "Epoch 467, Loss 11.472355\n",
      "Params: tensor([ 3.5285, -6.5735])\n",
      "Grad:   tensor([-0.1688,  0.9556])\n",
      "Epoch 468, Loss 11.462946\n",
      "Params: tensor([ 3.5302, -6.5831])\n",
      "Grad:   tensor([-0.1685,  0.9540])\n",
      "Epoch 469, Loss 11.453568\n",
      "Params: tensor([ 3.5319, -6.5926])\n",
      "Grad:   tensor([-0.1682,  0.9524])\n",
      "Epoch 470, Loss 11.444226\n",
      "Params: tensor([ 3.5336, -6.6021])\n",
      "Grad:   tensor([-0.1679,  0.9508])\n",
      "Epoch 471, Loss 11.434912\n",
      "Params: tensor([ 3.5353, -6.6116])\n",
      "Grad:   tensor([-0.1677,  0.9492])\n",
      "Epoch 472, Loss 11.425629\n",
      "Params: tensor([ 3.5369, -6.6211])\n",
      "Grad:   tensor([-0.1674,  0.9475])\n",
      "Epoch 473, Loss 11.416378\n",
      "Params: tensor([ 3.5386, -6.6305])\n",
      "Grad:   tensor([-0.1671,  0.9459])\n",
      "Epoch 474, Loss 11.407158\n",
      "Params: tensor([ 3.5403, -6.6400])\n",
      "Grad:   tensor([-0.1668,  0.9443])\n",
      "Epoch 475, Loss 11.397969\n",
      "Params: tensor([ 3.5419, -6.6494])\n",
      "Grad:   tensor([-0.1665,  0.9427])\n",
      "Epoch 476, Loss 11.388813\n",
      "Params: tensor([ 3.5436, -6.6588])\n",
      "Grad:   tensor([-0.1662,  0.9411])\n",
      "Epoch 477, Loss 11.379686\n",
      "Params: tensor([ 3.5453, -6.6682])\n",
      "Grad:   tensor([-0.1660,  0.9395])\n",
      "Epoch 478, Loss 11.370591\n",
      "Params: tensor([ 3.5469, -6.6776])\n",
      "Grad:   tensor([-0.1657,  0.9379])\n",
      "Epoch 479, Loss 11.361527\n",
      "Params: tensor([ 3.5486, -6.6869])\n",
      "Grad:   tensor([-0.1654,  0.9363])\n",
      "Epoch 480, Loss 11.352492\n",
      "Params: tensor([ 3.5502, -6.6963])\n",
      "Grad:   tensor([-0.1651,  0.9347])\n",
      "Epoch 481, Loss 11.343492\n",
      "Params: tensor([ 3.5519, -6.7056])\n",
      "Grad:   tensor([-0.1648,  0.9332])\n",
      "Epoch 482, Loss 11.334520\n",
      "Params: tensor([ 3.5535, -6.7149])\n",
      "Grad:   tensor([-0.1646,  0.9316])\n",
      "Epoch 483, Loss 11.325581\n",
      "Params: tensor([ 3.5552, -6.7242])\n",
      "Grad:   tensor([-0.1643,  0.9300])\n",
      "Epoch 484, Loss 11.316667\n",
      "Params: tensor([ 3.5568, -6.7335])\n",
      "Grad:   tensor([-0.1640,  0.9284])\n",
      "Epoch 485, Loss 11.307789\n",
      "Params: tensor([ 3.5584, -6.7428])\n",
      "Grad:   tensor([-0.1637,  0.9268])\n",
      "Epoch 486, Loss 11.298936\n",
      "Params: tensor([ 3.5601, -6.7520])\n",
      "Grad:   tensor([-0.1635,  0.9253])\n",
      "Epoch 487, Loss 11.290116\n",
      "Params: tensor([ 3.5617, -6.7613])\n",
      "Grad:   tensor([-0.1632,  0.9237])\n",
      "Epoch 488, Loss 11.281322\n",
      "Params: tensor([ 3.5633, -6.7705])\n",
      "Grad:   tensor([-0.1629,  0.9221])\n",
      "Epoch 489, Loss 11.272564\n",
      "Params: tensor([ 3.5650, -6.7797])\n",
      "Grad:   tensor([-0.1626,  0.9206])\n",
      "Epoch 490, Loss 11.263832\n",
      "Params: tensor([ 3.5666, -6.7889])\n",
      "Grad:   tensor([-0.1623,  0.9190])\n",
      "Epoch 491, Loss 11.255133\n",
      "Params: tensor([ 3.5682, -6.7981])\n",
      "Grad:   tensor([-0.1621,  0.9174])\n",
      "Epoch 492, Loss 11.246461\n",
      "Params: tensor([ 3.5698, -6.8072])\n",
      "Grad:   tensor([-0.1618,  0.9159])\n",
      "Epoch 493, Loss 11.237817\n",
      "Params: tensor([ 3.5714, -6.8164])\n",
      "Grad:   tensor([-0.1615,  0.9143])\n",
      "Epoch 494, Loss 11.229205\n",
      "Params: tensor([ 3.5730, -6.8255])\n",
      "Grad:   tensor([-0.1613,  0.9128])\n",
      "Epoch 495, Loss 11.220618\n",
      "Params: tensor([ 3.5747, -6.8346])\n",
      "Grad:   tensor([-0.1610,  0.9112])\n",
      "Epoch 496, Loss 11.212064\n",
      "Params: tensor([ 3.5763, -6.8437])\n",
      "Grad:   tensor([-0.1607,  0.9097])\n",
      "Epoch 497, Loss 11.203541\n",
      "Params: tensor([ 3.5779, -6.8528])\n",
      "Grad:   tensor([-0.1604,  0.9081])\n",
      "Epoch 498, Loss 11.195043\n",
      "Params: tensor([ 3.5795, -6.8618])\n",
      "Grad:   tensor([-0.1601,  0.9066])\n",
      "Epoch 499, Loss 11.186572\n",
      "Params: tensor([ 3.5811, -6.8709])\n",
      "Grad:   tensor([-0.1599,  0.9050])\n",
      "Epoch 500, Loss 11.178135\n",
      "Params: tensor([ 3.5827, -6.8799])\n",
      "Grad:   tensor([-0.1596,  0.9035])\n",
      "Epoch 501, Loss 11.169724\n",
      "Params: tensor([ 3.5843, -6.8890])\n",
      "Grad:   tensor([-0.1593,  0.9020])\n",
      "Epoch 502, Loss 11.161343\n",
      "Params: tensor([ 3.5858, -6.8980])\n",
      "Grad:   tensor([-0.1591,  0.9004])\n",
      "Epoch 503, Loss 11.152990\n",
      "Params: tensor([ 3.5874, -6.9069])\n",
      "Grad:   tensor([-0.1588,  0.8989])\n",
      "Epoch 504, Loss 11.144665\n",
      "Params: tensor([ 3.5890, -6.9159])\n",
      "Grad:   tensor([-0.1585,  0.8974])\n",
      "Epoch 505, Loss 11.136368\n",
      "Params: tensor([ 3.5906, -6.9249])\n",
      "Grad:   tensor([-0.1582,  0.8958])\n",
      "Epoch 506, Loss 11.128098\n",
      "Params: tensor([ 3.5922, -6.9338])\n",
      "Grad:   tensor([-0.1580,  0.8943])\n",
      "Epoch 507, Loss 11.119857\n",
      "Params: tensor([ 3.5938, -6.9427])\n",
      "Grad:   tensor([-0.1577,  0.8928])\n",
      "Epoch 508, Loss 11.111647\n",
      "Params: tensor([ 3.5953, -6.9517])\n",
      "Grad:   tensor([-0.1575,  0.8913])\n",
      "Epoch 509, Loss 11.103461\n",
      "Params: tensor([ 3.5969, -6.9606])\n",
      "Grad:   tensor([-0.1572,  0.8898])\n",
      "Epoch 510, Loss 11.095302\n",
      "Params: tensor([ 3.5985, -6.9694])\n",
      "Grad:   tensor([-0.1569,  0.8883])\n",
      "Epoch 511, Loss 11.087173\n",
      "Params: tensor([ 3.6000, -6.9783])\n",
      "Grad:   tensor([-0.1566,  0.8868])\n",
      "Epoch 512, Loss 11.079070\n",
      "Params: tensor([ 3.6016, -6.9872])\n",
      "Grad:   tensor([-0.1564,  0.8852])\n",
      "Epoch 513, Loss 11.070995\n",
      "Params: tensor([ 3.6032, -6.9960])\n",
      "Grad:   tensor([-0.1561,  0.8837])\n",
      "Epoch 514, Loss 11.062951\n",
      "Params: tensor([ 3.6047, -7.0048])\n",
      "Grad:   tensor([-0.1559,  0.8822])\n",
      "Epoch 515, Loss 11.054931\n",
      "Params: tensor([ 3.6063, -7.0136])\n",
      "Grad:   tensor([-0.1556,  0.8807])\n",
      "Epoch 516, Loss 11.046937\n",
      "Params: tensor([ 3.6078, -7.0224])\n",
      "Grad:   tensor([-0.1553,  0.8792])\n",
      "Epoch 517, Loss 11.038975\n",
      "Params: tensor([ 3.6094, -7.0312])\n",
      "Grad:   tensor([-0.1550,  0.8778])\n",
      "Epoch 518, Loss 11.031034\n",
      "Params: tensor([ 3.6109, -7.0400])\n",
      "Grad:   tensor([-0.1548,  0.8763])\n",
      "Epoch 519, Loss 11.023121\n",
      "Params: tensor([ 3.6125, -7.0487])\n",
      "Grad:   tensor([-0.1545,  0.8748])\n",
      "Epoch 520, Loss 11.015239\n",
      "Params: tensor([ 3.6140, -7.0574])\n",
      "Grad:   tensor([-0.1543,  0.8733])\n",
      "Epoch 521, Loss 11.007382\n",
      "Params: tensor([ 3.6156, -7.0662])\n",
      "Grad:   tensor([-0.1540,  0.8718])\n",
      "Epoch 522, Loss 10.999549\n",
      "Params: tensor([ 3.6171, -7.0749])\n",
      "Grad:   tensor([-0.1537,  0.8703])\n",
      "Epoch 523, Loss 10.991746\n",
      "Params: tensor([ 3.6186, -7.0836])\n",
      "Grad:   tensor([-0.1535,  0.8688])\n",
      "Epoch 524, Loss 10.983968\n",
      "Params: tensor([ 3.6202, -7.0922])\n",
      "Grad:   tensor([-0.1532,  0.8674])\n",
      "Epoch 525, Loss 10.976215\n",
      "Params: tensor([ 3.6217, -7.1009])\n",
      "Grad:   tensor([-0.1530,  0.8659])\n",
      "Epoch 526, Loss 10.968492\n",
      "Params: tensor([ 3.6232, -7.1095])\n",
      "Grad:   tensor([-0.1527,  0.8644])\n",
      "Epoch 527, Loss 10.960793\n",
      "Params: tensor([ 3.6247, -7.1182])\n",
      "Grad:   tensor([-0.1524,  0.8630])\n",
      "Epoch 528, Loss 10.953118\n",
      "Params: tensor([ 3.6263, -7.1268])\n",
      "Grad:   tensor([-0.1522,  0.8615])\n",
      "Epoch 529, Loss 10.945474\n",
      "Params: tensor([ 3.6278, -7.1354])\n",
      "Grad:   tensor([-0.1519,  0.8600])\n",
      "Epoch 530, Loss 10.937852\n",
      "Params: tensor([ 3.6293, -7.1440])\n",
      "Grad:   tensor([-0.1517,  0.8586])\n",
      "Epoch 531, Loss 10.930257\n",
      "Params: tensor([ 3.6308, -7.1525])\n",
      "Grad:   tensor([-0.1514,  0.8571])\n",
      "Epoch 532, Loss 10.922688\n",
      "Params: tensor([ 3.6323, -7.1611])\n",
      "Grad:   tensor([-0.1512,  0.8557])\n",
      "Epoch 533, Loss 10.915145\n",
      "Params: tensor([ 3.6338, -7.1696])\n",
      "Grad:   tensor([-0.1509,  0.8542])\n",
      "Epoch 534, Loss 10.907627\n",
      "Params: tensor([ 3.6353, -7.1782])\n",
      "Grad:   tensor([-0.1506,  0.8527])\n",
      "Epoch 535, Loss 10.900132\n",
      "Params: tensor([ 3.6368, -7.1867])\n",
      "Grad:   tensor([-0.1504,  0.8513])\n",
      "Epoch 536, Loss 10.892667\n",
      "Params: tensor([ 3.6383, -7.1952])\n",
      "Grad:   tensor([-0.1501,  0.8499])\n",
      "Epoch 537, Loss 10.885227\n",
      "Params: tensor([ 3.6398, -7.2036])\n",
      "Grad:   tensor([-0.1499,  0.8484])\n",
      "Epoch 538, Loss 10.877811\n",
      "Params: tensor([ 3.6413, -7.2121])\n",
      "Grad:   tensor([-0.1496,  0.8470])\n",
      "Epoch 539, Loss 10.870419\n",
      "Params: tensor([ 3.6428, -7.2206])\n",
      "Grad:   tensor([-0.1494,  0.8455])\n",
      "Epoch 540, Loss 10.863053\n",
      "Params: tensor([ 3.6443, -7.2290])\n",
      "Grad:   tensor([-0.1491,  0.8441])\n",
      "Epoch 541, Loss 10.855709\n",
      "Params: tensor([ 3.6458, -7.2374])\n",
      "Grad:   tensor([-0.1489,  0.8427])\n",
      "Epoch 542, Loss 10.848395\n",
      "Params: tensor([ 3.6473, -7.2459])\n",
      "Grad:   tensor([-0.1486,  0.8412])\n",
      "Epoch 543, Loss 10.841104\n",
      "Params: tensor([ 3.6488, -7.2543])\n",
      "Grad:   tensor([-0.1484,  0.8398])\n",
      "Epoch 544, Loss 10.833838\n",
      "Params: tensor([ 3.6503, -7.2626])\n",
      "Grad:   tensor([-0.1481,  0.8384])\n",
      "Epoch 545, Loss 10.826592\n",
      "Params: tensor([ 3.6517, -7.2710])\n",
      "Grad:   tensor([-0.1478,  0.8369])\n",
      "Epoch 546, Loss 10.819378\n",
      "Params: tensor([ 3.6532, -7.2794])\n",
      "Grad:   tensor([-0.1476,  0.8355])\n",
      "Epoch 547, Loss 10.812183\n",
      "Params: tensor([ 3.6547, -7.2877])\n",
      "Grad:   tensor([-0.1474,  0.8341])\n",
      "Epoch 548, Loss 10.805015\n",
      "Params: tensor([ 3.6562, -7.2960])\n",
      "Grad:   tensor([-0.1471,  0.8327])\n",
      "Epoch 549, Loss 10.797872\n",
      "Params: tensor([ 3.6576, -7.3043])\n",
      "Grad:   tensor([-0.1468,  0.8313])\n",
      "Epoch 550, Loss 10.790752\n",
      "Params: tensor([ 3.6591, -7.3126])\n",
      "Grad:   tensor([-0.1466,  0.8299])\n",
      "Epoch 551, Loss 10.783659\n",
      "Params: tensor([ 3.6606, -7.3209])\n",
      "Grad:   tensor([-0.1463,  0.8285])\n",
      "Epoch 552, Loss 10.776587\n",
      "Params: tensor([ 3.6620, -7.3292])\n",
      "Grad:   tensor([-0.1461,  0.8270])\n",
      "Epoch 553, Loss 10.769539\n",
      "Params: tensor([ 3.6635, -7.3375])\n",
      "Grad:   tensor([-0.1458,  0.8256])\n",
      "Epoch 554, Loss 10.762514\n",
      "Params: tensor([ 3.6649, -7.3457])\n",
      "Grad:   tensor([-0.1456,  0.8242])\n",
      "Epoch 555, Loss 10.755517\n",
      "Params: tensor([ 3.6664, -7.3539])\n",
      "Grad:   tensor([-0.1454,  0.8228])\n",
      "Epoch 556, Loss 10.748539\n",
      "Params: tensor([ 3.6678, -7.3621])\n",
      "Grad:   tensor([-0.1451,  0.8214])\n",
      "Epoch 557, Loss 10.741587\n",
      "Params: tensor([ 3.6693, -7.3703])\n",
      "Grad:   tensor([-0.1449,  0.8200])\n",
      "Epoch 558, Loss 10.734657\n",
      "Params: tensor([ 3.6707, -7.3785])\n",
      "Grad:   tensor([-0.1446,  0.8187])\n",
      "Epoch 559, Loss 10.727754\n",
      "Params: tensor([ 3.6722, -7.3867])\n",
      "Grad:   tensor([-0.1444,  0.8173])\n",
      "Epoch 560, Loss 10.720872\n",
      "Params: tensor([ 3.6736, -7.3949])\n",
      "Grad:   tensor([-0.1441,  0.8159])\n",
      "Epoch 561, Loss 10.714012\n",
      "Params: tensor([ 3.6751, -7.4030])\n",
      "Grad:   tensor([-0.1439,  0.8145])\n",
      "Epoch 562, Loss 10.707176\n",
      "Params: tensor([ 3.6765, -7.4111])\n",
      "Grad:   tensor([-0.1436,  0.8131])\n",
      "Epoch 563, Loss 10.700367\n",
      "Params: tensor([ 3.6779, -7.4192])\n",
      "Grad:   tensor([-0.1434,  0.8117])\n",
      "Epoch 564, Loss 10.693578\n",
      "Params: tensor([ 3.6794, -7.4274])\n",
      "Grad:   tensor([-0.1432,  0.8103])\n",
      "Epoch 565, Loss 10.686812\n",
      "Params: tensor([ 3.6808, -7.4354])\n",
      "Grad:   tensor([-0.1429,  0.8090])\n",
      "Epoch 566, Loss 10.680070\n",
      "Params: tensor([ 3.6822, -7.4435])\n",
      "Grad:   tensor([-0.1427,  0.8076])\n",
      "Epoch 567, Loss 10.673349\n",
      "Params: tensor([ 3.6836, -7.4516])\n",
      "Grad:   tensor([-0.1424,  0.8062])\n",
      "Epoch 568, Loss 10.666655\n",
      "Params: tensor([ 3.6851, -7.4596])\n",
      "Grad:   tensor([-0.1422,  0.8049])\n",
      "Epoch 569, Loss 10.659977\n",
      "Params: tensor([ 3.6865, -7.4677])\n",
      "Grad:   tensor([-0.1419,  0.8035])\n",
      "Epoch 570, Loss 10.653327\n",
      "Params: tensor([ 3.6879, -7.4757])\n",
      "Grad:   tensor([-0.1417,  0.8021])\n",
      "Epoch 571, Loss 10.646699\n",
      "Params: tensor([ 3.6893, -7.4837])\n",
      "Grad:   tensor([-0.1415,  0.8008])\n",
      "Epoch 572, Loss 10.640087\n",
      "Params: tensor([ 3.6907, -7.4917])\n",
      "Grad:   tensor([-0.1412,  0.7994])\n",
      "Epoch 573, Loss 10.633506\n",
      "Params: tensor([ 3.6921, -7.4997])\n",
      "Grad:   tensor([-0.1410,  0.7980])\n",
      "Epoch 574, Loss 10.626946\n",
      "Params: tensor([ 3.6935, -7.5076])\n",
      "Grad:   tensor([-0.1407,  0.7967])\n",
      "Epoch 575, Loss 10.620405\n",
      "Params: tensor([ 3.6950, -7.5156])\n",
      "Grad:   tensor([-0.1405,  0.7953])\n",
      "Epoch 576, Loss 10.613885\n",
      "Params: tensor([ 3.6964, -7.5235])\n",
      "Grad:   tensor([-0.1403,  0.7940])\n",
      "Epoch 577, Loss 10.607392\n",
      "Params: tensor([ 3.6978, -7.5315])\n",
      "Grad:   tensor([-0.1400,  0.7926])\n",
      "Epoch 578, Loss 10.600919\n",
      "Params: tensor([ 3.6992, -7.5394])\n",
      "Grad:   tensor([-0.1398,  0.7913])\n",
      "Epoch 579, Loss 10.594468\n",
      "Params: tensor([ 3.7005, -7.5473])\n",
      "Grad:   tensor([-0.1395,  0.7899])\n",
      "Epoch 580, Loss 10.588039\n",
      "Params: tensor([ 3.7019, -7.5552])\n",
      "Grad:   tensor([-0.1393,  0.7886])\n",
      "Epoch 581, Loss 10.581629\n",
      "Params: tensor([ 3.7033, -7.5630])\n",
      "Grad:   tensor([-0.1391,  0.7873])\n",
      "Epoch 582, Loss 10.575245\n",
      "Params: tensor([ 3.7047, -7.5709])\n",
      "Grad:   tensor([-0.1388,  0.7859])\n",
      "Epoch 583, Loss 10.568882\n",
      "Params: tensor([ 3.7061, -7.5787])\n",
      "Grad:   tensor([-0.1386,  0.7846])\n",
      "Epoch 584, Loss 10.562538\n",
      "Params: tensor([ 3.7075, -7.5866])\n",
      "Grad:   tensor([-0.1384,  0.7833])\n",
      "Epoch 585, Loss 10.556217\n",
      "Params: tensor([ 3.7089, -7.5944])\n",
      "Grad:   tensor([-0.1381,  0.7819])\n",
      "Epoch 586, Loss 10.549919\n",
      "Params: tensor([ 3.7102, -7.6022])\n",
      "Grad:   tensor([-0.1379,  0.7806])\n",
      "Epoch 587, Loss 10.543643\n",
      "Params: tensor([ 3.7116, -7.6100])\n",
      "Grad:   tensor([-0.1377,  0.7793])\n",
      "Epoch 588, Loss 10.537383\n",
      "Params: tensor([ 3.7130, -7.6178])\n",
      "Grad:   tensor([-0.1374,  0.7779])\n",
      "Epoch 589, Loss 10.531148\n",
      "Params: tensor([ 3.7144, -7.6255])\n",
      "Grad:   tensor([-0.1372,  0.7766])\n",
      "Epoch 590, Loss 10.524934\n",
      "Params: tensor([ 3.7157, -7.6333])\n",
      "Grad:   tensor([-0.1370,  0.7753])\n",
      "Epoch 591, Loss 10.518740\n",
      "Params: tensor([ 3.7171, -7.6410])\n",
      "Grad:   tensor([-0.1367,  0.7740])\n",
      "Epoch 592, Loss 10.512568\n",
      "Params: tensor([ 3.7185, -7.6487])\n",
      "Grad:   tensor([-0.1365,  0.7727])\n",
      "Epoch 593, Loss 10.506418\n",
      "Params: tensor([ 3.7198, -7.6565])\n",
      "Grad:   tensor([-0.1363,  0.7714])\n",
      "Epoch 594, Loss 10.500286\n",
      "Params: tensor([ 3.7212, -7.6642])\n",
      "Grad:   tensor([-0.1360,  0.7700])\n",
      "Epoch 595, Loss 10.494177\n",
      "Params: tensor([ 3.7226, -7.6718])\n",
      "Grad:   tensor([-0.1358,  0.7687])\n",
      "Epoch 596, Loss 10.488090\n",
      "Params: tensor([ 3.7239, -7.6795])\n",
      "Grad:   tensor([-0.1356,  0.7674])\n",
      "Epoch 597, Loss 10.482021\n",
      "Params: tensor([ 3.7253, -7.6872])\n",
      "Grad:   tensor([-0.1353,  0.7661])\n",
      "Epoch 598, Loss 10.475974\n",
      "Params: tensor([ 3.7266, -7.6948])\n",
      "Grad:   tensor([-0.1351,  0.7648])\n",
      "Epoch 599, Loss 10.469945\n",
      "Params: tensor([ 3.7280, -7.7025])\n",
      "Grad:   tensor([-0.1349,  0.7635])\n",
      "Epoch 600, Loss 10.463943\n",
      "Params: tensor([ 3.7293, -7.7101])\n",
      "Grad:   tensor([-0.1347,  0.7622])\n",
      "Epoch 601, Loss 10.457953\n",
      "Params: tensor([ 3.7307, -7.7177])\n",
      "Grad:   tensor([-0.1344,  0.7609])\n",
      "Epoch 602, Loss 10.451987\n",
      "Params: tensor([ 3.7320, -7.7253])\n",
      "Grad:   tensor([-0.1342,  0.7596])\n",
      "Epoch 603, Loss 10.446042\n",
      "Params: tensor([ 3.7333, -7.7329])\n",
      "Grad:   tensor([-0.1340,  0.7584])\n",
      "Epoch 604, Loss 10.440116\n",
      "Params: tensor([ 3.7347, -7.7404])\n",
      "Grad:   tensor([-0.1337,  0.7571])\n",
      "Epoch 605, Loss 10.434212\n",
      "Params: tensor([ 3.7360, -7.7480])\n",
      "Grad:   tensor([-0.1335,  0.7558])\n",
      "Epoch 606, Loss 10.428326\n",
      "Params: tensor([ 3.7373, -7.7555])\n",
      "Grad:   tensor([-0.1333,  0.7545])\n",
      "Epoch 607, Loss 10.422460\n",
      "Params: tensor([ 3.7387, -7.7631])\n",
      "Grad:   tensor([-0.1331,  0.7532])\n",
      "Epoch 608, Loss 10.416615\n",
      "Params: tensor([ 3.7400, -7.7706])\n",
      "Grad:   tensor([-0.1328,  0.7519])\n",
      "Epoch 609, Loss 10.410790\n",
      "Params: tensor([ 3.7413, -7.7781])\n",
      "Grad:   tensor([-0.1326,  0.7507])\n",
      "Epoch 610, Loss 10.404984\n",
      "Params: tensor([ 3.7427, -7.7856])\n",
      "Grad:   tensor([-0.1324,  0.7494])\n",
      "Epoch 611, Loss 10.399197\n",
      "Params: tensor([ 3.7440, -7.7931])\n",
      "Grad:   tensor([-0.1322,  0.7481])\n",
      "Epoch 612, Loss 10.393428\n",
      "Params: tensor([ 3.7453, -7.8006])\n",
      "Grad:   tensor([-0.1319,  0.7468])\n",
      "Epoch 613, Loss 10.387684\n",
      "Params: tensor([ 3.7466, -7.8080])\n",
      "Grad:   tensor([-0.1317,  0.7456])\n",
      "Epoch 614, Loss 10.381957\n",
      "Params: tensor([ 3.7479, -7.8154])\n",
      "Grad:   tensor([-0.1315,  0.7443])\n",
      "Epoch 615, Loss 10.376250\n",
      "Params: tensor([ 3.7492, -7.8229])\n",
      "Grad:   tensor([-0.1313,  0.7430])\n",
      "Epoch 616, Loss 10.370560\n",
      "Params: tensor([ 3.7505, -7.8303])\n",
      "Grad:   tensor([-0.1310,  0.7418])\n",
      "Epoch 617, Loss 10.364890\n",
      "Params: tensor([ 3.7519, -7.8377])\n",
      "Grad:   tensor([-0.1308,  0.7405])\n",
      "Epoch 618, Loss 10.359241\n",
      "Params: tensor([ 3.7532, -7.8451])\n",
      "Grad:   tensor([-0.1306,  0.7393])\n",
      "Epoch 619, Loss 10.353610\n",
      "Params: tensor([ 3.7545, -7.8525])\n",
      "Grad:   tensor([-0.1304,  0.7380])\n",
      "Epoch 620, Loss 10.347999\n",
      "Params: tensor([ 3.7558, -7.8598])\n",
      "Grad:   tensor([-0.1301,  0.7367])\n",
      "Epoch 621, Loss 10.342405\n",
      "Params: tensor([ 3.7571, -7.8672])\n",
      "Grad:   tensor([-0.1299,  0.7355])\n",
      "Epoch 622, Loss 10.336834\n",
      "Params: tensor([ 3.7584, -7.8745])\n",
      "Grad:   tensor([-0.1297,  0.7342])\n",
      "Epoch 623, Loss 10.331278\n",
      "Params: tensor([ 3.7597, -7.8819])\n",
      "Grad:   tensor([-0.1295,  0.7330])\n",
      "Epoch 624, Loss 10.325743\n",
      "Params: tensor([ 3.7609, -7.8892])\n",
      "Grad:   tensor([-0.1293,  0.7318])\n",
      "Epoch 625, Loss 10.320222\n",
      "Params: tensor([ 3.7622, -7.8965])\n",
      "Grad:   tensor([-0.1290,  0.7305])\n",
      "Epoch 626, Loss 10.314727\n",
      "Params: tensor([ 3.7635, -7.9038])\n",
      "Grad:   tensor([-0.1288,  0.7293])\n",
      "Epoch 627, Loss 10.309248\n",
      "Params: tensor([ 3.7648, -7.9111])\n",
      "Grad:   tensor([-0.1286,  0.7280])\n",
      "Epoch 628, Loss 10.303786\n",
      "Params: tensor([ 3.7661, -7.9183])\n",
      "Grad:   tensor([-0.1284,  0.7268])\n",
      "Epoch 629, Loss 10.298344\n",
      "Params: tensor([ 3.7674, -7.9256])\n",
      "Grad:   tensor([-0.1282,  0.7256])\n",
      "Epoch 630, Loss 10.292919\n",
      "Params: tensor([ 3.7687, -7.9328])\n",
      "Grad:   tensor([-0.1280,  0.7243])\n",
      "Epoch 631, Loss 10.287513\n",
      "Params: tensor([ 3.7699, -7.9401])\n",
      "Grad:   tensor([-0.1277,  0.7231])\n",
      "Epoch 632, Loss 10.282126\n",
      "Params: tensor([ 3.7712, -7.9473])\n",
      "Grad:   tensor([-0.1275,  0.7219])\n",
      "Epoch 633, Loss 10.276757\n",
      "Params: tensor([ 3.7725, -7.9545])\n",
      "Grad:   tensor([-0.1273,  0.7206])\n",
      "Epoch 634, Loss 10.271406\n",
      "Params: tensor([ 3.7738, -7.9617])\n",
      "Grad:   tensor([-0.1271,  0.7194])\n",
      "Epoch 635, Loss 10.266073\n",
      "Params: tensor([ 3.7750, -7.9689])\n",
      "Grad:   tensor([-0.1269,  0.7182])\n",
      "Epoch 636, Loss 10.260761\n",
      "Params: tensor([ 3.7763, -7.9760])\n",
      "Grad:   tensor([-0.1266,  0.7170])\n",
      "Epoch 637, Loss 10.255463\n",
      "Params: tensor([ 3.7776, -7.9832])\n",
      "Grad:   tensor([-0.1264,  0.7158])\n",
      "Epoch 638, Loss 10.250184\n",
      "Params: tensor([ 3.7788, -7.9903])\n",
      "Grad:   tensor([-0.1262,  0.7145])\n",
      "Epoch 639, Loss 10.244923\n",
      "Params: tensor([ 3.7801, -7.9975])\n",
      "Grad:   tensor([-0.1260,  0.7133])\n",
      "Epoch 640, Loss 10.239681\n",
      "Params: tensor([ 3.7813, -8.0046])\n",
      "Grad:   tensor([-0.1258,  0.7121])\n",
      "Epoch 641, Loss 10.234455\n",
      "Params: tensor([ 3.7826, -8.0117])\n",
      "Grad:   tensor([-0.1256,  0.7109])\n",
      "Epoch 642, Loss 10.229249\n",
      "Params: tensor([ 3.7838, -8.0188])\n",
      "Grad:   tensor([-0.1254,  0.7097])\n",
      "Epoch 643, Loss 10.224058\n",
      "Params: tensor([ 3.7851, -8.0259])\n",
      "Grad:   tensor([-0.1252,  0.7085])\n",
      "Epoch 644, Loss 10.218887\n",
      "Params: tensor([ 3.7863, -8.0330])\n",
      "Grad:   tensor([-0.1249,  0.7073])\n",
      "Epoch 645, Loss 10.213731\n",
      "Params: tensor([ 3.7876, -8.0400])\n",
      "Grad:   tensor([-0.1247,  0.7061])\n",
      "Epoch 646, Loss 10.208596\n",
      "Params: tensor([ 3.7888, -8.0471])\n",
      "Grad:   tensor([-0.1245,  0.7049])\n",
      "Epoch 647, Loss 10.203477\n",
      "Params: tensor([ 3.7901, -8.0541])\n",
      "Grad:   tensor([-0.1243,  0.7037])\n",
      "Epoch 648, Loss 10.198377\n",
      "Params: tensor([ 3.7913, -8.0611])\n",
      "Grad:   tensor([-0.1241,  0.7025])\n",
      "Epoch 649, Loss 10.193292\n",
      "Params: tensor([ 3.7926, -8.0681])\n",
      "Grad:   tensor([-0.1239,  0.7013])\n",
      "Epoch 650, Loss 10.188223\n",
      "Params: tensor([ 3.7938, -8.0751])\n",
      "Grad:   tensor([-0.1237,  0.7001])\n",
      "Epoch 651, Loss 10.183173\n",
      "Params: tensor([ 3.7950, -8.0821])\n",
      "Grad:   tensor([-0.1235,  0.6989])\n",
      "Epoch 652, Loss 10.178137\n",
      "Params: tensor([ 3.7963, -8.0891])\n",
      "Grad:   tensor([-0.1233,  0.6977])\n",
      "Epoch 653, Loss 10.173123\n",
      "Params: tensor([ 3.7975, -8.0961])\n",
      "Grad:   tensor([-0.1230,  0.6966])\n",
      "Epoch 654, Loss 10.168124\n",
      "Params: tensor([ 3.7987, -8.1030])\n",
      "Grad:   tensor([-0.1228,  0.6954])\n",
      "Epoch 655, Loss 10.163141\n",
      "Params: tensor([ 3.8000, -8.1100])\n",
      "Grad:   tensor([-0.1226,  0.6942])\n",
      "Epoch 656, Loss 10.158179\n",
      "Params: tensor([ 3.8012, -8.1169])\n",
      "Grad:   tensor([-0.1224,  0.6930])\n",
      "Epoch 657, Loss 10.153231\n",
      "Params: tensor([ 3.8024, -8.1238])\n",
      "Grad:   tensor([-0.1222,  0.6918])\n",
      "Epoch 658, Loss 10.148299\n",
      "Params: tensor([ 3.8036, -8.1307])\n",
      "Grad:   tensor([-0.1220,  0.6907])\n",
      "Epoch 659, Loss 10.143383\n",
      "Params: tensor([ 3.8048, -8.1376])\n",
      "Grad:   tensor([-0.1218,  0.6895])\n",
      "Epoch 660, Loss 10.138483\n",
      "Params: tensor([ 3.8061, -8.1445])\n",
      "Grad:   tensor([-0.1216,  0.6883])\n",
      "Epoch 661, Loss 10.133604\n",
      "Params: tensor([ 3.8073, -8.1514])\n",
      "Grad:   tensor([-0.1214,  0.6871])\n",
      "Epoch 662, Loss 10.128739\n",
      "Params: tensor([ 3.8085, -8.1582])\n",
      "Grad:   tensor([-0.1212,  0.6860])\n",
      "Epoch 663, Loss 10.123891\n",
      "Params: tensor([ 3.8097, -8.1651])\n",
      "Grad:   tensor([-0.1210,  0.6848])\n",
      "Epoch 664, Loss 10.119058\n",
      "Params: tensor([ 3.8109, -8.1719])\n",
      "Grad:   tensor([-0.1208,  0.6836])\n",
      "Epoch 665, Loss 10.114244\n",
      "Params: tensor([ 3.8121, -8.1787])\n",
      "Grad:   tensor([-0.1206,  0.6825])\n",
      "Epoch 666, Loss 10.109447\n",
      "Params: tensor([ 3.8133, -8.1856])\n",
      "Grad:   tensor([-0.1204,  0.6813])\n",
      "Epoch 667, Loss 10.104663\n",
      "Params: tensor([ 3.8145, -8.1924])\n",
      "Grad:   tensor([-0.1202,  0.6802])\n",
      "Epoch 668, Loss 10.099895\n",
      "Params: tensor([ 3.8157, -8.1991])\n",
      "Grad:   tensor([-0.1199,  0.6790])\n",
      "Epoch 669, Loss 10.095146\n",
      "Params: tensor([ 3.8169, -8.2059])\n",
      "Grad:   tensor([-0.1197,  0.6779])\n",
      "Epoch 670, Loss 10.090409\n",
      "Params: tensor([ 3.8181, -8.2127])\n",
      "Grad:   tensor([-0.1195,  0.6767])\n",
      "Epoch 671, Loss 10.085691\n",
      "Params: tensor([ 3.8193, -8.2194])\n",
      "Grad:   tensor([-0.1193,  0.6756])\n",
      "Epoch 672, Loss 10.080988\n",
      "Params: tensor([ 3.8205, -8.2262])\n",
      "Grad:   tensor([-0.1191,  0.6744])\n",
      "Epoch 673, Loss 10.076306\n",
      "Params: tensor([ 3.8217, -8.2329])\n",
      "Grad:   tensor([-0.1189,  0.6733])\n",
      "Epoch 674, Loss 10.071631\n",
      "Params: tensor([ 3.8229, -8.2396])\n",
      "Grad:   tensor([-0.1187,  0.6721])\n",
      "Epoch 675, Loss 10.066978\n",
      "Params: tensor([ 3.8240, -8.2464])\n",
      "Grad:   tensor([-0.1185,  0.6710])\n",
      "Epoch 676, Loss 10.062341\n",
      "Params: tensor([ 3.8252, -8.2531])\n",
      "Grad:   tensor([-0.1183,  0.6698])\n",
      "Epoch 677, Loss 10.057714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: tensor([ 3.8264, -8.2597])\n",
      "Grad:   tensor([-0.1181,  0.6687])\n",
      "Epoch 678, Loss 10.053109\n",
      "Params: tensor([ 3.8276, -8.2664])\n",
      "Grad:   tensor([-0.1179,  0.6676])\n",
      "Epoch 679, Loss 10.048517\n",
      "Params: tensor([ 3.8288, -8.2731])\n",
      "Grad:   tensor([-0.1177,  0.6664])\n",
      "Epoch 680, Loss 10.043941\n",
      "Params: tensor([ 3.8299, -8.2797])\n",
      "Grad:   tensor([-0.1175,  0.6653])\n",
      "Epoch 681, Loss 10.039380\n",
      "Params: tensor([ 3.8311, -8.2864])\n",
      "Grad:   tensor([-0.1173,  0.6642])\n",
      "Epoch 682, Loss 10.034836\n",
      "Params: tensor([ 3.8323, -8.2930])\n",
      "Grad:   tensor([-0.1171,  0.6630])\n",
      "Epoch 683, Loss 10.030307\n",
      "Params: tensor([ 3.8335, -8.2996])\n",
      "Grad:   tensor([-0.1169,  0.6619])\n",
      "Epoch 684, Loss 10.025791\n",
      "Params: tensor([ 3.8346, -8.3062])\n",
      "Grad:   tensor([-0.1167,  0.6608])\n",
      "Epoch 685, Loss 10.021293\n",
      "Params: tensor([ 3.8358, -8.3128])\n",
      "Grad:   tensor([-0.1165,  0.6597])\n",
      "Epoch 686, Loss 10.016809\n",
      "Params: tensor([ 3.8370, -8.3194])\n",
      "Grad:   tensor([-0.1163,  0.6585])\n",
      "Epoch 687, Loss 10.012341\n",
      "Params: tensor([ 3.8381, -8.3260])\n",
      "Grad:   tensor([-0.1161,  0.6574])\n",
      "Epoch 688, Loss 10.007890\n",
      "Params: tensor([ 3.8393, -8.3326])\n",
      "Grad:   tensor([-0.1159,  0.6563])\n",
      "Epoch 689, Loss 10.003452\n",
      "Params: tensor([ 3.8404, -8.3391])\n",
      "Grad:   tensor([-0.1157,  0.6552])\n",
      "Epoch 690, Loss 9.999027\n",
      "Params: tensor([ 3.8416, -8.3456])\n",
      "Grad:   tensor([-0.1155,  0.6541])\n",
      "Epoch 691, Loss 9.994620\n",
      "Params: tensor([ 3.8427, -8.3522])\n",
      "Grad:   tensor([-0.1153,  0.6530])\n",
      "Epoch 692, Loss 9.990228\n",
      "Params: tensor([ 3.8439, -8.3587])\n",
      "Grad:   tensor([-0.1152,  0.6519])\n",
      "Epoch 693, Loss 9.985847\n",
      "Params: tensor([ 3.8450, -8.3652])\n",
      "Grad:   tensor([-0.1150,  0.6508])\n",
      "Epoch 694, Loss 9.981483\n",
      "Params: tensor([ 3.8462, -8.3717])\n",
      "Grad:   tensor([-0.1148,  0.6496])\n",
      "Epoch 695, Loss 9.977136\n",
      "Params: tensor([ 3.8473, -8.3782])\n",
      "Grad:   tensor([-0.1146,  0.6485])\n",
      "Epoch 696, Loss 9.972802\n",
      "Params: tensor([ 3.8485, -8.3847])\n",
      "Grad:   tensor([-0.1144,  0.6474])\n",
      "Epoch 697, Loss 9.968483\n",
      "Params: tensor([ 3.8496, -8.3911])\n",
      "Grad:   tensor([-0.1142,  0.6463])\n",
      "Epoch 698, Loss 9.964179\n",
      "Params: tensor([ 3.8508, -8.3976])\n",
      "Grad:   tensor([-0.1140,  0.6452])\n",
      "Epoch 699, Loss 9.959890\n",
      "Params: tensor([ 3.8519, -8.4040])\n",
      "Grad:   tensor([-0.1138,  0.6441])\n",
      "Epoch 700, Loss 9.955613\n",
      "Params: tensor([ 3.8530, -8.4104])\n",
      "Grad:   tensor([-0.1136,  0.6431])\n",
      "Epoch 701, Loss 9.951354\n",
      "Params: tensor([ 3.8542, -8.4169])\n",
      "Grad:   tensor([-0.1134,  0.6420])\n",
      "Epoch 702, Loss 9.947108\n",
      "Params: tensor([ 3.8553, -8.4233])\n",
      "Grad:   tensor([-0.1132,  0.6409])\n",
      "Epoch 703, Loss 9.942878\n",
      "Params: tensor([ 3.8564, -8.4297])\n",
      "Grad:   tensor([-0.1130,  0.6398])\n",
      "Epoch 704, Loss 9.938659\n",
      "Params: tensor([ 3.8576, -8.4361])\n",
      "Grad:   tensor([-0.1128,  0.6387])\n",
      "Epoch 705, Loss 9.934457\n",
      "Params: tensor([ 3.8587, -8.4424])\n",
      "Grad:   tensor([-0.1126,  0.6376])\n",
      "Epoch 706, Loss 9.930267\n",
      "Params: tensor([ 3.8598, -8.4488])\n",
      "Grad:   tensor([-0.1124,  0.6365])\n",
      "Epoch 707, Loss 9.926093\n",
      "Params: tensor([ 3.8609, -8.4552])\n",
      "Grad:   tensor([-0.1122,  0.6354])\n",
      "Epoch 708, Loss 9.921935\n",
      "Params: tensor([ 3.8620, -8.4615])\n",
      "Grad:   tensor([-0.1121,  0.6344])\n",
      "Epoch 709, Loss 9.917788\n",
      "Params: tensor([ 3.8632, -8.4678])\n",
      "Grad:   tensor([-0.1119,  0.6333])\n",
      "Epoch 710, Loss 9.913652\n",
      "Params: tensor([ 3.8643, -8.4742])\n",
      "Grad:   tensor([-0.1117,  0.6322])\n",
      "Epoch 711, Loss 9.909534\n",
      "Params: tensor([ 3.8654, -8.4805])\n",
      "Grad:   tensor([-0.1115,  0.6311])\n",
      "Epoch 712, Loss 9.905430\n",
      "Params: tensor([ 3.8665, -8.4868])\n",
      "Grad:   tensor([-0.1113,  0.6301])\n",
      "Epoch 713, Loss 9.901340\n",
      "Params: tensor([ 3.8676, -8.4931])\n",
      "Grad:   tensor([-0.1111,  0.6290])\n",
      "Epoch 714, Loss 9.897265\n",
      "Params: tensor([ 3.8687, -8.4993])\n",
      "Grad:   tensor([-0.1109,  0.6279])\n",
      "Epoch 715, Loss 9.893201\n",
      "Params: tensor([ 3.8698, -8.5056])\n",
      "Grad:   tensor([-0.1107,  0.6269])\n",
      "Epoch 716, Loss 9.889154\n",
      "Params: tensor([ 3.8709, -8.5119])\n",
      "Grad:   tensor([-0.1105,  0.6258])\n",
      "Epoch 717, Loss 9.885120\n",
      "Params: tensor([ 3.8721, -8.5181])\n",
      "Grad:   tensor([-0.1104,  0.6247])\n",
      "Epoch 718, Loss 9.881097\n",
      "Params: tensor([ 3.8732, -8.5243])\n",
      "Grad:   tensor([-0.1102,  0.6237])\n",
      "Epoch 719, Loss 9.877090\n",
      "Params: tensor([ 3.8743, -8.5306])\n",
      "Grad:   tensor([-0.1100,  0.6226])\n",
      "Epoch 720, Loss 9.873094\n",
      "Params: tensor([ 3.8753, -8.5368])\n",
      "Grad:   tensor([-0.1098,  0.6216])\n",
      "Epoch 721, Loss 9.869114\n",
      "Params: tensor([ 3.8764, -8.5430])\n",
      "Grad:   tensor([-0.1096,  0.6205])\n",
      "Epoch 722, Loss 9.865149\n",
      "Params: tensor([ 3.8775, -8.5492])\n",
      "Grad:   tensor([-0.1094,  0.6194])\n",
      "Epoch 723, Loss 9.861195\n",
      "Params: tensor([ 3.8786, -8.5554])\n",
      "Grad:   tensor([-0.1092,  0.6184])\n",
      "Epoch 724, Loss 9.857254\n",
      "Params: tensor([ 3.8797, -8.5615])\n",
      "Grad:   tensor([-0.1090,  0.6173])\n",
      "Epoch 725, Loss 9.853327\n",
      "Params: tensor([ 3.8808, -8.5677])\n",
      "Grad:   tensor([-0.1089,  0.6163])\n",
      "Epoch 726, Loss 9.849418\n",
      "Params: tensor([ 3.8819, -8.5739])\n",
      "Grad:   tensor([-0.1087,  0.6152])\n",
      "Epoch 727, Loss 9.845516\n",
      "Params: tensor([ 3.8830, -8.5800])\n",
      "Grad:   tensor([-0.1085,  0.6142])\n",
      "Epoch 728, Loss 9.841628\n",
      "Params: tensor([ 3.8841, -8.5861])\n",
      "Grad:   tensor([-0.1083,  0.6132])\n",
      "Epoch 729, Loss 9.837757\n",
      "Params: tensor([ 3.8851, -8.5923])\n",
      "Grad:   tensor([-0.1081,  0.6121])\n",
      "Epoch 730, Loss 9.833894\n",
      "Params: tensor([ 3.8862, -8.5984])\n",
      "Grad:   tensor([-0.1080,  0.6111])\n",
      "Epoch 731, Loss 9.830045\n",
      "Params: tensor([ 3.8873, -8.6045])\n",
      "Grad:   tensor([-0.1078,  0.6100])\n",
      "Epoch 732, Loss 9.826214\n",
      "Params: tensor([ 3.8884, -8.6106])\n",
      "Grad:   tensor([-0.1076,  0.6090])\n",
      "Epoch 733, Loss 9.822392\n",
      "Params: tensor([ 3.8895, -8.6166])\n",
      "Grad:   tensor([-0.1074,  0.6080])\n",
      "Epoch 734, Loss 9.818583\n",
      "Params: tensor([ 3.8905, -8.6227])\n",
      "Grad:   tensor([-0.1072,  0.6069])\n",
      "Epoch 735, Loss 9.814788\n",
      "Params: tensor([ 3.8916, -8.6288])\n",
      "Grad:   tensor([-0.1070,  0.6059])\n",
      "Epoch 736, Loss 9.811004\n",
      "Params: tensor([ 3.8927, -8.6348])\n",
      "Grad:   tensor([-0.1068,  0.6049])\n",
      "Epoch 737, Loss 9.807236\n",
      "Params: tensor([ 3.8937, -8.6409])\n",
      "Grad:   tensor([-0.1067,  0.6038])\n",
      "Epoch 738, Loss 9.803478\n",
      "Params: tensor([ 3.8948, -8.6469])\n",
      "Grad:   tensor([-0.1065,  0.6028])\n",
      "Epoch 739, Loss 9.799735\n",
      "Params: tensor([ 3.8959, -8.6529])\n",
      "Grad:   tensor([-0.1063,  0.6018])\n",
      "Epoch 740, Loss 9.796002\n",
      "Params: tensor([ 3.8969, -8.6589])\n",
      "Grad:   tensor([-0.1061,  0.6008])\n",
      "Epoch 741, Loss 9.792283\n",
      "Params: tensor([ 3.8980, -8.6649])\n",
      "Grad:   tensor([-0.1060,  0.5998])\n",
      "Epoch 742, Loss 9.788579\n",
      "Params: tensor([ 3.8990, -8.6709])\n",
      "Grad:   tensor([-0.1058,  0.5987])\n",
      "Epoch 743, Loss 9.784883\n",
      "Params: tensor([ 3.9001, -8.6769])\n",
      "Grad:   tensor([-0.1056,  0.5977])\n",
      "Epoch 744, Loss 9.781201\n",
      "Params: tensor([ 3.9011, -8.6828])\n",
      "Grad:   tensor([-0.1054,  0.5967])\n",
      "Epoch 745, Loss 9.777534\n",
      "Params: tensor([ 3.9022, -8.6888])\n",
      "Grad:   tensor([-0.1052,  0.5957])\n",
      "Epoch 746, Loss 9.773875\n",
      "Params: tensor([ 3.9033, -8.6947])\n",
      "Grad:   tensor([-0.1051,  0.5947])\n",
      "Epoch 747, Loss 9.770234\n",
      "Params: tensor([ 3.9043, -8.7007])\n",
      "Grad:   tensor([-0.1049,  0.5937])\n",
      "Epoch 748, Loss 9.766603\n",
      "Params: tensor([ 3.9053, -8.7066])\n",
      "Grad:   tensor([-0.1047,  0.5927])\n",
      "Epoch 749, Loss 9.762986\n",
      "Params: tensor([ 3.9064, -8.7125])\n",
      "Grad:   tensor([-0.1045,  0.5917])\n",
      "Epoch 750, Loss 9.759376\n",
      "Params: tensor([ 3.9074, -8.7184])\n",
      "Grad:   tensor([-0.1043,  0.5906])\n",
      "Epoch 751, Loss 9.755782\n",
      "Params: tensor([ 3.9085, -8.7243])\n",
      "Grad:   tensor([-0.1042,  0.5896])\n",
      "Epoch 752, Loss 9.752201\n",
      "Params: tensor([ 3.9095, -8.7302])\n",
      "Grad:   tensor([-0.1040,  0.5886])\n",
      "Epoch 753, Loss 9.748631\n",
      "Params: tensor([ 3.9106, -8.7361])\n",
      "Grad:   tensor([-0.1038,  0.5876])\n",
      "Epoch 754, Loss 9.745074\n",
      "Params: tensor([ 3.9116, -8.7419])\n",
      "Grad:   tensor([-0.1036,  0.5866])\n",
      "Epoch 755, Loss 9.741528\n",
      "Params: tensor([ 3.9126, -8.7478])\n",
      "Grad:   tensor([-0.1035,  0.5856])\n",
      "Epoch 756, Loss 9.737994\n",
      "Params: tensor([ 3.9137, -8.7537])\n",
      "Grad:   tensor([-0.1033,  0.5847])\n",
      "Epoch 757, Loss 9.734469\n",
      "Params: tensor([ 3.9147, -8.7595])\n",
      "Grad:   tensor([-0.1031,  0.5837])\n",
      "Epoch 758, Loss 9.730964\n",
      "Params: tensor([ 3.9157, -8.7653])\n",
      "Grad:   tensor([-0.1029,  0.5827])\n",
      "Epoch 759, Loss 9.727464\n",
      "Params: tensor([ 3.9167, -8.7711])\n",
      "Grad:   tensor([-0.1028,  0.5817])\n",
      "Epoch 760, Loss 9.723980\n",
      "Params: tensor([ 3.9178, -8.7769])\n",
      "Grad:   tensor([-0.1026,  0.5807])\n",
      "Epoch 761, Loss 9.720504\n",
      "Params: tensor([ 3.9188, -8.7827])\n",
      "Grad:   tensor([-0.1024,  0.5797])\n",
      "Epoch 762, Loss 9.717041\n",
      "Params: tensor([ 3.9198, -8.7885])\n",
      "Grad:   tensor([-0.1022,  0.5787])\n",
      "Epoch 763, Loss 9.713592\n",
      "Params: tensor([ 3.9208, -8.7943])\n",
      "Grad:   tensor([-0.1021,  0.5777])\n",
      "Epoch 764, Loss 9.710148\n",
      "Params: tensor([ 3.9219, -8.8001])\n",
      "Grad:   tensor([-0.1019,  0.5768])\n",
      "Epoch 765, Loss 9.706722\n",
      "Params: tensor([ 3.9229, -8.8058])\n",
      "Grad:   tensor([-0.1017,  0.5758])\n",
      "Epoch 766, Loss 9.703306\n",
      "Params: tensor([ 3.9239, -8.8116])\n",
      "Grad:   tensor([-0.1015,  0.5748])\n",
      "Epoch 767, Loss 9.699904\n",
      "Params: tensor([ 3.9249, -8.8173])\n",
      "Grad:   tensor([-0.1014,  0.5738])\n",
      "Epoch 768, Loss 9.696508\n",
      "Params: tensor([ 3.9259, -8.8230])\n",
      "Grad:   tensor([-0.1012,  0.5728])\n",
      "Epoch 769, Loss 9.693128\n",
      "Params: tensor([ 3.9269, -8.8288])\n",
      "Grad:   tensor([-0.1010,  0.5719])\n",
      "Epoch 770, Loss 9.689762\n",
      "Params: tensor([ 3.9279, -8.8345])\n",
      "Grad:   tensor([-0.1009,  0.5709])\n",
      "Epoch 771, Loss 9.686401\n",
      "Params: tensor([ 3.9289, -8.8402])\n",
      "Grad:   tensor([-0.1007,  0.5699])\n",
      "Epoch 772, Loss 9.683054\n",
      "Params: tensor([ 3.9299, -8.8459])\n",
      "Grad:   tensor([-0.1005,  0.5690])\n",
      "Epoch 773, Loss 9.679721\n",
      "Params: tensor([ 3.9310, -8.8515])\n",
      "Grad:   tensor([-0.1003,  0.5680])\n",
      "Epoch 774, Loss 9.676395\n",
      "Params: tensor([ 3.9320, -8.8572])\n",
      "Grad:   tensor([-0.1002,  0.5670])\n",
      "Epoch 775, Loss 9.673083\n",
      "Params: tensor([ 3.9330, -8.8629])\n",
      "Grad:   tensor([-0.1000,  0.5661])\n",
      "Epoch 776, Loss 9.669779\n",
      "Params: tensor([ 3.9340, -8.8685])\n",
      "Grad:   tensor([-0.0998,  0.5651])\n",
      "Epoch 777, Loss 9.666491\n",
      "Params: tensor([ 3.9349, -8.8742])\n",
      "Grad:   tensor([-0.0997,  0.5641])\n",
      "Epoch 778, Loss 9.663211\n",
      "Params: tensor([ 3.9359, -8.8798])\n",
      "Grad:   tensor([-0.0995,  0.5632])\n",
      "Epoch 779, Loss 9.659944\n",
      "Params: tensor([ 3.9369, -8.8854])\n",
      "Grad:   tensor([-0.0993,  0.5622])\n",
      "Epoch 780, Loss 9.656685\n",
      "Params: tensor([ 3.9379, -8.8910])\n",
      "Grad:   tensor([-0.0991,  0.5613])\n",
      "Epoch 781, Loss 9.653443\n",
      "Params: tensor([ 3.9389, -8.8966])\n",
      "Grad:   tensor([-0.0990,  0.5603])\n",
      "Epoch 782, Loss 9.650207\n",
      "Params: tensor([ 3.9399, -8.9022])\n",
      "Grad:   tensor([-0.0988,  0.5594])\n",
      "Epoch 783, Loss 9.646984\n",
      "Params: tensor([ 3.9409, -8.9078])\n",
      "Grad:   tensor([-0.0986,  0.5584])\n",
      "Epoch 784, Loss 9.643771\n",
      "Params: tensor([ 3.9419, -8.9134])\n",
      "Grad:   tensor([-0.0985,  0.5575])\n",
      "Epoch 785, Loss 9.640570\n",
      "Params: tensor([ 3.9429, -8.9189])\n",
      "Grad:   tensor([-0.0983,  0.5565])\n",
      "Epoch 786, Loss 9.637377\n",
      "Params: tensor([ 3.9438, -8.9245])\n",
      "Grad:   tensor([-0.0982,  0.5556])\n",
      "Epoch 787, Loss 9.634195\n",
      "Params: tensor([ 3.9448, -8.9301])\n",
      "Grad:   tensor([-0.0980,  0.5546])\n",
      "Epoch 788, Loss 9.631025\n",
      "Params: tensor([ 3.9458, -8.9356])\n",
      "Grad:   tensor([-0.0978,  0.5537])\n",
      "Epoch 789, Loss 9.627870\n",
      "Params: tensor([ 3.9468, -8.9411])\n",
      "Grad:   tensor([-0.0976,  0.5528])\n",
      "Epoch 790, Loss 9.624722\n",
      "Params: tensor([ 3.9477, -8.9466])\n",
      "Grad:   tensor([-0.0975,  0.5518])\n",
      "Epoch 791, Loss 9.621581\n",
      "Params: tensor([ 3.9487, -8.9521])\n",
      "Grad:   tensor([-0.0973,  0.5509])\n",
      "Epoch 792, Loss 9.618455\n",
      "Params: tensor([ 3.9497, -8.9576])\n",
      "Grad:   tensor([-0.0972,  0.5499])\n",
      "Epoch 793, Loss 9.615339\n",
      "Params: tensor([ 3.9507, -8.9631])\n",
      "Grad:   tensor([-0.0970,  0.5490])\n",
      "Epoch 794, Loss 9.612234\n",
      "Params: tensor([ 3.9516, -8.9686])\n",
      "Grad:   tensor([-0.0968,  0.5481])\n",
      "Epoch 795, Loss 9.609139\n",
      "Params: tensor([ 3.9526, -8.9741])\n",
      "Grad:   tensor([-0.0966,  0.5471])\n",
      "Epoch 796, Loss 9.606054\n",
      "Params: tensor([ 3.9536, -8.9795])\n",
      "Grad:   tensor([-0.0965,  0.5462])\n",
      "Epoch 797, Loss 9.602981\n",
      "Params: tensor([ 3.9545, -8.9850])\n",
      "Grad:   tensor([-0.0963,  0.5453])\n",
      "Epoch 798, Loss 9.599916\n",
      "Params: tensor([ 3.9555, -8.9904])\n",
      "Grad:   tensor([-0.0962,  0.5444])\n",
      "Epoch 799, Loss 9.596864\n",
      "Params: tensor([ 3.9564, -8.9959])\n",
      "Grad:   tensor([-0.0960,  0.5434])\n",
      "Epoch 800, Loss 9.593822\n",
      "Params: tensor([ 3.9574, -9.0013])\n",
      "Grad:   tensor([-0.0958,  0.5425])\n",
      "Epoch 801, Loss 9.590786\n",
      "Params: tensor([ 3.9584, -9.0067])\n",
      "Grad:   tensor([-0.0957,  0.5416])\n",
      "Epoch 802, Loss 9.587767\n",
      "Params: tensor([ 3.9593, -9.0121])\n",
      "Grad:   tensor([-0.0955,  0.5407])\n",
      "Epoch 803, Loss 9.584754\n",
      "Params: tensor([ 3.9603, -9.0175])\n",
      "Grad:   tensor([-0.0954,  0.5398])\n",
      "Epoch 804, Loss 9.581754\n",
      "Params: tensor([ 3.9612, -9.0229])\n",
      "Grad:   tensor([-0.0952,  0.5388])\n",
      "Epoch 805, Loss 9.578762\n",
      "Params: tensor([ 3.9622, -9.0283])\n",
      "Grad:   tensor([-0.0950,  0.5379])\n",
      "Epoch 806, Loss 9.575779\n",
      "Params: tensor([ 3.9631, -9.0337])\n",
      "Grad:   tensor([-0.0949,  0.5370])\n",
      "Epoch 807, Loss 9.572809\n",
      "Params: tensor([ 3.9641, -9.0390])\n",
      "Grad:   tensor([-0.0947,  0.5361])\n",
      "Epoch 808, Loss 9.569848\n",
      "Params: tensor([ 3.9650, -9.0444])\n",
      "Grad:   tensor([-0.0945,  0.5352])\n",
      "Epoch 809, Loss 9.566895\n",
      "Params: tensor([ 3.9660, -9.0497])\n",
      "Grad:   tensor([-0.0944,  0.5343])\n",
      "Epoch 810, Loss 9.563955\n",
      "Params: tensor([ 3.9669, -9.0550])\n",
      "Grad:   tensor([-0.0942,  0.5334])\n",
      "Epoch 811, Loss 9.561026\n",
      "Params: tensor([ 3.9678, -9.0604])\n",
      "Grad:   tensor([-0.0941,  0.5325])\n",
      "Epoch 812, Loss 9.558105\n",
      "Params: tensor([ 3.9688, -9.0657])\n",
      "Grad:   tensor([-0.0939,  0.5316])\n",
      "Epoch 813, Loss 9.555192\n",
      "Params: tensor([ 3.9697, -9.0710])\n",
      "Grad:   tensor([-0.0937,  0.5307])\n",
      "Epoch 814, Loss 9.552293\n",
      "Params: tensor([ 3.9707, -9.0763])\n",
      "Grad:   tensor([-0.0936,  0.5298])\n",
      "Epoch 815, Loss 9.549401\n",
      "Params: tensor([ 3.9716, -9.0816])\n",
      "Grad:   tensor([-0.0934,  0.5289])\n",
      "Epoch 816, Loss 9.546519\n",
      "Params: tensor([ 3.9725, -9.0869])\n",
      "Grad:   tensor([-0.0933,  0.5280])\n",
      "Epoch 817, Loss 9.543647\n",
      "Params: tensor([ 3.9735, -9.0921])\n",
      "Grad:   tensor([-0.0931,  0.5271])\n",
      "Epoch 818, Loss 9.540783\n",
      "Params: tensor([ 3.9744, -9.0974])\n",
      "Grad:   tensor([-0.0930,  0.5262])\n",
      "Epoch 819, Loss 9.537932\n",
      "Params: tensor([ 3.9753, -9.1026])\n",
      "Grad:   tensor([-0.0928,  0.5253])\n",
      "Epoch 820, Loss 9.535091\n",
      "Params: tensor([ 3.9762, -9.1079])\n",
      "Grad:   tensor([-0.0926,  0.5244])\n",
      "Epoch 821, Loss 9.532256\n",
      "Params: tensor([ 3.9772, -9.1131])\n",
      "Grad:   tensor([-0.0925,  0.5235])\n",
      "Epoch 822, Loss 9.529433\n",
      "Params: tensor([ 3.9781, -9.1183])\n",
      "Grad:   tensor([-0.0923,  0.5226])\n",
      "Epoch 823, Loss 9.526619\n",
      "Params: tensor([ 3.9790, -9.1236])\n",
      "Grad:   tensor([-0.0922,  0.5217])\n",
      "Epoch 824, Loss 9.523818\n",
      "Params: tensor([ 3.9799, -9.1288])\n",
      "Grad:   tensor([-0.0920,  0.5208])\n",
      "Epoch 825, Loss 9.521016\n",
      "Params: tensor([ 3.9808, -9.1340])\n",
      "Grad:   tensor([-0.0918,  0.5199])\n",
      "Epoch 826, Loss 9.518236\n",
      "Params: tensor([ 3.9818, -9.1392])\n",
      "Grad:   tensor([-0.0917,  0.5191])\n",
      "Epoch 827, Loss 9.515460\n",
      "Params: tensor([ 3.9827, -9.1443])\n",
      "Grad:   tensor([-0.0915,  0.5182])\n",
      "Epoch 828, Loss 9.512691\n",
      "Params: tensor([ 3.9836, -9.1495])\n",
      "Grad:   tensor([-0.0914,  0.5173])\n",
      "Epoch 829, Loss 9.509936\n",
      "Params: tensor([ 3.9845, -9.1547])\n",
      "Grad:   tensor([-0.0912,  0.5164])\n",
      "Epoch 830, Loss 9.507188\n",
      "Params: tensor([ 3.9854, -9.1598])\n",
      "Grad:   tensor([-0.0911,  0.5155])\n",
      "Epoch 831, Loss 9.504449\n",
      "Params: tensor([ 3.9863, -9.1650])\n",
      "Grad:   tensor([-0.0909,  0.5147])\n",
      "Epoch 832, Loss 9.501723\n",
      "Params: tensor([ 3.9872, -9.1701])\n",
      "Grad:   tensor([-0.0908,  0.5138])\n",
      "Epoch 833, Loss 9.499001\n",
      "Params: tensor([ 3.9881, -9.1753])\n",
      "Grad:   tensor([-0.0906,  0.5129])\n",
      "Epoch 834, Loss 9.496291\n",
      "Params: tensor([ 3.9890, -9.1804])\n",
      "Grad:   tensor([-0.0904,  0.5120])\n",
      "Epoch 835, Loss 9.493588\n",
      "Params: tensor([ 3.9899, -9.1855])\n",
      "Grad:   tensor([-0.0903,  0.5112])\n",
      "Epoch 836, Loss 9.490894\n",
      "Params: tensor([ 3.9908, -9.1906])\n",
      "Grad:   tensor([-0.0901,  0.5103])\n",
      "Epoch 837, Loss 9.488213\n",
      "Params: tensor([ 3.9917, -9.1957])\n",
      "Grad:   tensor([-0.0900,  0.5094])\n",
      "Epoch 838, Loss 9.485540\n",
      "Params: tensor([ 3.9926, -9.2008])\n",
      "Grad:   tensor([-0.0898,  0.5086])\n",
      "Epoch 839, Loss 9.482876\n",
      "Params: tensor([ 3.9935, -9.2058])\n",
      "Grad:   tensor([-0.0897,  0.5077])\n",
      "Epoch 840, Loss 9.480221\n",
      "Params: tensor([ 3.9944, -9.2109])\n",
      "Grad:   tensor([-0.0895,  0.5068])\n",
      "Epoch 841, Loss 9.477570\n",
      "Params: tensor([ 3.9953, -9.2160])\n",
      "Grad:   tensor([-0.0894,  0.5060])\n",
      "Epoch 842, Loss 9.474933\n",
      "Params: tensor([ 3.9962, -9.2210])\n",
      "Grad:   tensor([-0.0892,  0.5051])\n",
      "Epoch 843, Loss 9.472303\n",
      "Params: tensor([ 3.9971, -9.2261])\n",
      "Grad:   tensor([-0.0891,  0.5043])\n",
      "Epoch 844, Loss 9.469684\n",
      "Params: tensor([ 3.9980, -9.2311])\n",
      "Grad:   tensor([-0.0889,  0.5034])\n",
      "Epoch 845, Loss 9.467072\n",
      "Params: tensor([ 3.9989, -9.2361])\n",
      "Grad:   tensor([-0.0888,  0.5026])\n",
      "Epoch 846, Loss 9.464472\n",
      "Params: tensor([ 3.9998, -9.2411])\n",
      "Grad:   tensor([-0.0886,  0.5017])\n",
      "Epoch 847, Loss 9.461880\n",
      "Params: tensor([ 4.0007, -9.2462])\n",
      "Grad:   tensor([-0.0885,  0.5008])\n",
      "Epoch 848, Loss 9.459293\n",
      "Params: tensor([ 4.0015, -9.2512])\n",
      "Grad:   tensor([-0.0883,  0.5000])\n",
      "Epoch 849, Loss 9.456715\n",
      "Params: tensor([ 4.0024, -9.2561])\n",
      "Grad:   tensor([-0.0882,  0.4991])\n",
      "Epoch 850, Loss 9.454148\n",
      "Params: tensor([ 4.0033, -9.2611])\n",
      "Grad:   tensor([-0.0880,  0.4983])\n",
      "Epoch 851, Loss 9.451591\n",
      "Params: tensor([ 4.0042, -9.2661])\n",
      "Grad:   tensor([-0.0879,  0.4975])\n",
      "Epoch 852, Loss 9.449042\n",
      "Params: tensor([ 4.0051, -9.2711])\n",
      "Grad:   tensor([-0.0877,  0.4966])\n",
      "Epoch 853, Loss 9.446501\n",
      "Params: tensor([ 4.0059, -9.2760])\n",
      "Grad:   tensor([-0.0876,  0.4958])\n",
      "Epoch 854, Loss 9.443969\n",
      "Params: tensor([ 4.0068, -9.2810])\n",
      "Grad:   tensor([-0.0874,  0.4949])\n",
      "Epoch 855, Loss 9.441446\n",
      "Params: tensor([ 4.0077, -9.2859])\n",
      "Grad:   tensor([-0.0873,  0.4941])\n",
      "Epoch 856, Loss 9.438928\n",
      "Params: tensor([ 4.0086, -9.2908])\n",
      "Grad:   tensor([-0.0871,  0.4932])\n",
      "Epoch 857, Loss 9.436420\n",
      "Params: tensor([ 4.0094, -9.2958])\n",
      "Grad:   tensor([-0.0870,  0.4924])\n",
      "Epoch 858, Loss 9.433928\n",
      "Params: tensor([ 4.0103, -9.3007])\n",
      "Grad:   tensor([-0.0868,  0.4916])\n",
      "Epoch 859, Loss 9.431436\n",
      "Params: tensor([ 4.0112, -9.3056])\n",
      "Grad:   tensor([-0.0867,  0.4907])\n",
      "Epoch 860, Loss 9.428953\n",
      "Params: tensor([ 4.0120, -9.3105])\n",
      "Grad:   tensor([-0.0865,  0.4899])\n",
      "Epoch 861, Loss 9.426479\n",
      "Params: tensor([ 4.0129, -9.3154])\n",
      "Grad:   tensor([-0.0864,  0.4891])\n",
      "Epoch 862, Loss 9.424015\n",
      "Params: tensor([ 4.0138, -9.3203])\n",
      "Grad:   tensor([-0.0862,  0.4882])\n",
      "Epoch 863, Loss 9.421559\n",
      "Params: tensor([ 4.0146, -9.3251])\n",
      "Grad:   tensor([-0.0861,  0.4874])\n",
      "Epoch 864, Loss 9.419112\n",
      "Params: tensor([ 4.0155, -9.3300])\n",
      "Grad:   tensor([-0.0860,  0.4866])\n",
      "Epoch 865, Loss 9.416673\n",
      "Params: tensor([ 4.0163, -9.3349])\n",
      "Grad:   tensor([-0.0858,  0.4858])\n",
      "Epoch 866, Loss 9.414245\n",
      "Params: tensor([ 4.0172, -9.3397])\n",
      "Grad:   tensor([-0.0857,  0.4849])\n",
      "Epoch 867, Loss 9.411820\n",
      "Params: tensor([ 4.0180, -9.3446])\n",
      "Grad:   tensor([-0.0855,  0.4841])\n",
      "Epoch 868, Loss 9.409405\n",
      "Params: tensor([ 4.0189, -9.3494])\n",
      "Grad:   tensor([-0.0854,  0.4833])\n",
      "Epoch 869, Loss 9.407000\n",
      "Params: tensor([ 4.0197, -9.3542])\n",
      "Grad:   tensor([-0.0852,  0.4825])\n",
      "Epoch 870, Loss 9.404599\n",
      "Params: tensor([ 4.0206, -9.3590])\n",
      "Grad:   tensor([-0.0851,  0.4816])\n",
      "Epoch 871, Loss 9.402210\n",
      "Params: tensor([ 4.0215, -9.3638])\n",
      "Grad:   tensor([-0.0850,  0.4808])\n",
      "Epoch 872, Loss 9.399829\n",
      "Params: tensor([ 4.0223, -9.3686])\n",
      "Grad:   tensor([-0.0848,  0.4800])\n",
      "Epoch 873, Loss 9.397454\n",
      "Params: tensor([ 4.0231, -9.3734])\n",
      "Grad:   tensor([-0.0846,  0.4792])\n",
      "Epoch 874, Loss 9.395087\n",
      "Params: tensor([ 4.0240, -9.3782])\n",
      "Grad:   tensor([-0.0845,  0.4784])\n",
      "Epoch 875, Loss 9.392730\n",
      "Params: tensor([ 4.0248, -9.3830])\n",
      "Grad:   tensor([-0.0844,  0.4776])\n",
      "Epoch 876, Loss 9.390381\n",
      "Params: tensor([ 4.0257, -9.3878])\n",
      "Grad:   tensor([-0.0843,  0.4767])\n",
      "Epoch 877, Loss 9.388038\n",
      "Params: tensor([ 4.0265, -9.3925])\n",
      "Grad:   tensor([-0.0841,  0.4759])\n",
      "Epoch 878, Loss 9.385705\n",
      "Params: tensor([ 4.0274, -9.3973])\n",
      "Grad:   tensor([-0.0839,  0.4751])\n",
      "Epoch 879, Loss 9.383377\n",
      "Params: tensor([ 4.0282, -9.4020])\n",
      "Grad:   tensor([-0.0838,  0.4743])\n",
      "Epoch 880, Loss 9.381062\n",
      "Params: tensor([ 4.0290, -9.4067])\n",
      "Grad:   tensor([-0.0837,  0.4735])\n",
      "Epoch 881, Loss 9.378751\n",
      "Params: tensor([ 4.0299, -9.4115])\n",
      "Grad:   tensor([-0.0835,  0.4727])\n",
      "Epoch 882, Loss 9.376449\n",
      "Params: tensor([ 4.0307, -9.4162])\n",
      "Grad:   tensor([-0.0834,  0.4719])\n",
      "Epoch 883, Loss 9.374152\n",
      "Params: tensor([ 4.0315, -9.4209])\n",
      "Grad:   tensor([-0.0832,  0.4711])\n",
      "Epoch 884, Loss 9.371867\n",
      "Params: tensor([ 4.0324, -9.4256])\n",
      "Grad:   tensor([-0.0831,  0.4703])\n",
      "Epoch 885, Loss 9.369586\n",
      "Params: tensor([ 4.0332, -9.4303])\n",
      "Grad:   tensor([-0.0830,  0.4695])\n",
      "Epoch 886, Loss 9.367317\n",
      "Params: tensor([ 4.0340, -9.4350])\n",
      "Grad:   tensor([-0.0828,  0.4687])\n",
      "Epoch 887, Loss 9.365053\n",
      "Params: tensor([ 4.0348, -9.4397])\n",
      "Grad:   tensor([-0.0827,  0.4679])\n",
      "Epoch 888, Loss 9.362793\n",
      "Params: tensor([ 4.0357, -9.4443])\n",
      "Grad:   tensor([-0.0825,  0.4671])\n",
      "Epoch 889, Loss 9.360549\n",
      "Params: tensor([ 4.0365, -9.4490])\n",
      "Grad:   tensor([-0.0824,  0.4663])\n",
      "Epoch 890, Loss 9.358307\n",
      "Params: tensor([ 4.0373, -9.4537])\n",
      "Grad:   tensor([-0.0822,  0.4655])\n",
      "Epoch 891, Loss 9.356075\n",
      "Params: tensor([ 4.0381, -9.4583])\n",
      "Grad:   tensor([-0.0821,  0.4647])\n",
      "Epoch 892, Loss 9.353848\n",
      "Params: tensor([ 4.0390, -9.4629])\n",
      "Grad:   tensor([-0.0819,  0.4640])\n",
      "Epoch 893, Loss 9.351633\n",
      "Params: tensor([ 4.0398, -9.4676])\n",
      "Grad:   tensor([-0.0818,  0.4632])\n",
      "Epoch 894, Loss 9.349422\n",
      "Params: tensor([ 4.0406, -9.4722])\n",
      "Grad:   tensor([-0.0817,  0.4624])\n",
      "Epoch 895, Loss 9.347218\n",
      "Params: tensor([ 4.0414, -9.4768])\n",
      "Grad:   tensor([-0.0815,  0.4616])\n",
      "Epoch 896, Loss 9.345025\n",
      "Params: tensor([ 4.0422, -9.4814])\n",
      "Grad:   tensor([-0.0814,  0.4608])\n",
      "Epoch 897, Loss 9.342834\n",
      "Params: tensor([ 4.0430, -9.4860])\n",
      "Grad:   tensor([-0.0813,  0.4600])\n",
      "Epoch 898, Loss 9.340657\n",
      "Params: tensor([ 4.0438, -9.4906])\n",
      "Grad:   tensor([-0.0811,  0.4592])\n",
      "Epoch 899, Loss 9.338480\n",
      "Params: tensor([ 4.0447, -9.4952])\n",
      "Grad:   tensor([-0.0810,  0.4585])\n",
      "Epoch 900, Loss 9.336314\n",
      "Params: tensor([ 4.0455, -9.4998])\n",
      "Grad:   tensor([-0.0809,  0.4577])\n",
      "Epoch 901, Loss 9.334159\n",
      "Params: tensor([ 4.0463, -9.5043])\n",
      "Grad:   tensor([-0.0807,  0.4569])\n",
      "Epoch 902, Loss 9.332006\n",
      "Params: tensor([ 4.0471, -9.5089])\n",
      "Grad:   tensor([-0.0806,  0.4561])\n",
      "Epoch 903, Loss 9.329862\n",
      "Params: tensor([ 4.0479, -9.5135])\n",
      "Grad:   tensor([-0.0804,  0.4554])\n",
      "Epoch 904, Loss 9.327727\n",
      "Params: tensor([ 4.0487, -9.5180])\n",
      "Grad:   tensor([-0.0803,  0.4546])\n",
      "Epoch 905, Loss 9.325598\n",
      "Params: tensor([ 4.0495, -9.5225])\n",
      "Grad:   tensor([-0.0802,  0.4538])\n",
      "Epoch 906, Loss 9.323475\n",
      "Params: tensor([ 4.0503, -9.5271])\n",
      "Grad:   tensor([-0.0800,  0.4530])\n",
      "Epoch 907, Loss 9.321360\n",
      "Params: tensor([ 4.0511, -9.5316])\n",
      "Grad:   tensor([-0.0799,  0.4523])\n",
      "Epoch 908, Loss 9.319256\n",
      "Params: tensor([ 4.0519, -9.5361])\n",
      "Grad:   tensor([-0.0798,  0.4515])\n",
      "Epoch 909, Loss 9.317153\n",
      "Params: tensor([ 4.0527, -9.5406])\n",
      "Grad:   tensor([-0.0796,  0.4507])\n",
      "Epoch 910, Loss 9.315059\n",
      "Params: tensor([ 4.0535, -9.5451])\n",
      "Grad:   tensor([-0.0795,  0.4500])\n",
      "Epoch 911, Loss 9.312974\n",
      "Params: tensor([ 4.0543, -9.5496])\n",
      "Grad:   tensor([-0.0794,  0.4492])\n",
      "Epoch 912, Loss 9.310895\n",
      "Params: tensor([ 4.0551, -9.5541])\n",
      "Grad:   tensor([-0.0792,  0.4484])\n",
      "Epoch 913, Loss 9.308823\n",
      "Params: tensor([ 4.0559, -9.5586])\n",
      "Grad:   tensor([-0.0791,  0.4477])\n",
      "Epoch 914, Loss 9.306757\n",
      "Params: tensor([ 4.0566, -9.5630])\n",
      "Grad:   tensor([-0.0789,  0.4469])\n",
      "Epoch 915, Loss 9.304701\n",
      "Params: tensor([ 4.0574, -9.5675])\n",
      "Grad:   tensor([-0.0788,  0.4462])\n",
      "Epoch 916, Loss 9.302652\n",
      "Params: tensor([ 4.0582, -9.5720])\n",
      "Grad:   tensor([-0.0787,  0.4454])\n",
      "Epoch 917, Loss 9.300605\n",
      "Params: tensor([ 4.0590, -9.5764])\n",
      "Grad:   tensor([-0.0785,  0.4447])\n",
      "Epoch 918, Loss 9.298568\n",
      "Params: tensor([ 4.0598, -9.5808])\n",
      "Grad:   tensor([-0.0784,  0.4439])\n",
      "Epoch 919, Loss 9.296536\n",
      "Params: tensor([ 4.0606, -9.5853])\n",
      "Grad:   tensor([-0.0783,  0.4431])\n",
      "Epoch 920, Loss 9.294514\n",
      "Params: tensor([ 4.0613, -9.5897])\n",
      "Grad:   tensor([-0.0782,  0.4424])\n",
      "Epoch 921, Loss 9.292498\n",
      "Params: tensor([ 4.0621, -9.5941])\n",
      "Grad:   tensor([-0.0780,  0.4416])\n",
      "Epoch 922, Loss 9.290490\n",
      "Params: tensor([ 4.0629, -9.5985])\n",
      "Grad:   tensor([-0.0779,  0.4409])\n",
      "Epoch 923, Loss 9.288486\n",
      "Params: tensor([ 4.0637, -9.6029])\n",
      "Grad:   tensor([-0.0778,  0.4401])\n",
      "Epoch 924, Loss 9.286490\n",
      "Params: tensor([ 4.0645, -9.6073])\n",
      "Grad:   tensor([-0.0776,  0.4394])\n",
      "Epoch 925, Loss 9.284500\n",
      "Params: tensor([ 4.0652, -9.6117])\n",
      "Grad:   tensor([-0.0775,  0.4386])\n",
      "Epoch 926, Loss 9.282519\n",
      "Params: tensor([ 4.0660, -9.6161])\n",
      "Grad:   tensor([-0.0774,  0.4379])\n",
      "Epoch 927, Loss 9.280545\n",
      "Params: tensor([ 4.0668, -9.6205])\n",
      "Grad:   tensor([-0.0772,  0.4372])\n",
      "Epoch 928, Loss 9.278576\n",
      "Params: tensor([ 4.0676, -9.6248])\n",
      "Grad:   tensor([-0.0771,  0.4364])\n",
      "Epoch 929, Loss 9.276612\n",
      "Params: tensor([ 4.0683, -9.6292])\n",
      "Grad:   tensor([-0.0769,  0.4357])\n",
      "Epoch 930, Loss 9.274658\n",
      "Params: tensor([ 4.0691, -9.6335])\n",
      "Grad:   tensor([-0.0768,  0.4349])\n",
      "Epoch 931, Loss 9.272708\n",
      "Params: tensor([ 4.0699, -9.6379])\n",
      "Grad:   tensor([-0.0767,  0.4342])\n",
      "Epoch 932, Loss 9.270764\n",
      "Params: tensor([ 4.0706, -9.6422])\n",
      "Grad:   tensor([-0.0766,  0.4335])\n",
      "Epoch 933, Loss 9.268827\n",
      "Params: tensor([ 4.0714, -9.6465])\n",
      "Grad:   tensor([-0.0764,  0.4327])\n",
      "Epoch 934, Loss 9.266902\n",
      "Params: tensor([ 4.0722, -9.6508])\n",
      "Grad:   tensor([-0.0763,  0.4320])\n",
      "Epoch 935, Loss 9.264977\n",
      "Params: tensor([ 4.0729, -9.6552])\n",
      "Grad:   tensor([-0.0762,  0.4312])\n",
      "Epoch 936, Loss 9.263061\n",
      "Params: tensor([ 4.0737, -9.6595])\n",
      "Grad:   tensor([-0.0761,  0.4305])\n",
      "Epoch 937, Loss 9.261148\n",
      "Params: tensor([ 4.0744, -9.6638])\n",
      "Grad:   tensor([-0.0759,  0.4298])\n",
      "Epoch 938, Loss 9.259248\n",
      "Params: tensor([ 4.0752, -9.6681])\n",
      "Grad:   tensor([-0.0758,  0.4291])\n",
      "Epoch 939, Loss 9.257349\n",
      "Params: tensor([ 4.0759, -9.6723])\n",
      "Grad:   tensor([-0.0757,  0.4283])\n",
      "Epoch 940, Loss 9.255461\n",
      "Params: tensor([ 4.0767, -9.6766])\n",
      "Grad:   tensor([-0.0755,  0.4276])\n",
      "Epoch 941, Loss 9.253579\n",
      "Params: tensor([ 4.0775, -9.6809])\n",
      "Grad:   tensor([-0.0754,  0.4269])\n",
      "Epoch 942, Loss 9.251698\n",
      "Params: tensor([ 4.0782, -9.6851])\n",
      "Grad:   tensor([-0.0753,  0.4261])\n",
      "Epoch 943, Loss 9.249830\n",
      "Params: tensor([ 4.0790, -9.6894])\n",
      "Grad:   tensor([-0.0752,  0.4254])\n",
      "Epoch 944, Loss 9.247967\n",
      "Params: tensor([ 4.0797, -9.6936])\n",
      "Grad:   tensor([-0.0750,  0.4247])\n",
      "Epoch 945, Loss 9.246108\n",
      "Params: tensor([ 4.0805, -9.6979])\n",
      "Grad:   tensor([-0.0749,  0.4240])\n",
      "Epoch 946, Loss 9.244251\n",
      "Params: tensor([ 4.0812, -9.7021])\n",
      "Grad:   tensor([-0.0748,  0.4233])\n",
      "Epoch 947, Loss 9.242407\n",
      "Params: tensor([ 4.0820, -9.7063])\n",
      "Grad:   tensor([-0.0746,  0.4225])\n",
      "Epoch 948, Loss 9.240569\n",
      "Params: tensor([ 4.0827, -9.7106])\n",
      "Grad:   tensor([-0.0745,  0.4218])\n",
      "Epoch 949, Loss 9.238735\n",
      "Params: tensor([ 4.0834, -9.7148])\n",
      "Grad:   tensor([-0.0744,  0.4211])\n",
      "Epoch 950, Loss 9.236908\n",
      "Params: tensor([ 4.0842, -9.7190])\n",
      "Grad:   tensor([-0.0743,  0.4204])\n",
      "Epoch 951, Loss 9.235088\n",
      "Params: tensor([ 4.0849, -9.7232])\n",
      "Grad:   tensor([-0.0741,  0.4197])\n",
      "Epoch 952, Loss 9.233272\n",
      "Params: tensor([ 4.0857, -9.7274])\n",
      "Grad:   tensor([-0.0740,  0.4190])\n",
      "Epoch 953, Loss 9.231463\n",
      "Params: tensor([ 4.0864, -9.7315])\n",
      "Grad:   tensor([-0.0739,  0.4183])\n",
      "Epoch 954, Loss 9.229660\n",
      "Params: tensor([ 4.0871, -9.7357])\n",
      "Grad:   tensor([-0.0738,  0.4175])\n",
      "Epoch 955, Loss 9.227866\n",
      "Params: tensor([ 4.0879, -9.7399])\n",
      "Grad:   tensor([-0.0736,  0.4168])\n",
      "Epoch 956, Loss 9.226077\n",
      "Params: tensor([ 4.0886, -9.7441])\n",
      "Grad:   tensor([-0.0735,  0.4161])\n",
      "Epoch 957, Loss 9.224290\n",
      "Params: tensor([ 4.0893, -9.7482])\n",
      "Grad:   tensor([-0.0734,  0.4154])\n",
      "Epoch 958, Loss 9.222513\n",
      "Params: tensor([ 4.0901, -9.7524])\n",
      "Grad:   tensor([-0.0733,  0.4147])\n",
      "Epoch 959, Loss 9.220741\n",
      "Params: tensor([ 4.0908, -9.7565])\n",
      "Grad:   tensor([-0.0732,  0.4140])\n",
      "Epoch 960, Loss 9.218975\n",
      "Params: tensor([ 4.0915, -9.7606])\n",
      "Grad:   tensor([-0.0730,  0.4133])\n",
      "Epoch 961, Loss 9.217213\n",
      "Params: tensor([ 4.0923, -9.7648])\n",
      "Grad:   tensor([-0.0729,  0.4126])\n",
      "Epoch 962, Loss 9.215460\n",
      "Params: tensor([ 4.0930, -9.7689])\n",
      "Grad:   tensor([-0.0728,  0.4119])\n",
      "Epoch 963, Loss 9.213714\n",
      "Params: tensor([ 4.0937, -9.7730])\n",
      "Grad:   tensor([-0.0726,  0.4112])\n",
      "Epoch 964, Loss 9.211971\n",
      "Params: tensor([ 4.0945, -9.7771])\n",
      "Grad:   tensor([-0.0725,  0.4105])\n",
      "Epoch 965, Loss 9.210237\n",
      "Params: tensor([ 4.0952, -9.7812])\n",
      "Grad:   tensor([-0.0724,  0.4098])\n",
      "Epoch 966, Loss 9.208505\n",
      "Params: tensor([ 4.0959, -9.7853])\n",
      "Grad:   tensor([-0.0723,  0.4091])\n",
      "Epoch 967, Loss 9.206780\n",
      "Params: tensor([ 4.0966, -9.7894])\n",
      "Grad:   tensor([-0.0721,  0.4084])\n",
      "Epoch 968, Loss 9.205063\n",
      "Params: tensor([ 4.0973, -9.7934])\n",
      "Grad:   tensor([-0.0720,  0.4077])\n",
      "Epoch 969, Loss 9.203351\n",
      "Params: tensor([ 4.0981, -9.7975])\n",
      "Grad:   tensor([-0.0719,  0.4070])\n",
      "Epoch 970, Loss 9.201641\n",
      "Params: tensor([ 4.0988, -9.8016])\n",
      "Grad:   tensor([-0.0718,  0.4063])\n",
      "Epoch 971, Loss 9.199941\n",
      "Params: tensor([ 4.0995, -9.8056])\n",
      "Grad:   tensor([-0.0717,  0.4056])\n",
      "Epoch 972, Loss 9.198242\n",
      "Params: tensor([ 4.1002, -9.8097])\n",
      "Grad:   tensor([-0.0715,  0.4050])\n",
      "Epoch 973, Loss 9.196553\n",
      "Params: tensor([ 4.1009, -9.8137])\n",
      "Grad:   tensor([-0.0714,  0.4043])\n",
      "Epoch 974, Loss 9.194870\n",
      "Params: tensor([ 4.1016, -9.8178])\n",
      "Grad:   tensor([-0.0713,  0.4036])\n",
      "Epoch 975, Loss 9.193195\n",
      "Params: tensor([ 4.1023, -9.8218])\n",
      "Grad:   tensor([-0.0712,  0.4029])\n",
      "Epoch 976, Loss 9.191519\n",
      "Params: tensor([ 4.1031, -9.8258])\n",
      "Grad:   tensor([-0.0710,  0.4022])\n",
      "Epoch 977, Loss 9.189854\n",
      "Params: tensor([ 4.1038, -9.8298])\n",
      "Grad:   tensor([-0.0709,  0.4015])\n",
      "Epoch 978, Loss 9.188195\n",
      "Params: tensor([ 4.1045, -9.8338])\n",
      "Grad:   tensor([-0.0708,  0.4008])\n",
      "Epoch 979, Loss 9.186537\n",
      "Params: tensor([ 4.1052, -9.8378])\n",
      "Grad:   tensor([-0.0707,  0.4002])\n",
      "Epoch 980, Loss 9.184888\n",
      "Params: tensor([ 4.1059, -9.8418])\n",
      "Grad:   tensor([-0.0706,  0.3995])\n",
      "Epoch 981, Loss 9.183243\n",
      "Params: tensor([ 4.1066, -9.8458])\n",
      "Grad:   tensor([-0.0705,  0.3988])\n",
      "Epoch 982, Loss 9.181606\n",
      "Params: tensor([ 4.1073, -9.8498])\n",
      "Grad:   tensor([-0.0703,  0.3981])\n",
      "Epoch 983, Loss 9.179971\n",
      "Params: tensor([ 4.1080, -9.8538])\n",
      "Grad:   tensor([-0.0702,  0.3974])\n",
      "Epoch 984, Loss 9.178344\n",
      "Params: tensor([ 4.1087, -9.8577])\n",
      "Grad:   tensor([-0.0701,  0.3968])\n",
      "Epoch 985, Loss 9.176719\n",
      "Params: tensor([ 4.1094, -9.8617])\n",
      "Grad:   tensor([-0.0700,  0.3961])\n",
      "Epoch 986, Loss 9.175103\n",
      "Params: tensor([ 4.1101, -9.8657])\n",
      "Grad:   tensor([-0.0699,  0.3954])\n",
      "Epoch 987, Loss 9.173491\n",
      "Params: tensor([ 4.1108, -9.8696])\n",
      "Grad:   tensor([-0.0697,  0.3948])\n",
      "Epoch 988, Loss 9.171890\n",
      "Params: tensor([ 4.1115, -9.8735])\n",
      "Grad:   tensor([-0.0696,  0.3941])\n",
      "Epoch 989, Loss 9.170290\n",
      "Params: tensor([ 4.1122, -9.8775])\n",
      "Grad:   tensor([-0.0695,  0.3934])\n",
      "Epoch 990, Loss 9.168694\n",
      "Params: tensor([ 4.1129, -9.8814])\n",
      "Grad:   tensor([-0.0694,  0.3928])\n",
      "Epoch 991, Loss 9.167106\n",
      "Params: tensor([ 4.1136, -9.8853])\n",
      "Grad:   tensor([-0.0692,  0.3921])\n",
      "Epoch 992, Loss 9.165519\n",
      "Params: tensor([ 4.1143, -9.8892])\n",
      "Grad:   tensor([-0.0691,  0.3914])\n",
      "Epoch 993, Loss 9.163940\n",
      "Params: tensor([ 4.1150, -9.8931])\n",
      "Grad:   tensor([-0.0690,  0.3908])\n",
      "Epoch 994, Loss 9.162368\n",
      "Params: tensor([ 4.1156, -9.8970])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad:   tensor([-0.0689,  0.3901])\n",
      "Epoch 995, Loss 9.160801\n",
      "Params: tensor([ 4.1163, -9.9009])\n",
      "Grad:   tensor([-0.0688,  0.3894])\n",
      "Epoch 996, Loss 9.159239\n",
      "Params: tensor([ 4.1170, -9.9048])\n",
      "Grad:   tensor([-0.0687,  0.3888])\n",
      "Epoch 997, Loss 9.157685\n",
      "Params: tensor([ 4.1177, -9.9087])\n",
      "Grad:   tensor([-0.0686,  0.3881])\n",
      "Epoch 998, Loss 9.156130\n",
      "Params: tensor([ 4.1184, -9.9126])\n",
      "Grad:   tensor([-0.0684,  0.3874])\n",
      "Epoch 999, Loss 9.154580\n",
      "Params: tensor([ 4.1191, -9.9165])\n",
      "Grad:   tensor([-0.0683,  0.3868])\n",
      "Epoch 1000, Loss 9.153041\n",
      "Params: tensor([ 4.1198, -9.9203])\n",
      "Grad:   tensor([-0.0682,  0.3861])\n",
      "Epoch 1001, Loss 9.151505\n",
      "Params: tensor([ 4.1204, -9.9242])\n",
      "Grad:   tensor([-0.0681,  0.3855])\n",
      "Epoch 1002, Loss 9.149974\n",
      "Params: tensor([ 4.1211, -9.9280])\n",
      "Grad:   tensor([-0.0680,  0.3848])\n",
      "Epoch 1003, Loss 9.148451\n",
      "Params: tensor([ 4.1218, -9.9319])\n",
      "Grad:   tensor([-0.0679,  0.3842])\n",
      "Epoch 1004, Loss 9.146929\n",
      "Params: tensor([ 4.1225, -9.9357])\n",
      "Grad:   tensor([-0.0677,  0.3835])\n",
      "Epoch 1005, Loss 9.145413\n",
      "Params: tensor([ 4.1231, -9.9395])\n",
      "Grad:   tensor([-0.0676,  0.3829])\n",
      "Epoch 1006, Loss 9.143902\n",
      "Params: tensor([ 4.1238, -9.9433])\n",
      "Grad:   tensor([-0.0675,  0.3822])\n",
      "Epoch 1007, Loss 9.142399\n",
      "Params: tensor([ 4.1245, -9.9472])\n",
      "Grad:   tensor([-0.0674,  0.3816])\n",
      "Epoch 1008, Loss 9.140899\n",
      "Params: tensor([ 4.1252, -9.9510])\n",
      "Grad:   tensor([-0.0673,  0.3809])\n",
      "Epoch 1009, Loss 9.139400\n",
      "Params: tensor([ 4.1258, -9.9548])\n",
      "Grad:   tensor([-0.0672,  0.3803])\n",
      "Epoch 1010, Loss 9.137912\n",
      "Params: tensor([ 4.1265, -9.9586])\n",
      "Grad:   tensor([-0.0670,  0.3796])\n",
      "Epoch 1011, Loss 9.136428\n",
      "Params: tensor([ 4.1272, -9.9624])\n",
      "Grad:   tensor([-0.0669,  0.3790])\n",
      "Epoch 1012, Loss 9.134948\n",
      "Params: tensor([ 4.1278, -9.9661])\n",
      "Grad:   tensor([-0.0668,  0.3783])\n",
      "Epoch 1013, Loss 9.133472\n",
      "Params: tensor([ 4.1285, -9.9699])\n",
      "Grad:   tensor([-0.0667,  0.3777])\n",
      "Epoch 1014, Loss 9.132005\n",
      "Params: tensor([ 4.1292, -9.9737])\n",
      "Grad:   tensor([-0.0666,  0.3770])\n",
      "Epoch 1015, Loss 9.130540\n",
      "Params: tensor([ 4.1298, -9.9775])\n",
      "Grad:   tensor([-0.0665,  0.3764])\n",
      "Epoch 1016, Loss 9.129081\n",
      "Params: tensor([ 4.1305, -9.9812])\n",
      "Grad:   tensor([-0.0664,  0.3758])\n",
      "Epoch 1017, Loss 9.127626\n",
      "Params: tensor([ 4.1312, -9.9850])\n",
      "Grad:   tensor([-0.0663,  0.3751])\n",
      "Epoch 1018, Loss 9.126176\n",
      "Params: tensor([ 4.1318, -9.9887])\n",
      "Grad:   tensor([-0.0661,  0.3745])\n",
      "Epoch 1019, Loss 9.124730\n",
      "Params: tensor([ 4.1325, -9.9924])\n",
      "Grad:   tensor([-0.0660,  0.3739])\n",
      "Epoch 1020, Loss 9.123292\n",
      "Params: tensor([ 4.1332, -9.9962])\n",
      "Grad:   tensor([-0.0659,  0.3732])\n",
      "Epoch 1021, Loss 9.121853\n",
      "Params: tensor([ 4.1338, -9.9999])\n",
      "Grad:   tensor([-0.0658,  0.3726])\n",
      "Epoch 1022, Loss 9.120424\n",
      "Params: tensor([  4.1345, -10.0036])\n",
      "Grad:   tensor([-0.0657,  0.3720])\n",
      "Epoch 1023, Loss 9.118999\n",
      "Params: tensor([  4.1351, -10.0073])\n",
      "Grad:   tensor([-0.0656,  0.3713])\n",
      "Epoch 1024, Loss 9.117578\n",
      "Params: tensor([  4.1358, -10.0110])\n",
      "Grad:   tensor([-0.0655,  0.3707])\n",
      "Epoch 1025, Loss 9.116161\n",
      "Params: tensor([  4.1364, -10.0147])\n",
      "Grad:   tensor([-0.0654,  0.3701])\n",
      "Epoch 1026, Loss 9.114753\n",
      "Params: tensor([  4.1371, -10.0184])\n",
      "Grad:   tensor([-0.0653,  0.3694])\n",
      "Epoch 1027, Loss 9.113343\n",
      "Params: tensor([  4.1377, -10.0221])\n",
      "Grad:   tensor([-0.0652,  0.3688])\n",
      "Epoch 1028, Loss 9.111945\n",
      "Params: tensor([  4.1384, -10.0258])\n",
      "Grad:   tensor([-0.0651,  0.3682])\n",
      "Epoch 1029, Loss 9.110546\n",
      "Params: tensor([  4.1390, -10.0295])\n",
      "Grad:   tensor([-0.0649,  0.3675])\n",
      "Epoch 1030, Loss 9.109155\n",
      "Params: tensor([  4.1397, -10.0331])\n",
      "Grad:   tensor([-0.0648,  0.3669])\n",
      "Epoch 1031, Loss 9.107769\n",
      "Params: tensor([  4.1403, -10.0368])\n",
      "Grad:   tensor([-0.0647,  0.3663])\n",
      "Epoch 1032, Loss 9.106385\n",
      "Params: tensor([  4.1410, -10.0405])\n",
      "Grad:   tensor([-0.0646,  0.3657])\n",
      "Epoch 1033, Loss 9.105008\n",
      "Params: tensor([  4.1416, -10.0441])\n",
      "Grad:   tensor([-0.0645,  0.3651])\n",
      "Epoch 1034, Loss 9.103635\n",
      "Params: tensor([  4.1423, -10.0478])\n",
      "Grad:   tensor([-0.0644,  0.3644])\n",
      "Epoch 1035, Loss 9.102266\n",
      "Params: tensor([  4.1429, -10.0514])\n",
      "Grad:   tensor([-0.0643,  0.3638])\n",
      "Epoch 1036, Loss 9.100903\n",
      "Params: tensor([  4.1436, -10.0550])\n",
      "Grad:   tensor([-0.0642,  0.3632])\n",
      "Epoch 1037, Loss 9.099543\n",
      "Params: tensor([  4.1442, -10.0587])\n",
      "Grad:   tensor([-0.0640,  0.3626])\n",
      "Epoch 1038, Loss 9.098189\n",
      "Params: tensor([  4.1448, -10.0623])\n",
      "Grad:   tensor([-0.0639,  0.3620])\n",
      "Epoch 1039, Loss 9.096839\n",
      "Params: tensor([  4.1455, -10.0659])\n",
      "Grad:   tensor([-0.0638,  0.3614])\n",
      "Epoch 1040, Loss 9.095490\n",
      "Params: tensor([  4.1461, -10.0695])\n",
      "Grad:   tensor([-0.0637,  0.3607])\n",
      "Epoch 1041, Loss 9.094153\n",
      "Params: tensor([  4.1467, -10.0731])\n",
      "Grad:   tensor([-0.0636,  0.3601])\n",
      "Epoch 1042, Loss 9.092815\n",
      "Params: tensor([  4.1474, -10.0767])\n",
      "Grad:   tensor([-0.0635,  0.3595])\n",
      "Epoch 1043, Loss 9.091483\n",
      "Params: tensor([  4.1480, -10.0803])\n",
      "Grad:   tensor([-0.0634,  0.3589])\n",
      "Epoch 1044, Loss 9.090158\n",
      "Params: tensor([  4.1486, -10.0839])\n",
      "Grad:   tensor([-0.0633,  0.3583])\n",
      "Epoch 1045, Loss 9.088834\n",
      "Params: tensor([  4.1493, -10.0874])\n",
      "Grad:   tensor([-0.0632,  0.3577])\n",
      "Epoch 1046, Loss 9.087517\n",
      "Params: tensor([  4.1499, -10.0910])\n",
      "Grad:   tensor([-0.0631,  0.3571])\n",
      "Epoch 1047, Loss 9.086201\n",
      "Params: tensor([  4.1505, -10.0946])\n",
      "Grad:   tensor([-0.0630,  0.3565])\n",
      "Epoch 1048, Loss 9.084892\n",
      "Params: tensor([  4.1512, -10.0981])\n",
      "Grad:   tensor([-0.0629,  0.3559])\n",
      "Epoch 1049, Loss 9.083589\n",
      "Params: tensor([  4.1518, -10.1017])\n",
      "Grad:   tensor([-0.0628,  0.3553])\n",
      "Epoch 1050, Loss 9.082290\n",
      "Params: tensor([  4.1524, -10.1052])\n",
      "Grad:   tensor([-0.0627,  0.3547])\n",
      "Epoch 1051, Loss 9.080993\n",
      "Params: tensor([  4.1530, -10.1088])\n",
      "Grad:   tensor([-0.0626,  0.3541])\n",
      "Epoch 1052, Loss 9.079700\n",
      "Params: tensor([  4.1537, -10.1123])\n",
      "Grad:   tensor([-0.0624,  0.3535])\n",
      "Epoch 1053, Loss 9.078414\n",
      "Params: tensor([  4.1543, -10.1158])\n",
      "Grad:   tensor([-0.0623,  0.3529])\n",
      "Epoch 1054, Loss 9.077130\n",
      "Params: tensor([  4.1549, -10.1194])\n",
      "Grad:   tensor([-0.0622,  0.3523])\n",
      "Epoch 1055, Loss 9.075850\n",
      "Params: tensor([  4.1555, -10.1229])\n",
      "Grad:   tensor([-0.0621,  0.3517])\n",
      "Epoch 1056, Loss 9.074578\n",
      "Params: tensor([  4.1562, -10.1264])\n",
      "Grad:   tensor([-0.0620,  0.3511])\n",
      "Epoch 1057, Loss 9.073309\n",
      "Params: tensor([  4.1568, -10.1299])\n",
      "Grad:   tensor([-0.0619,  0.3505])\n",
      "Epoch 1058, Loss 9.072041\n",
      "Params: tensor([  4.1574, -10.1334])\n",
      "Grad:   tensor([-0.0618,  0.3499])\n",
      "Epoch 1059, Loss 9.070785\n",
      "Params: tensor([  4.1580, -10.1369])\n",
      "Grad:   tensor([-0.0617,  0.3493])\n",
      "Epoch 1060, Loss 9.069526\n",
      "Params: tensor([  4.1586, -10.1404])\n",
      "Grad:   tensor([-0.0616,  0.3487])\n",
      "Epoch 1061, Loss 9.068272\n",
      "Params: tensor([  4.1592, -10.1439])\n",
      "Grad:   tensor([-0.0615,  0.3481])\n",
      "Epoch 1062, Loss 9.067025\n",
      "Params: tensor([  4.1599, -10.1473])\n",
      "Grad:   tensor([-0.0614,  0.3475])\n",
      "Epoch 1063, Loss 9.065780\n",
      "Params: tensor([  4.1605, -10.1508])\n",
      "Grad:   tensor([-0.0613,  0.3469])\n",
      "Epoch 1064, Loss 9.064538\n",
      "Params: tensor([  4.1611, -10.1543])\n",
      "Grad:   tensor([-0.0612,  0.3463])\n",
      "Epoch 1065, Loss 9.063302\n",
      "Params: tensor([  4.1617, -10.1577])\n",
      "Grad:   tensor([-0.0611,  0.3457])\n",
      "Epoch 1066, Loss 9.062074\n",
      "Params: tensor([  4.1623, -10.1612])\n",
      "Grad:   tensor([-0.0610,  0.3451])\n",
      "Epoch 1067, Loss 9.060843\n",
      "Params: tensor([  4.1629, -10.1646])\n",
      "Grad:   tensor([-0.0609,  0.3446])\n",
      "Epoch 1068, Loss 9.059623\n",
      "Params: tensor([  4.1635, -10.1681])\n",
      "Grad:   tensor([-0.0608,  0.3440])\n",
      "Epoch 1069, Loss 9.058403\n",
      "Params: tensor([  4.1641, -10.1715])\n",
      "Grad:   tensor([-0.0607,  0.3434])\n",
      "Epoch 1070, Loss 9.057187\n",
      "Params: tensor([  4.1647, -10.1749])\n",
      "Grad:   tensor([-0.0606,  0.3428])\n",
      "Epoch 1071, Loss 9.055977\n",
      "Params: tensor([  4.1653, -10.1783])\n",
      "Grad:   tensor([-0.0605,  0.3422])\n",
      "Epoch 1072, Loss 9.054768\n",
      "Params: tensor([  4.1659, -10.1818])\n",
      "Grad:   tensor([-0.0603,  0.3416])\n",
      "Epoch 1073, Loss 9.053568\n",
      "Params: tensor([  4.1665, -10.1852])\n",
      "Grad:   tensor([-0.0603,  0.3411])\n",
      "Epoch 1074, Loss 9.052371\n",
      "Params: tensor([  4.1671, -10.1886])\n",
      "Grad:   tensor([-0.0601,  0.3405])\n",
      "Epoch 1075, Loss 9.051174\n",
      "Params: tensor([  4.1677, -10.1920])\n",
      "Grad:   tensor([-0.0600,  0.3399])\n",
      "Epoch 1076, Loss 9.049982\n",
      "Params: tensor([  4.1683, -10.1954])\n",
      "Grad:   tensor([-0.0599,  0.3393])\n",
      "Epoch 1077, Loss 9.048798\n",
      "Params: tensor([  4.1689, -10.1988])\n",
      "Grad:   tensor([-0.0598,  0.3387])\n",
      "Epoch 1078, Loss 9.047617\n",
      "Params: tensor([  4.1695, -10.2021])\n",
      "Grad:   tensor([-0.0598,  0.3382])\n",
      "Epoch 1079, Loss 9.046436\n",
      "Params: tensor([  4.1701, -10.2055])\n",
      "Grad:   tensor([-0.0596,  0.3376])\n",
      "Epoch 1080, Loss 9.045262\n",
      "Params: tensor([  4.1707, -10.2089])\n",
      "Grad:   tensor([-0.0595,  0.3370])\n",
      "Epoch 1081, Loss 9.044091\n",
      "Params: tensor([  4.1713, -10.2122])\n",
      "Grad:   tensor([-0.0594,  0.3364])\n",
      "Epoch 1082, Loss 9.042927\n",
      "Params: tensor([  4.1719, -10.2156])\n",
      "Grad:   tensor([-0.0593,  0.3359])\n",
      "Epoch 1083, Loss 9.041762\n",
      "Params: tensor([  4.1725, -10.2190])\n",
      "Grad:   tensor([-0.0592,  0.3353])\n",
      "Epoch 1084, Loss 9.040606\n",
      "Params: tensor([  4.1731, -10.2223])\n",
      "Grad:   tensor([-0.0591,  0.3347])\n",
      "Epoch 1085, Loss 9.039452\n",
      "Params: tensor([  4.1737, -10.2256])\n",
      "Grad:   tensor([-0.0590,  0.3342])\n",
      "Epoch 1086, Loss 9.038301\n",
      "Params: tensor([  4.1743, -10.2290])\n",
      "Grad:   tensor([-0.0589,  0.3336])\n",
      "Epoch 1087, Loss 9.037155\n",
      "Params: tensor([  4.1749, -10.2323])\n",
      "Grad:   tensor([-0.0588,  0.3330])\n",
      "Epoch 1088, Loss 9.036011\n",
      "Params: tensor([  4.1755, -10.2356])\n",
      "Grad:   tensor([-0.0587,  0.3325])\n",
      "Epoch 1089, Loss 9.034875\n",
      "Params: tensor([  4.1760, -10.2390])\n",
      "Grad:   tensor([-0.0586,  0.3319])\n",
      "Epoch 1090, Loss 9.033738\n",
      "Params: tensor([  4.1766, -10.2423])\n",
      "Grad:   tensor([-0.0585,  0.3313])\n",
      "Epoch 1091, Loss 9.032607\n",
      "Params: tensor([  4.1772, -10.2456])\n",
      "Grad:   tensor([-0.0584,  0.3308])\n",
      "Epoch 1092, Loss 9.031478\n",
      "Params: tensor([  4.1778, -10.2489])\n",
      "Grad:   tensor([-0.0583,  0.3302])\n",
      "Epoch 1093, Loss 9.030353\n",
      "Params: tensor([  4.1784, -10.2522])\n",
      "Grad:   tensor([-0.0582,  0.3297])\n",
      "Epoch 1094, Loss 9.029233\n",
      "Params: tensor([  4.1790, -10.2555])\n",
      "Grad:   tensor([-0.0582,  0.3291])\n",
      "Epoch 1095, Loss 9.028121\n",
      "Params: tensor([  4.1795, -10.2588])\n",
      "Grad:   tensor([-0.0580,  0.3285])\n",
      "Epoch 1096, Loss 9.027008\n",
      "Params: tensor([  4.1801, -10.2620])\n",
      "Grad:   tensor([-0.0579,  0.3280])\n",
      "Epoch 1097, Loss 9.025901\n",
      "Params: tensor([  4.1807, -10.2653])\n",
      "Grad:   tensor([-0.0578,  0.3274])\n",
      "Epoch 1098, Loss 9.024796\n",
      "Params: tensor([  4.1813, -10.2686])\n",
      "Grad:   tensor([-0.0577,  0.3269])\n",
      "Epoch 1099, Loss 9.023694\n",
      "Params: tensor([  4.1819, -10.2718])\n",
      "Grad:   tensor([-0.0576,  0.3263])\n",
      "Epoch 1100, Loss 9.022597\n",
      "Params: tensor([  4.1824, -10.2751])\n",
      "Grad:   tensor([-0.0575,  0.3258])\n",
      "Epoch 1101, Loss 9.021504\n",
      "Params: tensor([  4.1830, -10.2783])\n",
      "Grad:   tensor([-0.0574,  0.3252])\n",
      "Epoch 1102, Loss 9.020413\n",
      "Params: tensor([  4.1836, -10.2816])\n",
      "Grad:   tensor([-0.0573,  0.3247])\n",
      "Epoch 1103, Loss 9.019329\n",
      "Params: tensor([  4.1841, -10.2848])\n",
      "Grad:   tensor([-0.0573,  0.3241])\n",
      "Epoch 1104, Loss 9.018246\n",
      "Params: tensor([  4.1847, -10.2881])\n",
      "Grad:   tensor([-0.0571,  0.3236])\n",
      "Epoch 1105, Loss 9.017170\n",
      "Params: tensor([  4.1853, -10.2913])\n",
      "Grad:   tensor([-0.0571,  0.3230])\n",
      "Epoch 1106, Loss 9.016093\n",
      "Params: tensor([  4.1859, -10.2945])\n",
      "Grad:   tensor([-0.0570,  0.3224])\n",
      "Epoch 1107, Loss 9.015023\n",
      "Params: tensor([  4.1864, -10.2977])\n",
      "Grad:   tensor([-0.0569,  0.3219])\n",
      "Epoch 1108, Loss 9.013955\n",
      "Params: tensor([  4.1870, -10.3010])\n",
      "Grad:   tensor([-0.0568,  0.3214])\n",
      "Epoch 1109, Loss 9.012889\n",
      "Params: tensor([  4.1876, -10.3042])\n",
      "Grad:   tensor([-0.0567,  0.3208])\n",
      "Epoch 1110, Loss 9.011827\n",
      "Params: tensor([  4.1881, -10.3074])\n",
      "Grad:   tensor([-0.0566,  0.3203])\n",
      "Epoch 1111, Loss 9.010773\n",
      "Params: tensor([  4.1887, -10.3106])\n",
      "Grad:   tensor([-0.0565,  0.3197])\n",
      "Epoch 1112, Loss 9.009721\n",
      "Params: tensor([  4.1893, -10.3138])\n",
      "Grad:   tensor([-0.0564,  0.3192])\n",
      "Epoch 1113, Loss 9.008671\n",
      "Params: tensor([  4.1898, -10.3169])\n",
      "Grad:   tensor([-0.0563,  0.3186])\n",
      "Epoch 1114, Loss 9.007626\n",
      "Params: tensor([  4.1904, -10.3201])\n",
      "Grad:   tensor([-0.0562,  0.3181])\n",
      "Epoch 1115, Loss 9.006583\n",
      "Params: tensor([  4.1909, -10.3233])\n",
      "Grad:   tensor([-0.0561,  0.3176])\n",
      "Epoch 1116, Loss 9.005544\n",
      "Params: tensor([  4.1915, -10.3265])\n",
      "Grad:   tensor([-0.0560,  0.3170])\n",
      "Epoch 1117, Loss 9.004507\n",
      "Params: tensor([  4.1921, -10.3296])\n",
      "Grad:   tensor([-0.0559,  0.3165])\n",
      "Epoch 1118, Loss 9.003475\n",
      "Params: tensor([  4.1926, -10.3328])\n",
      "Grad:   tensor([-0.0558,  0.3159])\n",
      "Epoch 1119, Loss 9.002448\n",
      "Params: tensor([  4.1932, -10.3359])\n",
      "Grad:   tensor([-0.0557,  0.3154])\n",
      "Epoch 1120, Loss 9.001419\n",
      "Params: tensor([  4.1937, -10.3391])\n",
      "Grad:   tensor([-0.0556,  0.3149])\n",
      "Epoch 1121, Loss 9.000401\n",
      "Params: tensor([  4.1943, -10.3422])\n",
      "Grad:   tensor([-0.0555,  0.3143])\n",
      "Epoch 1122, Loss 8.999382\n",
      "Params: tensor([  4.1948, -10.3454])\n",
      "Grad:   tensor([-0.0554,  0.3138])\n",
      "Epoch 1123, Loss 8.998366\n",
      "Params: tensor([  4.1954, -10.3485])\n",
      "Grad:   tensor([-0.0553,  0.3133])\n",
      "Epoch 1124, Loss 8.997356\n",
      "Params: tensor([  4.1959, -10.3516])\n",
      "Grad:   tensor([-0.0553,  0.3127])\n",
      "Epoch 1125, Loss 8.996347\n",
      "Params: tensor([  4.1965, -10.3548])\n",
      "Grad:   tensor([-0.0552,  0.3122])\n",
      "Epoch 1126, Loss 8.995345\n",
      "Params: tensor([  4.1971, -10.3579])\n",
      "Grad:   tensor([-0.0551,  0.3117])\n",
      "Epoch 1127, Loss 8.994343\n",
      "Params: tensor([  4.1976, -10.3610])\n",
      "Grad:   tensor([-0.0549,  0.3111])\n",
      "Epoch 1128, Loss 8.993346\n",
      "Params: tensor([  4.1981, -10.3641])\n",
      "Grad:   tensor([-0.0549,  0.3106])\n",
      "Epoch 1129, Loss 8.992352\n",
      "Params: tensor([  4.1987, -10.3672])\n",
      "Grad:   tensor([-0.0548,  0.3101])\n",
      "Epoch 1130, Loss 8.991360\n",
      "Params: tensor([  4.1992, -10.3703])\n",
      "Grad:   tensor([-0.0547,  0.3096])\n",
      "Epoch 1131, Loss 8.990371\n",
      "Params: tensor([  4.1998, -10.3734])\n",
      "Grad:   tensor([-0.0546,  0.3090])\n",
      "Epoch 1132, Loss 8.989388\n",
      "Params: tensor([  4.2003, -10.3765])\n",
      "Grad:   tensor([-0.0545,  0.3085])\n",
      "Epoch 1133, Loss 8.988409\n",
      "Params: tensor([  4.2009, -10.3795])\n",
      "Grad:   tensor([-0.0544,  0.3080])\n",
      "Epoch 1134, Loss 8.987433\n",
      "Params: tensor([  4.2014, -10.3826])\n",
      "Grad:   tensor([-0.0543,  0.3075])\n",
      "Epoch 1135, Loss 8.986457\n",
      "Params: tensor([  4.2020, -10.3857])\n",
      "Grad:   tensor([-0.0542,  0.3069])\n",
      "Epoch 1136, Loss 8.985488\n",
      "Params: tensor([  4.2025, -10.3888])\n",
      "Grad:   tensor([-0.0541,  0.3064])\n",
      "Epoch 1137, Loss 8.984521\n",
      "Params: tensor([  4.2030, -10.3918])\n",
      "Grad:   tensor([-0.0540,  0.3059])\n",
      "Epoch 1138, Loss 8.983557\n",
      "Params: tensor([  4.2036, -10.3949])\n",
      "Grad:   tensor([-0.0540,  0.3054])\n",
      "Epoch 1139, Loss 8.982595\n",
      "Params: tensor([  4.2041, -10.3979])\n",
      "Grad:   tensor([-0.0538,  0.3049])\n",
      "Epoch 1140, Loss 8.981640\n",
      "Params: tensor([  4.2047, -10.4010])\n",
      "Grad:   tensor([-0.0538,  0.3043])\n",
      "Epoch 1141, Loss 8.980682\n",
      "Params: tensor([  4.2052, -10.4040])\n",
      "Grad:   tensor([-0.0537,  0.3038])\n",
      "Epoch 1142, Loss 8.979733\n",
      "Params: tensor([  4.2057, -10.4070])\n",
      "Grad:   tensor([-0.0536,  0.3033])\n",
      "Epoch 1143, Loss 8.978784\n",
      "Params: tensor([  4.2063, -10.4101])\n",
      "Grad:   tensor([-0.0535,  0.3028])\n",
      "Epoch 1144, Loss 8.977839\n",
      "Params: tensor([  4.2068, -10.4131])\n",
      "Grad:   tensor([-0.0534,  0.3023])\n",
      "Epoch 1145, Loss 8.976899\n",
      "Params: tensor([  4.2073, -10.4161])\n",
      "Grad:   tensor([-0.0533,  0.3018])\n",
      "Epoch 1146, Loss 8.975959\n",
      "Params: tensor([  4.2079, -10.4191])\n",
      "Grad:   tensor([-0.0532,  0.3012])\n",
      "Epoch 1147, Loss 8.975026\n",
      "Params: tensor([  4.2084, -10.4221])\n",
      "Grad:   tensor([-0.0531,  0.3007])\n",
      "Epoch 1148, Loss 8.974091\n",
      "Params: tensor([  4.2089, -10.4251])\n",
      "Grad:   tensor([-0.0530,  0.3002])\n",
      "Epoch 1149, Loss 8.973165\n",
      "Params: tensor([  4.2095, -10.4281])\n",
      "Grad:   tensor([-0.0530,  0.2997])\n",
      "Epoch 1150, Loss 8.972239\n",
      "Params: tensor([  4.2100, -10.4311])\n",
      "Grad:   tensor([-0.0529,  0.2992])\n",
      "Epoch 1151, Loss 8.971314\n",
      "Params: tensor([  4.2105, -10.4341])\n",
      "Grad:   tensor([-0.0528,  0.2987])\n",
      "Epoch 1152, Loss 8.970399\n",
      "Params: tensor([  4.2110, -10.4371])\n",
      "Grad:   tensor([-0.0527,  0.2982])\n",
      "Epoch 1153, Loss 8.969481\n",
      "Params: tensor([  4.2116, -10.4401])\n",
      "Grad:   tensor([-0.0526,  0.2977])\n",
      "Epoch 1154, Loss 8.968566\n",
      "Params: tensor([  4.2121, -10.4430])\n",
      "Grad:   tensor([-0.0525,  0.2972])\n",
      "Epoch 1155, Loss 8.967657\n",
      "Params: tensor([  4.2126, -10.4460])\n",
      "Grad:   tensor([-0.0524,  0.2967])\n",
      "Epoch 1156, Loss 8.966751\n",
      "Params: tensor([  4.2131, -10.4490])\n",
      "Grad:   tensor([-0.0523,  0.2962])\n",
      "Epoch 1157, Loss 8.965846\n",
      "Params: tensor([  4.2137, -10.4519])\n",
      "Grad:   tensor([-0.0522,  0.2957])\n",
      "Epoch 1158, Loss 8.964948\n",
      "Params: tensor([  4.2142, -10.4549])\n",
      "Grad:   tensor([-0.0521,  0.2952])\n",
      "Epoch 1159, Loss 8.964046\n",
      "Params: tensor([  4.2147, -10.4578])\n",
      "Grad:   tensor([-0.0521,  0.2947])\n",
      "Epoch 1160, Loss 8.963154\n",
      "Params: tensor([  4.2152, -10.4608])\n",
      "Grad:   tensor([-0.0520,  0.2942])\n",
      "Epoch 1161, Loss 8.962263\n",
      "Params: tensor([  4.2157, -10.4637])\n",
      "Grad:   tensor([-0.0519,  0.2937])\n",
      "Epoch 1162, Loss 8.961374\n",
      "Params: tensor([  4.2163, -10.4666])\n",
      "Grad:   tensor([-0.0518,  0.2932])\n",
      "Epoch 1163, Loss 8.960488\n",
      "Params: tensor([  4.2168, -10.4695])\n",
      "Grad:   tensor([-0.0517,  0.2927])\n",
      "Epoch 1164, Loss 8.959608\n",
      "Params: tensor([  4.2173, -10.4725])\n",
      "Grad:   tensor([-0.0516,  0.2922])\n",
      "Epoch 1165, Loss 8.958724\n",
      "Params: tensor([  4.2178, -10.4754])\n",
      "Grad:   tensor([-0.0515,  0.2917])\n",
      "Epoch 1166, Loss 8.957851\n",
      "Params: tensor([  4.2183, -10.4783])\n",
      "Grad:   tensor([-0.0514,  0.2912])\n",
      "Epoch 1167, Loss 8.956977\n",
      "Params: tensor([  4.2188, -10.4812])\n",
      "Grad:   tensor([-0.0513,  0.2907])\n",
      "Epoch 1168, Loss 8.956104\n",
      "Params: tensor([  4.2193, -10.4841])\n",
      "Grad:   tensor([-0.0513,  0.2902])\n",
      "Epoch 1169, Loss 8.955239\n",
      "Params: tensor([  4.2199, -10.4870])\n",
      "Grad:   tensor([-0.0512,  0.2897])\n",
      "Epoch 1170, Loss 8.954372\n",
      "Params: tensor([  4.2204, -10.4899])\n",
      "Grad:   tensor([-0.0511,  0.2892])\n",
      "Epoch 1171, Loss 8.953515\n",
      "Params: tensor([  4.2209, -10.4928])\n",
      "Grad:   tensor([-0.0510,  0.2887])\n",
      "Epoch 1172, Loss 8.952652\n",
      "Params: tensor([  4.2214, -10.4957])\n",
      "Grad:   tensor([-0.0509,  0.2882])\n",
      "Epoch 1173, Loss 8.951797\n",
      "Params: tensor([  4.2219, -10.4985])\n",
      "Grad:   tensor([-0.0508,  0.2877])\n",
      "Epoch 1174, Loss 8.950944\n",
      "Params: tensor([  4.2224, -10.5014])\n",
      "Grad:   tensor([-0.0507,  0.2872])\n",
      "Epoch 1175, Loss 8.950094\n",
      "Params: tensor([  4.2229, -10.5043])\n",
      "Grad:   tensor([-0.0507,  0.2868])\n",
      "Epoch 1176, Loss 8.949246\n",
      "Params: tensor([  4.2234, -10.5071])\n",
      "Grad:   tensor([-0.0506,  0.2863])\n",
      "Epoch 1177, Loss 8.948401\n",
      "Params: tensor([  4.2239, -10.5100])\n",
      "Grad:   tensor([-0.0505,  0.2858])\n",
      "Epoch 1178, Loss 8.947562\n",
      "Params: tensor([  4.2244, -10.5129])\n",
      "Grad:   tensor([-0.0504,  0.2853])\n",
      "Epoch 1179, Loss 8.946723\n",
      "Params: tensor([  4.2249, -10.5157])\n",
      "Grad:   tensor([-0.0503,  0.2848])\n",
      "Epoch 1180, Loss 8.945888\n",
      "Params: tensor([  4.2254, -10.5185])\n",
      "Grad:   tensor([-0.0502,  0.2843])\n",
      "Epoch 1181, Loss 8.945053\n",
      "Params: tensor([  4.2259, -10.5214])\n",
      "Grad:   tensor([-0.0501,  0.2838])\n",
      "Epoch 1182, Loss 8.944224\n",
      "Params: tensor([  4.2264, -10.5242])\n",
      "Grad:   tensor([-0.0500,  0.2834])\n",
      "Epoch 1183, Loss 8.943397\n",
      "Params: tensor([  4.2269, -10.5270])\n",
      "Grad:   tensor([-0.0500,  0.2829])\n",
      "Epoch 1184, Loss 8.942573\n",
      "Params: tensor([  4.2274, -10.5299])\n",
      "Grad:   tensor([-0.0499,  0.2824])\n",
      "Epoch 1185, Loss 8.941749\n",
      "Params: tensor([  4.2279, -10.5327])\n",
      "Grad:   tensor([-0.0498,  0.2819])\n",
      "Epoch 1186, Loss 8.940929\n",
      "Params: tensor([  4.2284, -10.5355])\n",
      "Grad:   tensor([-0.0497,  0.2814])\n",
      "Epoch 1187, Loss 8.940118\n",
      "Params: tensor([  4.2289, -10.5383])\n",
      "Grad:   tensor([-0.0496,  0.2810])\n",
      "Epoch 1188, Loss 8.939301\n",
      "Params: tensor([  4.2294, -10.5411])\n",
      "Grad:   tensor([-0.0495,  0.2805])\n",
      "Epoch 1189, Loss 8.938489\n",
      "Params: tensor([  4.2299, -10.5439])\n",
      "Grad:   tensor([-0.0494,  0.2800])\n",
      "Epoch 1190, Loss 8.937684\n",
      "Params: tensor([  4.2304, -10.5467])\n",
      "Grad:   tensor([-0.0494,  0.2795])\n",
      "Epoch 1191, Loss 8.936877\n",
      "Params: tensor([  4.2309, -10.5495])\n",
      "Grad:   tensor([-0.0493,  0.2791])\n",
      "Epoch 1192, Loss 8.936075\n",
      "Params: tensor([  4.2314, -10.5523])\n",
      "Grad:   tensor([-0.0492,  0.2786])\n",
      "Epoch 1193, Loss 8.935276\n",
      "Params: tensor([  4.2319, -10.5551])\n",
      "Grad:   tensor([-0.0491,  0.2781])\n",
      "Epoch 1194, Loss 8.934478\n",
      "Params: tensor([  4.2324, -10.5578])\n",
      "Grad:   tensor([-0.0490,  0.2776])\n",
      "Epoch 1195, Loss 8.933686\n",
      "Params: tensor([  4.2329, -10.5606])\n",
      "Grad:   tensor([-0.0490,  0.2772])\n",
      "Epoch 1196, Loss 8.932894\n",
      "Params: tensor([  4.2334, -10.5634])\n",
      "Grad:   tensor([-0.0489,  0.2767])\n",
      "Epoch 1197, Loss 8.932106\n",
      "Params: tensor([  4.2338, -10.5661])\n",
      "Grad:   tensor([-0.0488,  0.2762])\n",
      "Epoch 1198, Loss 8.931321\n",
      "Params: tensor([  4.2343, -10.5689])\n",
      "Grad:   tensor([-0.0487,  0.2758])\n",
      "Epoch 1199, Loss 8.930538\n",
      "Params: tensor([  4.2348, -10.5717])\n",
      "Grad:   tensor([-0.0486,  0.2753])\n",
      "Epoch 1200, Loss 8.929752\n",
      "Params: tensor([  4.2353, -10.5744])\n",
      "Grad:   tensor([-0.0485,  0.2748])\n",
      "Epoch 1201, Loss 8.928974\n",
      "Params: tensor([  4.2358, -10.5771])\n",
      "Grad:   tensor([-0.0485,  0.2744])\n",
      "Epoch 1202, Loss 8.928198\n",
      "Params: tensor([  4.2363, -10.5799])\n",
      "Grad:   tensor([-0.0484,  0.2739])\n",
      "Epoch 1203, Loss 8.927427\n",
      "Params: tensor([  4.2368, -10.5826])\n",
      "Grad:   tensor([-0.0483,  0.2734])\n",
      "Epoch 1204, Loss 8.926658\n",
      "Params: tensor([  4.2372, -10.5854])\n",
      "Grad:   tensor([-0.0482,  0.2730])\n",
      "Epoch 1205, Loss 8.925890\n",
      "Params: tensor([  4.2377, -10.5881])\n",
      "Grad:   tensor([-0.0481,  0.2725])\n",
      "Epoch 1206, Loss 8.925125\n",
      "Params: tensor([  4.2382, -10.5908])\n",
      "Grad:   tensor([-0.0480,  0.2720])\n",
      "Epoch 1207, Loss 8.924361\n",
      "Params: tensor([  4.2387, -10.5935])\n",
      "Grad:   tensor([-0.0480,  0.2716])\n",
      "Epoch 1208, Loss 8.923601\n",
      "Params: tensor([  4.2392, -10.5962])\n",
      "Grad:   tensor([-0.0479,  0.2711])\n",
      "Epoch 1209, Loss 8.922845\n",
      "Params: tensor([  4.2396, -10.5989])\n",
      "Grad:   tensor([-0.0478,  0.2707])\n",
      "Epoch 1210, Loss 8.922090\n",
      "Params: tensor([  4.2401, -10.6016])\n",
      "Grad:   tensor([-0.0477,  0.2702])\n",
      "Epoch 1211, Loss 8.921340\n",
      "Params: tensor([  4.2406, -10.6043])\n",
      "Grad:   tensor([-0.0476,  0.2697])\n",
      "Epoch 1212, Loss 8.920589\n",
      "Params: tensor([  4.2411, -10.6070])\n",
      "Grad:   tensor([-0.0476,  0.2693])\n",
      "Epoch 1213, Loss 8.919840\n",
      "Params: tensor([  4.2415, -10.6097])\n",
      "Grad:   tensor([-0.0475,  0.2688])\n",
      "Epoch 1214, Loss 8.919097\n",
      "Params: tensor([  4.2420, -10.6124])\n",
      "Grad:   tensor([-0.0474,  0.2684])\n",
      "Epoch 1215, Loss 8.918356\n",
      "Params: tensor([  4.2425, -10.6151])\n",
      "Grad:   tensor([-0.0473,  0.2679])\n",
      "Epoch 1216, Loss 8.917615\n",
      "Params: tensor([  4.2430, -10.6177])\n",
      "Grad:   tensor([-0.0472,  0.2674])\n",
      "Epoch 1217, Loss 8.916880\n",
      "Params: tensor([  4.2434, -10.6204])\n",
      "Grad:   tensor([-0.0472,  0.2670])\n",
      "Epoch 1218, Loss 8.916142\n",
      "Params: tensor([  4.2439, -10.6231])\n",
      "Grad:   tensor([-0.0471,  0.2665])\n",
      "Epoch 1219, Loss 8.915412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: tensor([  4.2444, -10.6257])\n",
      "Grad:   tensor([-0.0470,  0.2661])\n",
      "Epoch 1220, Loss 8.914684\n",
      "Params: tensor([  4.2448, -10.6284])\n",
      "Grad:   tensor([-0.0469,  0.2656])\n",
      "Epoch 1221, Loss 8.913955\n",
      "Params: tensor([  4.2453, -10.6311])\n",
      "Grad:   tensor([-0.0469,  0.2652])\n",
      "Epoch 1222, Loss 8.913235\n",
      "Params: tensor([  4.2458, -10.6337])\n",
      "Grad:   tensor([-0.0468,  0.2647])\n",
      "Epoch 1223, Loss 8.912511\n",
      "Params: tensor([  4.2462, -10.6363])\n",
      "Grad:   tensor([-0.0467,  0.2643])\n",
      "Epoch 1224, Loss 8.911788\n",
      "Params: tensor([  4.2467, -10.6390])\n",
      "Grad:   tensor([-0.0466,  0.2638])\n",
      "Epoch 1225, Loss 8.911071\n",
      "Params: tensor([  4.2472, -10.6416])\n",
      "Grad:   tensor([-0.0465,  0.2634])\n",
      "Epoch 1226, Loss 8.910358\n",
      "Params: tensor([  4.2476, -10.6442])\n",
      "Grad:   tensor([-0.0464,  0.2629])\n",
      "Epoch 1227, Loss 8.909645\n",
      "Params: tensor([  4.2481, -10.6469])\n",
      "Grad:   tensor([-0.0464,  0.2625])\n",
      "Epoch 1228, Loss 8.908935\n",
      "Params: tensor([  4.2486, -10.6495])\n",
      "Grad:   tensor([-0.0463,  0.2621])\n",
      "Epoch 1229, Loss 8.908227\n",
      "Params: tensor([  4.2490, -10.6521])\n",
      "Grad:   tensor([-0.0462,  0.2616])\n",
      "Epoch 1230, Loss 8.907523\n",
      "Params: tensor([  4.2495, -10.6547])\n",
      "Grad:   tensor([-0.0461,  0.2612])\n",
      "Epoch 1231, Loss 8.906819\n",
      "Params: tensor([  4.2499, -10.6573])\n",
      "Grad:   tensor([-0.0460,  0.2607])\n",
      "Epoch 1232, Loss 8.906121\n",
      "Params: tensor([  4.2504, -10.6599])\n",
      "Grad:   tensor([-0.0460,  0.2603])\n",
      "Epoch 1233, Loss 8.905420\n",
      "Params: tensor([  4.2509, -10.6625])\n",
      "Grad:   tensor([-0.0459,  0.2598])\n",
      "Epoch 1234, Loss 8.904725\n",
      "Params: tensor([  4.2513, -10.6651])\n",
      "Grad:   tensor([-0.0458,  0.2594])\n",
      "Epoch 1235, Loss 8.904031\n",
      "Params: tensor([  4.2518, -10.6677])\n",
      "Grad:   tensor([-0.0458,  0.2589])\n",
      "Epoch 1236, Loss 8.903341\n",
      "Params: tensor([  4.2522, -10.6703])\n",
      "Grad:   tensor([-0.0457,  0.2585])\n",
      "Epoch 1237, Loss 8.902655\n",
      "Params: tensor([  4.2527, -10.6729])\n",
      "Grad:   tensor([-0.0456,  0.2581])\n",
      "Epoch 1238, Loss 8.901967\n",
      "Params: tensor([  4.2532, -10.6755])\n",
      "Grad:   tensor([-0.0455,  0.2576])\n",
      "Epoch 1239, Loss 8.901282\n",
      "Params: tensor([  4.2536, -10.6780])\n",
      "Grad:   tensor([-0.0454,  0.2572])\n",
      "Epoch 1240, Loss 8.900604\n",
      "Params: tensor([  4.2541, -10.6806])\n",
      "Grad:   tensor([-0.0454,  0.2568])\n",
      "Epoch 1241, Loss 8.899924\n",
      "Params: tensor([  4.2545, -10.6832])\n",
      "Grad:   tensor([-0.0453,  0.2563])\n",
      "Epoch 1242, Loss 8.899245\n",
      "Params: tensor([  4.2550, -10.6857])\n",
      "Grad:   tensor([-0.0452,  0.2559])\n",
      "Epoch 1243, Loss 8.898571\n",
      "Params: tensor([  4.2554, -10.6883])\n",
      "Grad:   tensor([-0.0451,  0.2554])\n",
      "Epoch 1244, Loss 8.897895\n",
      "Params: tensor([  4.2559, -10.6908])\n",
      "Grad:   tensor([-0.0450,  0.2550])\n",
      "Epoch 1245, Loss 8.897229\n",
      "Params: tensor([  4.2563, -10.6934])\n",
      "Grad:   tensor([-0.0450,  0.2546])\n",
      "Epoch 1246, Loss 8.896561\n",
      "Params: tensor([  4.2568, -10.6959])\n",
      "Grad:   tensor([-0.0449,  0.2541])\n",
      "Epoch 1247, Loss 8.895894\n",
      "Params: tensor([  4.2572, -10.6984])\n",
      "Grad:   tensor([-0.0448,  0.2537])\n",
      "Epoch 1248, Loss 8.895232\n",
      "Params: tensor([  4.2577, -10.7010])\n",
      "Grad:   tensor([-0.0448,  0.2533])\n",
      "Epoch 1249, Loss 8.894571\n",
      "Params: tensor([  4.2581, -10.7035])\n",
      "Grad:   tensor([-0.0447,  0.2529])\n",
      "Epoch 1250, Loss 8.893910\n",
      "Params: tensor([  4.2586, -10.7060])\n",
      "Grad:   tensor([-0.0446,  0.2524])\n",
      "Epoch 1251, Loss 8.893256\n",
      "Params: tensor([  4.2590, -10.7085])\n",
      "Grad:   tensor([-0.0445,  0.2520])\n",
      "Epoch 1252, Loss 8.892600\n",
      "Params: tensor([  4.2594, -10.7111])\n",
      "Grad:   tensor([-0.0444,  0.2516])\n",
      "Epoch 1253, Loss 8.891950\n",
      "Params: tensor([  4.2599, -10.7136])\n",
      "Grad:   tensor([-0.0444,  0.2511])\n",
      "Epoch 1254, Loss 8.891299\n",
      "Params: tensor([  4.2603, -10.7161])\n",
      "Grad:   tensor([-0.0443,  0.2507])\n",
      "Epoch 1255, Loss 8.890652\n",
      "Params: tensor([  4.2608, -10.7186])\n",
      "Grad:   tensor([-0.0442,  0.2503])\n",
      "Epoch 1256, Loss 8.890006\n",
      "Params: tensor([  4.2612, -10.7211])\n",
      "Grad:   tensor([-0.0441,  0.2499])\n",
      "Epoch 1257, Loss 8.889364\n",
      "Params: tensor([  4.2617, -10.7236])\n",
      "Grad:   tensor([-0.0441,  0.2494])\n",
      "Epoch 1258, Loss 8.888721\n",
      "Params: tensor([  4.2621, -10.7261])\n",
      "Grad:   tensor([-0.0440,  0.2490])\n",
      "Epoch 1259, Loss 8.888083\n",
      "Params: tensor([  4.2625, -10.7286])\n",
      "Grad:   tensor([-0.0439,  0.2486])\n",
      "Epoch 1260, Loss 8.887445\n",
      "Params: tensor([  4.2630, -10.7310])\n",
      "Grad:   tensor([-0.0438,  0.2482])\n",
      "Epoch 1261, Loss 8.886810\n",
      "Params: tensor([  4.2634, -10.7335])\n",
      "Grad:   tensor([-0.0438,  0.2478])\n",
      "Epoch 1262, Loss 8.886178\n",
      "Params: tensor([  4.2638, -10.7360])\n",
      "Grad:   tensor([-0.0437,  0.2473])\n",
      "Epoch 1263, Loss 8.885550\n",
      "Params: tensor([  4.2643, -10.7385])\n",
      "Grad:   tensor([-0.0436,  0.2469])\n",
      "Epoch 1264, Loss 8.884922\n",
      "Params: tensor([  4.2647, -10.7409])\n",
      "Grad:   tensor([-0.0435,  0.2465])\n",
      "Epoch 1265, Loss 8.884295\n",
      "Params: tensor([  4.2652, -10.7434])\n",
      "Grad:   tensor([-0.0435,  0.2461])\n",
      "Epoch 1266, Loss 8.883674\n",
      "Params: tensor([  4.2656, -10.7458])\n",
      "Grad:   tensor([-0.0434,  0.2457])\n",
      "Epoch 1267, Loss 8.883051\n",
      "Params: tensor([  4.2660, -10.7483])\n",
      "Grad:   tensor([-0.0433,  0.2452])\n",
      "Epoch 1268, Loss 8.882429\n",
      "Params: tensor([  4.2664, -10.7507])\n",
      "Grad:   tensor([-0.0432,  0.2448])\n",
      "Epoch 1269, Loss 8.881811\n",
      "Params: tensor([  4.2669, -10.7532])\n",
      "Grad:   tensor([-0.0432,  0.2444])\n",
      "Epoch 1270, Loss 8.881195\n",
      "Params: tensor([  4.2673, -10.7556])\n",
      "Grad:   tensor([-0.0431,  0.2440])\n",
      "Epoch 1271, Loss 8.880584\n",
      "Params: tensor([  4.2677, -10.7581])\n",
      "Grad:   tensor([-0.0430,  0.2436])\n",
      "Epoch 1272, Loss 8.879970\n",
      "Params: tensor([  4.2682, -10.7605])\n",
      "Grad:   tensor([-0.0430,  0.2432])\n",
      "Epoch 1273, Loss 8.879363\n",
      "Params: tensor([  4.2686, -10.7629])\n",
      "Grad:   tensor([-0.0429,  0.2427])\n",
      "Epoch 1274, Loss 8.878757\n",
      "Params: tensor([  4.2690, -10.7653])\n",
      "Grad:   tensor([-0.0428,  0.2423])\n",
      "Epoch 1275, Loss 8.878149\n",
      "Params: tensor([  4.2695, -10.7678])\n",
      "Grad:   tensor([-0.0427,  0.2419])\n",
      "Epoch 1276, Loss 8.877547\n",
      "Params: tensor([  4.2699, -10.7702])\n",
      "Grad:   tensor([-0.0427,  0.2415])\n",
      "Epoch 1277, Loss 8.876946\n",
      "Params: tensor([  4.2703, -10.7726])\n",
      "Grad:   tensor([-0.0426,  0.2411])\n",
      "Epoch 1278, Loss 8.876349\n",
      "Params: tensor([  4.2707, -10.7750])\n",
      "Grad:   tensor([-0.0425,  0.2407])\n",
      "Epoch 1279, Loss 8.875749\n",
      "Params: tensor([  4.2712, -10.7774])\n",
      "Grad:   tensor([-0.0424,  0.2403])\n",
      "Epoch 1280, Loss 8.875154\n",
      "Params: tensor([  4.2716, -10.7798])\n",
      "Grad:   tensor([-0.0424,  0.2399])\n",
      "Epoch 1281, Loss 8.874563\n",
      "Params: tensor([  4.2720, -10.7822])\n",
      "Grad:   tensor([-0.0423,  0.2395])\n",
      "Epoch 1282, Loss 8.873973\n",
      "Params: tensor([  4.2724, -10.7846])\n",
      "Grad:   tensor([-0.0422,  0.2391])\n",
      "Epoch 1283, Loss 8.873384\n",
      "Params: tensor([  4.2728, -10.7870])\n",
      "Grad:   tensor([-0.0422,  0.2387])\n",
      "Epoch 1284, Loss 8.872796\n",
      "Params: tensor([  4.2733, -10.7893])\n",
      "Grad:   tensor([-0.0421,  0.2382])\n",
      "Epoch 1285, Loss 8.872212\n",
      "Params: tensor([  4.2737, -10.7917])\n",
      "Grad:   tensor([-0.0420,  0.2378])\n",
      "Epoch 1286, Loss 8.871629\n",
      "Params: tensor([  4.2741, -10.7941])\n",
      "Grad:   tensor([-0.0419,  0.2374])\n",
      "Epoch 1287, Loss 8.871047\n",
      "Params: tensor([  4.2745, -10.7965])\n",
      "Grad:   tensor([-0.0419,  0.2370])\n",
      "Epoch 1288, Loss 8.870468\n",
      "Params: tensor([  4.2749, -10.7988])\n",
      "Grad:   tensor([-0.0418,  0.2366])\n",
      "Epoch 1289, Loss 8.869895\n",
      "Params: tensor([  4.2754, -10.8012])\n",
      "Grad:   tensor([-0.0417,  0.2362])\n",
      "Epoch 1290, Loss 8.869318\n",
      "Params: tensor([  4.2758, -10.8036])\n",
      "Grad:   tensor([-0.0417,  0.2358])\n",
      "Epoch 1291, Loss 8.868744\n",
      "Params: tensor([  4.2762, -10.8059])\n",
      "Grad:   tensor([-0.0416,  0.2354])\n",
      "Epoch 1292, Loss 8.868174\n",
      "Params: tensor([  4.2766, -10.8083])\n",
      "Grad:   tensor([-0.0415,  0.2350])\n",
      "Epoch 1293, Loss 8.867606\n",
      "Params: tensor([  4.2770, -10.8106])\n",
      "Grad:   tensor([-0.0414,  0.2346])\n",
      "Epoch 1294, Loss 8.867038\n",
      "Params: tensor([  4.2774, -10.8129])\n",
      "Grad:   tensor([-0.0414,  0.2342])\n",
      "Epoch 1295, Loss 8.866471\n",
      "Params: tensor([  4.2779, -10.8153])\n",
      "Grad:   tensor([-0.0413,  0.2338])\n",
      "Epoch 1296, Loss 8.865910\n",
      "Params: tensor([  4.2783, -10.8176])\n",
      "Grad:   tensor([-0.0412,  0.2334])\n",
      "Epoch 1297, Loss 8.865348\n",
      "Params: tensor([  4.2787, -10.8200])\n",
      "Grad:   tensor([-0.0412,  0.2330])\n",
      "Epoch 1298, Loss 8.864788\n",
      "Params: tensor([  4.2791, -10.8223])\n",
      "Grad:   tensor([-0.0411,  0.2326])\n",
      "Epoch 1299, Loss 8.864228\n",
      "Params: tensor([  4.2795, -10.8246])\n",
      "Grad:   tensor([-0.0410,  0.2323])\n",
      "Epoch 1300, Loss 8.863674\n",
      "Params: tensor([  4.2799, -10.8269])\n",
      "Grad:   tensor([-0.0410,  0.2319])\n",
      "Epoch 1301, Loss 8.863120\n",
      "Params: tensor([  4.2803, -10.8292])\n",
      "Grad:   tensor([-0.0409,  0.2315])\n",
      "Epoch 1302, Loss 8.862568\n",
      "Params: tensor([  4.2807, -10.8315])\n",
      "Grad:   tensor([-0.0408,  0.2311])\n",
      "Epoch 1303, Loss 8.862019\n",
      "Params: tensor([  4.2811, -10.8339])\n",
      "Grad:   tensor([-0.0408,  0.2307])\n",
      "Epoch 1304, Loss 8.861471\n",
      "Params: tensor([  4.2815, -10.8362])\n",
      "Grad:   tensor([-0.0407,  0.2303])\n",
      "Epoch 1305, Loss 8.860922\n",
      "Params: tensor([  4.2819, -10.8385])\n",
      "Grad:   tensor([-0.0406,  0.2299])\n",
      "Epoch 1306, Loss 8.860379\n",
      "Params: tensor([  4.2824, -10.8407])\n",
      "Grad:   tensor([-0.0406,  0.2295])\n",
      "Epoch 1307, Loss 8.859836\n",
      "Params: tensor([  4.2828, -10.8430])\n",
      "Grad:   tensor([-0.0405,  0.2291])\n",
      "Epoch 1308, Loss 8.859298\n",
      "Params: tensor([  4.2832, -10.8453])\n",
      "Grad:   tensor([-0.0404,  0.2287])\n",
      "Epoch 1309, Loss 8.858756\n",
      "Params: tensor([  4.2836, -10.8476])\n",
      "Grad:   tensor([-0.0403,  0.2283])\n",
      "Epoch 1310, Loss 8.858218\n",
      "Params: tensor([  4.2840, -10.8499])\n",
      "Grad:   tensor([-0.0403,  0.2279])\n",
      "Epoch 1311, Loss 8.857682\n",
      "Params: tensor([  4.2844, -10.8522])\n",
      "Grad:   tensor([-0.0402,  0.2276])\n",
      "Epoch 1312, Loss 8.857148\n",
      "Params: tensor([  4.2848, -10.8544])\n",
      "Grad:   tensor([-0.0401,  0.2272])\n",
      "Epoch 1313, Loss 8.856619\n",
      "Params: tensor([  4.2852, -10.8567])\n",
      "Grad:   tensor([-0.0401,  0.2268])\n",
      "Epoch 1314, Loss 8.856091\n",
      "Params: tensor([  4.2856, -10.8590])\n",
      "Grad:   tensor([-0.0400,  0.2264])\n",
      "Epoch 1315, Loss 8.855560\n",
      "Params: tensor([  4.2860, -10.8612])\n",
      "Grad:   tensor([-0.0399,  0.2260])\n",
      "Epoch 1316, Loss 8.855036\n",
      "Params: tensor([  4.2864, -10.8635])\n",
      "Grad:   tensor([-0.0399,  0.2256])\n",
      "Epoch 1317, Loss 8.854511\n",
      "Params: tensor([  4.2868, -10.8657])\n",
      "Grad:   tensor([-0.0398,  0.2252])\n",
      "Epoch 1318, Loss 8.853988\n",
      "Params: tensor([  4.2872, -10.8680])\n",
      "Grad:   tensor([-0.0397,  0.2249])\n",
      "Epoch 1319, Loss 8.853466\n",
      "Params: tensor([  4.2876, -10.8702])\n",
      "Grad:   tensor([-0.0396,  0.2245])\n",
      "Epoch 1320, Loss 8.852947\n",
      "Params: tensor([  4.2880, -10.8725])\n",
      "Grad:   tensor([-0.0396,  0.2241])\n",
      "Epoch 1321, Loss 8.852429\n",
      "Params: tensor([  4.2883, -10.8747])\n",
      "Grad:   tensor([-0.0395,  0.2237])\n",
      "Epoch 1322, Loss 8.851916\n",
      "Params: tensor([  4.2887, -10.8769])\n",
      "Grad:   tensor([-0.0395,  0.2233])\n",
      "Epoch 1323, Loss 8.851398\n",
      "Params: tensor([  4.2891, -10.8792])\n",
      "Grad:   tensor([-0.0394,  0.2230])\n",
      "Epoch 1324, Loss 8.850888\n",
      "Params: tensor([  4.2895, -10.8814])\n",
      "Grad:   tensor([-0.0393,  0.2226])\n",
      "Epoch 1325, Loss 8.850376\n",
      "Params: tensor([  4.2899, -10.8836])\n",
      "Grad:   tensor([-0.0392,  0.2222])\n",
      "Epoch 1326, Loss 8.849871\n",
      "Params: tensor([  4.2903, -10.8858])\n",
      "Grad:   tensor([-0.0392,  0.2218])\n",
      "Epoch 1327, Loss 8.849361\n",
      "Params: tensor([  4.2907, -10.8881])\n",
      "Grad:   tensor([-0.0391,  0.2215])\n",
      "Epoch 1328, Loss 8.848858\n",
      "Params: tensor([  4.2911, -10.8903])\n",
      "Grad:   tensor([-0.0391,  0.2211])\n",
      "Epoch 1329, Loss 8.848351\n",
      "Params: tensor([  4.2915, -10.8925])\n",
      "Grad:   tensor([-0.0390,  0.2207])\n",
      "Epoch 1330, Loss 8.847854\n",
      "Params: tensor([  4.2919, -10.8947])\n",
      "Grad:   tensor([-0.0389,  0.2203])\n",
      "Epoch 1331, Loss 8.847348\n",
      "Params: tensor([  4.2923, -10.8969])\n",
      "Grad:   tensor([-0.0388,  0.2200])\n",
      "Epoch 1332, Loss 8.846853\n",
      "Params: tensor([  4.2927, -10.8991])\n",
      "Grad:   tensor([-0.0388,  0.2196])\n",
      "Epoch 1333, Loss 8.846355\n",
      "Params: tensor([  4.2930, -10.9013])\n",
      "Grad:   tensor([-0.0387,  0.2192])\n",
      "Epoch 1334, Loss 8.845859\n",
      "Params: tensor([  4.2934, -10.9034])\n",
      "Grad:   tensor([-0.0387,  0.2188])\n",
      "Epoch 1335, Loss 8.845366\n",
      "Params: tensor([  4.2938, -10.9056])\n",
      "Grad:   tensor([-0.0386,  0.2185])\n",
      "Epoch 1336, Loss 8.844876\n",
      "Params: tensor([  4.2942, -10.9078])\n",
      "Grad:   tensor([-0.0385,  0.2181])\n",
      "Epoch 1337, Loss 8.844386\n",
      "Params: tensor([  4.2946, -10.9100])\n",
      "Grad:   tensor([-0.0385,  0.2177])\n",
      "Epoch 1338, Loss 8.843897\n",
      "Params: tensor([  4.2950, -10.9122])\n",
      "Grad:   tensor([-0.0384,  0.2173])\n",
      "Epoch 1339, Loss 8.843408\n",
      "Params: tensor([  4.2954, -10.9143])\n",
      "Grad:   tensor([-0.0383,  0.2170])\n",
      "Epoch 1340, Loss 8.842925\n",
      "Params: tensor([  4.2957, -10.9165])\n",
      "Grad:   tensor([-0.0383,  0.2166])\n",
      "Epoch 1341, Loss 8.842441\n",
      "Params: tensor([  4.2961, -10.9187])\n",
      "Grad:   tensor([-0.0382,  0.2162])\n",
      "Epoch 1342, Loss 8.841958\n",
      "Params: tensor([  4.2965, -10.9208])\n",
      "Grad:   tensor([-0.0381,  0.2159])\n",
      "Epoch 1343, Loss 8.841477\n",
      "Params: tensor([  4.2969, -10.9230])\n",
      "Grad:   tensor([-0.0381,  0.2155])\n",
      "Epoch 1344, Loss 8.841000\n",
      "Params: tensor([  4.2973, -10.9251])\n",
      "Grad:   tensor([-0.0380,  0.2151])\n",
      "Epoch 1345, Loss 8.840524\n",
      "Params: tensor([  4.2976, -10.9273])\n",
      "Grad:   tensor([-0.0380,  0.2148])\n",
      "Epoch 1346, Loss 8.840048\n",
      "Params: tensor([  4.2980, -10.9294])\n",
      "Grad:   tensor([-0.0379,  0.2144])\n",
      "Epoch 1347, Loss 8.839577\n",
      "Params: tensor([  4.2984, -10.9316])\n",
      "Grad:   tensor([-0.0378,  0.2140])\n",
      "Epoch 1348, Loss 8.839103\n",
      "Params: tensor([  4.2988, -10.9337])\n",
      "Grad:   tensor([-0.0378,  0.2137])\n",
      "Epoch 1349, Loss 8.838631\n",
      "Params: tensor([  4.2991, -10.9358])\n",
      "Grad:   tensor([-0.0377,  0.2133])\n",
      "Epoch 1350, Loss 8.838164\n",
      "Params: tensor([  4.2995, -10.9380])\n",
      "Grad:   tensor([-0.0376,  0.2130])\n",
      "Epoch 1351, Loss 8.837699\n",
      "Params: tensor([  4.2999, -10.9401])\n",
      "Grad:   tensor([-0.0376,  0.2126])\n",
      "Epoch 1352, Loss 8.837231\n",
      "Params: tensor([  4.3003, -10.9422])\n",
      "Grad:   tensor([-0.0375,  0.2122])\n",
      "Epoch 1353, Loss 8.836765\n",
      "Params: tensor([  4.3006, -10.9443])\n",
      "Grad:   tensor([-0.0374,  0.2119])\n",
      "Epoch 1354, Loss 8.836304\n",
      "Params: tensor([  4.3010, -10.9464])\n",
      "Grad:   tensor([-0.0374,  0.2115])\n",
      "Epoch 1355, Loss 8.835844\n",
      "Params: tensor([  4.3014, -10.9486])\n",
      "Grad:   tensor([-0.0373,  0.2112])\n",
      "Epoch 1356, Loss 8.835384\n",
      "Params: tensor([  4.3018, -10.9507])\n",
      "Grad:   tensor([-0.0372,  0.2108])\n",
      "Epoch 1357, Loss 8.834927\n",
      "Params: tensor([  4.3021, -10.9528])\n",
      "Grad:   tensor([-0.0372,  0.2104])\n",
      "Epoch 1358, Loss 8.834470\n",
      "Params: tensor([  4.3025, -10.9549])\n",
      "Grad:   tensor([-0.0371,  0.2101])\n",
      "Epoch 1359, Loss 8.834016\n",
      "Params: tensor([  4.3029, -10.9570])\n",
      "Grad:   tensor([-0.0371,  0.2097])\n",
      "Epoch 1360, Loss 8.833561\n",
      "Params: tensor([  4.3033, -10.9591])\n",
      "Grad:   tensor([-0.0370,  0.2094])\n",
      "Epoch 1361, Loss 8.833111\n",
      "Params: tensor([  4.3036, -10.9611])\n",
      "Grad:   tensor([-0.0369,  0.2090])\n",
      "Epoch 1362, Loss 8.832660\n",
      "Params: tensor([  4.3040, -10.9632])\n",
      "Grad:   tensor([-0.0369,  0.2087])\n",
      "Epoch 1363, Loss 8.832211\n",
      "Params: tensor([  4.3044, -10.9653])\n",
      "Grad:   tensor([-0.0368,  0.2083])\n",
      "Epoch 1364, Loss 8.831765\n",
      "Params: tensor([  4.3047, -10.9674])\n",
      "Grad:   tensor([-0.0367,  0.2080])\n",
      "Epoch 1365, Loss 8.831317\n",
      "Params: tensor([  4.3051, -10.9695])\n",
      "Grad:   tensor([-0.0367,  0.2076])\n",
      "Epoch 1366, Loss 8.830875\n",
      "Params: tensor([  4.3055, -10.9715])\n",
      "Grad:   tensor([-0.0366,  0.2072])\n",
      "Epoch 1367, Loss 8.830433\n",
      "Params: tensor([  4.3058, -10.9736])\n",
      "Grad:   tensor([-0.0366,  0.2069])\n",
      "Epoch 1368, Loss 8.829993\n",
      "Params: tensor([  4.3062, -10.9757])\n",
      "Grad:   tensor([-0.0365,  0.2065])\n",
      "Epoch 1369, Loss 8.829553\n",
      "Params: tensor([  4.3066, -10.9777])\n",
      "Grad:   tensor([-0.0364,  0.2062])\n",
      "Epoch 1370, Loss 8.829112\n",
      "Params: tensor([  4.3069, -10.9798])\n",
      "Grad:   tensor([-0.0364,  0.2058])\n",
      "Epoch 1371, Loss 8.828676\n",
      "Params: tensor([  4.3073, -10.9819])\n",
      "Grad:   tensor([-0.0363,  0.2055])\n",
      "Epoch 1372, Loss 8.828240\n",
      "Params: tensor([  4.3076, -10.9839])\n",
      "Grad:   tensor([-0.0363,  0.2051])\n",
      "Epoch 1373, Loss 8.827806\n",
      "Params: tensor([  4.3080, -10.9860])\n",
      "Grad:   tensor([-0.0362,  0.2048])\n",
      "Epoch 1374, Loss 8.827376\n",
      "Params: tensor([  4.3084, -10.9880])\n",
      "Grad:   tensor([-0.0361,  0.2044])\n",
      "Epoch 1375, Loss 8.826945\n",
      "Params: tensor([  4.3087, -10.9900])\n",
      "Grad:   tensor([-0.0360,  0.2041])\n",
      "Epoch 1376, Loss 8.826514\n",
      "Params: tensor([  4.3091, -10.9921])\n",
      "Grad:   tensor([-0.0360,  0.2038])\n",
      "Epoch 1377, Loss 8.826088\n",
      "Params: tensor([  4.3094, -10.9941])\n",
      "Grad:   tensor([-0.0359,  0.2034])\n",
      "Epoch 1378, Loss 8.825662\n",
      "Params: tensor([  4.3098, -10.9961])\n",
      "Grad:   tensor([-0.0359,  0.2031])\n",
      "Epoch 1379, Loss 8.825238\n",
      "Params: tensor([  4.3102, -10.9982])\n",
      "Grad:   tensor([-0.0358,  0.2027])\n",
      "Epoch 1380, Loss 8.824814\n",
      "Params: tensor([  4.3105, -11.0002])\n",
      "Grad:   tensor([-0.0358,  0.2024])\n",
      "Epoch 1381, Loss 8.824392\n",
      "Params: tensor([  4.3109, -11.0022])\n",
      "Grad:   tensor([-0.0357,  0.2020])\n",
      "Epoch 1382, Loss 8.823973\n",
      "Params: tensor([  4.3112, -11.0042])\n",
      "Grad:   tensor([-0.0356,  0.2017])\n",
      "Epoch 1383, Loss 8.823552\n",
      "Params: tensor([  4.3116, -11.0062])\n",
      "Grad:   tensor([-0.0356,  0.2013])\n",
      "Epoch 1384, Loss 8.823135\n",
      "Params: tensor([  4.3119, -11.0083])\n",
      "Grad:   tensor([-0.0355,  0.2010])\n",
      "Epoch 1385, Loss 8.822718\n",
      "Params: tensor([  4.3123, -11.0103])\n",
      "Grad:   tensor([-0.0355,  0.2007])\n",
      "Epoch 1386, Loss 8.822303\n",
      "Params: tensor([  4.3126, -11.0123])\n",
      "Grad:   tensor([-0.0354,  0.2003])\n",
      "Epoch 1387, Loss 8.821890\n",
      "Params: tensor([  4.3130, -11.0143])\n",
      "Grad:   tensor([-0.0353,  0.2000])\n",
      "Epoch 1388, Loss 8.821479\n",
      "Params: tensor([  4.3134, -11.0163])\n",
      "Grad:   tensor([-0.0353,  0.1996])\n",
      "Epoch 1389, Loss 8.821069\n",
      "Params: tensor([  4.3137, -11.0183])\n",
      "Grad:   tensor([-0.0352,  0.1993])\n",
      "Epoch 1390, Loss 8.820659\n",
      "Params: tensor([  4.3141, -11.0202])\n",
      "Grad:   tensor([-0.0352,  0.1990])\n",
      "Epoch 1391, Loss 8.820251\n",
      "Params: tensor([  4.3144, -11.0222])\n",
      "Grad:   tensor([-0.0351,  0.1986])\n",
      "Epoch 1392, Loss 8.819846\n",
      "Params: tensor([  4.3148, -11.0242])\n",
      "Grad:   tensor([-0.0350,  0.1983])\n",
      "Epoch 1393, Loss 8.819442\n",
      "Params: tensor([  4.3151, -11.0262])\n",
      "Grad:   tensor([-0.0350,  0.1979])\n",
      "Epoch 1394, Loss 8.819034\n",
      "Params: tensor([  4.3155, -11.0282])\n",
      "Grad:   tensor([-0.0349,  0.1976])\n",
      "Epoch 1395, Loss 8.818634\n",
      "Params: tensor([  4.3158, -11.0301])\n",
      "Grad:   tensor([-0.0349,  0.1973])\n",
      "Epoch 1396, Loss 8.818233\n",
      "Params: tensor([  4.3162, -11.0321])\n",
      "Grad:   tensor([-0.0348,  0.1969])\n",
      "Epoch 1397, Loss 8.817833\n",
      "Params: tensor([  4.3165, -11.0341])\n",
      "Grad:   tensor([-0.0347,  0.1966])\n",
      "Epoch 1398, Loss 8.817432\n",
      "Params: tensor([  4.3168, -11.0360])\n",
      "Grad:   tensor([-0.0347,  0.1963])\n",
      "Epoch 1399, Loss 8.817039\n",
      "Params: tensor([  4.3172, -11.0380])\n",
      "Grad:   tensor([-0.0346,  0.1959])\n",
      "Epoch 1400, Loss 8.816640\n",
      "Params: tensor([  4.3175, -11.0400])\n",
      "Grad:   tensor([-0.0346,  0.1956])\n",
      "Epoch 1401, Loss 8.816248\n",
      "Params: tensor([  4.3179, -11.0419])\n",
      "Grad:   tensor([-0.0345,  0.1953])\n",
      "Epoch 1402, Loss 8.815856\n",
      "Params: tensor([  4.3182, -11.0439])\n",
      "Grad:   tensor([-0.0345,  0.1949])\n",
      "Epoch 1403, Loss 8.815461\n",
      "Params: tensor([  4.3186, -11.0458])\n",
      "Grad:   tensor([-0.0344,  0.1946])\n",
      "Epoch 1404, Loss 8.815075\n",
      "Params: tensor([  4.3189, -11.0477])\n",
      "Grad:   tensor([-0.0343,  0.1943])\n",
      "Epoch 1405, Loss 8.814683\n",
      "Params: tensor([  4.3193, -11.0497])\n",
      "Grad:   tensor([-0.0343,  0.1939])\n",
      "Epoch 1406, Loss 8.814295\n",
      "Params: tensor([  4.3196, -11.0516])\n",
      "Grad:   tensor([-0.0342,  0.1936])\n",
      "Epoch 1407, Loss 8.813908\n",
      "Params: tensor([  4.3199, -11.0536])\n",
      "Grad:   tensor([-0.0342,  0.1933])\n",
      "Epoch 1408, Loss 8.813525\n",
      "Params: tensor([  4.3203, -11.0555])\n",
      "Grad:   tensor([-0.0341,  0.1930])\n",
      "Epoch 1409, Loss 8.813140\n",
      "Params: tensor([  4.3206, -11.0574])\n",
      "Grad:   tensor([-0.0340,  0.1926])\n",
      "Epoch 1410, Loss 8.812760\n",
      "Params: tensor([  4.3210, -11.0593])\n",
      "Grad:   tensor([-0.0340,  0.1923])\n",
      "Epoch 1411, Loss 8.812379\n",
      "Params: tensor([  4.3213, -11.0613])\n",
      "Grad:   tensor([-0.0339,  0.1920])\n",
      "Epoch 1412, Loss 8.811999\n",
      "Params: tensor([  4.3216, -11.0632])\n",
      "Grad:   tensor([-0.0338,  0.1917])\n",
      "Epoch 1413, Loss 8.811620\n",
      "Params: tensor([  4.3220, -11.0651])\n",
      "Grad:   tensor([-0.0338,  0.1913])\n",
      "Epoch 1414, Loss 8.811245\n",
      "Params: tensor([  4.3223, -11.0670])\n",
      "Grad:   tensor([-0.0337,  0.1910])\n",
      "Epoch 1415, Loss 8.810867\n",
      "Params: tensor([  4.3227, -11.0689])\n",
      "Grad:   tensor([-0.0337,  0.1907])\n",
      "Epoch 1416, Loss 8.810491\n",
      "Params: tensor([  4.3230, -11.0708])\n",
      "Grad:   tensor([-0.0336,  0.1904])\n",
      "Epoch 1417, Loss 8.810119\n",
      "Params: tensor([  4.3233, -11.0727])\n",
      "Grad:   tensor([-0.0336,  0.1900])\n",
      "Epoch 1418, Loss 8.809747\n",
      "Params: tensor([  4.3237, -11.0746])\n",
      "Grad:   tensor([-0.0335,  0.1897])\n",
      "Epoch 1419, Loss 8.809376\n",
      "Params: tensor([  4.3240, -11.0765])\n",
      "Grad:   tensor([-0.0335,  0.1894])\n",
      "Epoch 1420, Loss 8.809007\n",
      "Params: tensor([  4.3243, -11.0784])\n",
      "Grad:   tensor([-0.0334,  0.1891])\n",
      "Epoch 1421, Loss 8.808639\n",
      "Params: tensor([  4.3247, -11.0803])\n",
      "Grad:   tensor([-0.0334,  0.1887])\n",
      "Epoch 1422, Loss 8.808270\n",
      "Params: tensor([  4.3250, -11.0822])\n",
      "Grad:   tensor([-0.0333,  0.1884])\n",
      "Epoch 1423, Loss 8.807906\n",
      "Params: tensor([  4.3253, -11.0840])\n",
      "Grad:   tensor([-0.0332,  0.1881])\n",
      "Epoch 1424, Loss 8.807540\n",
      "Params: tensor([  4.3257, -11.0859])\n",
      "Grad:   tensor([-0.0332,  0.1878])\n",
      "Epoch 1425, Loss 8.807179\n",
      "Params: tensor([  4.3260, -11.0878])\n",
      "Grad:   tensor([-0.0331,  0.1875])\n",
      "Epoch 1426, Loss 8.806814\n",
      "Params: tensor([  4.3263, -11.0897])\n",
      "Grad:   tensor([-0.0330,  0.1871])\n",
      "Epoch 1427, Loss 8.806458\n",
      "Params: tensor([  4.3267, -11.0915])\n",
      "Grad:   tensor([-0.0330,  0.1868])\n",
      "Epoch 1428, Loss 8.806095\n",
      "Params: tensor([  4.3270, -11.0934])\n",
      "Grad:   tensor([-0.0329,  0.1865])\n",
      "Epoch 1429, Loss 8.805737\n",
      "Params: tensor([  4.3273, -11.0953])\n",
      "Grad:   tensor([-0.0329,  0.1862])\n",
      "Epoch 1430, Loss 8.805380\n",
      "Params: tensor([  4.3276, -11.0971])\n",
      "Grad:   tensor([-0.0328,  0.1859])\n",
      "Epoch 1431, Loss 8.805022\n",
      "Params: tensor([  4.3280, -11.0990])\n",
      "Grad:   tensor([-0.0328,  0.1856])\n",
      "Epoch 1432, Loss 8.804668\n",
      "Params: tensor([  4.3283, -11.1008])\n",
      "Grad:   tensor([-0.0327,  0.1852])\n",
      "Epoch 1433, Loss 8.804317\n",
      "Params: tensor([  4.3286, -11.1027])\n",
      "Grad:   tensor([-0.0327,  0.1849])\n",
      "Epoch 1434, Loss 8.803961\n",
      "Params: tensor([  4.3289, -11.1045])\n",
      "Grad:   tensor([-0.0326,  0.1846])\n",
      "Epoch 1435, Loss 8.803613\n",
      "Params: tensor([  4.3293, -11.1064])\n",
      "Grad:   tensor([-0.0326,  0.1843])\n",
      "Epoch 1436, Loss 8.803263\n",
      "Params: tensor([  4.3296, -11.1082])\n",
      "Grad:   tensor([-0.0325,  0.1840])\n",
      "Epoch 1437, Loss 8.802914\n",
      "Params: tensor([  4.3299, -11.1100])\n",
      "Grad:   tensor([-0.0324,  0.1837])\n",
      "Epoch 1438, Loss 8.802566\n",
      "Params: tensor([  4.3302, -11.1119])\n",
      "Grad:   tensor([-0.0324,  0.1834])\n",
      "Epoch 1439, Loss 8.802217\n",
      "Params: tensor([  4.3306, -11.1137])\n",
      "Grad:   tensor([-0.0323,  0.1831])\n",
      "Epoch 1440, Loss 8.801873\n",
      "Params: tensor([  4.3309, -11.1155])\n",
      "Grad:   tensor([-0.0323,  0.1827])\n",
      "Epoch 1441, Loss 8.801528\n",
      "Params: tensor([  4.3312, -11.1174])\n",
      "Grad:   tensor([-0.0322,  0.1824])\n",
      "Epoch 1442, Loss 8.801187\n",
      "Params: tensor([  4.3315, -11.1192])\n",
      "Grad:   tensor([-0.0322,  0.1821])\n",
      "Epoch 1443, Loss 8.800845\n",
      "Params: tensor([  4.3319, -11.1210])\n",
      "Grad:   tensor([-0.0321,  0.1818])\n",
      "Epoch 1444, Loss 8.800503\n",
      "Params: tensor([  4.3322, -11.1228])\n",
      "Grad:   tensor([-0.0321,  0.1815])\n",
      "Epoch 1445, Loss 8.800163\n",
      "Params: tensor([  4.3325, -11.1246])\n",
      "Grad:   tensor([-0.0320,  0.1812])\n",
      "Epoch 1446, Loss 8.799827\n",
      "Params: tensor([  4.3328, -11.1264])\n",
      "Grad:   tensor([-0.0319,  0.1809])\n",
      "Epoch 1447, Loss 8.799487\n",
      "Params: tensor([  4.3331, -11.1282])\n",
      "Grad:   tensor([-0.0319,  0.1806])\n",
      "Epoch 1448, Loss 8.799154\n",
      "Params: tensor([  4.3335, -11.1300])\n",
      "Grad:   tensor([-0.0319,  0.1803])\n",
      "Epoch 1449, Loss 8.798817\n",
      "Params: tensor([  4.3338, -11.1318])\n",
      "Grad:   tensor([-0.0318,  0.1800])\n",
      "Epoch 1450, Loss 8.798486\n",
      "Params: tensor([  4.3341, -11.1336])\n",
      "Grad:   tensor([-0.0317,  0.1797])\n",
      "Epoch 1451, Loss 8.798154\n",
      "Params: tensor([  4.3344, -11.1354])\n",
      "Grad:   tensor([-0.0317,  0.1794])\n",
      "Epoch 1452, Loss 8.797820\n",
      "Params: tensor([  4.3347, -11.1372])\n",
      "Grad:   tensor([-0.0316,  0.1791])\n",
      "Epoch 1453, Loss 8.797489\n",
      "Params: tensor([  4.3350, -11.1390])\n",
      "Grad:   tensor([-0.0316,  0.1787])\n",
      "Epoch 1454, Loss 8.797163\n",
      "Params: tensor([  4.3354, -11.1408])\n",
      "Grad:   tensor([-0.0315,  0.1784])\n",
      "Epoch 1455, Loss 8.796833\n",
      "Params: tensor([  4.3357, -11.1426])\n",
      "Grad:   tensor([-0.0315,  0.1781])\n",
      "Epoch 1456, Loss 8.796506\n",
      "Params: tensor([  4.3360, -11.1443])\n",
      "Grad:   tensor([-0.0314,  0.1778])\n",
      "Epoch 1457, Loss 8.796180\n",
      "Params: tensor([  4.3363, -11.1461])\n",
      "Grad:   tensor([-0.0313,  0.1775])\n",
      "Epoch 1458, Loss 8.795856\n",
      "Params: tensor([  4.3366, -11.1479])\n",
      "Grad:   tensor([-0.0313,  0.1772])\n",
      "Epoch 1459, Loss 8.795529\n",
      "Params: tensor([  4.3369, -11.1497])\n",
      "Grad:   tensor([-0.0312,  0.1769])\n",
      "Epoch 1460, Loss 8.795211\n",
      "Params: tensor([  4.3372, -11.1514])\n",
      "Grad:   tensor([-0.0312,  0.1766])\n",
      "Epoch 1461, Loss 8.794888\n",
      "Params: tensor([  4.3375, -11.1532])\n",
      "Grad:   tensor([-0.0311,  0.1763])\n",
      "Epoch 1462, Loss 8.794567\n",
      "Params: tensor([  4.3379, -11.1550])\n",
      "Grad:   tensor([-0.0311,  0.1760])\n",
      "Epoch 1463, Loss 8.794248\n",
      "Params: tensor([  4.3382, -11.1567])\n",
      "Grad:   tensor([-0.0310,  0.1757])\n",
      "Epoch 1464, Loss 8.793930\n",
      "Params: tensor([  4.3385, -11.1585])\n",
      "Grad:   tensor([-0.0310,  0.1754])\n",
      "Epoch 1465, Loss 8.793613\n",
      "Params: tensor([  4.3388, -11.1602])\n",
      "Grad:   tensor([-0.0309,  0.1751])\n",
      "Epoch 1466, Loss 8.793298\n",
      "Params: tensor([  4.3391, -11.1620])\n",
      "Grad:   tensor([-0.0309,  0.1748])\n",
      "Epoch 1467, Loss 8.792983\n",
      "Params: tensor([  4.3394, -11.1637])\n",
      "Grad:   tensor([-0.0308,  0.1745])\n",
      "Epoch 1468, Loss 8.792666\n",
      "Params: tensor([  4.3397, -11.1655])\n",
      "Grad:   tensor([-0.0308,  0.1742])\n",
      "Epoch 1469, Loss 8.792356\n",
      "Params: tensor([  4.3400, -11.1672])\n",
      "Grad:   tensor([-0.0307,  0.1739])\n",
      "Epoch 1470, Loss 8.792045\n",
      "Params: tensor([  4.3403, -11.1689])\n",
      "Grad:   tensor([-0.0307,  0.1737])\n",
      "Epoch 1471, Loss 8.791734\n",
      "Params: tensor([  4.3406, -11.1707])\n",
      "Grad:   tensor([-0.0306,  0.1734])\n",
      "Epoch 1472, Loss 8.791425\n",
      "Params: tensor([  4.3409, -11.1724])\n",
      "Grad:   tensor([-0.0306,  0.1731])\n",
      "Epoch 1473, Loss 8.791116\n",
      "Params: tensor([  4.3412, -11.1741])\n",
      "Grad:   tensor([-0.0305,  0.1728])\n",
      "Epoch 1474, Loss 8.790809\n",
      "Params: tensor([  4.3415, -11.1758])\n",
      "Grad:   tensor([-0.0305,  0.1725])\n",
      "Epoch 1475, Loss 8.790500\n",
      "Params: tensor([  4.3419, -11.1776])\n",
      "Grad:   tensor([-0.0304,  0.1722])\n",
      "Epoch 1476, Loss 8.790195\n",
      "Params: tensor([  4.3422, -11.1793])\n",
      "Grad:   tensor([-0.0304,  0.1719])\n",
      "Epoch 1477, Loss 8.789890\n",
      "Params: tensor([  4.3425, -11.1810])\n",
      "Grad:   tensor([-0.0303,  0.1716])\n",
      "Epoch 1478, Loss 8.789585\n",
      "Params: tensor([  4.3428, -11.1827])\n",
      "Grad:   tensor([-0.0303,  0.1713])\n",
      "Epoch 1479, Loss 8.789285\n",
      "Params: tensor([  4.3431, -11.1844])\n",
      "Grad:   tensor([-0.0302,  0.1710])\n",
      "Epoch 1480, Loss 8.788985\n",
      "Params: tensor([  4.3434, -11.1861])\n",
      "Grad:   tensor([-0.0302,  0.1707])\n",
      "Epoch 1481, Loss 8.788682\n",
      "Params: tensor([  4.3437, -11.1878])\n",
      "Grad:   tensor([-0.0301,  0.1704])\n",
      "Epoch 1482, Loss 8.788385\n",
      "Params: tensor([  4.3440, -11.1895])\n",
      "Grad:   tensor([-0.0301,  0.1701])\n",
      "Epoch 1483, Loss 8.788087\n",
      "Params: tensor([  4.3443, -11.1912])\n",
      "Grad:   tensor([-0.0300,  0.1699])\n",
      "Epoch 1484, Loss 8.787787\n",
      "Params: tensor([  4.3446, -11.1929])\n",
      "Grad:   tensor([-0.0300,  0.1696])\n",
      "Epoch 1485, Loss 8.787493\n",
      "Params: tensor([  4.3449, -11.1946])\n",
      "Grad:   tensor([-0.0299,  0.1693])\n",
      "Epoch 1486, Loss 8.787195\n",
      "Params: tensor([  4.3452, -11.1963])\n",
      "Grad:   tensor([-0.0299,  0.1690])\n",
      "Epoch 1487, Loss 8.786902\n",
      "Params: tensor([  4.3455, -11.1980])\n",
      "Grad:   tensor([-0.0298,  0.1687])\n",
      "Epoch 1488, Loss 8.786608\n",
      "Params: tensor([  4.3458, -11.1997])\n",
      "Grad:   tensor([-0.0298,  0.1684])\n",
      "Epoch 1489, Loss 8.786317\n",
      "Params: tensor([  4.3461, -11.2014])\n",
      "Grad:   tensor([-0.0297,  0.1681])\n",
      "Epoch 1490, Loss 8.786027\n",
      "Params: tensor([  4.3464, -11.2030])\n",
      "Grad:   tensor([-0.0297,  0.1678])\n",
      "Epoch 1491, Loss 8.785735\n",
      "Params: tensor([  4.3466, -11.2047])\n",
      "Grad:   tensor([-0.0296,  0.1676])\n",
      "Epoch 1492, Loss 8.785445\n",
      "Params: tensor([  4.3469, -11.2064])\n",
      "Grad:   tensor([-0.0296,  0.1673])\n",
      "Epoch 1493, Loss 8.785161\n",
      "Params: tensor([  4.3472, -11.2081])\n",
      "Grad:   tensor([-0.0295,  0.1670])\n",
      "Epoch 1494, Loss 8.784870\n",
      "Params: tensor([  4.3475, -11.2097])\n",
      "Grad:   tensor([-0.0294,  0.1667])\n",
      "Epoch 1495, Loss 8.784583\n",
      "Params: tensor([  4.3478, -11.2114])\n",
      "Grad:   tensor([-0.0294,  0.1664])\n",
      "Epoch 1496, Loss 8.784301\n",
      "Params: tensor([  4.3481, -11.2131])\n",
      "Grad:   tensor([-0.0293,  0.1661])\n",
      "Epoch 1497, Loss 8.784015\n",
      "Params: tensor([  4.3484, -11.2147])\n",
      "Grad:   tensor([-0.0293,  0.1659])\n",
      "Epoch 1498, Loss 8.783731\n",
      "Params: tensor([  4.3487, -11.2164])\n",
      "Grad:   tensor([-0.0292,  0.1656])\n",
      "Epoch 1499, Loss 8.783450\n",
      "Params: tensor([  4.3490, -11.2180])\n",
      "Grad:   tensor([-0.0292,  0.1653])\n",
      "Epoch 1500, Loss 8.783166\n",
      "Params: tensor([  4.3493, -11.2197])\n",
      "Grad:   tensor([-0.0292,  0.1650])\n",
      "Epoch 1501, Loss 8.782887\n",
      "Params: tensor([  4.3496, -11.2213])\n",
      "Grad:   tensor([-0.0291,  0.1647])\n",
      "Epoch 1502, Loss 8.782607\n",
      "Params: tensor([  4.3499, -11.2230])\n",
      "Grad:   tensor([-0.0291,  0.1645])\n",
      "Epoch 1503, Loss 8.782328\n",
      "Params: tensor([  4.3502, -11.2246])\n",
      "Grad:   tensor([-0.0290,  0.1642])\n",
      "Epoch 1504, Loss 8.782050\n",
      "Params: tensor([  4.3505, -11.2262])\n",
      "Grad:   tensor([-0.0290,  0.1639])\n",
      "Epoch 1505, Loss 8.781775\n",
      "Params: tensor([  4.3507, -11.2279])\n",
      "Grad:   tensor([-0.0289,  0.1636])\n",
      "Epoch 1506, Loss 8.781500\n",
      "Params: tensor([  4.3510, -11.2295])\n",
      "Grad:   tensor([-0.0289,  0.1633])\n",
      "Epoch 1507, Loss 8.781223\n",
      "Params: tensor([  4.3513, -11.2311])\n",
      "Grad:   tensor([-0.0288,  0.1631])\n",
      "Epoch 1508, Loss 8.780949\n",
      "Params: tensor([  4.3516, -11.2328])\n",
      "Grad:   tensor([-0.0288,  0.1628])\n",
      "Epoch 1509, Loss 8.780677\n",
      "Params: tensor([  4.3519, -11.2344])\n",
      "Grad:   tensor([-0.0287,  0.1625])\n",
      "Epoch 1510, Loss 8.780404\n",
      "Params: tensor([  4.3522, -11.2360])\n",
      "Grad:   tensor([-0.0287,  0.1622])\n",
      "Epoch 1511, Loss 8.780135\n",
      "Params: tensor([  4.3525, -11.2376])\n",
      "Grad:   tensor([-0.0286,  0.1620])\n",
      "Epoch 1512, Loss 8.779863\n",
      "Params: tensor([  4.3527, -11.2393])\n",
      "Grad:   tensor([-0.0286,  0.1617])\n",
      "Epoch 1513, Loss 8.779591\n",
      "Params: tensor([  4.3530, -11.2409])\n",
      "Grad:   tensor([-0.0285,  0.1614])\n",
      "Epoch 1514, Loss 8.779325\n",
      "Params: tensor([  4.3533, -11.2425])\n",
      "Grad:   tensor([-0.0285,  0.1611])\n",
      "Epoch 1515, Loss 8.779056\n",
      "Params: tensor([  4.3536, -11.2441])\n",
      "Grad:   tensor([-0.0284,  0.1609])\n",
      "Epoch 1516, Loss 8.778790\n",
      "Params: tensor([  4.3539, -11.2457])\n",
      "Grad:   tensor([-0.0284,  0.1606])\n",
      "Epoch 1517, Loss 8.778525\n",
      "Params: tensor([  4.3542, -11.2473])\n",
      "Grad:   tensor([-0.0283,  0.1603])\n",
      "Epoch 1518, Loss 8.778260\n",
      "Params: tensor([  4.3545, -11.2489])\n",
      "Grad:   tensor([-0.0283,  0.1600])\n",
      "Epoch 1519, Loss 8.777997\n",
      "Params: tensor([  4.3547, -11.2505])\n",
      "Grad:   tensor([-0.0282,  0.1598])\n",
      "Epoch 1520, Loss 8.777735\n",
      "Params: tensor([  4.3550, -11.2521])\n",
      "Grad:   tensor([-0.0282,  0.1595])\n",
      "Epoch 1521, Loss 8.777474\n",
      "Params: tensor([  4.3553, -11.2537])\n",
      "Grad:   tensor([-0.0281,  0.1592])\n",
      "Epoch 1522, Loss 8.777208\n",
      "Params: tensor([  4.3556, -11.2553])\n",
      "Grad:   tensor([-0.0281,  0.1590])\n",
      "Epoch 1523, Loss 8.776951\n",
      "Params: tensor([  4.3559, -11.2569])\n",
      "Grad:   tensor([-0.0280,  0.1587])\n",
      "Epoch 1524, Loss 8.776690\n",
      "Params: tensor([  4.3561, -11.2585])\n",
      "Grad:   tensor([-0.0280,  0.1584])\n",
      "Epoch 1525, Loss 8.776432\n",
      "Params: tensor([  4.3564, -11.2600])\n",
      "Grad:   tensor([-0.0279,  0.1582])\n",
      "Epoch 1526, Loss 8.776175\n",
      "Params: tensor([  4.3567, -11.2616])\n",
      "Grad:   tensor([-0.0279,  0.1579])\n",
      "Epoch 1527, Loss 8.775919\n",
      "Params: tensor([  4.3570, -11.2632])\n",
      "Grad:   tensor([-0.0279,  0.1576])\n",
      "Epoch 1528, Loss 8.775661\n",
      "Params: tensor([  4.3573, -11.2648])\n",
      "Grad:   tensor([-0.0278,  0.1573])\n",
      "Epoch 1529, Loss 8.775406\n",
      "Params: tensor([  4.3575, -11.2663])\n",
      "Grad:   tensor([-0.0278,  0.1571])\n",
      "Epoch 1530, Loss 8.775150\n",
      "Params: tensor([  4.3578, -11.2679])\n",
      "Grad:   tensor([-0.0277,  0.1568])\n",
      "Epoch 1531, Loss 8.774896\n",
      "Params: tensor([  4.3581, -11.2695])\n",
      "Grad:   tensor([-0.0277,  0.1565])\n",
      "Epoch 1532, Loss 8.774647\n",
      "Params: tensor([  4.3584, -11.2710])\n",
      "Grad:   tensor([-0.0276,  0.1563])\n",
      "Epoch 1533, Loss 8.774395\n",
      "Params: tensor([  4.3586, -11.2726])\n",
      "Grad:   tensor([-0.0276,  0.1560])\n",
      "Epoch 1534, Loss 8.774143\n",
      "Params: tensor([  4.3589, -11.2741])\n",
      "Grad:   tensor([-0.0275,  0.1558])\n",
      "Epoch 1535, Loss 8.773894\n",
      "Params: tensor([  4.3592, -11.2757])\n",
      "Grad:   tensor([-0.0275,  0.1555])\n",
      "Epoch 1536, Loss 8.773644\n",
      "Params: tensor([  4.3595, -11.2773])\n",
      "Grad:   tensor([-0.0274,  0.1552])\n",
      "Epoch 1537, Loss 8.773393\n",
      "Params: tensor([  4.3597, -11.2788])\n",
      "Grad:   tensor([-0.0274,  0.1550])\n",
      "Epoch 1538, Loss 8.773149\n",
      "Params: tensor([  4.3600, -11.2803])\n",
      "Grad:   tensor([-0.0273,  0.1547])\n",
      "Epoch 1539, Loss 8.772902\n",
      "Params: tensor([  4.3603, -11.2819])\n",
      "Grad:   tensor([-0.0273,  0.1544])\n",
      "Epoch 1540, Loss 8.772656\n",
      "Params: tensor([  4.3606, -11.2834])\n",
      "Grad:   tensor([-0.0272,  0.1542])\n",
      "Epoch 1541, Loss 8.772411\n",
      "Params: tensor([  4.3608, -11.2850])\n",
      "Grad:   tensor([-0.0272,  0.1539])\n",
      "Epoch 1542, Loss 8.772167\n",
      "Params: tensor([  4.3611, -11.2865])\n",
      "Grad:   tensor([-0.0271,  0.1536])\n",
      "Epoch 1543, Loss 8.771923\n",
      "Params: tensor([  4.3614, -11.2880])\n",
      "Grad:   tensor([-0.0271,  0.1534])\n",
      "Epoch 1544, Loss 8.771680\n",
      "Params: tensor([  4.3616, -11.2896])\n",
      "Grad:   tensor([-0.0270,  0.1531])\n",
      "Epoch 1545, Loss 8.771441\n",
      "Params: tensor([  4.3619, -11.2911])\n",
      "Grad:   tensor([-0.0270,  0.1529])\n",
      "Epoch 1546, Loss 8.771197\n",
      "Params: tensor([  4.3622, -11.2926])\n",
      "Grad:   tensor([-0.0270,  0.1526])\n",
      "Epoch 1547, Loss 8.770959\n",
      "Params: tensor([  4.3624, -11.2942])\n",
      "Grad:   tensor([-0.0269,  0.1523])\n",
      "Epoch 1548, Loss 8.770720\n",
      "Params: tensor([  4.3627, -11.2957])\n",
      "Grad:   tensor([-0.0268,  0.1521])\n",
      "Epoch 1549, Loss 8.770481\n",
      "Params: tensor([  4.3630, -11.2972])\n",
      "Grad:   tensor([-0.0268,  0.1518])\n",
      "Epoch 1550, Loss 8.770245\n",
      "Params: tensor([  4.3633, -11.2987])\n",
      "Grad:   tensor([-0.0268,  0.1516])\n",
      "Epoch 1551, Loss 8.770008\n",
      "Params: tensor([  4.3635, -11.3002])\n",
      "Grad:   tensor([-0.0267,  0.1513])\n",
      "Epoch 1552, Loss 8.769771\n",
      "Params: tensor([  4.3638, -11.3017])\n",
      "Grad:   tensor([-0.0267,  0.1511])\n",
      "Epoch 1553, Loss 8.769537\n",
      "Params: tensor([  4.3641, -11.3032])\n",
      "Grad:   tensor([-0.0266,  0.1508])\n",
      "Epoch 1554, Loss 8.769303\n",
      "Params: tensor([  4.3643, -11.3047])\n",
      "Grad:   tensor([-0.0266,  0.1505])\n",
      "Epoch 1555, Loss 8.769068\n",
      "Params: tensor([  4.3646, -11.3062])\n",
      "Grad:   tensor([-0.0265,  0.1503])\n",
      "Epoch 1556, Loss 8.768835\n",
      "Params: tensor([  4.3648, -11.3077])\n",
      "Grad:   tensor([-0.0265,  0.1500])\n",
      "Epoch 1557, Loss 8.768605\n",
      "Params: tensor([  4.3651, -11.3092])\n",
      "Grad:   tensor([-0.0265,  0.1498])\n",
      "Epoch 1558, Loss 8.768373\n",
      "Params: tensor([  4.3654, -11.3107])\n",
      "Grad:   tensor([-0.0264,  0.1495])\n",
      "Epoch 1559, Loss 8.768144\n",
      "Params: tensor([  4.3656, -11.3122])\n",
      "Grad:   tensor([-0.0264,  0.1493])\n",
      "Epoch 1560, Loss 8.767914\n",
      "Params: tensor([  4.3659, -11.3137])\n",
      "Grad:   tensor([-0.0263,  0.1490])\n",
      "Epoch 1561, Loss 8.767684\n",
      "Params: tensor([  4.3662, -11.3152])\n",
      "Grad:   tensor([-0.0263,  0.1488])\n",
      "Epoch 1562, Loss 8.767455\n",
      "Params: tensor([  4.3664, -11.3167])\n",
      "Grad:   tensor([-0.0262,  0.1485])\n",
      "Epoch 1563, Loss 8.767230\n",
      "Params: tensor([  4.3667, -11.3182])\n",
      "Grad:   tensor([-0.0262,  0.1483])\n",
      "Epoch 1564, Loss 8.767001\n",
      "Params: tensor([  4.3670, -11.3197])\n",
      "Grad:   tensor([-0.0261,  0.1480])\n",
      "Epoch 1565, Loss 8.766776\n",
      "Params: tensor([  4.3672, -11.3211])\n",
      "Grad:   tensor([-0.0261,  0.1478])\n",
      "Epoch 1566, Loss 8.766553\n",
      "Params: tensor([  4.3675, -11.3226])\n",
      "Grad:   tensor([-0.0260,  0.1475])\n",
      "Epoch 1567, Loss 8.766328\n",
      "Params: tensor([  4.3677, -11.3241])\n",
      "Grad:   tensor([-0.0260,  0.1473])\n",
      "Epoch 1568, Loss 8.766105\n",
      "Params: tensor([  4.3680, -11.3256])\n",
      "Grad:   tensor([-0.0260,  0.1470])\n",
      "Epoch 1569, Loss 8.765882\n",
      "Params: tensor([  4.3683, -11.3270])\n",
      "Grad:   tensor([-0.0259,  0.1468])\n",
      "Epoch 1570, Loss 8.765659\n",
      "Params: tensor([  4.3685, -11.3285])\n",
      "Grad:   tensor([-0.0259,  0.1465])\n",
      "Epoch 1571, Loss 8.765438\n",
      "Params: tensor([  4.3688, -11.3300])\n",
      "Grad:   tensor([-0.0258,  0.1463])\n",
      "Epoch 1572, Loss 8.765219\n",
      "Params: tensor([  4.3690, -11.3314])\n",
      "Grad:   tensor([-0.0258,  0.1460])\n",
      "Epoch 1573, Loss 8.764998\n",
      "Params: tensor([  4.3693, -11.3329])\n",
      "Grad:   tensor([-0.0258,  0.1458])\n",
      "Epoch 1574, Loss 8.764782\n",
      "Params: tensor([  4.3695, -11.3343])\n",
      "Grad:   tensor([-0.0257,  0.1455])\n",
      "Epoch 1575, Loss 8.764560\n",
      "Params: tensor([  4.3698, -11.3358])\n",
      "Grad:   tensor([-0.0257,  0.1453])\n",
      "Epoch 1576, Loss 8.764343\n",
      "Params: tensor([  4.3701, -11.3372])\n",
      "Grad:   tensor([-0.0256,  0.1450])\n",
      "Epoch 1577, Loss 8.764125\n",
      "Params: tensor([  4.3703, -11.3387])\n",
      "Grad:   tensor([-0.0256,  0.1448])\n",
      "Epoch 1578, Loss 8.763912\n",
      "Params: tensor([  4.3706, -11.3401])\n",
      "Grad:   tensor([-0.0255,  0.1445])\n",
      "Epoch 1579, Loss 8.763695\n",
      "Params: tensor([  4.3708, -11.3416])\n",
      "Grad:   tensor([-0.0255,  0.1443])\n",
      "Epoch 1580, Loss 8.763482\n",
      "Params: tensor([  4.3711, -11.3430])\n",
      "Grad:   tensor([-0.0254,  0.1440])\n",
      "Epoch 1581, Loss 8.763268\n",
      "Params: tensor([  4.3713, -11.3444])\n",
      "Grad:   tensor([-0.0254,  0.1438])\n",
      "Epoch 1582, Loss 8.763053\n",
      "Params: tensor([  4.3716, -11.3459])\n",
      "Grad:   tensor([-0.0254,  0.1435])\n",
      "Epoch 1583, Loss 8.762842\n",
      "Params: tensor([  4.3718, -11.3473])\n",
      "Grad:   tensor([-0.0253,  0.1433])\n",
      "Epoch 1584, Loss 8.762630\n",
      "Params: tensor([  4.3721, -11.3487])\n",
      "Grad:   tensor([-0.0253,  0.1431])\n",
      "Epoch 1585, Loss 8.762421\n",
      "Params: tensor([  4.3723, -11.3502])\n",
      "Grad:   tensor([-0.0252,  0.1428])\n",
      "Epoch 1586, Loss 8.762213\n",
      "Params: tensor([  4.3726, -11.3516])\n",
      "Grad:   tensor([-0.0252,  0.1426])\n",
      "Epoch 1587, Loss 8.762000\n",
      "Params: tensor([  4.3728, -11.3530])\n",
      "Grad:   tensor([-0.0252,  0.1423])\n",
      "Epoch 1588, Loss 8.761792\n",
      "Params: tensor([  4.3731, -11.3544])\n",
      "Grad:   tensor([-0.0251,  0.1421])\n",
      "Epoch 1589, Loss 8.761584\n",
      "Params: tensor([  4.3733, -11.3559])\n",
      "Grad:   tensor([-0.0251,  0.1418])\n",
      "Epoch 1590, Loss 8.761376\n",
      "Params: tensor([  4.3736, -11.3573])\n",
      "Grad:   tensor([-0.0250,  0.1416])\n",
      "Epoch 1591, Loss 8.761168\n",
      "Params: tensor([  4.3738, -11.3587])\n",
      "Grad:   tensor([-0.0250,  0.1414])\n",
      "Epoch 1592, Loss 8.760964\n",
      "Params: tensor([  4.3741, -11.3601])\n",
      "Grad:   tensor([-0.0249,  0.1411])\n",
      "Epoch 1593, Loss 8.760757\n",
      "Params: tensor([  4.3743, -11.3615])\n",
      "Grad:   tensor([-0.0249,  0.1409])\n",
      "Epoch 1594, Loss 8.760555\n",
      "Params: tensor([  4.3746, -11.3629])\n",
      "Grad:   tensor([-0.0248,  0.1407])\n",
      "Epoch 1595, Loss 8.760349\n",
      "Params: tensor([  4.3748, -11.3643])\n",
      "Grad:   tensor([-0.0248,  0.1404])\n",
      "Epoch 1596, Loss 8.760147\n",
      "Params: tensor([  4.3751, -11.3657])\n",
      "Grad:   tensor([-0.0247,  0.1402])\n",
      "Epoch 1597, Loss 8.759945\n",
      "Params: tensor([  4.3753, -11.3671])\n",
      "Grad:   tensor([-0.0247,  0.1399])\n",
      "Epoch 1598, Loss 8.759742\n",
      "Params: tensor([  4.3756, -11.3685])\n",
      "Grad:   tensor([-0.0247,  0.1397])\n",
      "Epoch 1599, Loss 8.759542\n",
      "Params: tensor([  4.3758, -11.3699])\n",
      "Grad:   tensor([-0.0246,  0.1395])\n",
      "Epoch 1600, Loss 8.759343\n",
      "Params: tensor([  4.3761, -11.3713])\n",
      "Grad:   tensor([-0.0246,  0.1392])\n",
      "Epoch 1601, Loss 8.759142\n",
      "Params: tensor([  4.3763, -11.3727])\n",
      "Grad:   tensor([-0.0246,  0.1390])\n",
      "Epoch 1602, Loss 8.758943\n",
      "Params: tensor([  4.3766, -11.3741])\n",
      "Grad:   tensor([-0.0245,  0.1387])\n",
      "Epoch 1603, Loss 8.758744\n",
      "Params: tensor([  4.3768, -11.3755])\n",
      "Grad:   tensor([-0.0245,  0.1385])\n",
      "Epoch 1604, Loss 8.758549\n",
      "Params: tensor([  4.3771, -11.3768])\n",
      "Grad:   tensor([-0.0244,  0.1383])\n",
      "Epoch 1605, Loss 8.758348\n",
      "Params: tensor([  4.3773, -11.3782])\n",
      "Grad:   tensor([-0.0244,  0.1380])\n",
      "Epoch 1606, Loss 8.758155\n",
      "Params: tensor([  4.3775, -11.3796])\n",
      "Grad:   tensor([-0.0243,  0.1378])\n",
      "Epoch 1607, Loss 8.757958\n",
      "Params: tensor([  4.3778, -11.3810])\n",
      "Grad:   tensor([-0.0243,  0.1376])\n",
      "Epoch 1608, Loss 8.757765\n",
      "Params: tensor([  4.3780, -11.3824])\n",
      "Grad:   tensor([-0.0243,  0.1373])\n",
      "Epoch 1609, Loss 8.757569\n",
      "Params: tensor([  4.3783, -11.3837])\n",
      "Grad:   tensor([-0.0242,  0.1371])\n",
      "Epoch 1610, Loss 8.757374\n",
      "Params: tensor([  4.3785, -11.3851])\n",
      "Grad:   tensor([-0.0242,  0.1369])\n",
      "Epoch 1611, Loss 8.757180\n",
      "Params: tensor([  4.3788, -11.3865])\n",
      "Grad:   tensor([-0.0241,  0.1366])\n",
      "Epoch 1612, Loss 8.756989\n",
      "Params: tensor([  4.3790, -11.3878])\n",
      "Grad:   tensor([-0.0241,  0.1364])\n",
      "Epoch 1613, Loss 8.756797\n",
      "Params: tensor([  4.3792, -11.3892])\n",
      "Grad:   tensor([-0.0241,  0.1362])\n",
      "Epoch 1614, Loss 8.756606\n",
      "Params: tensor([  4.3795, -11.3905])\n",
      "Grad:   tensor([-0.0240,  0.1359])\n",
      "Epoch 1615, Loss 8.756415\n",
      "Params: tensor([  4.3797, -11.3919])\n",
      "Grad:   tensor([-0.0240,  0.1357])\n",
      "Epoch 1616, Loss 8.756226\n",
      "Params: tensor([  4.3800, -11.3933])\n",
      "Grad:   tensor([-0.0239,  0.1355])\n",
      "Epoch 1617, Loss 8.756034\n",
      "Params: tensor([  4.3802, -11.3946])\n",
      "Grad:   tensor([-0.0239,  0.1353])\n",
      "Epoch 1618, Loss 8.755850\n",
      "Params: tensor([  4.3804, -11.3960])\n",
      "Grad:   tensor([-0.0239,  0.1350])\n",
      "Epoch 1619, Loss 8.755662\n",
      "Params: tensor([  4.3807, -11.3973])\n",
      "Grad:   tensor([-0.0238,  0.1348])\n",
      "Epoch 1620, Loss 8.755472\n",
      "Params: tensor([  4.3809, -11.3987])\n",
      "Grad:   tensor([-0.0238,  0.1346])\n",
      "Epoch 1621, Loss 8.755286\n",
      "Params: tensor([  4.3811, -11.4000])\n",
      "Grad:   tensor([-0.0237,  0.1343])\n",
      "Epoch 1622, Loss 8.755100\n",
      "Params: tensor([  4.3814, -11.4013])\n",
      "Grad:   tensor([-0.0237,  0.1341])\n",
      "Epoch 1623, Loss 8.754916\n",
      "Params: tensor([  4.3816, -11.4027])\n",
      "Grad:   tensor([-0.0236,  0.1339])\n",
      "Epoch 1624, Loss 8.754733\n",
      "Params: tensor([  4.3819, -11.4040])\n",
      "Grad:   tensor([-0.0236,  0.1337])\n",
      "Epoch 1625, Loss 8.754548\n",
      "Params: tensor([  4.3821, -11.4053])\n",
      "Grad:   tensor([-0.0236,  0.1334])\n",
      "Epoch 1626, Loss 8.754363\n",
      "Params: tensor([  4.3823, -11.4067])\n",
      "Grad:   tensor([-0.0235,  0.1332])\n",
      "Epoch 1627, Loss 8.754180\n",
      "Params: tensor([  4.3826, -11.4080])\n",
      "Grad:   tensor([-0.0235,  0.1330])\n",
      "Epoch 1628, Loss 8.753999\n",
      "Params: tensor([  4.3828, -11.4093])\n",
      "Grad:   tensor([-0.0235,  0.1327])\n",
      "Epoch 1629, Loss 8.753818\n",
      "Params: tensor([  4.3830, -11.4107])\n",
      "Grad:   tensor([-0.0234,  0.1325])\n",
      "Epoch 1630, Loss 8.753635\n",
      "Params: tensor([  4.3833, -11.4120])\n",
      "Grad:   tensor([-0.0234,  0.1323])\n",
      "Epoch 1631, Loss 8.753456\n",
      "Params: tensor([  4.3835, -11.4133])\n",
      "Grad:   tensor([-0.0233,  0.1321])\n",
      "Epoch 1632, Loss 8.753277\n",
      "Params: tensor([  4.3837, -11.4146])\n",
      "Grad:   tensor([-0.0233,  0.1318])\n",
      "Epoch 1633, Loss 8.753097\n",
      "Params: tensor([  4.3840, -11.4159])\n",
      "Grad:   tensor([-0.0233,  0.1316])\n",
      "Epoch 1634, Loss 8.752919\n",
      "Params: tensor([  4.3842, -11.4173])\n",
      "Grad:   tensor([-0.0232,  0.1314])\n",
      "Epoch 1635, Loss 8.752740\n",
      "Params: tensor([  4.3844, -11.4186])\n",
      "Grad:   tensor([-0.0232,  0.1312])\n",
      "Epoch 1636, Loss 8.752564\n",
      "Params: tensor([  4.3847, -11.4199])\n",
      "Grad:   tensor([-0.0231,  0.1310])\n",
      "Epoch 1637, Loss 8.752386\n",
      "Params: tensor([  4.3849, -11.4212])\n",
      "Grad:   tensor([-0.0231,  0.1307])\n",
      "Epoch 1638, Loss 8.752212\n",
      "Params: tensor([  4.3851, -11.4225])\n",
      "Grad:   tensor([-0.0231,  0.1305])\n",
      "Epoch 1639, Loss 8.752034\n",
      "Params: tensor([  4.3853, -11.4238])\n",
      "Grad:   tensor([-0.0230,  0.1303])\n",
      "Epoch 1640, Loss 8.751861\n",
      "Params: tensor([  4.3856, -11.4251])\n",
      "Grad:   tensor([-0.0230,  0.1301])\n",
      "Epoch 1641, Loss 8.751685\n",
      "Params: tensor([  4.3858, -11.4264])\n",
      "Grad:   tensor([-0.0229,  0.1298])\n",
      "Epoch 1642, Loss 8.751513\n",
      "Params: tensor([  4.3860, -11.4277])\n",
      "Grad:   tensor([-0.0229,  0.1296])\n",
      "Epoch 1643, Loss 8.751342\n",
      "Params: tensor([  4.3863, -11.4290])\n",
      "Grad:   tensor([-0.0229,  0.1294])\n",
      "Epoch 1644, Loss 8.751165\n",
      "Params: tensor([  4.3865, -11.4303])\n",
      "Grad:   tensor([-0.0228,  0.1292])\n",
      "Epoch 1645, Loss 8.750996\n",
      "Params: tensor([  4.3867, -11.4316])\n",
      "Grad:   tensor([-0.0228,  0.1290])\n",
      "Epoch 1646, Loss 8.750822\n",
      "Params: tensor([  4.3869, -11.4329])\n",
      "Grad:   tensor([-0.0227,  0.1287])\n",
      "Epoch 1647, Loss 8.750650\n",
      "Params: tensor([  4.3872, -11.4341])\n",
      "Grad:   tensor([-0.0227,  0.1285])\n",
      "Epoch 1648, Loss 8.750482\n",
      "Params: tensor([  4.3874, -11.4354])\n",
      "Grad:   tensor([-0.0227,  0.1283])\n",
      "Epoch 1649, Loss 8.750314\n",
      "Params: tensor([  4.3876, -11.4367])\n",
      "Grad:   tensor([-0.0226,  0.1281])\n",
      "Epoch 1650, Loss 8.750144\n",
      "Params: tensor([  4.3879, -11.4380])\n",
      "Grad:   tensor([-0.0226,  0.1279])\n",
      "Epoch 1651, Loss 8.749973\n",
      "Params: tensor([  4.3881, -11.4393])\n",
      "Grad:   tensor([-0.0225,  0.1277])\n",
      "Epoch 1652, Loss 8.749808\n",
      "Params: tensor([  4.3883, -11.4405])\n",
      "Grad:   tensor([-0.0225,  0.1274])\n",
      "Epoch 1653, Loss 8.749640\n",
      "Params: tensor([  4.3885, -11.4418])\n",
      "Grad:   tensor([-0.0225,  0.1272])\n",
      "Epoch 1654, Loss 8.749473\n",
      "Params: tensor([  4.3888, -11.4431])\n",
      "Grad:   tensor([-0.0224,  0.1270])\n",
      "Epoch 1655, Loss 8.749307\n",
      "Params: tensor([  4.3890, -11.4443])\n",
      "Grad:   tensor([-0.0224,  0.1268])\n",
      "Epoch 1656, Loss 8.749140\n",
      "Params: tensor([  4.3892, -11.4456])\n",
      "Grad:   tensor([-0.0223,  0.1266])\n",
      "Epoch 1657, Loss 8.748977\n",
      "Params: tensor([  4.3894, -11.4469])\n",
      "Grad:   tensor([-0.0223,  0.1264])\n",
      "Epoch 1658, Loss 8.748813\n",
      "Params: tensor([  4.3896, -11.4481])\n",
      "Grad:   tensor([-0.0223,  0.1261])\n",
      "Epoch 1659, Loss 8.748650\n",
      "Params: tensor([  4.3899, -11.4494])\n",
      "Grad:   tensor([-0.0223,  0.1259])\n",
      "Epoch 1660, Loss 8.748486\n",
      "Params: tensor([  4.3901, -11.4506])\n",
      "Grad:   tensor([-0.0222,  0.1257])\n",
      "Epoch 1661, Loss 8.748323\n",
      "Params: tensor([  4.3903, -11.4519])\n",
      "Grad:   tensor([-0.0222,  0.1255])\n",
      "Epoch 1662, Loss 8.748159\n",
      "Params: tensor([  4.3905, -11.4532])\n",
      "Grad:   tensor([-0.0221,  0.1253])\n",
      "Epoch 1663, Loss 8.747997\n",
      "Params: tensor([  4.3908, -11.4544])\n",
      "Grad:   tensor([-0.0221,  0.1251])\n",
      "Epoch 1664, Loss 8.747833\n",
      "Params: tensor([  4.3910, -11.4557])\n",
      "Grad:   tensor([-0.0221,  0.1249])\n",
      "Epoch 1665, Loss 8.747675\n",
      "Params: tensor([  4.3912, -11.4569])\n",
      "Grad:   tensor([-0.0220,  0.1247])\n",
      "Epoch 1666, Loss 8.747517\n",
      "Params: tensor([  4.3914, -11.4581])\n",
      "Grad:   tensor([-0.0220,  0.1244])\n",
      "Epoch 1667, Loss 8.747357\n",
      "Params: tensor([  4.3916, -11.4594])\n",
      "Grad:   tensor([-0.0220,  0.1242])\n",
      "Epoch 1668, Loss 8.747197\n",
      "Params: tensor([  4.3919, -11.4606])\n",
      "Grad:   tensor([-0.0219,  0.1240])\n",
      "Epoch 1669, Loss 8.747040\n",
      "Params: tensor([  4.3921, -11.4619])\n",
      "Grad:   tensor([-0.0219,  0.1238])\n",
      "Epoch 1670, Loss 8.746881\n",
      "Params: tensor([  4.3923, -11.4631])\n",
      "Grad:   tensor([-0.0218,  0.1236])\n",
      "Epoch 1671, Loss 8.746723\n",
      "Params: tensor([  4.3925, -11.4643])\n",
      "Grad:   tensor([-0.0218,  0.1234])\n",
      "Epoch 1672, Loss 8.746565\n",
      "Params: tensor([  4.3927, -11.4656])\n",
      "Grad:   tensor([-0.0217,  0.1232])\n",
      "Epoch 1673, Loss 8.746408\n",
      "Params: tensor([  4.3929, -11.4668])\n",
      "Grad:   tensor([-0.0217,  0.1230])\n",
      "Epoch 1674, Loss 8.746252\n",
      "Params: tensor([  4.3932, -11.4680])\n",
      "Grad:   tensor([-0.0217,  0.1228])\n",
      "Epoch 1675, Loss 8.746099\n",
      "Params: tensor([  4.3934, -11.4693])\n",
      "Grad:   tensor([-0.0217,  0.1226])\n",
      "Epoch 1676, Loss 8.745942\n",
      "Params: tensor([  4.3936, -11.4705])\n",
      "Grad:   tensor([-0.0216,  0.1223])\n",
      "Epoch 1677, Loss 8.745790\n",
      "Params: tensor([  4.3938, -11.4717])\n",
      "Grad:   tensor([-0.0216,  0.1221])\n",
      "Epoch 1678, Loss 8.745635\n",
      "Params: tensor([  4.3940, -11.4729])\n",
      "Grad:   tensor([-0.0215,  0.1219])\n",
      "Epoch 1679, Loss 8.745482\n",
      "Params: tensor([  4.3942, -11.4741])\n",
      "Grad:   tensor([-0.0215,  0.1217])\n",
      "Epoch 1680, Loss 8.745330\n",
      "Params: tensor([  4.3945, -11.4753])\n",
      "Grad:   tensor([-0.0215,  0.1215])\n",
      "Epoch 1681, Loss 8.745178\n",
      "Params: tensor([  4.3947, -11.4766])\n",
      "Grad:   tensor([-0.0214,  0.1213])\n",
      "Epoch 1682, Loss 8.745028\n",
      "Params: tensor([  4.3949, -11.4778])\n",
      "Grad:   tensor([-0.0214,  0.1211])\n",
      "Epoch 1683, Loss 8.744875\n",
      "Params: tensor([  4.3951, -11.4790])\n",
      "Grad:   tensor([-0.0214,  0.1209])\n",
      "Epoch 1684, Loss 8.744723\n",
      "Params: tensor([  4.3953, -11.4802])\n",
      "Grad:   tensor([-0.0213,  0.1207])\n",
      "Epoch 1685, Loss 8.744575\n",
      "Params: tensor([  4.3955, -11.4814])\n",
      "Grad:   tensor([-0.0213,  0.1205])\n",
      "Epoch 1686, Loss 8.744425\n",
      "Params: tensor([  4.3957, -11.4826])\n",
      "Grad:   tensor([-0.0212,  0.1203])\n",
      "Epoch 1687, Loss 8.744275\n",
      "Params: tensor([  4.3959, -11.4838])\n",
      "Grad:   tensor([-0.0212,  0.1201])\n",
      "Epoch 1688, Loss 8.744126\n",
      "Params: tensor([  4.3962, -11.4850])\n",
      "Grad:   tensor([-0.0212,  0.1199])\n",
      "Epoch 1689, Loss 8.743979\n",
      "Params: tensor([  4.3964, -11.4862])\n",
      "Grad:   tensor([-0.0211,  0.1197])\n",
      "Epoch 1690, Loss 8.743833\n",
      "Params: tensor([  4.3966, -11.4874])\n",
      "Grad:   tensor([-0.0211,  0.1195])\n",
      "Epoch 1691, Loss 8.743684\n",
      "Params: tensor([  4.3968, -11.4886])\n",
      "Grad:   tensor([-0.0211,  0.1193])\n",
      "Epoch 1692, Loss 8.743539\n",
      "Params: tensor([  4.3970, -11.4898])\n",
      "Grad:   tensor([-0.0210,  0.1191])\n",
      "Epoch 1693, Loss 8.743390\n",
      "Params: tensor([  4.3972, -11.4910])\n",
      "Grad:   tensor([-0.0210,  0.1189])\n",
      "Epoch 1694, Loss 8.743247\n",
      "Params: tensor([  4.3974, -11.4921])\n",
      "Grad:   tensor([-0.0210,  0.1187])\n",
      "Epoch 1695, Loss 8.743102\n",
      "Params: tensor([  4.3976, -11.4933])\n",
      "Grad:   tensor([-0.0209,  0.1185])\n",
      "Epoch 1696, Loss 8.742958\n",
      "Params: tensor([  4.3978, -11.4945])\n",
      "Grad:   tensor([-0.0209,  0.1183])\n",
      "Epoch 1697, Loss 8.742813\n",
      "Params: tensor([  4.3980, -11.4957])\n",
      "Grad:   tensor([-0.0208,  0.1181])\n",
      "Epoch 1698, Loss 8.742669\n",
      "Params: tensor([  4.3983, -11.4969])\n",
      "Grad:   tensor([-0.0208,  0.1179])\n",
      "Epoch 1699, Loss 8.742527\n",
      "Params: tensor([  4.3985, -11.4980])\n",
      "Grad:   tensor([-0.0208,  0.1177])\n",
      "Epoch 1700, Loss 8.742382\n",
      "Params: tensor([  4.3987, -11.4992])\n",
      "Grad:   tensor([-0.0207,  0.1175])\n",
      "Epoch 1701, Loss 8.742240\n",
      "Params: tensor([  4.3989, -11.5004])\n",
      "Grad:   tensor([-0.0207,  0.1173])\n",
      "Epoch 1702, Loss 8.742102\n",
      "Params: tensor([  4.3991, -11.5016])\n",
      "Grad:   tensor([-0.0207,  0.1171])\n",
      "Epoch 1703, Loss 8.741960\n",
      "Params: tensor([  4.3993, -11.5027])\n",
      "Grad:   tensor([-0.0206,  0.1169])\n",
      "Epoch 1704, Loss 8.741816\n",
      "Params: tensor([  4.3995, -11.5039])\n",
      "Grad:   tensor([-0.0206,  0.1167])\n",
      "Epoch 1705, Loss 8.741677\n",
      "Params: tensor([  4.3997, -11.5051])\n",
      "Grad:   tensor([-0.0206,  0.1165])\n",
      "Epoch 1706, Loss 8.741538\n",
      "Params: tensor([  4.3999, -11.5062])\n",
      "Grad:   tensor([-0.0206,  0.1163])\n",
      "Epoch 1707, Loss 8.741401\n",
      "Params: tensor([  4.4001, -11.5074])\n",
      "Grad:   tensor([-0.0205,  0.1161])\n",
      "Epoch 1708, Loss 8.741260\n",
      "Params: tensor([  4.4003, -11.5085])\n",
      "Grad:   tensor([-0.0205,  0.1159])\n",
      "Epoch 1709, Loss 8.741120\n",
      "Params: tensor([  4.4005, -11.5097])\n",
      "Grad:   tensor([-0.0204,  0.1157])\n",
      "Epoch 1710, Loss 8.740985\n",
      "Params: tensor([  4.4007, -11.5109])\n",
      "Grad:   tensor([-0.0204,  0.1155])\n",
      "Epoch 1711, Loss 8.740846\n",
      "Params: tensor([  4.4009, -11.5120])\n",
      "Grad:   tensor([-0.0204,  0.1153])\n",
      "Epoch 1712, Loss 8.740711\n",
      "Params: tensor([  4.4011, -11.5132])\n",
      "Grad:   tensor([-0.0203,  0.1151])\n",
      "Epoch 1713, Loss 8.740570\n",
      "Params: tensor([  4.4013, -11.5143])\n",
      "Grad:   tensor([-0.0203,  0.1149])\n",
      "Epoch 1714, Loss 8.740437\n",
      "Params: tensor([  4.4015, -11.5155])\n",
      "Grad:   tensor([-0.0203,  0.1147])\n",
      "Epoch 1715, Loss 8.740301\n",
      "Params: tensor([  4.4017, -11.5166])\n",
      "Grad:   tensor([-0.0202,  0.1145])\n",
      "Epoch 1716, Loss 8.740167\n",
      "Params: tensor([  4.4019, -11.5177])\n",
      "Grad:   tensor([-0.0202,  0.1143])\n",
      "Epoch 1717, Loss 8.740030\n",
      "Params: tensor([  4.4021, -11.5189])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad:   tensor([-0.0202,  0.1141])\n",
      "Epoch 1718, Loss 8.739898\n",
      "Params: tensor([  4.4023, -11.5200])\n",
      "Grad:   tensor([-0.0201,  0.1139])\n",
      "Epoch 1719, Loss 8.739764\n",
      "Params: tensor([  4.4025, -11.5212])\n",
      "Grad:   tensor([-0.0201,  0.1137])\n",
      "Epoch 1720, Loss 8.739631\n",
      "Params: tensor([  4.4027, -11.5223])\n",
      "Grad:   tensor([-0.0201,  0.1135])\n",
      "Epoch 1721, Loss 8.739498\n",
      "Params: tensor([  4.4029, -11.5234])\n",
      "Grad:   tensor([-0.0200,  0.1133])\n",
      "Epoch 1722, Loss 8.739365\n",
      "Params: tensor([  4.4031, -11.5246])\n",
      "Grad:   tensor([-0.0200,  0.1131])\n",
      "Epoch 1723, Loss 8.739233\n",
      "Params: tensor([  4.4033, -11.5257])\n",
      "Grad:   tensor([-0.0199,  0.1130])\n",
      "Epoch 1724, Loss 8.739102\n",
      "Params: tensor([  4.4035, -11.5268])\n",
      "Grad:   tensor([-0.0199,  0.1128])\n",
      "Epoch 1725, Loss 8.738971\n",
      "Params: tensor([  4.4037, -11.5279])\n",
      "Grad:   tensor([-0.0199,  0.1126])\n",
      "Epoch 1726, Loss 8.738840\n",
      "Params: tensor([  4.4039, -11.5291])\n",
      "Grad:   tensor([-0.0198,  0.1124])\n",
      "Epoch 1727, Loss 8.738712\n",
      "Params: tensor([  4.4041, -11.5302])\n",
      "Grad:   tensor([-0.0198,  0.1122])\n",
      "Epoch 1728, Loss 8.738583\n",
      "Params: tensor([  4.4043, -11.5313])\n",
      "Grad:   tensor([-0.0198,  0.1120])\n",
      "Epoch 1729, Loss 8.738452\n",
      "Params: tensor([  4.4045, -11.5324])\n",
      "Grad:   tensor([-0.0197,  0.1118])\n",
      "Epoch 1730, Loss 8.738322\n",
      "Params: tensor([  4.4047, -11.5335])\n",
      "Grad:   tensor([-0.0197,  0.1116])\n",
      "Epoch 1731, Loss 8.738195\n",
      "Params: tensor([  4.4049, -11.5347])\n",
      "Grad:   tensor([-0.0197,  0.1114])\n",
      "Epoch 1732, Loss 8.738068\n",
      "Params: tensor([  4.4051, -11.5358])\n",
      "Grad:   tensor([-0.0196,  0.1112])\n",
      "Epoch 1733, Loss 8.737940\n",
      "Params: tensor([  4.4053, -11.5369])\n",
      "Grad:   tensor([-0.0196,  0.1110])\n",
      "Epoch 1734, Loss 8.737812\n",
      "Params: tensor([  4.4055, -11.5380])\n",
      "Grad:   tensor([-0.0196,  0.1109])\n",
      "Epoch 1735, Loss 8.737687\n",
      "Params: tensor([  4.4057, -11.5391])\n",
      "Grad:   tensor([-0.0195,  0.1107])\n",
      "Epoch 1736, Loss 8.737560\n",
      "Params: tensor([  4.4059, -11.5402])\n",
      "Grad:   tensor([-0.0195,  0.1105])\n",
      "Epoch 1737, Loss 8.737435\n",
      "Params: tensor([  4.4061, -11.5413])\n",
      "Grad:   tensor([-0.0195,  0.1103])\n",
      "Epoch 1738, Loss 8.737309\n",
      "Params: tensor([  4.4063, -11.5424])\n",
      "Grad:   tensor([-0.0195,  0.1101])\n",
      "Epoch 1739, Loss 8.737182\n",
      "Params: tensor([  4.4065, -11.5435])\n",
      "Grad:   tensor([-0.0194,  0.1099])\n",
      "Epoch 1740, Loss 8.737061\n",
      "Params: tensor([  4.4067, -11.5446])\n",
      "Grad:   tensor([-0.0194,  0.1097])\n",
      "Epoch 1741, Loss 8.736935\n",
      "Params: tensor([  4.4069, -11.5457])\n",
      "Grad:   tensor([-0.0194,  0.1095])\n",
      "Epoch 1742, Loss 8.736811\n",
      "Params: tensor([  4.4071, -11.5468])\n",
      "Grad:   tensor([-0.0193,  0.1094])\n",
      "Epoch 1743, Loss 8.736689\n",
      "Params: tensor([  4.4073, -11.5479])\n",
      "Grad:   tensor([-0.0193,  0.1092])\n",
      "Epoch 1744, Loss 8.736567\n",
      "Params: tensor([  4.4075, -11.5490])\n",
      "Grad:   tensor([-0.0193,  0.1090])\n",
      "Epoch 1745, Loss 8.736442\n",
      "Params: tensor([  4.4077, -11.5501])\n",
      "Grad:   tensor([-0.0192,  0.1088])\n",
      "Epoch 1746, Loss 8.736322\n",
      "Params: tensor([  4.4078, -11.5511])\n",
      "Grad:   tensor([-0.0192,  0.1086])\n",
      "Epoch 1747, Loss 8.736199\n",
      "Params: tensor([  4.4080, -11.5522])\n",
      "Grad:   tensor([-0.0191,  0.1084])\n",
      "Epoch 1748, Loss 8.736080\n",
      "Params: tensor([  4.4082, -11.5533])\n",
      "Grad:   tensor([-0.0191,  0.1082])\n",
      "Epoch 1749, Loss 8.735956\n",
      "Params: tensor([  4.4084, -11.5544])\n",
      "Grad:   tensor([-0.0191,  0.1081])\n",
      "Epoch 1750, Loss 8.735838\n",
      "Params: tensor([  4.4086, -11.5555])\n",
      "Grad:   tensor([-0.0191,  0.1079])\n",
      "Epoch 1751, Loss 8.735717\n",
      "Params: tensor([  4.4088, -11.5565])\n",
      "Grad:   tensor([-0.0190,  0.1077])\n",
      "Epoch 1752, Loss 8.735600\n",
      "Params: tensor([  4.4090, -11.5576])\n",
      "Grad:   tensor([-0.0190,  0.1075])\n",
      "Epoch 1753, Loss 8.735477\n",
      "Params: tensor([  4.4092, -11.5587])\n",
      "Grad:   tensor([-0.0190,  0.1073])\n",
      "Epoch 1754, Loss 8.735362\n",
      "Params: tensor([  4.4094, -11.5598])\n",
      "Grad:   tensor([-0.0189,  0.1072])\n",
      "Epoch 1755, Loss 8.735241\n",
      "Params: tensor([  4.4096, -11.5608])\n",
      "Grad:   tensor([-0.0189,  0.1070])\n",
      "Epoch 1756, Loss 8.735124\n",
      "Params: tensor([  4.4097, -11.5619])\n",
      "Grad:   tensor([-0.0189,  0.1068])\n",
      "Epoch 1757, Loss 8.735006\n",
      "Params: tensor([  4.4099, -11.5630])\n",
      "Grad:   tensor([-0.0188,  0.1066])\n",
      "Epoch 1758, Loss 8.734891\n",
      "Params: tensor([  4.4101, -11.5640])\n",
      "Grad:   tensor([-0.0188,  0.1064])\n",
      "Epoch 1759, Loss 8.734772\n",
      "Params: tensor([  4.4103, -11.5651])\n",
      "Grad:   tensor([-0.0188,  0.1062])\n",
      "Epoch 1760, Loss 8.734656\n",
      "Params: tensor([  4.4105, -11.5662])\n",
      "Grad:   tensor([-0.0187,  0.1061])\n",
      "Epoch 1761, Loss 8.734539\n",
      "Params: tensor([  4.4107, -11.5672])\n",
      "Grad:   tensor([-0.0187,  0.1059])\n",
      "Epoch 1762, Loss 8.734426\n",
      "Params: tensor([  4.4109, -11.5683])\n",
      "Grad:   tensor([-0.0187,  0.1057])\n",
      "Epoch 1763, Loss 8.734311\n",
      "Params: tensor([  4.4111, -11.5693])\n",
      "Grad:   tensor([-0.0187,  0.1055])\n",
      "Epoch 1764, Loss 8.734195\n",
      "Params: tensor([  4.4112, -11.5704])\n",
      "Grad:   tensor([-0.0186,  0.1053])\n",
      "Epoch 1765, Loss 8.734081\n",
      "Params: tensor([  4.4114, -11.5714])\n",
      "Grad:   tensor([-0.0186,  0.1052])\n",
      "Epoch 1766, Loss 8.733965\n",
      "Params: tensor([  4.4116, -11.5725])\n",
      "Grad:   tensor([-0.0185,  0.1050])\n",
      "Epoch 1767, Loss 8.733854\n",
      "Params: tensor([  4.4118, -11.5735])\n",
      "Grad:   tensor([-0.0185,  0.1048])\n",
      "Epoch 1768, Loss 8.733740\n",
      "Params: tensor([  4.4120, -11.5746])\n",
      "Grad:   tensor([-0.0185,  0.1046])\n",
      "Epoch 1769, Loss 8.733628\n",
      "Params: tensor([  4.4122, -11.5756])\n",
      "Grad:   tensor([-0.0184,  0.1045])\n",
      "Epoch 1770, Loss 8.733515\n",
      "Params: tensor([  4.4124, -11.5767])\n",
      "Grad:   tensor([-0.0184,  0.1043])\n",
      "Epoch 1771, Loss 8.733402\n",
      "Params: tensor([  4.4125, -11.5777])\n",
      "Grad:   tensor([-0.0184,  0.1041])\n",
      "Epoch 1772, Loss 8.733292\n",
      "Params: tensor([  4.4127, -11.5787])\n",
      "Grad:   tensor([-0.0184,  0.1039])\n",
      "Epoch 1773, Loss 8.733179\n",
      "Params: tensor([  4.4129, -11.5798])\n",
      "Grad:   tensor([-0.0183,  0.1037])\n",
      "Epoch 1774, Loss 8.733067\n",
      "Params: tensor([  4.4131, -11.5808])\n",
      "Grad:   tensor([-0.0183,  0.1036])\n",
      "Epoch 1775, Loss 8.732957\n",
      "Params: tensor([  4.4133, -11.5819])\n",
      "Grad:   tensor([-0.0183,  0.1034])\n",
      "Epoch 1776, Loss 8.732848\n",
      "Params: tensor([  4.4135, -11.5829])\n",
      "Grad:   tensor([-0.0182,  0.1032])\n",
      "Epoch 1777, Loss 8.732738\n",
      "Params: tensor([  4.4136, -11.5839])\n",
      "Grad:   tensor([-0.0182,  0.1030])\n",
      "Epoch 1778, Loss 8.732630\n",
      "Params: tensor([  4.4138, -11.5849])\n",
      "Grad:   tensor([-0.0182,  0.1029])\n",
      "Epoch 1779, Loss 8.732522\n",
      "Params: tensor([  4.4140, -11.5860])\n",
      "Grad:   tensor([-0.0181,  0.1027])\n",
      "Epoch 1780, Loss 8.732413\n",
      "Params: tensor([  4.4142, -11.5870])\n",
      "Grad:   tensor([-0.0181,  0.1025])\n",
      "Epoch 1781, Loss 8.732306\n",
      "Params: tensor([  4.4144, -11.5880])\n",
      "Grad:   tensor([-0.0181,  0.1023])\n",
      "Epoch 1782, Loss 8.732194\n",
      "Params: tensor([  4.4145, -11.5890])\n",
      "Grad:   tensor([-0.0180,  0.1022])\n",
      "Epoch 1783, Loss 8.732090\n",
      "Params: tensor([  4.4147, -11.5901])\n",
      "Grad:   tensor([-0.0180,  0.1020])\n",
      "Epoch 1784, Loss 8.731980\n",
      "Params: tensor([  4.4149, -11.5911])\n",
      "Grad:   tensor([-0.0180,  0.1018])\n",
      "Epoch 1785, Loss 8.731873\n",
      "Params: tensor([  4.4151, -11.5921])\n",
      "Grad:   tensor([-0.0180,  0.1016])\n",
      "Epoch 1786, Loss 8.731769\n",
      "Params: tensor([  4.4153, -11.5931])\n",
      "Grad:   tensor([-0.0179,  0.1015])\n",
      "Epoch 1787, Loss 8.731660\n",
      "Params: tensor([  4.4154, -11.5941])\n",
      "Grad:   tensor([-0.0179,  0.1013])\n",
      "Epoch 1788, Loss 8.731554\n",
      "Params: tensor([  4.4156, -11.5951])\n",
      "Grad:   tensor([-0.0179,  0.1011])\n",
      "Epoch 1789, Loss 8.731450\n",
      "Params: tensor([  4.4158, -11.5961])\n",
      "Grad:   tensor([-0.0178,  0.1010])\n",
      "Epoch 1790, Loss 8.731344\n",
      "Params: tensor([  4.4160, -11.5972])\n",
      "Grad:   tensor([-0.0178,  0.1008])\n",
      "Epoch 1791, Loss 8.731240\n",
      "Params: tensor([  4.4161, -11.5982])\n",
      "Grad:   tensor([-0.0178,  0.1006])\n",
      "Epoch 1792, Loss 8.731134\n",
      "Params: tensor([  4.4163, -11.5992])\n",
      "Grad:   tensor([-0.0177,  0.1004])\n",
      "Epoch 1793, Loss 8.731032\n",
      "Params: tensor([  4.4165, -11.6002])\n",
      "Grad:   tensor([-0.0177,  0.1003])\n",
      "Epoch 1794, Loss 8.730928\n",
      "Params: tensor([  4.4167, -11.6012])\n",
      "Grad:   tensor([-0.0177,  0.1001])\n",
      "Epoch 1795, Loss 8.730824\n",
      "Params: tensor([  4.4169, -11.6022])\n",
      "Grad:   tensor([-0.0177,  0.0999])\n",
      "Epoch 1796, Loss 8.730722\n",
      "Params: tensor([  4.4170, -11.6032])\n",
      "Grad:   tensor([-0.0176,  0.0998])\n",
      "Epoch 1797, Loss 8.730621\n",
      "Params: tensor([  4.4172, -11.6042])\n",
      "Grad:   tensor([-0.0176,  0.0996])\n",
      "Epoch 1798, Loss 8.730518\n",
      "Params: tensor([  4.4174, -11.6052])\n",
      "Grad:   tensor([-0.0176,  0.0994])\n",
      "Epoch 1799, Loss 8.730414\n",
      "Params: tensor([  4.4176, -11.6061])\n",
      "Grad:   tensor([-0.0175,  0.0993])\n",
      "Epoch 1800, Loss 8.730314\n",
      "Params: tensor([  4.4177, -11.6071])\n",
      "Grad:   tensor([-0.0175,  0.0991])\n",
      "Epoch 1801, Loss 8.730215\n",
      "Params: tensor([  4.4179, -11.6081])\n",
      "Grad:   tensor([-0.0175,  0.0989])\n",
      "Epoch 1802, Loss 8.730112\n",
      "Params: tensor([  4.4181, -11.6091])\n",
      "Grad:   tensor([-0.0174,  0.0988])\n",
      "Epoch 1803, Loss 8.730011\n",
      "Params: tensor([  4.4183, -11.6101])\n",
      "Grad:   tensor([-0.0174,  0.0986])\n",
      "Epoch 1804, Loss 8.729913\n",
      "Params: tensor([  4.4184, -11.6111])\n",
      "Grad:   tensor([-0.0174,  0.0984])\n",
      "Epoch 1805, Loss 8.729813\n",
      "Params: tensor([  4.4186, -11.6121])\n",
      "Grad:   tensor([-0.0173,  0.0983])\n",
      "Epoch 1806, Loss 8.729712\n",
      "Params: tensor([  4.4188, -11.6130])\n",
      "Grad:   tensor([-0.0173,  0.0981])\n",
      "Epoch 1807, Loss 8.729614\n",
      "Params: tensor([  4.4190, -11.6140])\n",
      "Grad:   tensor([-0.0173,  0.0979])\n",
      "Epoch 1808, Loss 8.729514\n",
      "Params: tensor([  4.4191, -11.6150])\n",
      "Grad:   tensor([-0.0173,  0.0978])\n",
      "Epoch 1809, Loss 8.729416\n",
      "Params: tensor([  4.4193, -11.6160])\n",
      "Grad:   tensor([-0.0172,  0.0976])\n",
      "Epoch 1810, Loss 8.729318\n",
      "Params: tensor([  4.4195, -11.6170])\n",
      "Grad:   tensor([-0.0172,  0.0974])\n",
      "Epoch 1811, Loss 8.729220\n",
      "Params: tensor([  4.4196, -11.6179])\n",
      "Grad:   tensor([-0.0172,  0.0973])\n",
      "Epoch 1812, Loss 8.729123\n",
      "Params: tensor([  4.4198, -11.6189])\n",
      "Grad:   tensor([-0.0172,  0.0971])\n",
      "Epoch 1813, Loss 8.729026\n",
      "Params: tensor([  4.4200, -11.6199])\n",
      "Grad:   tensor([-0.0171,  0.0969])\n",
      "Epoch 1814, Loss 8.728931\n",
      "Params: tensor([  4.4202, -11.6208])\n",
      "Grad:   tensor([-0.0171,  0.0968])\n",
      "Epoch 1815, Loss 8.728832\n",
      "Params: tensor([  4.4203, -11.6218])\n",
      "Grad:   tensor([-0.0171,  0.0966])\n",
      "Epoch 1816, Loss 8.728736\n",
      "Params: tensor([  4.4205, -11.6228])\n",
      "Grad:   tensor([-0.0170,  0.0964])\n",
      "Epoch 1817, Loss 8.728641\n",
      "Params: tensor([  4.4207, -11.6237])\n",
      "Grad:   tensor([-0.0170,  0.0963])\n",
      "Epoch 1818, Loss 8.728547\n",
      "Params: tensor([  4.4208, -11.6247])\n",
      "Grad:   tensor([-0.0170,  0.0961])\n",
      "Epoch 1819, Loss 8.728449\n",
      "Params: tensor([  4.4210, -11.6256])\n",
      "Grad:   tensor([-0.0170,  0.0959])\n",
      "Epoch 1820, Loss 8.728356\n",
      "Params: tensor([  4.4212, -11.6266])\n",
      "Grad:   tensor([-0.0169,  0.0958])\n",
      "Epoch 1821, Loss 8.728258\n",
      "Params: tensor([  4.4213, -11.6276])\n",
      "Grad:   tensor([-0.0169,  0.0956])\n",
      "Epoch 1822, Loss 8.728166\n",
      "Params: tensor([  4.4215, -11.6285])\n",
      "Grad:   tensor([-0.0169,  0.0955])\n",
      "Epoch 1823, Loss 8.728073\n",
      "Params: tensor([  4.4217, -11.6295])\n",
      "Grad:   tensor([-0.0168,  0.0953])\n",
      "Epoch 1824, Loss 8.727978\n",
      "Params: tensor([  4.4218, -11.6304])\n",
      "Grad:   tensor([-0.0168,  0.0951])\n",
      "Epoch 1825, Loss 8.727886\n",
      "Params: tensor([  4.4220, -11.6314])\n",
      "Grad:   tensor([-0.0168,  0.0950])\n",
      "Epoch 1826, Loss 8.727792\n",
      "Params: tensor([  4.4222, -11.6323])\n",
      "Grad:   tensor([-0.0167,  0.0948])\n",
      "Epoch 1827, Loss 8.727700\n",
      "Params: tensor([  4.4224, -11.6333])\n",
      "Grad:   tensor([-0.0167,  0.0946])\n",
      "Epoch 1828, Loss 8.727608\n",
      "Params: tensor([  4.4225, -11.6342])\n",
      "Grad:   tensor([-0.0167,  0.0945])\n",
      "Epoch 1829, Loss 8.727515\n",
      "Params: tensor([  4.4227, -11.6352])\n",
      "Grad:   tensor([-0.0167,  0.0943])\n",
      "Epoch 1830, Loss 8.727424\n",
      "Params: tensor([  4.4229, -11.6361])\n",
      "Grad:   tensor([-0.0166,  0.0942])\n",
      "Epoch 1831, Loss 8.727332\n",
      "Params: tensor([  4.4230, -11.6370])\n",
      "Grad:   tensor([-0.0166,  0.0940])\n",
      "Epoch 1832, Loss 8.727242\n",
      "Params: tensor([  4.4232, -11.6380])\n",
      "Grad:   tensor([-0.0166,  0.0938])\n",
      "Epoch 1833, Loss 8.727150\n",
      "Params: tensor([  4.4233, -11.6389])\n",
      "Grad:   tensor([-0.0165,  0.0937])\n",
      "Epoch 1834, Loss 8.727060\n",
      "Params: tensor([  4.4235, -11.6398])\n",
      "Grad:   tensor([-0.0165,  0.0935])\n",
      "Epoch 1835, Loss 8.726971\n",
      "Params: tensor([  4.4237, -11.6408])\n",
      "Grad:   tensor([-0.0165,  0.0934])\n",
      "Epoch 1836, Loss 8.726882\n",
      "Params: tensor([  4.4238, -11.6417])\n",
      "Grad:   tensor([-0.0164,  0.0932])\n",
      "Epoch 1837, Loss 8.726789\n",
      "Params: tensor([  4.4240, -11.6426])\n",
      "Grad:   tensor([-0.0164,  0.0930])\n",
      "Epoch 1838, Loss 8.726701\n",
      "Params: tensor([  4.4242, -11.6436])\n",
      "Grad:   tensor([-0.0164,  0.0929])\n",
      "Epoch 1839, Loss 8.726612\n",
      "Params: tensor([  4.4243, -11.6445])\n",
      "Grad:   tensor([-0.0164,  0.0927])\n",
      "Epoch 1840, Loss 8.726524\n",
      "Params: tensor([  4.4245, -11.6454])\n",
      "Grad:   tensor([-0.0163,  0.0926])\n",
      "Epoch 1841, Loss 8.726435\n",
      "Params: tensor([  4.4247, -11.6463])\n",
      "Grad:   tensor([-0.0163,  0.0924])\n",
      "Epoch 1842, Loss 8.726349\n",
      "Params: tensor([  4.4248, -11.6473])\n",
      "Grad:   tensor([-0.0163,  0.0923])\n",
      "Epoch 1843, Loss 8.726261\n",
      "Params: tensor([  4.4250, -11.6482])\n",
      "Grad:   tensor([-0.0163,  0.0921])\n",
      "Epoch 1844, Loss 8.726171\n",
      "Params: tensor([  4.4252, -11.6491])\n",
      "Grad:   tensor([-0.0163,  0.0919])\n",
      "Epoch 1845, Loss 8.726086\n",
      "Params: tensor([  4.4253, -11.6500])\n",
      "Grad:   tensor([-0.0162,  0.0918])\n",
      "Epoch 1846, Loss 8.725999\n",
      "Params: tensor([  4.4255, -11.6509])\n",
      "Grad:   tensor([-0.0162,  0.0916])\n",
      "Epoch 1847, Loss 8.725913\n",
      "Params: tensor([  4.4256, -11.6519])\n",
      "Grad:   tensor([-0.0162,  0.0915])\n",
      "Epoch 1848, Loss 8.725826\n",
      "Params: tensor([  4.4258, -11.6528])\n",
      "Grad:   tensor([-0.0161,  0.0913])\n",
      "Epoch 1849, Loss 8.725739\n",
      "Params: tensor([  4.4260, -11.6537])\n",
      "Grad:   tensor([-0.0161,  0.0912])\n",
      "Epoch 1850, Loss 8.725655\n",
      "Params: tensor([  4.4261, -11.6546])\n",
      "Grad:   tensor([-0.0161,  0.0910])\n",
      "Epoch 1851, Loss 8.725570\n",
      "Params: tensor([  4.4263, -11.6555])\n",
      "Grad:   tensor([-0.0160,  0.0909])\n",
      "Epoch 1852, Loss 8.725484\n",
      "Params: tensor([  4.4264, -11.6564])\n",
      "Grad:   tensor([-0.0160,  0.0907])\n",
      "Epoch 1853, Loss 8.725400\n",
      "Params: tensor([  4.4266, -11.6573])\n",
      "Grad:   tensor([-0.0160,  0.0905])\n",
      "Epoch 1854, Loss 8.725314\n",
      "Params: tensor([  4.4268, -11.6582])\n",
      "Grad:   tensor([-0.0160,  0.0904])\n",
      "Epoch 1855, Loss 8.725231\n",
      "Params: tensor([  4.4269, -11.6591])\n",
      "Grad:   tensor([-0.0159,  0.0902])\n",
      "Epoch 1856, Loss 8.725146\n",
      "Params: tensor([  4.4271, -11.6600])\n",
      "Grad:   tensor([-0.0159,  0.0901])\n",
      "Epoch 1857, Loss 8.725064\n",
      "Params: tensor([  4.4272, -11.6609])\n",
      "Grad:   tensor([-0.0159,  0.0899])\n",
      "Epoch 1858, Loss 8.724978\n",
      "Params: tensor([  4.4274, -11.6618])\n",
      "Grad:   tensor([-0.0159,  0.0898])\n",
      "Epoch 1859, Loss 8.724896\n",
      "Params: tensor([  4.4276, -11.6627])\n",
      "Grad:   tensor([-0.0158,  0.0896])\n",
      "Epoch 1860, Loss 8.724816\n",
      "Params: tensor([  4.4277, -11.6636])\n",
      "Grad:   tensor([-0.0158,  0.0895])\n",
      "Epoch 1861, Loss 8.724731\n",
      "Params: tensor([  4.4279, -11.6645])\n",
      "Grad:   tensor([-0.0158,  0.0893])\n",
      "Epoch 1862, Loss 8.724649\n",
      "Params: tensor([  4.4280, -11.6654])\n",
      "Grad:   tensor([-0.0158,  0.0892])\n",
      "Epoch 1863, Loss 8.724569\n",
      "Params: tensor([  4.4282, -11.6663])\n",
      "Grad:   tensor([-0.0157,  0.0890])\n",
      "Epoch 1864, Loss 8.724486\n",
      "Params: tensor([  4.4283, -11.6672])\n",
      "Grad:   tensor([-0.0157,  0.0889])\n",
      "Epoch 1865, Loss 8.724401\n",
      "Params: tensor([  4.4285, -11.6681])\n",
      "Grad:   tensor([-0.0157,  0.0887])\n",
      "Epoch 1866, Loss 8.724325\n",
      "Params: tensor([  4.4287, -11.6689])\n",
      "Grad:   tensor([-0.0156,  0.0886])\n",
      "Epoch 1867, Loss 8.724243\n",
      "Params: tensor([  4.4288, -11.6698])\n",
      "Grad:   tensor([-0.0156,  0.0884])\n",
      "Epoch 1868, Loss 8.724163\n",
      "Params: tensor([  4.4290, -11.6707])\n",
      "Grad:   tensor([-0.0156,  0.0883])\n",
      "Epoch 1869, Loss 8.724082\n",
      "Params: tensor([  4.4291, -11.6716])\n",
      "Grad:   tensor([-0.0156,  0.0881])\n",
      "Epoch 1870, Loss 8.724002\n",
      "Params: tensor([  4.4293, -11.6725])\n",
      "Grad:   tensor([-0.0155,  0.0880])\n",
      "Epoch 1871, Loss 8.723924\n",
      "Params: tensor([  4.4294, -11.6734])\n",
      "Grad:   tensor([-0.0155,  0.0878])\n",
      "Epoch 1872, Loss 8.723841\n",
      "Params: tensor([  4.4296, -11.6742])\n",
      "Grad:   tensor([-0.0155,  0.0877])\n",
      "Epoch 1873, Loss 8.723763\n",
      "Params: tensor([  4.4297, -11.6751])\n",
      "Grad:   tensor([-0.0155,  0.0875])\n",
      "Epoch 1874, Loss 8.723684\n",
      "Params: tensor([  4.4299, -11.6760])\n",
      "Grad:   tensor([-0.0154,  0.0874])\n",
      "Epoch 1875, Loss 8.723605\n",
      "Params: tensor([  4.4301, -11.6769])\n",
      "Grad:   tensor([-0.0154,  0.0872])\n",
      "Epoch 1876, Loss 8.723527\n",
      "Params: tensor([  4.4302, -11.6777])\n",
      "Grad:   tensor([-0.0154,  0.0871])\n",
      "Epoch 1877, Loss 8.723451\n",
      "Params: tensor([  4.4304, -11.6786])\n",
      "Grad:   tensor([-0.0153,  0.0869])\n",
      "Epoch 1878, Loss 8.723372\n",
      "Params: tensor([  4.4305, -11.6795])\n",
      "Grad:   tensor([-0.0153,  0.0868])\n",
      "Epoch 1879, Loss 8.723295\n",
      "Params: tensor([  4.4307, -11.6803])\n",
      "Grad:   tensor([-0.0153,  0.0866])\n",
      "Epoch 1880, Loss 8.723218\n",
      "Params: tensor([  4.4308, -11.6812])\n",
      "Grad:   tensor([-0.0153,  0.0865])\n",
      "Epoch 1881, Loss 8.723141\n",
      "Params: tensor([  4.4310, -11.6821])\n",
      "Grad:   tensor([-0.0152,  0.0863])\n",
      "Epoch 1882, Loss 8.723062\n",
      "Params: tensor([  4.4311, -11.6829])\n",
      "Grad:   tensor([-0.0152,  0.0862])\n",
      "Epoch 1883, Loss 8.722986\n",
      "Params: tensor([  4.4313, -11.6838])\n",
      "Grad:   tensor([-0.0152,  0.0860])\n",
      "Epoch 1884, Loss 8.722909\n",
      "Params: tensor([  4.4314, -11.6846])\n",
      "Grad:   tensor([-0.0152,  0.0859])\n",
      "Epoch 1885, Loss 8.722836\n",
      "Params: tensor([  4.4316, -11.6855])\n",
      "Grad:   tensor([-0.0151,  0.0858])\n",
      "Epoch 1886, Loss 8.722756\n",
      "Params: tensor([  4.4317, -11.6864])\n",
      "Grad:   tensor([-0.0151,  0.0856])\n",
      "Epoch 1887, Loss 8.722685\n",
      "Params: tensor([  4.4319, -11.6872])\n",
      "Grad:   tensor([-0.0151,  0.0855])\n",
      "Epoch 1888, Loss 8.722607\n",
      "Params: tensor([  4.4320, -11.6881])\n",
      "Grad:   tensor([-0.0151,  0.0853])\n",
      "Epoch 1889, Loss 8.722533\n",
      "Params: tensor([  4.4322, -11.6889])\n",
      "Grad:   tensor([-0.0150,  0.0852])\n",
      "Epoch 1890, Loss 8.722457\n",
      "Params: tensor([  4.4323, -11.6898])\n",
      "Grad:   tensor([-0.0150,  0.0850])\n",
      "Epoch 1891, Loss 8.722384\n",
      "Params: tensor([  4.4325, -11.6906])\n",
      "Grad:   tensor([-0.0150,  0.0849])\n",
      "Epoch 1892, Loss 8.722308\n",
      "Params: tensor([  4.4326, -11.6915])\n",
      "Grad:   tensor([-0.0150,  0.0847])\n",
      "Epoch 1893, Loss 8.722237\n",
      "Params: tensor([  4.4328, -11.6923])\n",
      "Grad:   tensor([-0.0149,  0.0846])\n",
      "Epoch 1894, Loss 8.722158\n",
      "Params: tensor([  4.4329, -11.6931])\n",
      "Grad:   tensor([-0.0149,  0.0845])\n",
      "Epoch 1895, Loss 8.722088\n",
      "Params: tensor([  4.4331, -11.6940])\n",
      "Grad:   tensor([-0.0149,  0.0843])\n",
      "Epoch 1896, Loss 8.722013\n",
      "Params: tensor([  4.4332, -11.6948])\n",
      "Grad:   tensor([-0.0149,  0.0842])\n",
      "Epoch 1897, Loss 8.721940\n",
      "Params: tensor([  4.4334, -11.6957])\n",
      "Grad:   tensor([-0.0149,  0.0840])\n",
      "Epoch 1898, Loss 8.721869\n",
      "Params: tensor([  4.4335, -11.6965])\n",
      "Grad:   tensor([-0.0148,  0.0839])\n",
      "Epoch 1899, Loss 8.721797\n",
      "Params: tensor([  4.4337, -11.6974])\n",
      "Grad:   tensor([-0.0148,  0.0837])\n",
      "Epoch 1900, Loss 8.721723\n",
      "Params: tensor([  4.4338, -11.6982])\n",
      "Grad:   tensor([-0.0148,  0.0836])\n",
      "Epoch 1901, Loss 8.721652\n",
      "Params: tensor([  4.4340, -11.6990])\n",
      "Grad:   tensor([-0.0147,  0.0835])\n",
      "Epoch 1902, Loss 8.721579\n",
      "Params: tensor([  4.4341, -11.6999])\n",
      "Grad:   tensor([-0.0147,  0.0833])\n",
      "Epoch 1903, Loss 8.721510\n",
      "Params: tensor([  4.4343, -11.7007])\n",
      "Grad:   tensor([-0.0147,  0.0832])\n",
      "Epoch 1904, Loss 8.721438\n",
      "Params: tensor([  4.4344, -11.7015])\n",
      "Grad:   tensor([-0.0147,  0.0830])\n",
      "Epoch 1905, Loss 8.721365\n",
      "Params: tensor([  4.4346, -11.7023])\n",
      "Grad:   tensor([-0.0146,  0.0829])\n",
      "Epoch 1906, Loss 8.721294\n",
      "Params: tensor([  4.4347, -11.7032])\n",
      "Grad:   tensor([-0.0146,  0.0827])\n",
      "Epoch 1907, Loss 8.721227\n",
      "Params: tensor([  4.4348, -11.7040])\n",
      "Grad:   tensor([-0.0146,  0.0826])\n",
      "Epoch 1908, Loss 8.721151\n",
      "Params: tensor([  4.4350, -11.7048])\n",
      "Grad:   tensor([-0.0146,  0.0825])\n",
      "Epoch 1909, Loss 8.721084\n",
      "Params: tensor([  4.4351, -11.7056])\n",
      "Grad:   tensor([-0.0146,  0.0823])\n",
      "Epoch 1910, Loss 8.721015\n",
      "Params: tensor([  4.4353, -11.7065])\n",
      "Grad:   tensor([-0.0145,  0.0822])\n",
      "Epoch 1911, Loss 8.720946\n",
      "Params: tensor([  4.4354, -11.7073])\n",
      "Grad:   tensor([-0.0145,  0.0820])\n",
      "Epoch 1912, Loss 8.720877\n",
      "Params: tensor([  4.4356, -11.7081])\n",
      "Grad:   tensor([-0.0145,  0.0819])\n",
      "Epoch 1913, Loss 8.720805\n",
      "Params: tensor([  4.4357, -11.7089])\n",
      "Grad:   tensor([-0.0145,  0.0818])\n",
      "Epoch 1914, Loss 8.720738\n",
      "Params: tensor([  4.4359, -11.7097])\n",
      "Grad:   tensor([-0.0144,  0.0816])\n",
      "Epoch 1915, Loss 8.720669\n",
      "Params: tensor([  4.4360, -11.7106])\n",
      "Grad:   tensor([-0.0144,  0.0815])\n",
      "Epoch 1916, Loss 8.720602\n",
      "Params: tensor([  4.4361, -11.7114])\n",
      "Grad:   tensor([-0.0144,  0.0814])\n",
      "Epoch 1917, Loss 8.720535\n",
      "Params: tensor([  4.4363, -11.7122])\n",
      "Grad:   tensor([-0.0144,  0.0812])\n",
      "Epoch 1918, Loss 8.720466\n",
      "Params: tensor([  4.4364, -11.7130])\n",
      "Grad:   tensor([-0.0143,  0.0811])\n",
      "Epoch 1919, Loss 8.720397\n",
      "Params: tensor([  4.4366, -11.7138])\n",
      "Grad:   tensor([-0.0143,  0.0809])\n",
      "Epoch 1920, Loss 8.720329\n",
      "Params: tensor([  4.4367, -11.7146])\n",
      "Grad:   tensor([-0.0143,  0.0808])\n",
      "Epoch 1921, Loss 8.720262\n",
      "Params: tensor([  4.4369, -11.7154])\n",
      "Grad:   tensor([-0.0142,  0.0807])\n",
      "Epoch 1922, Loss 8.720196\n",
      "Params: tensor([  4.4370, -11.7162])\n",
      "Grad:   tensor([-0.0142,  0.0805])\n",
      "Epoch 1923, Loss 8.720129\n",
      "Params: tensor([  4.4371, -11.7170])\n",
      "Grad:   tensor([-0.0142,  0.0804])\n",
      "Epoch 1924, Loss 8.720061\n",
      "Params: tensor([  4.4373, -11.7178])\n",
      "Grad:   tensor([-0.0142,  0.0803])\n",
      "Epoch 1925, Loss 8.719995\n",
      "Params: tensor([  4.4374, -11.7186])\n",
      "Grad:   tensor([-0.0142,  0.0801])\n",
      "Epoch 1926, Loss 8.719931\n",
      "Params: tensor([  4.4376, -11.7194])\n",
      "Grad:   tensor([-0.0141,  0.0800])\n",
      "Epoch 1927, Loss 8.719865\n",
      "Params: tensor([  4.4377, -11.7202])\n",
      "Grad:   tensor([-0.0141,  0.0798])\n",
      "Epoch 1928, Loss 8.719797\n",
      "Params: tensor([  4.4379, -11.7210])\n",
      "Grad:   tensor([-0.0141,  0.0797])\n",
      "Epoch 1929, Loss 8.719733\n",
      "Params: tensor([  4.4380, -11.7218])\n",
      "Grad:   tensor([-0.0141,  0.0796])\n",
      "Epoch 1930, Loss 8.719668\n",
      "Params: tensor([  4.4381, -11.7226])\n",
      "Grad:   tensor([-0.0140,  0.0794])\n",
      "Epoch 1931, Loss 8.719604\n",
      "Params: tensor([  4.4383, -11.7234])\n",
      "Grad:   tensor([-0.0140,  0.0793])\n",
      "Epoch 1932, Loss 8.719539\n",
      "Params: tensor([  4.4384, -11.7242])\n",
      "Grad:   tensor([-0.0140,  0.0792])\n",
      "Epoch 1933, Loss 8.719473\n",
      "Params: tensor([  4.4386, -11.7250])\n",
      "Grad:   tensor([-0.0139,  0.0790])\n",
      "Epoch 1934, Loss 8.719409\n",
      "Params: tensor([  4.4387, -11.7258])\n",
      "Grad:   tensor([-0.0139,  0.0789])\n",
      "Epoch 1935, Loss 8.719344\n",
      "Params: tensor([  4.4388, -11.7266])\n",
      "Grad:   tensor([-0.0139,  0.0788])\n",
      "Epoch 1936, Loss 8.719280\n",
      "Params: tensor([  4.4390, -11.7274])\n",
      "Grad:   tensor([-0.0139,  0.0786])\n",
      "Epoch 1937, Loss 8.719216\n",
      "Params: tensor([  4.4391, -11.7281])\n",
      "Grad:   tensor([-0.0139,  0.0785])\n",
      "Epoch 1938, Loss 8.719152\n",
      "Params: tensor([  4.4392, -11.7289])\n",
      "Grad:   tensor([-0.0138,  0.0784])\n",
      "Epoch 1939, Loss 8.719087\n",
      "Params: tensor([  4.4394, -11.7297])\n",
      "Grad:   tensor([-0.0138,  0.0782])\n",
      "Epoch 1940, Loss 8.719025\n",
      "Params: tensor([  4.4395, -11.7305])\n",
      "Grad:   tensor([-0.0138,  0.0781])\n",
      "Epoch 1941, Loss 8.718963\n",
      "Params: tensor([  4.4397, -11.7313])\n",
      "Grad:   tensor([-0.0138,  0.0780])\n",
      "Epoch 1942, Loss 8.718900\n",
      "Params: tensor([  4.4398, -11.7320])\n",
      "Grad:   tensor([-0.0137,  0.0778])\n",
      "Epoch 1943, Loss 8.718838\n",
      "Params: tensor([  4.4399, -11.7328])\n",
      "Grad:   tensor([-0.0137,  0.0777])\n",
      "Epoch 1944, Loss 8.718777\n",
      "Params: tensor([  4.4401, -11.7336])\n",
      "Grad:   tensor([-0.0137,  0.0776])\n",
      "Epoch 1945, Loss 8.718714\n",
      "Params: tensor([  4.4402, -11.7344])\n",
      "Grad:   tensor([-0.0137,  0.0774])\n",
      "Epoch 1946, Loss 8.718653\n",
      "Params: tensor([  4.4403, -11.7351])\n",
      "Grad:   tensor([-0.0136,  0.0773])\n",
      "Epoch 1947, Loss 8.718589\n",
      "Params: tensor([  4.4405, -11.7359])\n",
      "Grad:   tensor([-0.0136,  0.0772])\n",
      "Epoch 1948, Loss 8.718531\n",
      "Params: tensor([  4.4406, -11.7367])\n",
      "Grad:   tensor([-0.0136,  0.0770])\n",
      "Epoch 1949, Loss 8.718469\n",
      "Params: tensor([  4.4408, -11.7375])\n",
      "Grad:   tensor([-0.0136,  0.0769])\n",
      "Epoch 1950, Loss 8.718406\n",
      "Params: tensor([  4.4409, -11.7382])\n",
      "Grad:   tensor([-0.0136,  0.0768])\n",
      "Epoch 1951, Loss 8.718345\n",
      "Params: tensor([  4.4410, -11.7390])\n",
      "Grad:   tensor([-0.0135,  0.0767])\n",
      "Epoch 1952, Loss 8.718284\n",
      "Params: tensor([  4.4412, -11.7398])\n",
      "Grad:   tensor([-0.0135,  0.0765])\n",
      "Epoch 1953, Loss 8.718227\n",
      "Params: tensor([  4.4413, -11.7405])\n",
      "Grad:   tensor([-0.0135,  0.0764])\n",
      "Epoch 1954, Loss 8.718166\n",
      "Params: tensor([  4.4414, -11.7413])\n",
      "Grad:   tensor([-0.0135,  0.0763])\n",
      "Epoch 1955, Loss 8.718105\n",
      "Params: tensor([  4.4416, -11.7420])\n",
      "Grad:   tensor([-0.0135,  0.0761])\n",
      "Epoch 1956, Loss 8.718047\n",
      "Params: tensor([  4.4417, -11.7428])\n",
      "Grad:   tensor([-0.0134,  0.0760])\n",
      "Epoch 1957, Loss 8.717986\n",
      "Params: tensor([  4.4418, -11.7436])\n",
      "Grad:   tensor([-0.0134,  0.0759])\n",
      "Epoch 1958, Loss 8.717926\n",
      "Params: tensor([  4.4420, -11.7443])\n",
      "Grad:   tensor([-0.0134,  0.0757])\n",
      "Epoch 1959, Loss 8.717867\n",
      "Params: tensor([  4.4421, -11.7451])\n",
      "Grad:   tensor([-0.0134,  0.0756])\n",
      "Epoch 1960, Loss 8.717809\n",
      "Params: tensor([  4.4422, -11.7458])\n",
      "Grad:   tensor([-0.0133,  0.0755])\n",
      "Epoch 1961, Loss 8.717751\n",
      "Params: tensor([  4.4424, -11.7466])\n",
      "Grad:   tensor([-0.0133,  0.0754])\n",
      "Epoch 1962, Loss 8.717693\n",
      "Params: tensor([  4.4425, -11.7473])\n",
      "Grad:   tensor([-0.0133,  0.0752])\n",
      "Epoch 1963, Loss 8.717633\n",
      "Params: tensor([  4.4426, -11.7481])\n",
      "Grad:   tensor([-0.0133,  0.0751])\n",
      "Epoch 1964, Loss 8.717572\n",
      "Params: tensor([  4.4428, -11.7488])\n",
      "Grad:   tensor([-0.0132,  0.0750])\n",
      "Epoch 1965, Loss 8.717520\n",
      "Params: tensor([  4.4429, -11.7496])\n",
      "Grad:   tensor([-0.0132,  0.0749])\n",
      "Epoch 1966, Loss 8.717458\n",
      "Params: tensor([  4.4430, -11.7503])\n",
      "Grad:   tensor([-0.0132,  0.0747])\n",
      "Epoch 1967, Loss 8.717403\n",
      "Params: tensor([  4.4432, -11.7511])\n",
      "Grad:   tensor([-0.0132,  0.0746])\n",
      "Epoch 1968, Loss 8.717343\n",
      "Params: tensor([  4.4433, -11.7518])\n",
      "Grad:   tensor([-0.0132,  0.0745])\n",
      "Epoch 1969, Loss 8.717289\n",
      "Params: tensor([  4.4434, -11.7526])\n",
      "Grad:   tensor([-0.0131,  0.0743])\n",
      "Epoch 1970, Loss 8.717231\n",
      "Params: tensor([  4.4436, -11.7533])\n",
      "Grad:   tensor([-0.0131,  0.0742])\n",
      "Epoch 1971, Loss 8.717170\n",
      "Params: tensor([  4.4437, -11.7541])\n",
      "Grad:   tensor([-0.0131,  0.0741])\n",
      "Epoch 1972, Loss 8.717116\n",
      "Params: tensor([  4.4438, -11.7548])\n",
      "Grad:   tensor([-0.0131,  0.0740])\n",
      "Epoch 1973, Loss 8.717060\n",
      "Params: tensor([  4.4439, -11.7555])\n",
      "Grad:   tensor([-0.0131,  0.0738])\n",
      "Epoch 1974, Loss 8.717005\n",
      "Params: tensor([  4.4441, -11.7563])\n",
      "Grad:   tensor([-0.0130,  0.0737])\n",
      "Epoch 1975, Loss 8.716949\n",
      "Params: tensor([  4.4442, -11.7570])\n",
      "Grad:   tensor([-0.0130,  0.0736])\n",
      "Epoch 1976, Loss 8.716892\n",
      "Params: tensor([  4.4443, -11.7577])\n",
      "Grad:   tensor([-0.0130,  0.0735])\n",
      "Epoch 1977, Loss 8.716840\n",
      "Params: tensor([  4.4445, -11.7585])\n",
      "Grad:   tensor([-0.0130,  0.0733])\n",
      "Epoch 1978, Loss 8.716781\n",
      "Params: tensor([  4.4446, -11.7592])\n",
      "Grad:   tensor([-0.0129,  0.0732])\n",
      "Epoch 1979, Loss 8.716727\n",
      "Params: tensor([  4.4447, -11.7599])\n",
      "Grad:   tensor([-0.0129,  0.0731])\n",
      "Epoch 1980, Loss 8.716671\n",
      "Params: tensor([  4.4449, -11.7607])\n",
      "Grad:   tensor([-0.0129,  0.0730])\n",
      "Epoch 1981, Loss 8.716618\n",
      "Params: tensor([  4.4450, -11.7614])\n",
      "Grad:   tensor([-0.0129,  0.0728])\n",
      "Epoch 1982, Loss 8.716561\n",
      "Params: tensor([  4.4451, -11.7621])\n",
      "Grad:   tensor([-0.0128,  0.0727])\n",
      "Epoch 1983, Loss 8.716508\n",
      "Params: tensor([  4.4452, -11.7628])\n",
      "Grad:   tensor([-0.0128,  0.0726])\n",
      "Epoch 1984, Loss 8.716455\n",
      "Params: tensor([  4.4454, -11.7636])\n",
      "Grad:   tensor([-0.0128,  0.0725])\n",
      "Epoch 1985, Loss 8.716400\n",
      "Params: tensor([  4.4455, -11.7643])\n",
      "Grad:   tensor([-0.0128,  0.0723])\n",
      "Epoch 1986, Loss 8.716346\n",
      "Params: tensor([  4.4456, -11.7650])\n",
      "Grad:   tensor([-0.0128,  0.0722])\n",
      "Epoch 1987, Loss 8.716293\n",
      "Params: tensor([  4.4458, -11.7657])\n",
      "Grad:   tensor([-0.0127,  0.0721])\n",
      "Epoch 1988, Loss 8.716238\n",
      "Params: tensor([  4.4459, -11.7665])\n",
      "Grad:   tensor([-0.0127,  0.0720])\n",
      "Epoch 1989, Loss 8.716185\n",
      "Params: tensor([  4.4460, -11.7672])\n",
      "Grad:   tensor([-0.0127,  0.0719])\n",
      "Epoch 1990, Loss 8.716134\n",
      "Params: tensor([  4.4461, -11.7679])\n",
      "Grad:   tensor([-0.0127,  0.0717])\n",
      "Epoch 1991, Loss 8.716077\n",
      "Params: tensor([  4.4463, -11.7686])\n",
      "Grad:   tensor([-0.0126,  0.0716])\n",
      "Epoch 1992, Loss 8.716025\n",
      "Params: tensor([  4.4464, -11.7693])\n",
      "Grad:   tensor([-0.0126,  0.0715])\n",
      "Epoch 1993, Loss 8.715973\n",
      "Params: tensor([  4.4465, -11.7700])\n",
      "Grad:   tensor([-0.0126,  0.0714])\n",
      "Epoch 1994, Loss 8.715919\n",
      "Params: tensor([  4.4466, -11.7708])\n",
      "Grad:   tensor([-0.0126,  0.0713])\n",
      "Epoch 1995, Loss 8.715870\n",
      "Params: tensor([  4.4468, -11.7715])\n",
      "Grad:   tensor([-0.0125,  0.0711])\n",
      "Epoch 1996, Loss 8.715815\n",
      "Params: tensor([  4.4469, -11.7722])\n",
      "Grad:   tensor([-0.0125,  0.0710])\n",
      "Epoch 1997, Loss 8.715766\n",
      "Params: tensor([  4.4470, -11.7729])\n",
      "Grad:   tensor([-0.0125,  0.0709])\n",
      "Epoch 1998, Loss 8.715711\n",
      "Params: tensor([  4.4471, -11.7736])\n",
      "Grad:   tensor([-0.0125,  0.0708])\n",
      "Epoch 1999, Loss 8.715661\n",
      "Params: tensor([  4.4473, -11.7743])\n",
      "Grad:   tensor([-0.0125,  0.0706])\n",
      "Epoch 2000, Loss 8.715611\n",
      "Params: tensor([  4.4474, -11.7750])\n",
      "Grad:   tensor([-0.0124,  0.0705])\n",
      "Epoch 2001, Loss 8.715558\n",
      "Params: tensor([  4.4475, -11.7757])\n",
      "Grad:   tensor([-0.0124,  0.0704])\n",
      "Epoch 2002, Loss 8.715506\n",
      "Params: tensor([  4.4476, -11.7764])\n",
      "Grad:   tensor([-0.0124,  0.0703])\n",
      "Epoch 2003, Loss 8.715455\n",
      "Params: tensor([  4.4478, -11.7771])\n",
      "Grad:   tensor([-0.0124,  0.0702])\n",
      "Epoch 2004, Loss 8.715405\n",
      "Params: tensor([  4.4479, -11.7778])\n",
      "Grad:   tensor([-0.0124,  0.0700])\n",
      "Epoch 2005, Loss 8.715354\n",
      "Params: tensor([  4.4480, -11.7785])\n",
      "Grad:   tensor([-0.0123,  0.0699])\n",
      "Epoch 2006, Loss 8.715304\n",
      "Params: tensor([  4.4481, -11.7792])\n",
      "Grad:   tensor([-0.0123,  0.0698])\n",
      "Epoch 2007, Loss 8.715256\n",
      "Params: tensor([  4.4483, -11.7799])\n",
      "Grad:   tensor([-0.0123,  0.0697])\n",
      "Epoch 2008, Loss 8.715204\n",
      "Params: tensor([  4.4484, -11.7806])\n",
      "Grad:   tensor([-0.0123,  0.0696])\n",
      "Epoch 2009, Loss 8.715154\n",
      "Params: tensor([  4.4485, -11.7813])\n",
      "Grad:   tensor([-0.0123,  0.0695])\n",
      "Epoch 2010, Loss 8.715103\n",
      "Params: tensor([  4.4486, -11.7820])\n",
      "Grad:   tensor([-0.0122,  0.0693])\n",
      "Epoch 2011, Loss 8.715055\n",
      "Params: tensor([  4.4487, -11.7827])\n",
      "Grad:   tensor([-0.0122,  0.0692])\n",
      "Epoch 2012, Loss 8.715005\n",
      "Params: tensor([  4.4489, -11.7834])\n",
      "Grad:   tensor([-0.0122,  0.0691])\n",
      "Epoch 2013, Loss 8.714956\n",
      "Params: tensor([  4.4490, -11.7841])\n",
      "Grad:   tensor([-0.0122,  0.0690])\n",
      "Epoch 2014, Loss 8.714909\n",
      "Params: tensor([  4.4491, -11.7847])\n",
      "Grad:   tensor([-0.0122,  0.0689])\n",
      "Epoch 2015, Loss 8.714858\n",
      "Params: tensor([  4.4492, -11.7854])\n",
      "Grad:   tensor([-0.0121,  0.0687])\n",
      "Epoch 2016, Loss 8.714810\n",
      "Params: tensor([  4.4494, -11.7861])\n",
      "Grad:   tensor([-0.0121,  0.0686])\n",
      "Epoch 2017, Loss 8.714761\n",
      "Params: tensor([  4.4495, -11.7868])\n",
      "Grad:   tensor([-0.0121,  0.0685])\n",
      "Epoch 2018, Loss 8.714713\n",
      "Params: tensor([  4.4496, -11.7875])\n",
      "Grad:   tensor([-0.0121,  0.0684])\n",
      "Epoch 2019, Loss 8.714664\n",
      "Params: tensor([  4.4497, -11.7882])\n",
      "Grad:   tensor([-0.0121,  0.0683])\n",
      "Epoch 2020, Loss 8.714618\n",
      "Params: tensor([  4.4498, -11.7889])\n",
      "Grad:   tensor([-0.0120,  0.0682])\n",
      "Epoch 2021, Loss 8.714569\n",
      "Params: tensor([  4.4500, -11.7895])\n",
      "Grad:   tensor([-0.0120,  0.0681])\n",
      "Epoch 2022, Loss 8.714520\n",
      "Params: tensor([  4.4501, -11.7902])\n",
      "Grad:   tensor([-0.0120,  0.0679])\n",
      "Epoch 2023, Loss 8.714475\n",
      "Params: tensor([  4.4502, -11.7909])\n",
      "Grad:   tensor([-0.0120,  0.0678])\n",
      "Epoch 2024, Loss 8.714425\n",
      "Params: tensor([  4.4503, -11.7916])\n",
      "Grad:   tensor([-0.0120,  0.0677])\n",
      "Epoch 2025, Loss 8.714380\n",
      "Params: tensor([  4.4504, -11.7922])\n",
      "Grad:   tensor([-0.0119,  0.0676])\n",
      "Epoch 2026, Loss 8.714332\n",
      "Params: tensor([  4.4506, -11.7929])\n",
      "Grad:   tensor([-0.0119,  0.0675])\n",
      "Epoch 2027, Loss 8.714284\n",
      "Params: tensor([  4.4507, -11.7936])\n",
      "Grad:   tensor([-0.0119,  0.0674])\n",
      "Epoch 2028, Loss 8.714237\n",
      "Params: tensor([  4.4508, -11.7943])\n",
      "Grad:   tensor([-0.0119,  0.0672])\n",
      "Epoch 2029, Loss 8.714191\n",
      "Params: tensor([  4.4509, -11.7949])\n",
      "Grad:   tensor([-0.0119,  0.0671])\n",
      "Epoch 2030, Loss 8.714145\n",
      "Params: tensor([  4.4510, -11.7956])\n",
      "Grad:   tensor([-0.0118,  0.0670])\n",
      "Epoch 2031, Loss 8.714097\n",
      "Params: tensor([  4.4511, -11.7963])\n",
      "Grad:   tensor([-0.0118,  0.0669])\n",
      "Epoch 2032, Loss 8.714051\n",
      "Params: tensor([  4.4513, -11.7969])\n",
      "Grad:   tensor([-0.0118,  0.0668])\n",
      "Epoch 2033, Loss 8.714005\n",
      "Params: tensor([  4.4514, -11.7976])\n",
      "Grad:   tensor([-0.0118,  0.0667])\n",
      "Epoch 2034, Loss 8.713963\n",
      "Params: tensor([  4.4515, -11.7983])\n",
      "Grad:   tensor([-0.0118,  0.0666])\n",
      "Epoch 2035, Loss 8.713914\n",
      "Params: tensor([  4.4516, -11.7989])\n",
      "Grad:   tensor([-0.0117,  0.0665])\n",
      "Epoch 2036, Loss 8.713871\n",
      "Params: tensor([  4.4517, -11.7996])\n",
      "Grad:   tensor([-0.0117,  0.0663])\n",
      "Epoch 2037, Loss 8.713824\n",
      "Params: tensor([  4.4519, -11.8003])\n",
      "Grad:   tensor([-0.0117,  0.0662])\n",
      "Epoch 2038, Loss 8.713778\n",
      "Params: tensor([  4.4520, -11.8009])\n",
      "Grad:   tensor([-0.0117,  0.0661])\n",
      "Epoch 2039, Loss 8.713734\n",
      "Params: tensor([  4.4521, -11.8016])\n",
      "Grad:   tensor([-0.0117,  0.0660])\n",
      "Epoch 2040, Loss 8.713691\n",
      "Params: tensor([  4.4522, -11.8022])\n",
      "Grad:   tensor([-0.0116,  0.0659])\n",
      "Epoch 2041, Loss 8.713645\n",
      "Params: tensor([  4.4523, -11.8029])\n",
      "Grad:   tensor([-0.0116,  0.0658])\n",
      "Epoch 2042, Loss 8.713601\n",
      "Params: tensor([  4.4524, -11.8036])\n",
      "Grad:   tensor([-0.0116,  0.0657])\n",
      "Epoch 2043, Loss 8.713555\n",
      "Params: tensor([  4.4526, -11.8042])\n",
      "Grad:   tensor([-0.0116,  0.0656])\n",
      "Epoch 2044, Loss 8.713512\n",
      "Params: tensor([  4.4527, -11.8049])\n",
      "Grad:   tensor([-0.0116,  0.0654])\n",
      "Epoch 2045, Loss 8.713468\n",
      "Params: tensor([  4.4528, -11.8055])\n",
      "Grad:   tensor([-0.0115,  0.0653])\n",
      "Epoch 2046, Loss 8.713422\n",
      "Params: tensor([  4.4529, -11.8062])\n",
      "Grad:   tensor([-0.0115,  0.0652])\n",
      "Epoch 2047, Loss 8.713378\n",
      "Params: tensor([  4.4530, -11.8068])\n",
      "Grad:   tensor([-0.0115,  0.0651])\n",
      "Epoch 2048, Loss 8.713337\n",
      "Params: tensor([  4.4531, -11.8075])\n",
      "Grad:   tensor([-0.0115,  0.0650])\n",
      "Epoch 2049, Loss 8.713291\n",
      "Params: tensor([  4.4532, -11.8081])\n",
      "Grad:   tensor([-0.0115,  0.0649])\n",
      "Epoch 2050, Loss 8.713248\n",
      "Params: tensor([  4.4534, -11.8088])\n",
      "Grad:   tensor([-0.0114,  0.0648])\n",
      "Epoch 2051, Loss 8.713204\n",
      "Params: tensor([  4.4535, -11.8094])\n",
      "Grad:   tensor([-0.0114,  0.0647])\n",
      "Epoch 2052, Loss 8.713162\n",
      "Params: tensor([  4.4536, -11.8101])\n",
      "Grad:   tensor([-0.0114,  0.0646])\n",
      "Epoch 2053, Loss 8.713120\n",
      "Params: tensor([  4.4537, -11.8107])\n",
      "Grad:   tensor([-0.0114,  0.0644])\n",
      "Epoch 2054, Loss 8.713075\n",
      "Params: tensor([  4.4538, -11.8114])\n",
      "Grad:   tensor([-0.0113,  0.0643])\n",
      "Epoch 2055, Loss 8.713036\n",
      "Params: tensor([  4.4539, -11.8120])\n",
      "Grad:   tensor([-0.0113,  0.0642])\n",
      "Epoch 2056, Loss 8.712992\n",
      "Params: tensor([  4.4540, -11.8126])\n",
      "Grad:   tensor([-0.0113,  0.0641])\n",
      "Epoch 2057, Loss 8.712948\n",
      "Params: tensor([  4.4542, -11.8133])\n",
      "Grad:   tensor([-0.0113,  0.0640])\n",
      "Epoch 2058, Loss 8.712907\n",
      "Params: tensor([  4.4543, -11.8139])\n",
      "Grad:   tensor([-0.0113,  0.0639])\n",
      "Epoch 2059, Loss 8.712863\n",
      "Params: tensor([  4.4544, -11.8146])\n",
      "Grad:   tensor([-0.0113,  0.0638])\n",
      "Epoch 2060, Loss 8.712823\n",
      "Params: tensor([  4.4545, -11.8152])\n",
      "Grad:   tensor([-0.0113,  0.0637])\n",
      "Epoch 2061, Loss 8.712781\n",
      "Params: tensor([  4.4546, -11.8158])\n",
      "Grad:   tensor([-0.0112,  0.0636])\n",
      "Epoch 2062, Loss 8.712740\n",
      "Params: tensor([  4.4547, -11.8165])\n",
      "Grad:   tensor([-0.0112,  0.0635])\n",
      "Epoch 2063, Loss 8.712699\n",
      "Params: tensor([  4.4548, -11.8171])\n",
      "Grad:   tensor([-0.0112,  0.0634])\n",
      "Epoch 2064, Loss 8.712655\n",
      "Params: tensor([  4.4549, -11.8177])\n",
      "Grad:   tensor([-0.0112,  0.0633])\n",
      "Epoch 2065, Loss 8.712615\n",
      "Params: tensor([  4.4550, -11.8184])\n",
      "Grad:   tensor([-0.0112,  0.0631])\n",
      "Epoch 2066, Loss 8.712574\n",
      "Params: tensor([  4.4552, -11.8190])\n",
      "Grad:   tensor([-0.0111,  0.0630])\n",
      "Epoch 2067, Loss 8.712534\n",
      "Params: tensor([  4.4553, -11.8196])\n",
      "Grad:   tensor([-0.0111,  0.0629])\n",
      "Epoch 2068, Loss 8.712491\n",
      "Params: tensor([  4.4554, -11.8203])\n",
      "Grad:   tensor([-0.0111,  0.0628])\n",
      "Epoch 2069, Loss 8.712454\n",
      "Params: tensor([  4.4555, -11.8209])\n",
      "Grad:   tensor([-0.0111,  0.0627])\n",
      "Epoch 2070, Loss 8.712411\n",
      "Params: tensor([  4.4556, -11.8215])\n",
      "Grad:   tensor([-0.0111,  0.0626])\n",
      "Epoch 2071, Loss 8.712371\n",
      "Params: tensor([  4.4557, -11.8221])\n",
      "Grad:   tensor([-0.0110,  0.0625])\n",
      "Epoch 2072, Loss 8.712332\n",
      "Params: tensor([  4.4558, -11.8228])\n",
      "Grad:   tensor([-0.0110,  0.0624])\n",
      "Epoch 2073, Loss 8.712292\n",
      "Params: tensor([  4.4559, -11.8234])\n",
      "Grad:   tensor([-0.0110,  0.0623])\n",
      "Epoch 2074, Loss 8.712250\n",
      "Params: tensor([  4.4560, -11.8240])\n",
      "Grad:   tensor([-0.0110,  0.0622])\n",
      "Epoch 2075, Loss 8.712213\n",
      "Params: tensor([  4.4562, -11.8246])\n",
      "Grad:   tensor([-0.0110,  0.0621])\n",
      "Epoch 2076, Loss 8.712172\n",
      "Params: tensor([  4.4563, -11.8252])\n",
      "Grad:   tensor([-0.0109,  0.0620])\n",
      "Epoch 2077, Loss 8.712132\n",
      "Params: tensor([  4.4564, -11.8259])\n",
      "Grad:   tensor([-0.0109,  0.0619])\n",
      "Epoch 2078, Loss 8.712090\n",
      "Params: tensor([  4.4565, -11.8265])\n",
      "Grad:   tensor([-0.0109,  0.0618])\n",
      "Epoch 2079, Loss 8.712054\n",
      "Params: tensor([  4.4566, -11.8271])\n",
      "Grad:   tensor([-0.0109,  0.0617])\n",
      "Epoch 2080, Loss 8.712013\n",
      "Params: tensor([  4.4567, -11.8277])\n",
      "Grad:   tensor([-0.0109,  0.0616])\n",
      "Epoch 2081, Loss 8.711976\n",
      "Params: tensor([  4.4568, -11.8283])\n",
      "Grad:   tensor([-0.0109,  0.0615])\n",
      "Epoch 2082, Loss 8.711936\n",
      "Params: tensor([  4.4569, -11.8289])\n",
      "Grad:   tensor([-0.0108,  0.0613])\n",
      "Epoch 2083, Loss 8.711896\n",
      "Params: tensor([  4.4570, -11.8295])\n",
      "Grad:   tensor([-0.0108,  0.0612])\n",
      "Epoch 2084, Loss 8.711860\n",
      "Params: tensor([  4.4571, -11.8302])\n",
      "Grad:   tensor([-0.0108,  0.0611])\n",
      "Epoch 2085, Loss 8.711819\n",
      "Params: tensor([  4.4572, -11.8308])\n",
      "Grad:   tensor([-0.0108,  0.0610])\n",
      "Epoch 2086, Loss 8.711782\n",
      "Params: tensor([  4.4573, -11.8314])\n",
      "Grad:   tensor([-0.0108,  0.0609])\n",
      "Epoch 2087, Loss 8.711742\n",
      "Params: tensor([  4.4575, -11.8320])\n",
      "Grad:   tensor([-0.0107,  0.0608])\n",
      "Epoch 2088, Loss 8.711704\n",
      "Params: tensor([  4.4576, -11.8326])\n",
      "Grad:   tensor([-0.0107,  0.0607])\n",
      "Epoch 2089, Loss 8.711669\n",
      "Params: tensor([  4.4577, -11.8332])\n",
      "Grad:   tensor([-0.0107,  0.0606])\n",
      "Epoch 2090, Loss 8.711631\n",
      "Params: tensor([  4.4578, -11.8338])\n",
      "Grad:   tensor([-0.0107,  0.0605])\n",
      "Epoch 2091, Loss 8.711589\n",
      "Params: tensor([  4.4579, -11.8344])\n",
      "Grad:   tensor([-0.0107,  0.0604])\n",
      "Epoch 2092, Loss 8.711555\n",
      "Params: tensor([  4.4580, -11.8350])\n",
      "Grad:   tensor([-0.0107,  0.0603])\n",
      "Epoch 2093, Loss 8.711518\n",
      "Params: tensor([  4.4581, -11.8356])\n",
      "Grad:   tensor([-0.0106,  0.0602])\n",
      "Epoch 2094, Loss 8.711479\n",
      "Params: tensor([  4.4582, -11.8362])\n",
      "Grad:   tensor([-0.0106,  0.0601])\n",
      "Epoch 2095, Loss 8.711440\n",
      "Params: tensor([  4.4583, -11.8368])\n",
      "Grad:   tensor([-0.0106,  0.0600])\n",
      "Epoch 2096, Loss 8.711404\n",
      "Params: tensor([  4.4584, -11.8374])\n",
      "Grad:   tensor([-0.0106,  0.0599])\n",
      "Epoch 2097, Loss 8.711369\n",
      "Params: tensor([  4.4585, -11.8380])\n",
      "Grad:   tensor([-0.0106,  0.0598])\n",
      "Epoch 2098, Loss 8.711329\n",
      "Params: tensor([  4.4586, -11.8386])\n",
      "Grad:   tensor([-0.0105,  0.0597])\n",
      "Epoch 2099, Loss 8.711292\n",
      "Params: tensor([  4.4587, -11.8392])\n",
      "Grad:   tensor([-0.0105,  0.0596])\n",
      "Epoch 2100, Loss 8.711259\n",
      "Params: tensor([  4.4588, -11.8398])\n",
      "Grad:   tensor([-0.0105,  0.0595])\n",
      "Epoch 2101, Loss 8.711224\n",
      "Params: tensor([  4.4589, -11.8404])\n",
      "Grad:   tensor([-0.0105,  0.0594])\n",
      "Epoch 2102, Loss 8.711185\n",
      "Params: tensor([  4.4590, -11.8410])\n",
      "Grad:   tensor([-0.0105,  0.0593])\n",
      "Epoch 2103, Loss 8.711148\n",
      "Params: tensor([  4.4592, -11.8416])\n",
      "Grad:   tensor([-0.0105,  0.0592])\n",
      "Epoch 2104, Loss 8.711113\n",
      "Params: tensor([  4.4593, -11.8422])\n",
      "Grad:   tensor([-0.0104,  0.0591])\n",
      "Epoch 2105, Loss 8.711079\n",
      "Params: tensor([  4.4594, -11.8428])\n",
      "Grad:   tensor([-0.0104,  0.0590])\n",
      "Epoch 2106, Loss 8.711041\n",
      "Params: tensor([  4.4595, -11.8434])\n",
      "Grad:   tensor([-0.0104,  0.0589])\n",
      "Epoch 2107, Loss 8.711003\n",
      "Params: tensor([  4.4596, -11.8439])\n",
      "Grad:   tensor([-0.0104,  0.0588])\n",
      "Epoch 2108, Loss 8.710969\n",
      "Params: tensor([  4.4597, -11.8445])\n",
      "Grad:   tensor([-0.0104,  0.0587])\n",
      "Epoch 2109, Loss 8.710934\n",
      "Params: tensor([  4.4598, -11.8451])\n",
      "Grad:   tensor([-0.0104,  0.0586])\n",
      "Epoch 2110, Loss 8.710898\n",
      "Params: tensor([  4.4599, -11.8457])\n",
      "Grad:   tensor([-0.0103,  0.0585])\n",
      "Epoch 2111, Loss 8.710864\n",
      "Params: tensor([  4.4600, -11.8463])\n",
      "Grad:   tensor([-0.0103,  0.0584])\n",
      "Epoch 2112, Loss 8.710829\n",
      "Params: tensor([  4.4601, -11.8469])\n",
      "Grad:   tensor([-0.0103,  0.0583])\n",
      "Epoch 2113, Loss 8.710793\n",
      "Params: tensor([  4.4602, -11.8474])\n",
      "Grad:   tensor([-0.0103,  0.0582])\n",
      "Epoch 2114, Loss 8.710757\n",
      "Params: tensor([  4.4603, -11.8480])\n",
      "Grad:   tensor([-0.0103,  0.0581])\n",
      "Epoch 2115, Loss 8.710724\n",
      "Params: tensor([  4.4604, -11.8486])\n",
      "Grad:   tensor([-0.0103,  0.0580])\n",
      "Epoch 2116, Loss 8.710688\n",
      "Params: tensor([  4.4605, -11.8492])\n",
      "Grad:   tensor([-0.0102,  0.0579])\n",
      "Epoch 2117, Loss 8.710653\n",
      "Params: tensor([  4.4606, -11.8498])\n",
      "Grad:   tensor([-0.0102,  0.0578])\n",
      "Epoch 2118, Loss 8.710620\n",
      "Params: tensor([  4.4607, -11.8503])\n",
      "Grad:   tensor([-0.0102,  0.0577])\n",
      "Epoch 2119, Loss 8.710584\n",
      "Params: tensor([  4.4608, -11.8509])\n",
      "Grad:   tensor([-0.0102,  0.0576])\n",
      "Epoch 2120, Loss 8.710552\n",
      "Params: tensor([  4.4609, -11.8515])\n",
      "Grad:   tensor([-0.0102,  0.0575])\n",
      "Epoch 2121, Loss 8.710520\n",
      "Params: tensor([  4.4610, -11.8521])\n",
      "Grad:   tensor([-0.0102,  0.0574])\n",
      "Epoch 2122, Loss 8.710484\n",
      "Params: tensor([  4.4611, -11.8526])\n",
      "Grad:   tensor([-0.0101,  0.0573])\n",
      "Epoch 2123, Loss 8.710450\n",
      "Params: tensor([  4.4612, -11.8532])\n",
      "Grad:   tensor([-0.0101,  0.0572])\n",
      "Epoch 2124, Loss 8.710418\n",
      "Params: tensor([  4.4613, -11.8538])\n",
      "Grad:   tensor([-0.0101,  0.0571])\n",
      "Epoch 2125, Loss 8.710382\n",
      "Params: tensor([  4.4614, -11.8544])\n",
      "Grad:   tensor([-0.0101,  0.0570])\n",
      "Epoch 2126, Loss 8.710349\n",
      "Params: tensor([  4.4615, -11.8549])\n",
      "Grad:   tensor([-0.0101,  0.0569])\n",
      "Epoch 2127, Loss 8.710315\n",
      "Params: tensor([  4.4616, -11.8555])\n",
      "Grad:   tensor([-0.0100,  0.0568])\n",
      "Epoch 2128, Loss 8.710282\n",
      "Params: tensor([  4.4617, -11.8561])\n",
      "Grad:   tensor([-0.0100,  0.0567])\n",
      "Epoch 2129, Loss 8.710248\n",
      "Params: tensor([  4.4618, -11.8566])\n",
      "Grad:   tensor([-0.0100,  0.0566])\n",
      "Epoch 2130, Loss 8.710217\n",
      "Params: tensor([  4.4619, -11.8572])\n",
      "Grad:   tensor([-0.0100,  0.0565])\n",
      "Epoch 2131, Loss 8.710185\n",
      "Params: tensor([  4.4620, -11.8578])\n",
      "Grad:   tensor([-0.0100,  0.0564])\n",
      "Epoch 2132, Loss 8.710151\n",
      "Params: tensor([  4.4621, -11.8583])\n",
      "Grad:   tensor([-0.0100,  0.0563])\n",
      "Epoch 2133, Loss 8.710118\n",
      "Params: tensor([  4.4622, -11.8589])\n",
      "Grad:   tensor([-0.0099,  0.0563])\n",
      "Epoch 2134, Loss 8.710086\n",
      "Params: tensor([  4.4623, -11.8594])\n",
      "Grad:   tensor([-0.0099,  0.0562])\n",
      "Epoch 2135, Loss 8.710052\n",
      "Params: tensor([  4.4624, -11.8600])\n",
      "Grad:   tensor([-0.0099,  0.0561])\n",
      "Epoch 2136, Loss 8.710020\n",
      "Params: tensor([  4.4625, -11.8606])\n",
      "Grad:   tensor([-0.0099,  0.0560])\n",
      "Epoch 2137, Loss 8.709989\n",
      "Params: tensor([  4.4626, -11.8611])\n",
      "Grad:   tensor([-0.0099,  0.0559])\n",
      "Epoch 2138, Loss 8.709955\n",
      "Params: tensor([  4.4627, -11.8617])\n",
      "Grad:   tensor([-0.0099,  0.0558])\n",
      "Epoch 2139, Loss 8.709923\n",
      "Params: tensor([  4.4628, -11.8622])\n",
      "Grad:   tensor([-0.0098,  0.0557])\n",
      "Epoch 2140, Loss 8.709891\n",
      "Params: tensor([  4.4629, -11.8628])\n",
      "Grad:   tensor([-0.0098,  0.0556])\n",
      "Epoch 2141, Loss 8.709858\n",
      "Params: tensor([  4.4630, -11.8633])\n",
      "Grad:   tensor([-0.0098,  0.0555])\n",
      "Epoch 2142, Loss 8.709827\n",
      "Params: tensor([  4.4631, -11.8639])\n",
      "Grad:   tensor([-0.0098,  0.0554])\n",
      "Epoch 2143, Loss 8.709794\n",
      "Params: tensor([  4.4632, -11.8645])\n",
      "Grad:   tensor([-0.0098,  0.0553])\n",
      "Epoch 2144, Loss 8.709766\n",
      "Params: tensor([  4.4633, -11.8650])\n",
      "Grad:   tensor([-0.0097,  0.0552])\n",
      "Epoch 2145, Loss 8.709734\n",
      "Params: tensor([  4.4634, -11.8656])\n",
      "Grad:   tensor([-0.0097,  0.0551])\n",
      "Epoch 2146, Loss 8.709702\n",
      "Params: tensor([  4.4635, -11.8661])\n",
      "Grad:   tensor([-0.0097,  0.0550])\n",
      "Epoch 2147, Loss 8.709671\n",
      "Params: tensor([  4.4636, -11.8667])\n",
      "Grad:   tensor([-0.0097,  0.0549])\n",
      "Epoch 2148, Loss 8.709640\n",
      "Params: tensor([  4.4637, -11.8672])\n",
      "Grad:   tensor([-0.0097,  0.0548])\n",
      "Epoch 2149, Loss 8.709606\n",
      "Params: tensor([  4.4638, -11.8678])\n",
      "Grad:   tensor([-0.0097,  0.0547])\n",
      "Epoch 2150, Loss 8.709579\n",
      "Params: tensor([  4.4639, -11.8683])\n",
      "Grad:   tensor([-0.0096,  0.0546])\n",
      "Epoch 2151, Loss 8.709546\n",
      "Params: tensor([  4.4640, -11.8688])\n",
      "Grad:   tensor([-0.0096,  0.0546])\n",
      "Epoch 2152, Loss 8.709516\n",
      "Params: tensor([  4.4641, -11.8694])\n",
      "Grad:   tensor([-0.0096,  0.0545])\n",
      "Epoch 2153, Loss 8.709485\n",
      "Params: tensor([  4.4642, -11.8699])\n",
      "Grad:   tensor([-0.0096,  0.0544])\n",
      "Epoch 2154, Loss 8.709454\n",
      "Params: tensor([  4.4643, -11.8705])\n",
      "Grad:   tensor([-0.0096,  0.0543])\n",
      "Epoch 2155, Loss 8.709426\n",
      "Params: tensor([  4.4644, -11.8710])\n",
      "Grad:   tensor([-0.0096,  0.0542])\n",
      "Epoch 2156, Loss 8.709395\n",
      "Params: tensor([  4.4644, -11.8716])\n",
      "Grad:   tensor([-0.0096,  0.0541])\n",
      "Epoch 2157, Loss 8.709364\n",
      "Params: tensor([  4.4645, -11.8721])\n",
      "Grad:   tensor([-0.0095,  0.0540])\n",
      "Epoch 2158, Loss 8.709335\n",
      "Params: tensor([  4.4646, -11.8726])\n",
      "Grad:   tensor([-0.0095,  0.0539])\n",
      "Epoch 2159, Loss 8.709306\n",
      "Params: tensor([  4.4647, -11.8732])\n",
      "Grad:   tensor([-0.0095,  0.0538])\n",
      "Epoch 2160, Loss 8.709275\n",
      "Params: tensor([  4.4648, -11.8737])\n",
      "Grad:   tensor([-0.0095,  0.0537])\n",
      "Epoch 2161, Loss 8.709246\n",
      "Params: tensor([  4.4649, -11.8742])\n",
      "Grad:   tensor([-0.0095,  0.0536])\n",
      "Epoch 2162, Loss 8.709214\n",
      "Params: tensor([  4.4650, -11.8748])\n",
      "Grad:   tensor([-0.0094,  0.0535])\n",
      "Epoch 2163, Loss 8.709187\n",
      "Params: tensor([  4.4651, -11.8753])\n",
      "Grad:   tensor([-0.0094,  0.0535])\n",
      "Epoch 2164, Loss 8.709156\n",
      "Params: tensor([  4.4652, -11.8758])\n",
      "Grad:   tensor([-0.0094,  0.0534])\n",
      "Epoch 2165, Loss 8.709127\n",
      "Params: tensor([  4.4653, -11.8764])\n",
      "Grad:   tensor([-0.0094,  0.0533])\n",
      "Epoch 2166, Loss 8.709099\n",
      "Params: tensor([  4.4654, -11.8769])\n",
      "Grad:   tensor([-0.0094,  0.0532])\n",
      "Epoch 2167, Loss 8.709069\n",
      "Params: tensor([  4.4655, -11.8774])\n",
      "Grad:   tensor([-0.0094,  0.0531])\n",
      "Epoch 2168, Loss 8.709038\n",
      "Params: tensor([  4.4656, -11.8780])\n",
      "Grad:   tensor([-0.0094,  0.0530])\n",
      "Epoch 2169, Loss 8.709010\n",
      "Params: tensor([  4.4657, -11.8785])\n",
      "Grad:   tensor([-0.0093,  0.0529])\n",
      "Epoch 2170, Loss 8.708982\n",
      "Params: tensor([  4.4658, -11.8790])\n",
      "Grad:   tensor([-0.0093,  0.0528])\n",
      "Epoch 2171, Loss 8.708953\n",
      "Params: tensor([  4.4659, -11.8796])\n",
      "Grad:   tensor([-0.0093,  0.0527])\n",
      "Epoch 2172, Loss 8.708927\n",
      "Params: tensor([  4.4660, -11.8801])\n",
      "Grad:   tensor([-0.0093,  0.0526])\n",
      "Epoch 2173, Loss 8.708896\n",
      "Params: tensor([  4.4660, -11.8806])\n",
      "Grad:   tensor([-0.0093,  0.0526])\n",
      "Epoch 2174, Loss 8.708867\n",
      "Params: tensor([  4.4661, -11.8811])\n",
      "Grad:   tensor([-0.0093,  0.0525])\n",
      "Epoch 2175, Loss 8.708838\n",
      "Params: tensor([  4.4662, -11.8817])\n",
      "Grad:   tensor([-0.0093,  0.0524])\n",
      "Epoch 2176, Loss 8.708810\n",
      "Params: tensor([  4.4663, -11.8822])\n",
      "Grad:   tensor([-0.0092,  0.0523])\n",
      "Epoch 2177, Loss 8.708782\n",
      "Params: tensor([  4.4664, -11.8827])\n",
      "Grad:   tensor([-0.0092,  0.0522])\n",
      "Epoch 2178, Loss 8.708755\n",
      "Params: tensor([  4.4665, -11.8832])\n",
      "Grad:   tensor([-0.0092,  0.0521])\n",
      "Epoch 2179, Loss 8.708726\n",
      "Params: tensor([  4.4666, -11.8837])\n",
      "Grad:   tensor([-0.0092,  0.0520])\n",
      "Epoch 2180, Loss 8.708698\n",
      "Params: tensor([  4.4667, -11.8843])\n",
      "Grad:   tensor([-0.0092,  0.0519])\n",
      "Epoch 2181, Loss 8.708670\n",
      "Params: tensor([  4.4668, -11.8848])\n",
      "Grad:   tensor([-0.0092,  0.0518])\n",
      "Epoch 2182, Loss 8.708643\n",
      "Params: tensor([  4.4669, -11.8853])\n",
      "Grad:   tensor([-0.0092,  0.0518])\n",
      "Epoch 2183, Loss 8.708614\n",
      "Params: tensor([  4.4670, -11.8858])\n",
      "Grad:   tensor([-0.0091,  0.0517])\n",
      "Epoch 2184, Loss 8.708587\n",
      "Params: tensor([  4.4671, -11.8863])\n",
      "Grad:   tensor([-0.0091,  0.0516])\n",
      "Epoch 2185, Loss 8.708560\n",
      "Params: tensor([  4.4671, -11.8869])\n",
      "Grad:   tensor([-0.0091,  0.0515])\n",
      "Epoch 2186, Loss 8.708535\n",
      "Params: tensor([  4.4672, -11.8874])\n",
      "Grad:   tensor([-0.0091,  0.0514])\n",
      "Epoch 2187, Loss 8.708506\n",
      "Params: tensor([  4.4673, -11.8879])\n",
      "Grad:   tensor([-0.0091,  0.0513])\n",
      "Epoch 2188, Loss 8.708481\n",
      "Params: tensor([  4.4674, -11.8884])\n",
      "Grad:   tensor([-0.0091,  0.0512])\n",
      "Epoch 2189, Loss 8.708451\n",
      "Params: tensor([  4.4675, -11.8889])\n",
      "Grad:   tensor([-0.0090,  0.0511])\n",
      "Epoch 2190, Loss 8.708426\n",
      "Params: tensor([  4.4676, -11.8894])\n",
      "Grad:   tensor([-0.0090,  0.0511])\n",
      "Epoch 2191, Loss 8.708398\n",
      "Params: tensor([  4.4677, -11.8899])\n",
      "Grad:   tensor([-0.0090,  0.0510])\n",
      "Epoch 2192, Loss 8.708372\n",
      "Params: tensor([  4.4678, -11.8904])\n",
      "Grad:   tensor([-0.0090,  0.0509])\n",
      "Epoch 2193, Loss 8.708346\n",
      "Params: tensor([  4.4679, -11.8909])\n",
      "Grad:   tensor([-0.0090,  0.0508])\n",
      "Epoch 2194, Loss 8.708322\n",
      "Params: tensor([  4.4680, -11.8914])\n",
      "Grad:   tensor([-0.0090,  0.0507])\n",
      "Epoch 2195, Loss 8.708291\n",
      "Params: tensor([  4.4680, -11.8920])\n",
      "Grad:   tensor([-0.0090,  0.0506])\n",
      "Epoch 2196, Loss 8.708266\n",
      "Params: tensor([  4.4681, -11.8925])\n",
      "Grad:   tensor([-0.0089,  0.0505])\n",
      "Epoch 2197, Loss 8.708240\n",
      "Params: tensor([  4.4682, -11.8930])\n",
      "Grad:   tensor([-0.0089,  0.0504])\n",
      "Epoch 2198, Loss 8.708213\n",
      "Params: tensor([  4.4683, -11.8935])\n",
      "Grad:   tensor([-0.0089,  0.0504])\n",
      "Epoch 2199, Loss 8.708184\n",
      "Params: tensor([  4.4684, -11.8940])\n",
      "Grad:   tensor([-0.0089,  0.0503])\n",
      "Epoch 2200, Loss 8.708159\n",
      "Params: tensor([  4.4685, -11.8945])\n",
      "Grad:   tensor([-0.0089,  0.0502])\n",
      "Epoch 2201, Loss 8.708137\n",
      "Params: tensor([  4.4686, -11.8950])\n",
      "Grad:   tensor([-0.0089,  0.0501])\n",
      "Epoch 2202, Loss 8.708108\n",
      "Params: tensor([  4.4687, -11.8955])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad:   tensor([-0.0088,  0.0500])\n",
      "Epoch 2203, Loss 8.708081\n",
      "Params: tensor([  4.4688, -11.8960])\n",
      "Grad:   tensor([-0.0088,  0.0499])\n",
      "Epoch 2204, Loss 8.708056\n",
      "Params: tensor([  4.4688, -11.8965])\n",
      "Grad:   tensor([-0.0088,  0.0499])\n",
      "Epoch 2205, Loss 8.708032\n",
      "Params: tensor([  4.4689, -11.8970])\n",
      "Grad:   tensor([-0.0088,  0.0498])\n",
      "Epoch 2206, Loss 8.708009\n",
      "Params: tensor([  4.4690, -11.8975])\n",
      "Grad:   tensor([-0.0088,  0.0497])\n",
      "Epoch 2207, Loss 8.707981\n",
      "Params: tensor([  4.4691, -11.8980])\n",
      "Grad:   tensor([-0.0088,  0.0496])\n",
      "Epoch 2208, Loss 8.707955\n",
      "Params: tensor([  4.4692, -11.8985])\n",
      "Grad:   tensor([-0.0087,  0.0495])\n",
      "Epoch 2209, Loss 8.707929\n",
      "Params: tensor([  4.4693, -11.8989])\n",
      "Grad:   tensor([-0.0087,  0.0494])\n",
      "Epoch 2210, Loss 8.707904\n",
      "Params: tensor([  4.4694, -11.8994])\n",
      "Grad:   tensor([-0.0087,  0.0493])\n",
      "Epoch 2211, Loss 8.707879\n",
      "Params: tensor([  4.4695, -11.8999])\n",
      "Grad:   tensor([-0.0087,  0.0493])\n",
      "Epoch 2212, Loss 8.707854\n",
      "Params: tensor([  4.4695, -11.9004])\n",
      "Grad:   tensor([-0.0087,  0.0492])\n",
      "Epoch 2213, Loss 8.707830\n",
      "Params: tensor([  4.4696, -11.9009])\n",
      "Grad:   tensor([-0.0087,  0.0491])\n",
      "Epoch 2214, Loss 8.707804\n",
      "Params: tensor([  4.4697, -11.9014])\n",
      "Grad:   tensor([-0.0087,  0.0490])\n",
      "Epoch 2215, Loss 8.707778\n",
      "Params: tensor([  4.4698, -11.9019])\n",
      "Grad:   tensor([-0.0086,  0.0489])\n",
      "Epoch 2216, Loss 8.707754\n",
      "Params: tensor([  4.4699, -11.9024])\n",
      "Grad:   tensor([-0.0086,  0.0488])\n",
      "Epoch 2217, Loss 8.707731\n",
      "Params: tensor([  4.4700, -11.9029])\n",
      "Grad:   tensor([-0.0086,  0.0488])\n",
      "Epoch 2218, Loss 8.707708\n",
      "Params: tensor([  4.4701, -11.9034])\n",
      "Grad:   tensor([-0.0086,  0.0487])\n",
      "Epoch 2219, Loss 8.707682\n",
      "Params: tensor([  4.4701, -11.9038])\n",
      "Grad:   tensor([-0.0086,  0.0486])\n",
      "Epoch 2220, Loss 8.707658\n",
      "Params: tensor([  4.4702, -11.9043])\n",
      "Grad:   tensor([-0.0086,  0.0485])\n",
      "Epoch 2221, Loss 8.707635\n",
      "Params: tensor([  4.4703, -11.9048])\n",
      "Grad:   tensor([-0.0085,  0.0484])\n",
      "Epoch 2222, Loss 8.707608\n",
      "Params: tensor([  4.4704, -11.9053])\n",
      "Grad:   tensor([-0.0085,  0.0484])\n",
      "Epoch 2223, Loss 8.707584\n",
      "Params: tensor([  4.4705, -11.9058])\n",
      "Grad:   tensor([-0.0085,  0.0483])\n",
      "Epoch 2224, Loss 8.707562\n",
      "Params: tensor([  4.4706, -11.9063])\n",
      "Grad:   tensor([-0.0085,  0.0482])\n",
      "Epoch 2225, Loss 8.707538\n",
      "Params: tensor([  4.4707, -11.9067])\n",
      "Grad:   tensor([-0.0085,  0.0481])\n",
      "Epoch 2226, Loss 8.707513\n",
      "Params: tensor([  4.4707, -11.9072])\n",
      "Grad:   tensor([-0.0085,  0.0480])\n",
      "Epoch 2227, Loss 8.707489\n",
      "Params: tensor([  4.4708, -11.9077])\n",
      "Grad:   tensor([-0.0085,  0.0479])\n",
      "Epoch 2228, Loss 8.707465\n",
      "Params: tensor([  4.4709, -11.9082])\n",
      "Grad:   tensor([-0.0084,  0.0479])\n",
      "Epoch 2229, Loss 8.707442\n",
      "Params: tensor([  4.4710, -11.9087])\n",
      "Grad:   tensor([-0.0084,  0.0478])\n",
      "Epoch 2230, Loss 8.707419\n",
      "Params: tensor([  4.4711, -11.9091])\n",
      "Grad:   tensor([-0.0084,  0.0477])\n",
      "Epoch 2231, Loss 8.707394\n",
      "Params: tensor([  4.4712, -11.9096])\n",
      "Grad:   tensor([-0.0084,  0.0476])\n",
      "Epoch 2232, Loss 8.707373\n",
      "Params: tensor([  4.4713, -11.9101])\n",
      "Grad:   tensor([-0.0084,  0.0475])\n",
      "Epoch 2233, Loss 8.707349\n",
      "Params: tensor([  4.4713, -11.9106])\n",
      "Grad:   tensor([-0.0084,  0.0475])\n",
      "Epoch 2234, Loss 8.707327\n",
      "Params: tensor([  4.4714, -11.9110])\n",
      "Grad:   tensor([-0.0084,  0.0474])\n",
      "Epoch 2235, Loss 8.707302\n",
      "Params: tensor([  4.4715, -11.9115])\n",
      "Grad:   tensor([-0.0084,  0.0473])\n",
      "Epoch 2236, Loss 8.707279\n",
      "Params: tensor([  4.4716, -11.9120])\n",
      "Grad:   tensor([-0.0084,  0.0472])\n",
      "Epoch 2237, Loss 8.707254\n",
      "Params: tensor([  4.4717, -11.9125])\n",
      "Grad:   tensor([-0.0083,  0.0471])\n",
      "Epoch 2238, Loss 8.707233\n",
      "Params: tensor([  4.4718, -11.9129])\n",
      "Grad:   tensor([-0.0083,  0.0471])\n",
      "Epoch 2239, Loss 8.707211\n",
      "Params: tensor([  4.4718, -11.9134])\n",
      "Grad:   tensor([-0.0083,  0.0470])\n",
      "Epoch 2240, Loss 8.707190\n",
      "Params: tensor([  4.4719, -11.9139])\n",
      "Grad:   tensor([-0.0083,  0.0469])\n",
      "Epoch 2241, Loss 8.707164\n",
      "Params: tensor([  4.4720, -11.9143])\n",
      "Grad:   tensor([-0.0083,  0.0468])\n",
      "Epoch 2242, Loss 8.707144\n",
      "Params: tensor([  4.4721, -11.9148])\n",
      "Grad:   tensor([-0.0082,  0.0467])\n",
      "Epoch 2243, Loss 8.707120\n",
      "Params: tensor([  4.4722, -11.9153])\n",
      "Grad:   tensor([-0.0082,  0.0467])\n",
      "Epoch 2244, Loss 8.707099\n",
      "Params: tensor([  4.4722, -11.9157])\n",
      "Grad:   tensor([-0.0082,  0.0466])\n",
      "Epoch 2245, Loss 8.707074\n",
      "Params: tensor([  4.4723, -11.9162])\n",
      "Grad:   tensor([-0.0082,  0.0465])\n",
      "Epoch 2246, Loss 8.707053\n",
      "Params: tensor([  4.4724, -11.9167])\n",
      "Grad:   tensor([-0.0082,  0.0464])\n",
      "Epoch 2247, Loss 8.707030\n",
      "Params: tensor([  4.4725, -11.9171])\n",
      "Grad:   tensor([-0.0082,  0.0463])\n",
      "Epoch 2248, Loss 8.707009\n",
      "Params: tensor([  4.4726, -11.9176])\n",
      "Grad:   tensor([-0.0082,  0.0463])\n",
      "Epoch 2249, Loss 8.706985\n",
      "Params: tensor([  4.4727, -11.9180])\n",
      "Grad:   tensor([-0.0082,  0.0462])\n",
      "Epoch 2250, Loss 8.706964\n",
      "Params: tensor([  4.4727, -11.9185])\n",
      "Grad:   tensor([-0.0082,  0.0461])\n",
      "Epoch 2251, Loss 8.706943\n",
      "Params: tensor([  4.4728, -11.9190])\n",
      "Grad:   tensor([-0.0081,  0.0460])\n",
      "Epoch 2252, Loss 8.706922\n",
      "Params: tensor([  4.4729, -11.9194])\n",
      "Grad:   tensor([-0.0081,  0.0459])\n",
      "Epoch 2253, Loss 8.706900\n",
      "Params: tensor([  4.4730, -11.9199])\n",
      "Grad:   tensor([-0.0081,  0.0459])\n",
      "Epoch 2254, Loss 8.706878\n",
      "Params: tensor([  4.4731, -11.9203])\n",
      "Grad:   tensor([-0.0081,  0.0458])\n",
      "Epoch 2255, Loss 8.706855\n",
      "Params: tensor([  4.4731, -11.9208])\n",
      "Grad:   tensor([-0.0081,  0.0457])\n",
      "Epoch 2256, Loss 8.706835\n",
      "Params: tensor([  4.4732, -11.9213])\n",
      "Grad:   tensor([-0.0081,  0.0456])\n",
      "Epoch 2257, Loss 8.706816\n",
      "Params: tensor([  4.4733, -11.9217])\n",
      "Grad:   tensor([-0.0081,  0.0456])\n",
      "Epoch 2258, Loss 8.706791\n",
      "Params: tensor([  4.4734, -11.9222])\n",
      "Grad:   tensor([-0.0080,  0.0455])\n",
      "Epoch 2259, Loss 8.706771\n",
      "Params: tensor([  4.4735, -11.9226])\n",
      "Grad:   tensor([-0.0080,  0.0454])\n",
      "Epoch 2260, Loss 8.706750\n",
      "Params: tensor([  4.4735, -11.9231])\n",
      "Grad:   tensor([-0.0080,  0.0453])\n",
      "Epoch 2261, Loss 8.706728\n",
      "Params: tensor([  4.4736, -11.9235])\n",
      "Grad:   tensor([-0.0080,  0.0452])\n",
      "Epoch 2262, Loss 8.706708\n",
      "Params: tensor([  4.4737, -11.9240])\n",
      "Grad:   tensor([-0.0080,  0.0452])\n",
      "Epoch 2263, Loss 8.706685\n",
      "Params: tensor([  4.4738, -11.9244])\n",
      "Grad:   tensor([-0.0080,  0.0451])\n",
      "Epoch 2264, Loss 8.706665\n",
      "Params: tensor([  4.4739, -11.9249])\n",
      "Grad:   tensor([-0.0080,  0.0450])\n",
      "Epoch 2265, Loss 8.706646\n",
      "Params: tensor([  4.4739, -11.9253])\n",
      "Grad:   tensor([-0.0079,  0.0449])\n",
      "Epoch 2266, Loss 8.706623\n",
      "Params: tensor([  4.4740, -11.9258])\n",
      "Grad:   tensor([-0.0079,  0.0449])\n",
      "Epoch 2267, Loss 8.706603\n",
      "Params: tensor([  4.4741, -11.9262])\n",
      "Grad:   tensor([-0.0079,  0.0448])\n",
      "Epoch 2268, Loss 8.706580\n",
      "Params: tensor([  4.4742, -11.9267])\n",
      "Grad:   tensor([-0.0079,  0.0447])\n",
      "Epoch 2269, Loss 8.706561\n",
      "Params: tensor([  4.4743, -11.9271])\n",
      "Grad:   tensor([-0.0079,  0.0446])\n",
      "Epoch 2270, Loss 8.706540\n",
      "Params: tensor([  4.4743, -11.9276])\n",
      "Grad:   tensor([-0.0079,  0.0446])\n",
      "Epoch 2271, Loss 8.706518\n",
      "Params: tensor([  4.4744, -11.9280])\n",
      "Grad:   tensor([-0.0078,  0.0445])\n",
      "Epoch 2272, Loss 8.706498\n",
      "Params: tensor([  4.4745, -11.9285])\n",
      "Grad:   tensor([-0.0078,  0.0444])\n",
      "Epoch 2273, Loss 8.706479\n",
      "Params: tensor([  4.4746, -11.9289])\n",
      "Grad:   tensor([-0.0078,  0.0443])\n",
      "Epoch 2274, Loss 8.706460\n",
      "Params: tensor([  4.4747, -11.9293])\n",
      "Grad:   tensor([-0.0078,  0.0443])\n",
      "Epoch 2275, Loss 8.706439\n",
      "Params: tensor([  4.4747, -11.9298])\n",
      "Grad:   tensor([-0.0078,  0.0442])\n",
      "Epoch 2276, Loss 8.706418\n",
      "Params: tensor([  4.4748, -11.9302])\n",
      "Grad:   tensor([-0.0078,  0.0441])\n",
      "Epoch 2277, Loss 8.706399\n",
      "Params: tensor([  4.4749, -11.9307])\n",
      "Grad:   tensor([-0.0078,  0.0440])\n",
      "Epoch 2278, Loss 8.706378\n",
      "Params: tensor([  4.4750, -11.9311])\n",
      "Grad:   tensor([-0.0078,  0.0440])\n",
      "Epoch 2279, Loss 8.706359\n",
      "Params: tensor([  4.4750, -11.9315])\n",
      "Grad:   tensor([-0.0078,  0.0439])\n",
      "Epoch 2280, Loss 8.706341\n",
      "Params: tensor([  4.4751, -11.9320])\n",
      "Grad:   tensor([-0.0077,  0.0438])\n",
      "Epoch 2281, Loss 8.706318\n",
      "Params: tensor([  4.4752, -11.9324])\n",
      "Grad:   tensor([-0.0077,  0.0437])\n",
      "Epoch 2282, Loss 8.706300\n",
      "Params: tensor([  4.4753, -11.9329])\n",
      "Grad:   tensor([-0.0077,  0.0437])\n",
      "Epoch 2283, Loss 8.706283\n",
      "Params: tensor([  4.4754, -11.9333])\n",
      "Grad:   tensor([-0.0077,  0.0436])\n",
      "Epoch 2284, Loss 8.706261\n",
      "Params: tensor([  4.4754, -11.9337])\n",
      "Grad:   tensor([-0.0077,  0.0435])\n",
      "Epoch 2285, Loss 8.706241\n",
      "Params: tensor([  4.4755, -11.9342])\n",
      "Grad:   tensor([-0.0077,  0.0434])\n",
      "Epoch 2286, Loss 8.706222\n",
      "Params: tensor([  4.4756, -11.9346])\n",
      "Grad:   tensor([-0.0077,  0.0434])\n",
      "Epoch 2287, Loss 8.706201\n",
      "Params: tensor([  4.4757, -11.9350])\n",
      "Grad:   tensor([-0.0077,  0.0433])\n",
      "Epoch 2288, Loss 8.706183\n",
      "Params: tensor([  4.4757, -11.9355])\n",
      "Grad:   tensor([-0.0076,  0.0432])\n",
      "Epoch 2289, Loss 8.706164\n",
      "Params: tensor([  4.4758, -11.9359])\n",
      "Grad:   tensor([-0.0076,  0.0431])\n",
      "Epoch 2290, Loss 8.706145\n",
      "Params: tensor([  4.4759, -11.9363])\n",
      "Grad:   tensor([-0.0076,  0.0431])\n",
      "Epoch 2291, Loss 8.706125\n",
      "Params: tensor([  4.4760, -11.9368])\n",
      "Grad:   tensor([-0.0076,  0.0430])\n",
      "Epoch 2292, Loss 8.706104\n",
      "Params: tensor([  4.4760, -11.9372])\n",
      "Grad:   tensor([-0.0076,  0.0429])\n",
      "Epoch 2293, Loss 8.706088\n",
      "Params: tensor([  4.4761, -11.9376])\n",
      "Grad:   tensor([-0.0076,  0.0428])\n",
      "Epoch 2294, Loss 8.706069\n",
      "Params: tensor([  4.4762, -11.9380])\n",
      "Grad:   tensor([-0.0076,  0.0428])\n",
      "Epoch 2295, Loss 8.706047\n",
      "Params: tensor([  4.4763, -11.9385])\n",
      "Grad:   tensor([-0.0075,  0.0427])\n",
      "Epoch 2296, Loss 8.706028\n",
      "Params: tensor([  4.4763, -11.9389])\n",
      "Grad:   tensor([-0.0075,  0.0426])\n",
      "Epoch 2297, Loss 8.706012\n",
      "Params: tensor([  4.4764, -11.9393])\n",
      "Grad:   tensor([-0.0075,  0.0426])\n",
      "Epoch 2298, Loss 8.705994\n",
      "Params: tensor([  4.4765, -11.9397])\n",
      "Grad:   tensor([-0.0075,  0.0425])\n",
      "Epoch 2299, Loss 8.705975\n",
      "Params: tensor([  4.4766, -11.9402])\n",
      "Grad:   tensor([-0.0075,  0.0424])\n",
      "Epoch 2300, Loss 8.705955\n",
      "Params: tensor([  4.4766, -11.9406])\n",
      "Grad:   tensor([-0.0075,  0.0423])\n",
      "Epoch 2301, Loss 8.705937\n",
      "Params: tensor([  4.4767, -11.9410])\n",
      "Grad:   tensor([-0.0075,  0.0423])\n",
      "Epoch 2302, Loss 8.705918\n",
      "Params: tensor([  4.4768, -11.9414])\n",
      "Grad:   tensor([-0.0075,  0.0422])\n",
      "Epoch 2303, Loss 8.705899\n",
      "Params: tensor([  4.4769, -11.9419])\n",
      "Grad:   tensor([-0.0075,  0.0421])\n",
      "Epoch 2304, Loss 8.705882\n",
      "Params: tensor([  4.4769, -11.9423])\n",
      "Grad:   tensor([-0.0074,  0.0421])\n",
      "Epoch 2305, Loss 8.705865\n",
      "Params: tensor([  4.4770, -11.9427])\n",
      "Grad:   tensor([-0.0074,  0.0420])\n",
      "Epoch 2306, Loss 8.705846\n",
      "Params: tensor([  4.4771, -11.9431])\n",
      "Grad:   tensor([-0.0074,  0.0419])\n",
      "Epoch 2307, Loss 8.705827\n",
      "Params: tensor([  4.4772, -11.9435])\n",
      "Grad:   tensor([-0.0074,  0.0418])\n",
      "Epoch 2308, Loss 8.705811\n",
      "Params: tensor([  4.4772, -11.9440])\n",
      "Grad:   tensor([-0.0074,  0.0418])\n",
      "Epoch 2309, Loss 8.705792\n",
      "Params: tensor([  4.4773, -11.9444])\n",
      "Grad:   tensor([-0.0074,  0.0417])\n",
      "Epoch 2310, Loss 8.705773\n",
      "Params: tensor([  4.4774, -11.9448])\n",
      "Grad:   tensor([-0.0073,  0.0416])\n",
      "Epoch 2311, Loss 8.705755\n",
      "Params: tensor([  4.4775, -11.9452])\n",
      "Grad:   tensor([-0.0073,  0.0416])\n",
      "Epoch 2312, Loss 8.705737\n",
      "Params: tensor([  4.4775, -11.9456])\n",
      "Grad:   tensor([-0.0073,  0.0415])\n",
      "Epoch 2313, Loss 8.705719\n",
      "Params: tensor([  4.4776, -11.9460])\n",
      "Grad:   tensor([-0.0073,  0.0414])\n",
      "Epoch 2314, Loss 8.705704\n",
      "Params: tensor([  4.4777, -11.9464])\n",
      "Grad:   tensor([-0.0073,  0.0414])\n",
      "Epoch 2315, Loss 8.705685\n",
      "Params: tensor([  4.4777, -11.9469])\n",
      "Grad:   tensor([-0.0073,  0.0413])\n",
      "Epoch 2316, Loss 8.705667\n",
      "Params: tensor([  4.4778, -11.9473])\n",
      "Grad:   tensor([-0.0073,  0.0412])\n",
      "Epoch 2317, Loss 8.705648\n",
      "Params: tensor([  4.4779, -11.9477])\n",
      "Grad:   tensor([-0.0073,  0.0411])\n",
      "Epoch 2318, Loss 8.705632\n",
      "Params: tensor([  4.4780, -11.9481])\n",
      "Grad:   tensor([-0.0073,  0.0411])\n",
      "Epoch 2319, Loss 8.705617\n",
      "Params: tensor([  4.4780, -11.9485])\n",
      "Grad:   tensor([-0.0073,  0.0410])\n",
      "Epoch 2320, Loss 8.705597\n",
      "Params: tensor([  4.4781, -11.9489])\n",
      "Grad:   tensor([-0.0072,  0.0409])\n",
      "Epoch 2321, Loss 8.705581\n",
      "Params: tensor([  4.4782, -11.9493])\n",
      "Grad:   tensor([-0.0072,  0.0409])\n",
      "Epoch 2322, Loss 8.705564\n",
      "Params: tensor([  4.4783, -11.9497])\n",
      "Grad:   tensor([-0.0072,  0.0408])\n",
      "Epoch 2323, Loss 8.705544\n",
      "Params: tensor([  4.4783, -11.9501])\n",
      "Grad:   tensor([-0.0072,  0.0407])\n",
      "Epoch 2324, Loss 8.705529\n",
      "Params: tensor([  4.4784, -11.9505])\n",
      "Grad:   tensor([-0.0072,  0.0407])\n",
      "Epoch 2325, Loss 8.705514\n",
      "Params: tensor([  4.4785, -11.9509])\n",
      "Grad:   tensor([-0.0072,  0.0406])\n",
      "Epoch 2326, Loss 8.705496\n",
      "Params: tensor([  4.4785, -11.9514])\n",
      "Grad:   tensor([-0.0072,  0.0405])\n",
      "Epoch 2327, Loss 8.705479\n",
      "Params: tensor([  4.4786, -11.9518])\n",
      "Grad:   tensor([-0.0072,  0.0404])\n",
      "Epoch 2328, Loss 8.705461\n",
      "Params: tensor([  4.4787, -11.9522])\n",
      "Grad:   tensor([-0.0071,  0.0404])\n",
      "Epoch 2329, Loss 8.705444\n",
      "Params: tensor([  4.4788, -11.9526])\n",
      "Grad:   tensor([-0.0071,  0.0403])\n",
      "Epoch 2330, Loss 8.705428\n",
      "Params: tensor([  4.4788, -11.9530])\n",
      "Grad:   tensor([-0.0071,  0.0402])\n",
      "Epoch 2331, Loss 8.705411\n",
      "Params: tensor([  4.4789, -11.9534])\n",
      "Grad:   tensor([-0.0071,  0.0402])\n",
      "Epoch 2332, Loss 8.705395\n",
      "Params: tensor([  4.4790, -11.9538])\n",
      "Grad:   tensor([-0.0071,  0.0401])\n",
      "Epoch 2333, Loss 8.705379\n",
      "Params: tensor([  4.4790, -11.9542])\n",
      "Grad:   tensor([-0.0071,  0.0400])\n",
      "Epoch 2334, Loss 8.705360\n",
      "Params: tensor([  4.4791, -11.9546])\n",
      "Grad:   tensor([-0.0071,  0.0400])\n",
      "Epoch 2335, Loss 8.705346\n",
      "Params: tensor([  4.4792, -11.9550])\n",
      "Grad:   tensor([-0.0071,  0.0399])\n",
      "Epoch 2336, Loss 8.705329\n",
      "Params: tensor([  4.4793, -11.9554])\n",
      "Grad:   tensor([-0.0070,  0.0398])\n",
      "Epoch 2337, Loss 8.705314\n",
      "Params: tensor([  4.4793, -11.9558])\n",
      "Grad:   tensor([-0.0070,  0.0398])\n",
      "Epoch 2338, Loss 8.705296\n",
      "Params: tensor([  4.4794, -11.9562])\n",
      "Grad:   tensor([-0.0070,  0.0397])\n",
      "Epoch 2339, Loss 8.705280\n",
      "Params: tensor([  4.4795, -11.9566])\n",
      "Grad:   tensor([-0.0070,  0.0396])\n",
      "Epoch 2340, Loss 8.705264\n",
      "Params: tensor([  4.4795, -11.9570])\n",
      "Grad:   tensor([-0.0070,  0.0396])\n",
      "Epoch 2341, Loss 8.705249\n",
      "Params: tensor([  4.4796, -11.9573])\n",
      "Grad:   tensor([-0.0070,  0.0395])\n",
      "Epoch 2342, Loss 8.705231\n",
      "Params: tensor([  4.4797, -11.9577])\n",
      "Grad:   tensor([-0.0070,  0.0394])\n",
      "Epoch 2343, Loss 8.705215\n",
      "Params: tensor([  4.4797, -11.9581])\n",
      "Grad:   tensor([-0.0069,  0.0394])\n",
      "Epoch 2344, Loss 8.705200\n",
      "Params: tensor([  4.4798, -11.9585])\n",
      "Grad:   tensor([-0.0069,  0.0393])\n",
      "Epoch 2345, Loss 8.705185\n",
      "Params: tensor([  4.4799, -11.9589])\n",
      "Grad:   tensor([-0.0069,  0.0392])\n",
      "Epoch 2346, Loss 8.705168\n",
      "Params: tensor([  4.4799, -11.9593])\n",
      "Grad:   tensor([-0.0069,  0.0392])\n",
      "Epoch 2347, Loss 8.705151\n",
      "Params: tensor([  4.4800, -11.9597])\n",
      "Grad:   tensor([-0.0069,  0.0391])\n",
      "Epoch 2348, Loss 8.705138\n",
      "Params: tensor([  4.4801, -11.9601])\n",
      "Grad:   tensor([-0.0069,  0.0390])\n",
      "Epoch 2349, Loss 8.705121\n",
      "Params: tensor([  4.4802, -11.9605])\n",
      "Grad:   tensor([-0.0069,  0.0390])\n",
      "Epoch 2350, Loss 8.705105\n",
      "Params: tensor([  4.4802, -11.9609])\n",
      "Grad:   tensor([-0.0069,  0.0389])\n",
      "Epoch 2351, Loss 8.705088\n",
      "Params: tensor([  4.4803, -11.9613])\n",
      "Grad:   tensor([-0.0069,  0.0388])\n",
      "Epoch 2352, Loss 8.705074\n",
      "Params: tensor([  4.4804, -11.9616])\n",
      "Grad:   tensor([-0.0069,  0.0388])\n",
      "Epoch 2353, Loss 8.705056\n",
      "Params: tensor([  4.4804, -11.9620])\n",
      "Grad:   tensor([-0.0068,  0.0387])\n",
      "Epoch 2354, Loss 8.705044\n",
      "Params: tensor([  4.4805, -11.9624])\n",
      "Grad:   tensor([-0.0068,  0.0386])\n",
      "Epoch 2355, Loss 8.705027\n",
      "Params: tensor([  4.4806, -11.9628])\n",
      "Grad:   tensor([-0.0068,  0.0386])\n",
      "Epoch 2356, Loss 8.705010\n",
      "Params: tensor([  4.4806, -11.9632])\n",
      "Grad:   tensor([-0.0068,  0.0385])\n",
      "Epoch 2357, Loss 8.704996\n",
      "Params: tensor([  4.4807, -11.9636])\n",
      "Grad:   tensor([-0.0068,  0.0384])\n",
      "Epoch 2358, Loss 8.704981\n",
      "Params: tensor([  4.4808, -11.9640])\n",
      "Grad:   tensor([-0.0068,  0.0384])\n",
      "Epoch 2359, Loss 8.704967\n",
      "Params: tensor([  4.4808, -11.9643])\n",
      "Grad:   tensor([-0.0068,  0.0383])\n",
      "Epoch 2360, Loss 8.704952\n",
      "Params: tensor([  4.4809, -11.9647])\n",
      "Grad:   tensor([-0.0068,  0.0382])\n",
      "Epoch 2361, Loss 8.704934\n",
      "Params: tensor([  4.4810, -11.9651])\n",
      "Grad:   tensor([-0.0067,  0.0382])\n",
      "Epoch 2362, Loss 8.704922\n",
      "Params: tensor([  4.4810, -11.9655])\n",
      "Grad:   tensor([-0.0067,  0.0381])\n",
      "Epoch 2363, Loss 8.704907\n",
      "Params: tensor([  4.4811, -11.9659])\n",
      "Grad:   tensor([-0.0067,  0.0380])\n",
      "Epoch 2364, Loss 8.704889\n",
      "Params: tensor([  4.4812, -11.9662])\n",
      "Grad:   tensor([-0.0067,  0.0380])\n",
      "Epoch 2365, Loss 8.704879\n",
      "Params: tensor([  4.4812, -11.9666])\n",
      "Grad:   tensor([-0.0067,  0.0379])\n",
      "Epoch 2366, Loss 8.704863\n",
      "Params: tensor([  4.4813, -11.9670])\n",
      "Grad:   tensor([-0.0067,  0.0379])\n",
      "Epoch 2367, Loss 8.704845\n",
      "Params: tensor([  4.4814, -11.9674])\n",
      "Grad:   tensor([-0.0067,  0.0378])\n",
      "Epoch 2368, Loss 8.704832\n",
      "Params: tensor([  4.4814, -11.9678])\n",
      "Grad:   tensor([-0.0067,  0.0377])\n",
      "Epoch 2369, Loss 8.704818\n",
      "Params: tensor([  4.4815, -11.9681])\n",
      "Grad:   tensor([-0.0067,  0.0377])\n",
      "Epoch 2370, Loss 8.704803\n",
      "Params: tensor([  4.4816, -11.9685])\n",
      "Grad:   tensor([-0.0067,  0.0376])\n",
      "Epoch 2371, Loss 8.704788\n",
      "Params: tensor([  4.4816, -11.9689])\n",
      "Grad:   tensor([-0.0066,  0.0375])\n",
      "Epoch 2372, Loss 8.704773\n",
      "Params: tensor([  4.4817, -11.9693])\n",
      "Grad:   tensor([-0.0066,  0.0375])\n",
      "Epoch 2373, Loss 8.704758\n",
      "Params: tensor([  4.4818, -11.9696])\n",
      "Grad:   tensor([-0.0066,  0.0374])\n",
      "Epoch 2374, Loss 8.704745\n",
      "Params: tensor([  4.4818, -11.9700])\n",
      "Grad:   tensor([-0.0066,  0.0373])\n",
      "Epoch 2375, Loss 8.704732\n",
      "Params: tensor([  4.4819, -11.9704])\n",
      "Grad:   tensor([-0.0066,  0.0373])\n",
      "Epoch 2376, Loss 8.704718\n",
      "Params: tensor([  4.4820, -11.9708])\n",
      "Grad:   tensor([-0.0066,  0.0372])\n",
      "Epoch 2377, Loss 8.704700\n",
      "Params: tensor([  4.4820, -11.9711])\n",
      "Grad:   tensor([-0.0066,  0.0371])\n",
      "Epoch 2378, Loss 8.704688\n",
      "Params: tensor([  4.4821, -11.9715])\n",
      "Grad:   tensor([-0.0066,  0.0371])\n",
      "Epoch 2379, Loss 8.704673\n",
      "Params: tensor([  4.4822, -11.9719])\n",
      "Grad:   tensor([-0.0065,  0.0370])\n",
      "Epoch 2380, Loss 8.704658\n",
      "Params: tensor([  4.4822, -11.9722])\n",
      "Grad:   tensor([-0.0065,  0.0370])\n",
      "Epoch 2381, Loss 8.704644\n",
      "Params: tensor([  4.4823, -11.9726])\n",
      "Grad:   tensor([-0.0065,  0.0369])\n",
      "Epoch 2382, Loss 8.704632\n",
      "Params: tensor([  4.4824, -11.9730])\n",
      "Grad:   tensor([-0.0065,  0.0368])\n",
      "Epoch 2383, Loss 8.704617\n",
      "Params: tensor([  4.4824, -11.9733])\n",
      "Grad:   tensor([-0.0065,  0.0368])\n",
      "Epoch 2384, Loss 8.704605\n",
      "Params: tensor([  4.4825, -11.9737])\n",
      "Grad:   tensor([-0.0065,  0.0367])\n",
      "Epoch 2385, Loss 8.704589\n",
      "Params: tensor([  4.4826, -11.9741])\n",
      "Grad:   tensor([-0.0065,  0.0366])\n",
      "Epoch 2386, Loss 8.704576\n",
      "Params: tensor([  4.4826, -11.9744])\n",
      "Grad:   tensor([-0.0065,  0.0366])\n",
      "Epoch 2387, Loss 8.704562\n",
      "Params: tensor([  4.4827, -11.9748])\n",
      "Grad:   tensor([-0.0064,  0.0365])\n",
      "Epoch 2388, Loss 8.704548\n",
      "Params: tensor([  4.4828, -11.9752])\n",
      "Grad:   tensor([-0.0064,  0.0365])\n",
      "Epoch 2389, Loss 8.704533\n",
      "Params: tensor([  4.4828, -11.9755])\n",
      "Grad:   tensor([-0.0064,  0.0364])\n",
      "Epoch 2390, Loss 8.704519\n",
      "Params: tensor([  4.4829, -11.9759])\n",
      "Grad:   tensor([-0.0064,  0.0363])\n",
      "Epoch 2391, Loss 8.704508\n",
      "Params: tensor([  4.4829, -11.9763])\n",
      "Grad:   tensor([-0.0064,  0.0363])\n",
      "Epoch 2392, Loss 8.704494\n",
      "Params: tensor([  4.4830, -11.9766])\n",
      "Grad:   tensor([-0.0064,  0.0362])\n",
      "Epoch 2393, Loss 8.704479\n",
      "Params: tensor([  4.4831, -11.9770])\n",
      "Grad:   tensor([-0.0064,  0.0362])\n",
      "Epoch 2394, Loss 8.704465\n",
      "Params: tensor([  4.4831, -11.9774])\n",
      "Grad:   tensor([-0.0064,  0.0361])\n",
      "Epoch 2395, Loss 8.704453\n",
      "Params: tensor([  4.4832, -11.9777])\n",
      "Grad:   tensor([-0.0064,  0.0360])\n",
      "Epoch 2396, Loss 8.704438\n",
      "Params: tensor([  4.4833, -11.9781])\n",
      "Grad:   tensor([-0.0064,  0.0360])\n",
      "Epoch 2397, Loss 8.704426\n",
      "Params: tensor([  4.4833, -11.9784])\n",
      "Grad:   tensor([-0.0064,  0.0359])\n",
      "Epoch 2398, Loss 8.704412\n",
      "Params: tensor([  4.4834, -11.9788])\n",
      "Grad:   tensor([-0.0064,  0.0358])\n",
      "Epoch 2399, Loss 8.704400\n",
      "Params: tensor([  4.4835, -11.9791])\n",
      "Grad:   tensor([-0.0063,  0.0358])\n",
      "Epoch 2400, Loss 8.704386\n",
      "Params: tensor([  4.4835, -11.9795])\n",
      "Grad:   tensor([-0.0063,  0.0357])\n",
      "Epoch 2401, Loss 8.704373\n",
      "Params: tensor([  4.4836, -11.9799])\n",
      "Grad:   tensor([-0.0063,  0.0357])\n",
      "Epoch 2402, Loss 8.704360\n",
      "Params: tensor([  4.4836, -11.9802])\n",
      "Grad:   tensor([-0.0063,  0.0356])\n",
      "Epoch 2403, Loss 8.704349\n",
      "Params: tensor([  4.4837, -11.9806])\n",
      "Grad:   tensor([-0.0063,  0.0355])\n",
      "Epoch 2404, Loss 8.704334\n",
      "Params: tensor([  4.4838, -11.9809])\n",
      "Grad:   tensor([-0.0063,  0.0355])\n",
      "Epoch 2405, Loss 8.704322\n",
      "Params: tensor([  4.4838, -11.9813])\n",
      "Grad:   tensor([-0.0062,  0.0354])\n",
      "Epoch 2406, Loss 8.704309\n",
      "Params: tensor([  4.4839, -11.9816])\n",
      "Grad:   tensor([-0.0062,  0.0354])\n",
      "Epoch 2407, Loss 8.704299\n",
      "Params: tensor([  4.4840, -11.9820])\n",
      "Grad:   tensor([-0.0062,  0.0353])\n",
      "Epoch 2408, Loss 8.704282\n",
      "Params: tensor([  4.4840, -11.9823])\n",
      "Grad:   tensor([-0.0062,  0.0352])\n",
      "Epoch 2409, Loss 8.704270\n",
      "Params: tensor([  4.4841, -11.9827])\n",
      "Grad:   tensor([-0.0062,  0.0352])\n",
      "Epoch 2410, Loss 8.704258\n",
      "Params: tensor([  4.4841, -11.9830])\n",
      "Grad:   tensor([-0.0062,  0.0351])\n",
      "Epoch 2411, Loss 8.704246\n",
      "Params: tensor([  4.4842, -11.9834])\n",
      "Grad:   tensor([-0.0062,  0.0351])\n",
      "Epoch 2412, Loss 8.704232\n",
      "Params: tensor([  4.4843, -11.9837])\n",
      "Grad:   tensor([-0.0062,  0.0350])\n",
      "Epoch 2413, Loss 8.704220\n",
      "Params: tensor([  4.4843, -11.9841])\n",
      "Grad:   tensor([-0.0062,  0.0349])\n",
      "Epoch 2414, Loss 8.704207\n",
      "Params: tensor([  4.4844, -11.9844])\n",
      "Grad:   tensor([-0.0061,  0.0349])\n",
      "Epoch 2415, Loss 8.704193\n",
      "Params: tensor([  4.4844, -11.9848])\n",
      "Grad:   tensor([-0.0061,  0.0348])\n",
      "Epoch 2416, Loss 8.704182\n",
      "Params: tensor([  4.4845, -11.9851])\n",
      "Grad:   tensor([-0.0061,  0.0348])\n",
      "Epoch 2417, Loss 8.704171\n",
      "Params: tensor([  4.4846, -11.9855])\n",
      "Grad:   tensor([-0.0061,  0.0347])\n",
      "Epoch 2418, Loss 8.704157\n",
      "Params: tensor([  4.4846, -11.9858])\n",
      "Grad:   tensor([-0.0061,  0.0346])\n",
      "Epoch 2419, Loss 8.704146\n",
      "Params: tensor([  4.4847, -11.9862])\n",
      "Grad:   tensor([-0.0061,  0.0346])\n",
      "Epoch 2420, Loss 8.704132\n",
      "Params: tensor([  4.4848, -11.9865])\n",
      "Grad:   tensor([-0.0061,  0.0345])\n",
      "Epoch 2421, Loss 8.704122\n",
      "Params: tensor([  4.4848, -11.9869])\n",
      "Grad:   tensor([-0.0061,  0.0345])\n",
      "Epoch 2422, Loss 8.704108\n",
      "Params: tensor([  4.4849, -11.9872])\n",
      "Grad:   tensor([-0.0061,  0.0344])\n",
      "Epoch 2423, Loss 8.704098\n",
      "Params: tensor([  4.4849, -11.9876])\n",
      "Grad:   tensor([-0.0061,  0.0344])\n",
      "Epoch 2424, Loss 8.704082\n",
      "Params: tensor([  4.4850, -11.9879])\n",
      "Grad:   tensor([-0.0061,  0.0343])\n",
      "Epoch 2425, Loss 8.704070\n",
      "Params: tensor([  4.4851, -11.9882])\n",
      "Grad:   tensor([-0.0061,  0.0342])\n",
      "Epoch 2426, Loss 8.704058\n",
      "Params: tensor([  4.4851, -11.9886])\n",
      "Grad:   tensor([-0.0060,  0.0342])\n",
      "Epoch 2427, Loss 8.704046\n",
      "Params: tensor([  4.4852, -11.9889])\n",
      "Grad:   tensor([-0.0060,  0.0341])\n",
      "Epoch 2428, Loss 8.704034\n",
      "Params: tensor([  4.4852, -11.9893])\n",
      "Grad:   tensor([-0.0060,  0.0341])\n",
      "Epoch 2429, Loss 8.704022\n",
      "Params: tensor([  4.4853, -11.9896])\n",
      "Grad:   tensor([-0.0060,  0.0340])\n",
      "Epoch 2430, Loss 8.704013\n",
      "Params: tensor([  4.4854, -11.9899])\n",
      "Grad:   tensor([-0.0060,  0.0339])\n",
      "Epoch 2431, Loss 8.703999\n",
      "Params: tensor([  4.4854, -11.9903])\n",
      "Grad:   tensor([-0.0060,  0.0339])\n",
      "Epoch 2432, Loss 8.703986\n",
      "Params: tensor([  4.4855, -11.9906])\n",
      "Grad:   tensor([-0.0060,  0.0338])\n",
      "Epoch 2433, Loss 8.703977\n",
      "Params: tensor([  4.4855, -11.9910])\n",
      "Grad:   tensor([-0.0060,  0.0338])\n",
      "Epoch 2434, Loss 8.703965\n",
      "Params: tensor([  4.4856, -11.9913])\n",
      "Grad:   tensor([-0.0060,  0.0337])\n",
      "Epoch 2435, Loss 8.703951\n",
      "Params: tensor([  4.4857, -11.9916])\n",
      "Grad:   tensor([-0.0059,  0.0337])\n",
      "Epoch 2436, Loss 8.703942\n",
      "Params: tensor([  4.4857, -11.9920])\n",
      "Grad:   tensor([-0.0059,  0.0336])\n",
      "Epoch 2437, Loss 8.703929\n",
      "Params: tensor([  4.4858, -11.9923])\n",
      "Grad:   tensor([-0.0059,  0.0335])\n",
      "Epoch 2438, Loss 8.703918\n",
      "Params: tensor([  4.4858, -11.9926])\n",
      "Grad:   tensor([-0.0059,  0.0335])\n",
      "Epoch 2439, Loss 8.703907\n",
      "Params: tensor([  4.4859, -11.9930])\n",
      "Grad:   tensor([-0.0059,  0.0334])\n",
      "Epoch 2440, Loss 8.703896\n",
      "Params: tensor([  4.4860, -11.9933])\n",
      "Grad:   tensor([-0.0059,  0.0334])\n",
      "Epoch 2441, Loss 8.703884\n",
      "Params: tensor([  4.4860, -11.9936])\n",
      "Grad:   tensor([-0.0059,  0.0333])\n",
      "Epoch 2442, Loss 8.703874\n",
      "Params: tensor([  4.4861, -11.9940])\n",
      "Grad:   tensor([-0.0059,  0.0333])\n",
      "Epoch 2443, Loss 8.703859\n",
      "Params: tensor([  4.4861, -11.9943])\n",
      "Grad:   tensor([-0.0059,  0.0332])\n",
      "Epoch 2444, Loss 8.703848\n",
      "Params: tensor([  4.4862, -11.9946])\n",
      "Grad:   tensor([-0.0058,  0.0332])\n",
      "Epoch 2445, Loss 8.703838\n",
      "Params: tensor([  4.4862, -11.9950])\n",
      "Grad:   tensor([-0.0058,  0.0331])\n",
      "Epoch 2446, Loss 8.703826\n",
      "Params: tensor([  4.4863, -11.9953])\n",
      "Grad:   tensor([-0.0058,  0.0330])\n",
      "Epoch 2447, Loss 8.703813\n",
      "Params: tensor([  4.4864, -11.9956])\n",
      "Grad:   tensor([-0.0058,  0.0330])\n",
      "Epoch 2448, Loss 8.703803\n",
      "Params: tensor([  4.4864, -11.9960])\n",
      "Grad:   tensor([-0.0058,  0.0329])\n",
      "Epoch 2449, Loss 8.703793\n",
      "Params: tensor([  4.4865, -11.9963])\n",
      "Grad:   tensor([-0.0058,  0.0329])\n",
      "Epoch 2450, Loss 8.703780\n",
      "Params: tensor([  4.4865, -11.9966])\n",
      "Grad:   tensor([-0.0058,  0.0328])\n",
      "Epoch 2451, Loss 8.703770\n",
      "Params: tensor([  4.4866, -11.9969])\n",
      "Grad:   tensor([-0.0058,  0.0328])\n",
      "Epoch 2452, Loss 8.703759\n",
      "Params: tensor([  4.4867, -11.9973])\n",
      "Grad:   tensor([-0.0058,  0.0327])\n",
      "Epoch 2453, Loss 8.703748\n",
      "Params: tensor([  4.4867, -11.9976])\n",
      "Grad:   tensor([-0.0058,  0.0326])\n",
      "Epoch 2454, Loss 8.703735\n",
      "Params: tensor([  4.4868, -11.9979])\n",
      "Grad:   tensor([-0.0058,  0.0326])\n",
      "Epoch 2455, Loss 8.703727\n",
      "Params: tensor([  4.4868, -11.9982])\n",
      "Grad:   tensor([-0.0058,  0.0325])\n",
      "Epoch 2456, Loss 8.703714\n",
      "Params: tensor([  4.4869, -11.9986])\n",
      "Grad:   tensor([-0.0057,  0.0325])\n",
      "Epoch 2457, Loss 8.703705\n",
      "Params: tensor([  4.4869, -11.9989])\n",
      "Grad:   tensor([-0.0057,  0.0324])\n",
      "Epoch 2458, Loss 8.703692\n",
      "Params: tensor([  4.4870, -11.9992])\n",
      "Grad:   tensor([-0.0057,  0.0324])\n",
      "Epoch 2459, Loss 8.703682\n",
      "Params: tensor([  4.4871, -11.9995])\n",
      "Grad:   tensor([-0.0057,  0.0323])\n",
      "Epoch 2460, Loss 8.703673\n",
      "Params: tensor([  4.4871, -11.9999])\n",
      "Grad:   tensor([-0.0057,  0.0323])\n",
      "Epoch 2461, Loss 8.703661\n",
      "Params: tensor([  4.4872, -12.0002])\n",
      "Grad:   tensor([-0.0057,  0.0322])\n",
      "Epoch 2462, Loss 8.703650\n",
      "Params: tensor([  4.4872, -12.0005])\n",
      "Grad:   tensor([-0.0057,  0.0321])\n",
      "Epoch 2463, Loss 8.703640\n",
      "Params: tensor([  4.4873, -12.0008])\n",
      "Grad:   tensor([-0.0057,  0.0321])\n",
      "Epoch 2464, Loss 8.703629\n",
      "Params: tensor([  4.4873, -12.0011])\n",
      "Grad:   tensor([-0.0057,  0.0320])\n",
      "Epoch 2465, Loss 8.703620\n",
      "Params: tensor([  4.4874, -12.0015])\n",
      "Grad:   tensor([-0.0057,  0.0320])\n",
      "Epoch 2466, Loss 8.703609\n",
      "Params: tensor([  4.4875, -12.0018])\n",
      "Grad:   tensor([-0.0056,  0.0319])\n",
      "Epoch 2467, Loss 8.703598\n",
      "Params: tensor([  4.4875, -12.0021])\n",
      "Grad:   tensor([-0.0056,  0.0319])\n",
      "Epoch 2468, Loss 8.703585\n",
      "Params: tensor([  4.4876, -12.0024])\n",
      "Grad:   tensor([-0.0056,  0.0318])\n",
      "Epoch 2469, Loss 8.703579\n",
      "Params: tensor([  4.4876, -12.0027])\n",
      "Grad:   tensor([-0.0056,  0.0318])\n",
      "Epoch 2470, Loss 8.703567\n",
      "Params: tensor([  4.4877, -12.0031])\n",
      "Grad:   tensor([-0.0056,  0.0317])\n",
      "Epoch 2471, Loss 8.703555\n",
      "Params: tensor([  4.4877, -12.0034])\n",
      "Grad:   tensor([-0.0056,  0.0317])\n",
      "Epoch 2472, Loss 8.703546\n",
      "Params: tensor([  4.4878, -12.0037])\n",
      "Grad:   tensor([-0.0056,  0.0316])\n",
      "Epoch 2473, Loss 8.703536\n",
      "Params: tensor([  4.4878, -12.0040])\n",
      "Grad:   tensor([-0.0056,  0.0316])\n",
      "Epoch 2474, Loss 8.703528\n",
      "Params: tensor([  4.4879, -12.0043])\n",
      "Grad:   tensor([-0.0056,  0.0315])\n",
      "Epoch 2475, Loss 8.703515\n",
      "Params: tensor([  4.4880, -12.0046])\n",
      "Grad:   tensor([-0.0056,  0.0314])\n",
      "Epoch 2476, Loss 8.703506\n",
      "Params: tensor([  4.4880, -12.0050])\n",
      "Grad:   tensor([-0.0055,  0.0314])\n",
      "Epoch 2477, Loss 8.703494\n",
      "Params: tensor([  4.4881, -12.0053])\n",
      "Grad:   tensor([-0.0055,  0.0313])\n",
      "Epoch 2478, Loss 8.703487\n",
      "Params: tensor([  4.4881, -12.0056])\n",
      "Grad:   tensor([-0.0055,  0.0313])\n",
      "Epoch 2479, Loss 8.703473\n",
      "Params: tensor([  4.4882, -12.0059])\n",
      "Grad:   tensor([-0.0055,  0.0312])\n",
      "Epoch 2480, Loss 8.703464\n",
      "Params: tensor([  4.4882, -12.0062])\n",
      "Grad:   tensor([-0.0055,  0.0312])\n",
      "Epoch 2481, Loss 8.703454\n",
      "Params: tensor([  4.4883, -12.0065])\n",
      "Grad:   tensor([-0.0055,  0.0311])\n",
      "Epoch 2482, Loss 8.703445\n",
      "Params: tensor([  4.4883, -12.0068])\n",
      "Grad:   tensor([-0.0055,  0.0311])\n",
      "Epoch 2483, Loss 8.703434\n",
      "Params: tensor([  4.4884, -12.0071])\n",
      "Grad:   tensor([-0.0055,  0.0310])\n",
      "Epoch 2484, Loss 8.703424\n",
      "Params: tensor([  4.4885, -12.0074])\n",
      "Grad:   tensor([-0.0055,  0.0310])\n",
      "Epoch 2485, Loss 8.703414\n",
      "Params: tensor([  4.4885, -12.0078])\n",
      "Grad:   tensor([-0.0054,  0.0309])\n",
      "Epoch 2486, Loss 8.703407\n",
      "Params: tensor([  4.4886, -12.0081])\n",
      "Grad:   tensor([-0.0055,  0.0309])\n",
      "Epoch 2487, Loss 8.703393\n",
      "Params: tensor([  4.4886, -12.0084])\n",
      "Grad:   tensor([-0.0055,  0.0308])\n",
      "Epoch 2488, Loss 8.703383\n",
      "Params: tensor([  4.4887, -12.0087])\n",
      "Grad:   tensor([-0.0054,  0.0308])\n",
      "Epoch 2489, Loss 8.703376\n",
      "Params: tensor([  4.4887, -12.0090])\n",
      "Grad:   tensor([-0.0054,  0.0307])\n",
      "Epoch 2490, Loss 8.703365\n",
      "Params: tensor([  4.4888, -12.0093])\n",
      "Grad:   tensor([-0.0054,  0.0307])\n",
      "Epoch 2491, Loss 8.703356\n",
      "Params: tensor([  4.4888, -12.0096])\n",
      "Grad:   tensor([-0.0054,  0.0306])\n",
      "Epoch 2492, Loss 8.703346\n",
      "Params: tensor([  4.4889, -12.0099])\n",
      "Grad:   tensor([-0.0054,  0.0306])\n",
      "Epoch 2493, Loss 8.703338\n",
      "Params: tensor([  4.4889, -12.0102])\n",
      "Grad:   tensor([-0.0054,  0.0305])\n",
      "Epoch 2494, Loss 8.703328\n",
      "Params: tensor([  4.4890, -12.0105])\n",
      "Grad:   tensor([-0.0054,  0.0304])\n",
      "Epoch 2495, Loss 8.703318\n",
      "Params: tensor([  4.4890, -12.0108])\n",
      "Grad:   tensor([-0.0054,  0.0304])\n",
      "Epoch 2496, Loss 8.703309\n",
      "Params: tensor([  4.4891, -12.0111])\n",
      "Grad:   tensor([-0.0054,  0.0303])\n",
      "Epoch 2497, Loss 8.703299\n",
      "Params: tensor([  4.4892, -12.0114])\n",
      "Grad:   tensor([-0.0054,  0.0303])\n",
      "Epoch 2498, Loss 8.703287\n",
      "Params: tensor([  4.4892, -12.0117])\n",
      "Grad:   tensor([-0.0054,  0.0302])\n",
      "Epoch 2499, Loss 8.703280\n",
      "Params: tensor([  4.4893, -12.0120])\n",
      "Grad:   tensor([-0.0054,  0.0302])\n",
      "Epoch 2500, Loss 8.703269\n",
      "Params: tensor([  4.4893, -12.0123])\n",
      "Grad:   tensor([-0.0053,  0.0301])\n",
      "Epoch 2501, Loss 8.703262\n",
      "Params: tensor([  4.4894, -12.0126])\n",
      "Grad:   tensor([-0.0053,  0.0301])\n",
      "Epoch 2502, Loss 8.703253\n",
      "Params: tensor([  4.4894, -12.0129])\n",
      "Grad:   tensor([-0.0053,  0.0300])\n",
      "Epoch 2503, Loss 8.703241\n",
      "Params: tensor([  4.4895, -12.0132])\n",
      "Grad:   tensor([-0.0053,  0.0300])\n",
      "Epoch 2504, Loss 8.703234\n",
      "Params: tensor([  4.4895, -12.0135])\n",
      "Grad:   tensor([-0.0053,  0.0299])\n",
      "Epoch 2505, Loss 8.703223\n",
      "Params: tensor([  4.4896, -12.0138])\n",
      "Grad:   tensor([-0.0053,  0.0299])\n",
      "Epoch 2506, Loss 8.703216\n",
      "Params: tensor([  4.4896, -12.0141])\n",
      "Grad:   tensor([-0.0052,  0.0298])\n",
      "Epoch 2507, Loss 8.703208\n",
      "Params: tensor([  4.4897, -12.0144])\n",
      "Grad:   tensor([-0.0053,  0.0298])\n",
      "Epoch 2508, Loss 8.703197\n",
      "Params: tensor([  4.4897, -12.0147])\n",
      "Grad:   tensor([-0.0053,  0.0297])\n",
      "Epoch 2509, Loss 8.703186\n",
      "Params: tensor([  4.4898, -12.0150])\n",
      "Grad:   tensor([-0.0053,  0.0297])\n",
      "Epoch 2510, Loss 8.703177\n",
      "Params: tensor([  4.4898, -12.0153])\n",
      "Grad:   tensor([-0.0052,  0.0296])\n",
      "Epoch 2511, Loss 8.703169\n",
      "Params: tensor([  4.4899, -12.0156])\n",
      "Grad:   tensor([-0.0052,  0.0296])\n",
      "Epoch 2512, Loss 8.703161\n",
      "Params: tensor([  4.4899, -12.0159])\n",
      "Grad:   tensor([-0.0052,  0.0295])\n",
      "Epoch 2513, Loss 8.703152\n",
      "Params: tensor([  4.4900, -12.0162])\n",
      "Grad:   tensor([-0.0052,  0.0295])\n",
      "Epoch 2514, Loss 8.703142\n",
      "Params: tensor([  4.4900, -12.0165])\n",
      "Grad:   tensor([-0.0052,  0.0294])\n",
      "Epoch 2515, Loss 8.703134\n",
      "Params: tensor([  4.4901, -12.0168])\n",
      "Grad:   tensor([-0.0052,  0.0294])\n",
      "Epoch 2516, Loss 8.703124\n",
      "Params: tensor([  4.4902, -12.0171])\n",
      "Grad:   tensor([-0.0052,  0.0293])\n",
      "Epoch 2517, Loss 8.703116\n",
      "Params: tensor([  4.4902, -12.0174])\n",
      "Grad:   tensor([-0.0052,  0.0293])\n",
      "Epoch 2518, Loss 8.703107\n",
      "Params: tensor([  4.4903, -12.0177])\n",
      "Grad:   tensor([-0.0052,  0.0292])\n",
      "Epoch 2519, Loss 8.703098\n",
      "Params: tensor([  4.4903, -12.0180])\n",
      "Grad:   tensor([-0.0052,  0.0292])\n",
      "Epoch 2520, Loss 8.703089\n",
      "Params: tensor([  4.4904, -12.0183])\n",
      "Grad:   tensor([-0.0052,  0.0291])\n",
      "Epoch 2521, Loss 8.703078\n",
      "Params: tensor([  4.4904, -12.0185])\n",
      "Grad:   tensor([-0.0051,  0.0291])\n",
      "Epoch 2522, Loss 8.703071\n",
      "Params: tensor([  4.4905, -12.0188])\n",
      "Grad:   tensor([-0.0051,  0.0290])\n",
      "Epoch 2523, Loss 8.703063\n",
      "Params: tensor([  4.4905, -12.0191])\n",
      "Grad:   tensor([-0.0051,  0.0290])\n",
      "Epoch 2524, Loss 8.703055\n",
      "Params: tensor([  4.4906, -12.0194])\n",
      "Grad:   tensor([-0.0051,  0.0289])\n",
      "Epoch 2525, Loss 8.703044\n",
      "Params: tensor([  4.4906, -12.0197])\n",
      "Grad:   tensor([-0.0051,  0.0289])\n",
      "Epoch 2526, Loss 8.703038\n",
      "Params: tensor([  4.4907, -12.0200])\n",
      "Grad:   tensor([-0.0051,  0.0288])\n",
      "Epoch 2527, Loss 8.703028\n",
      "Params: tensor([  4.4907, -12.0203])\n",
      "Grad:   tensor([-0.0051,  0.0288])\n",
      "Epoch 2528, Loss 8.703022\n",
      "Params: tensor([  4.4908, -12.0206])\n",
      "Grad:   tensor([-0.0051,  0.0287])\n",
      "Epoch 2529, Loss 8.703010\n",
      "Params: tensor([  4.4908, -12.0208])\n",
      "Grad:   tensor([-0.0051,  0.0287])\n",
      "Epoch 2530, Loss 8.703003\n",
      "Params: tensor([  4.4909, -12.0211])\n",
      "Grad:   tensor([-0.0051,  0.0286])\n",
      "Epoch 2531, Loss 8.702994\n",
      "Params: tensor([  4.4909, -12.0214])\n",
      "Grad:   tensor([-0.0050,  0.0286])\n",
      "Epoch 2532, Loss 8.702984\n",
      "Params: tensor([  4.4910, -12.0217])\n",
      "Grad:   tensor([-0.0050,  0.0285])\n",
      "Epoch 2533, Loss 8.702976\n",
      "Params: tensor([  4.4910, -12.0220])\n",
      "Grad:   tensor([-0.0050,  0.0285])\n",
      "Epoch 2534, Loss 8.702967\n",
      "Params: tensor([  4.4911, -12.0223])\n",
      "Grad:   tensor([-0.0050,  0.0284])\n",
      "Epoch 2535, Loss 8.702961\n",
      "Params: tensor([  4.4911, -12.0226])\n",
      "Grad:   tensor([-0.0050,  0.0284])\n",
      "Epoch 2536, Loss 8.702951\n",
      "Params: tensor([  4.4912, -12.0228])\n",
      "Grad:   tensor([-0.0050,  0.0283])\n",
      "Epoch 2537, Loss 8.702946\n",
      "Params: tensor([  4.4912, -12.0231])\n",
      "Grad:   tensor([-0.0050,  0.0283])\n",
      "Epoch 2538, Loss 8.702937\n",
      "Params: tensor([  4.4913, -12.0234])\n",
      "Grad:   tensor([-0.0050,  0.0283])\n",
      "Epoch 2539, Loss 8.702928\n",
      "Params: tensor([  4.4913, -12.0237])\n",
      "Grad:   tensor([-0.0050,  0.0282])\n",
      "Epoch 2540, Loss 8.702920\n",
      "Params: tensor([  4.4914, -12.0240])\n",
      "Grad:   tensor([-0.0050,  0.0282])\n",
      "Epoch 2541, Loss 8.702912\n",
      "Params: tensor([  4.4914, -12.0243])\n",
      "Grad:   tensor([-0.0050,  0.0281])\n",
      "Epoch 2542, Loss 8.702903\n",
      "Params: tensor([  4.4915, -12.0245])\n",
      "Grad:   tensor([-0.0050,  0.0281])\n",
      "Epoch 2543, Loss 8.702893\n",
      "Params: tensor([  4.4915, -12.0248])\n",
      "Grad:   tensor([-0.0049,  0.0280])\n",
      "Epoch 2544, Loss 8.702888\n",
      "Params: tensor([  4.4916, -12.0251])\n",
      "Grad:   tensor([-0.0049,  0.0280])\n",
      "Epoch 2545, Loss 8.702880\n",
      "Params: tensor([  4.4916, -12.0254])\n",
      "Grad:   tensor([-0.0049,  0.0279])\n",
      "Epoch 2546, Loss 8.702872\n",
      "Params: tensor([  4.4917, -12.0257])\n",
      "Grad:   tensor([-0.0049,  0.0279])\n",
      "Epoch 2547, Loss 8.702862\n",
      "Params: tensor([  4.4917, -12.0259])\n",
      "Grad:   tensor([-0.0049,  0.0278])\n",
      "Epoch 2548, Loss 8.702857\n",
      "Params: tensor([  4.4918, -12.0262])\n",
      "Grad:   tensor([-0.0049,  0.0278])\n",
      "Epoch 2549, Loss 8.702847\n",
      "Params: tensor([  4.4918, -12.0265])\n",
      "Grad:   tensor([-0.0049,  0.0277])\n",
      "Epoch 2550, Loss 8.702838\n",
      "Params: tensor([  4.4919, -12.0268])\n",
      "Grad:   tensor([-0.0049,  0.0277])\n",
      "Epoch 2551, Loss 8.702833\n",
      "Params: tensor([  4.4919, -12.0270])\n",
      "Grad:   tensor([-0.0049,  0.0276])\n",
      "Epoch 2552, Loss 8.702824\n",
      "Params: tensor([  4.4920, -12.0273])\n",
      "Grad:   tensor([-0.0049,  0.0276])\n",
      "Epoch 2553, Loss 8.702815\n",
      "Params: tensor([  4.4920, -12.0276])\n",
      "Grad:   tensor([-0.0049,  0.0275])\n",
      "Epoch 2554, Loss 8.702807\n",
      "Params: tensor([  4.4921, -12.0279])\n",
      "Grad:   tensor([-0.0048,  0.0275])\n",
      "Epoch 2555, Loss 8.702801\n",
      "Params: tensor([  4.4921, -12.0281])\n",
      "Grad:   tensor([-0.0048,  0.0275])\n",
      "Epoch 2556, Loss 8.702791\n",
      "Params: tensor([  4.4922, -12.0284])\n",
      "Grad:   tensor([-0.0048,  0.0274])\n",
      "Epoch 2557, Loss 8.702785\n",
      "Params: tensor([  4.4922, -12.0287])\n",
      "Grad:   tensor([-0.0048,  0.0274])\n",
      "Epoch 2558, Loss 8.702778\n",
      "Params: tensor([  4.4923, -12.0290])\n",
      "Grad:   tensor([-0.0048,  0.0273])\n",
      "Epoch 2559, Loss 8.702768\n",
      "Params: tensor([  4.4923, -12.0292])\n",
      "Grad:   tensor([-0.0048,  0.0273])\n",
      "Epoch 2560, Loss 8.702763\n",
      "Params: tensor([  4.4923, -12.0295])\n",
      "Grad:   tensor([-0.0048,  0.0272])\n",
      "Epoch 2561, Loss 8.702752\n",
      "Params: tensor([  4.4924, -12.0298])\n",
      "Grad:   tensor([-0.0048,  0.0272])\n",
      "Epoch 2562, Loss 8.702744\n",
      "Params: tensor([  4.4924, -12.0300])\n",
      "Grad:   tensor([-0.0048,  0.0271])\n",
      "Epoch 2563, Loss 8.702739\n",
      "Params: tensor([  4.4925, -12.0303])\n",
      "Grad:   tensor([-0.0048,  0.0271])\n",
      "Epoch 2564, Loss 8.702729\n",
      "Params: tensor([  4.4925, -12.0306])\n",
      "Grad:   tensor([-0.0048,  0.0270])\n",
      "Epoch 2565, Loss 8.702724\n",
      "Params: tensor([  4.4926, -12.0309])\n",
      "Grad:   tensor([-0.0048,  0.0270])\n",
      "Epoch 2566, Loss 8.702713\n",
      "Params: tensor([  4.4926, -12.0311])\n",
      "Grad:   tensor([-0.0048,  0.0269])\n",
      "Epoch 2567, Loss 8.702707\n",
      "Params: tensor([  4.4927, -12.0314])\n",
      "Grad:   tensor([-0.0047,  0.0269])\n",
      "Epoch 2568, Loss 8.702702\n",
      "Params: tensor([  4.4927, -12.0317])\n",
      "Grad:   tensor([-0.0047,  0.0269])\n",
      "Epoch 2569, Loss 8.702692\n",
      "Params: tensor([  4.4928, -12.0319])\n",
      "Grad:   tensor([-0.0047,  0.0268])\n",
      "Epoch 2570, Loss 8.702690\n",
      "Params: tensor([  4.4928, -12.0322])\n",
      "Grad:   tensor([-0.0047,  0.0268])\n",
      "Epoch 2571, Loss 8.702680\n",
      "Params: tensor([  4.4929, -12.0325])\n",
      "Grad:   tensor([-0.0047,  0.0267])\n",
      "Epoch 2572, Loss 8.702670\n",
      "Params: tensor([  4.4929, -12.0327])\n",
      "Grad:   tensor([-0.0047,  0.0267])\n",
      "Epoch 2573, Loss 8.702665\n",
      "Params: tensor([  4.4930, -12.0330])\n",
      "Grad:   tensor([-0.0047,  0.0266])\n",
      "Epoch 2574, Loss 8.702659\n",
      "Params: tensor([  4.4930, -12.0333])\n",
      "Grad:   tensor([-0.0047,  0.0266])\n",
      "Epoch 2575, Loss 8.702648\n",
      "Params: tensor([  4.4931, -12.0335])\n",
      "Grad:   tensor([-0.0047,  0.0265])\n",
      "Epoch 2576, Loss 8.702642\n",
      "Params: tensor([  4.4931, -12.0338])\n",
      "Grad:   tensor([-0.0047,  0.0265])\n",
      "Epoch 2577, Loss 8.702635\n",
      "Params: tensor([  4.4932, -12.0341])\n",
      "Grad:   tensor([-0.0047,  0.0264])\n",
      "Epoch 2578, Loss 8.702627\n",
      "Params: tensor([  4.4932, -12.0343])\n",
      "Grad:   tensor([-0.0047,  0.0264])\n",
      "Epoch 2579, Loss 8.702621\n",
      "Params: tensor([  4.4932, -12.0346])\n",
      "Grad:   tensor([-0.0047,  0.0264])\n",
      "Epoch 2580, Loss 8.702615\n",
      "Params: tensor([  4.4933, -12.0349])\n",
      "Grad:   tensor([-0.0046,  0.0263])\n",
      "Epoch 2581, Loss 8.702605\n",
      "Params: tensor([  4.4933, -12.0351])\n",
      "Grad:   tensor([-0.0046,  0.0263])\n",
      "Epoch 2582, Loss 8.702600\n",
      "Params: tensor([  4.4934, -12.0354])\n",
      "Grad:   tensor([-0.0046,  0.0262])\n",
      "Epoch 2583, Loss 8.702595\n",
      "Params: tensor([  4.4934, -12.0356])\n",
      "Grad:   tensor([-0.0046,  0.0262])\n",
      "Epoch 2584, Loss 8.702584\n",
      "Params: tensor([  4.4935, -12.0359])\n",
      "Grad:   tensor([-0.0046,  0.0261])\n",
      "Epoch 2585, Loss 8.702579\n",
      "Params: tensor([  4.4935, -12.0362])\n",
      "Grad:   tensor([-0.0046,  0.0261])\n",
      "Epoch 2586, Loss 8.702573\n",
      "Params: tensor([  4.4936, -12.0364])\n",
      "Grad:   tensor([-0.0046,  0.0260])\n",
      "Epoch 2587, Loss 8.702564\n",
      "Params: tensor([  4.4936, -12.0367])\n",
      "Grad:   tensor([-0.0046,  0.0260])\n",
      "Epoch 2588, Loss 8.702557\n",
      "Params: tensor([  4.4937, -12.0369])\n",
      "Grad:   tensor([-0.0046,  0.0259])\n",
      "Epoch 2589, Loss 8.702550\n",
      "Params: tensor([  4.4937, -12.0372])\n",
      "Grad:   tensor([-0.0046,  0.0259])\n",
      "Epoch 2590, Loss 8.702545\n",
      "Params: tensor([  4.4938, -12.0375])\n",
      "Grad:   tensor([-0.0046,  0.0259])\n",
      "Epoch 2591, Loss 8.702537\n",
      "Params: tensor([  4.4938, -12.0377])\n",
      "Grad:   tensor([-0.0046,  0.0258])\n",
      "Epoch 2592, Loss 8.702529\n",
      "Params: tensor([  4.4938, -12.0380])\n",
      "Grad:   tensor([-0.0046,  0.0258])\n",
      "Epoch 2593, Loss 8.702523\n",
      "Params: tensor([  4.4939, -12.0382])\n",
      "Grad:   tensor([-0.0045,  0.0257])\n",
      "Epoch 2594, Loss 8.702518\n",
      "Params: tensor([  4.4939, -12.0385])\n",
      "Grad:   tensor([-0.0045,  0.0257])\n",
      "Epoch 2595, Loss 8.702508\n",
      "Params: tensor([  4.4940, -12.0387])\n",
      "Grad:   tensor([-0.0045,  0.0256])\n",
      "Epoch 2596, Loss 8.702502\n",
      "Params: tensor([  4.4940, -12.0390])\n",
      "Grad:   tensor([-0.0045,  0.0256])\n",
      "Epoch 2597, Loss 8.702497\n",
      "Params: tensor([  4.4941, -12.0393])\n",
      "Grad:   tensor([-0.0045,  0.0256])\n",
      "Epoch 2598, Loss 8.702490\n",
      "Params: tensor([  4.4941, -12.0395])\n",
      "Grad:   tensor([-0.0045,  0.0255])\n",
      "Epoch 2599, Loss 8.702481\n",
      "Params: tensor([  4.4942, -12.0398])\n",
      "Grad:   tensor([-0.0045,  0.0255])\n",
      "Epoch 2600, Loss 8.702475\n",
      "Params: tensor([  4.4942, -12.0400])\n",
      "Grad:   tensor([-0.0045,  0.0254])\n",
      "Epoch 2601, Loss 8.702469\n",
      "Params: tensor([  4.4943, -12.0403])\n",
      "Grad:   tensor([-0.0045,  0.0254])\n",
      "Epoch 2602, Loss 8.702461\n",
      "Params: tensor([  4.4943, -12.0405])\n",
      "Grad:   tensor([-0.0045,  0.0253])\n",
      "Epoch 2603, Loss 8.702455\n",
      "Params: tensor([  4.4943, -12.0408])\n",
      "Grad:   tensor([-0.0045,  0.0253])\n",
      "Epoch 2604, Loss 8.702448\n",
      "Params: tensor([  4.4944, -12.0410])\n",
      "Grad:   tensor([-0.0044,  0.0253])\n",
      "Epoch 2605, Loss 8.702444\n",
      "Params: tensor([  4.4944, -12.0413])\n",
      "Grad:   tensor([-0.0045,  0.0252])\n",
      "Epoch 2606, Loss 8.702437\n",
      "Params: tensor([  4.4945, -12.0415])\n",
      "Grad:   tensor([-0.0045,  0.0252])\n",
      "Epoch 2607, Loss 8.702430\n",
      "Params: tensor([  4.4945, -12.0418])\n",
      "Grad:   tensor([-0.0045,  0.0251])\n",
      "Epoch 2608, Loss 8.702423\n",
      "Params: tensor([  4.4946, -12.0420])\n",
      "Grad:   tensor([-0.0044,  0.0251])\n",
      "Epoch 2609, Loss 8.702416\n",
      "Params: tensor([  4.4946, -12.0423])\n",
      "Grad:   tensor([-0.0044,  0.0250])\n",
      "Epoch 2610, Loss 8.702409\n",
      "Params: tensor([  4.4947, -12.0425])\n",
      "Grad:   tensor([-0.0044,  0.0250])\n",
      "Epoch 2611, Loss 8.702404\n",
      "Params: tensor([  4.4947, -12.0428])\n",
      "Grad:   tensor([-0.0044,  0.0250])\n",
      "Epoch 2612, Loss 8.702398\n",
      "Params: tensor([  4.4947, -12.0430])\n",
      "Grad:   tensor([-0.0044,  0.0249])\n",
      "Epoch 2613, Loss 8.702389\n",
      "Params: tensor([  4.4948, -12.0433])\n",
      "Grad:   tensor([-0.0044,  0.0249])\n",
      "Epoch 2614, Loss 8.702383\n",
      "Params: tensor([  4.4948, -12.0435])\n",
      "Grad:   tensor([-0.0044,  0.0248])\n",
      "Epoch 2615, Loss 8.702377\n",
      "Params: tensor([  4.4949, -12.0438])\n",
      "Grad:   tensor([-0.0044,  0.0248])\n",
      "Epoch 2616, Loss 8.702374\n",
      "Params: tensor([  4.4949, -12.0440])\n",
      "Grad:   tensor([-0.0044,  0.0247])\n",
      "Epoch 2617, Loss 8.702367\n",
      "Params: tensor([  4.4950, -12.0443])\n",
      "Grad:   tensor([-0.0044,  0.0247])\n",
      "Epoch 2618, Loss 8.702359\n",
      "Params: tensor([  4.4950, -12.0445])\n",
      "Grad:   tensor([-0.0043,  0.0247])\n",
      "Epoch 2619, Loss 8.702353\n",
      "Params: tensor([  4.4950, -12.0448])\n",
      "Grad:   tensor([-0.0044,  0.0246])\n",
      "Epoch 2620, Loss 8.702345\n",
      "Params: tensor([  4.4951, -12.0450])\n",
      "Grad:   tensor([-0.0044,  0.0246])\n",
      "Epoch 2621, Loss 8.702341\n",
      "Params: tensor([  4.4951, -12.0453])\n",
      "Grad:   tensor([-0.0043,  0.0245])\n",
      "Epoch 2622, Loss 8.702335\n",
      "Params: tensor([  4.4952, -12.0455])\n",
      "Grad:   tensor([-0.0043,  0.0245])\n",
      "Epoch 2623, Loss 8.702330\n",
      "Params: tensor([  4.4952, -12.0457])\n",
      "Grad:   tensor([-0.0043,  0.0245])\n",
      "Epoch 2624, Loss 8.702322\n",
      "Params: tensor([  4.4953, -12.0460])\n",
      "Grad:   tensor([-0.0043,  0.0244])\n",
      "Epoch 2625, Loss 8.702316\n",
      "Params: tensor([  4.4953, -12.0462])\n",
      "Grad:   tensor([-0.0043,  0.0244])\n",
      "Epoch 2626, Loss 8.702311\n",
      "Params: tensor([  4.4953, -12.0465])\n",
      "Grad:   tensor([-0.0043,  0.0243])\n",
      "Epoch 2627, Loss 8.702304\n",
      "Params: tensor([  4.4954, -12.0467])\n",
      "Grad:   tensor([-0.0043,  0.0243])\n",
      "Epoch 2628, Loss 8.702298\n",
      "Params: tensor([  4.4954, -12.0470])\n",
      "Grad:   tensor([-0.0043,  0.0242])\n",
      "Epoch 2629, Loss 8.702291\n",
      "Params: tensor([  4.4955, -12.0472])\n",
      "Grad:   tensor([-0.0043,  0.0242])\n",
      "Epoch 2630, Loss 8.702285\n",
      "Params: tensor([  4.4955, -12.0475])\n",
      "Grad:   tensor([-0.0043,  0.0242])\n",
      "Epoch 2631, Loss 8.702279\n",
      "Params: tensor([  4.4956, -12.0477])\n",
      "Grad:   tensor([-0.0042,  0.0241])\n",
      "Epoch 2632, Loss 8.702273\n",
      "Params: tensor([  4.4956, -12.0479])\n",
      "Grad:   tensor([-0.0042,  0.0241])\n",
      "Epoch 2633, Loss 8.702267\n",
      "Params: tensor([  4.4956, -12.0482])\n",
      "Grad:   tensor([-0.0042,  0.0240])\n",
      "Epoch 2634, Loss 8.702260\n",
      "Params: tensor([  4.4957, -12.0484])\n",
      "Grad:   tensor([-0.0042,  0.0240])\n",
      "Epoch 2635, Loss 8.702255\n",
      "Params: tensor([  4.4957, -12.0487])\n",
      "Grad:   tensor([-0.0042,  0.0240])\n",
      "Epoch 2636, Loss 8.702250\n",
      "Params: tensor([  4.4958, -12.0489])\n",
      "Grad:   tensor([-0.0042,  0.0239])\n",
      "Epoch 2637, Loss 8.702244\n",
      "Params: tensor([  4.4958, -12.0491])\n",
      "Grad:   tensor([-0.0042,  0.0239])\n",
      "Epoch 2638, Loss 8.702239\n",
      "Params: tensor([  4.4959, -12.0494])\n",
      "Grad:   tensor([-0.0042,  0.0238])\n",
      "Epoch 2639, Loss 8.702231\n",
      "Params: tensor([  4.4959, -12.0496])\n",
      "Grad:   tensor([-0.0042,  0.0238])\n",
      "Epoch 2640, Loss 8.702228\n",
      "Params: tensor([  4.4959, -12.0498])\n",
      "Grad:   tensor([-0.0042,  0.0238])\n",
      "Epoch 2641, Loss 8.702218\n",
      "Params: tensor([  4.4960, -12.0501])\n",
      "Grad:   tensor([-0.0042,  0.0237])\n",
      "Epoch 2642, Loss 8.702215\n",
      "Params: tensor([  4.4960, -12.0503])\n",
      "Grad:   tensor([-0.0042,  0.0237])\n",
      "Epoch 2643, Loss 8.702206\n",
      "Params: tensor([  4.4961, -12.0506])\n",
      "Grad:   tensor([-0.0042,  0.0236])\n",
      "Epoch 2644, Loss 8.702204\n",
      "Params: tensor([  4.4961, -12.0508])\n",
      "Grad:   tensor([-0.0042,  0.0236])\n",
      "Epoch 2645, Loss 8.702198\n",
      "Params: tensor([  4.4961, -12.0510])\n",
      "Grad:   tensor([-0.0042,  0.0236])\n",
      "Epoch 2646, Loss 8.702191\n",
      "Params: tensor([  4.4962, -12.0513])\n",
      "Grad:   tensor([-0.0042,  0.0235])\n",
      "Epoch 2647, Loss 8.702186\n",
      "Params: tensor([  4.4962, -12.0515])\n",
      "Grad:   tensor([-0.0042,  0.0235])\n",
      "Epoch 2648, Loss 8.702180\n",
      "Params: tensor([  4.4963, -12.0517])\n",
      "Grad:   tensor([-0.0042,  0.0234])\n",
      "Epoch 2649, Loss 8.702175\n",
      "Params: tensor([  4.4963, -12.0520])\n",
      "Grad:   tensor([-0.0041,  0.0234])\n",
      "Epoch 2650, Loss 8.702169\n",
      "Params: tensor([  4.4964, -12.0522])\n",
      "Grad:   tensor([-0.0041,  0.0234])\n",
      "Epoch 2651, Loss 8.702164\n",
      "Params: tensor([  4.4964, -12.0524])\n",
      "Grad:   tensor([-0.0041,  0.0233])\n",
      "Epoch 2652, Loss 8.702157\n",
      "Params: tensor([  4.4964, -12.0527])\n",
      "Grad:   tensor([-0.0041,  0.0233])\n",
      "Epoch 2653, Loss 8.702154\n",
      "Params: tensor([  4.4965, -12.0529])\n",
      "Grad:   tensor([-0.0041,  0.0232])\n",
      "Epoch 2654, Loss 8.702148\n",
      "Params: tensor([  4.4965, -12.0531])\n",
      "Grad:   tensor([-0.0041,  0.0232])\n",
      "Epoch 2655, Loss 8.702142\n",
      "Params: tensor([  4.4966, -12.0534])\n",
      "Grad:   tensor([-0.0041,  0.0232])\n",
      "Epoch 2656, Loss 8.702134\n",
      "Params: tensor([  4.4966, -12.0536])\n",
      "Grad:   tensor([-0.0041,  0.0231])\n",
      "Epoch 2657, Loss 8.702129\n",
      "Params: tensor([  4.4966, -12.0538])\n",
      "Grad:   tensor([-0.0041,  0.0231])\n",
      "Epoch 2658, Loss 8.702125\n",
      "Params: tensor([  4.4967, -12.0541])\n",
      "Grad:   tensor([-0.0041,  0.0230])\n",
      "Epoch 2659, Loss 8.702118\n",
      "Params: tensor([  4.4967, -12.0543])\n",
      "Grad:   tensor([-0.0041,  0.0230])\n",
      "Epoch 2660, Loss 8.702114\n",
      "Params: tensor([  4.4968, -12.0545])\n",
      "Grad:   tensor([-0.0041,  0.0230])\n",
      "Epoch 2661, Loss 8.702106\n",
      "Params: tensor([  4.4968, -12.0547])\n",
      "Grad:   tensor([-0.0041,  0.0229])\n",
      "Epoch 2662, Loss 8.702101\n",
      "Params: tensor([  4.4968, -12.0550])\n",
      "Grad:   tensor([-0.0041,  0.0229])\n",
      "Epoch 2663, Loss 8.702096\n",
      "Params: tensor([  4.4969, -12.0552])\n",
      "Grad:   tensor([-0.0040,  0.0228])\n",
      "Epoch 2664, Loss 8.702091\n",
      "Params: tensor([  4.4969, -12.0554])\n",
      "Grad:   tensor([-0.0040,  0.0228])\n",
      "Epoch 2665, Loss 8.702086\n",
      "Params: tensor([  4.4970, -12.0557])\n",
      "Grad:   tensor([-0.0040,  0.0228])\n",
      "Epoch 2666, Loss 8.702081\n",
      "Params: tensor([  4.4970, -12.0559])\n",
      "Grad:   tensor([-0.0040,  0.0227])\n",
      "Epoch 2667, Loss 8.702075\n",
      "Params: tensor([  4.4970, -12.0561])\n",
      "Grad:   tensor([-0.0040,  0.0227])\n",
      "Epoch 2668, Loss 8.702070\n",
      "Params: tensor([  4.4971, -12.0563])\n",
      "Grad:   tensor([-0.0040,  0.0227])\n",
      "Epoch 2669, Loss 8.702065\n",
      "Params: tensor([  4.4971, -12.0566])\n",
      "Grad:   tensor([-0.0040,  0.0226])\n",
      "Epoch 2670, Loss 8.702058\n",
      "Params: tensor([  4.4972, -12.0568])\n",
      "Grad:   tensor([-0.0040,  0.0226])\n",
      "Epoch 2671, Loss 8.702054\n",
      "Params: tensor([  4.4972, -12.0570])\n",
      "Grad:   tensor([-0.0040,  0.0225])\n",
      "Epoch 2672, Loss 8.702048\n",
      "Params: tensor([  4.4972, -12.0572])\n",
      "Grad:   tensor([-0.0040,  0.0225])\n",
      "Epoch 2673, Loss 8.702044\n",
      "Params: tensor([  4.4973, -12.0575])\n",
      "Grad:   tensor([-0.0040,  0.0225])\n",
      "Epoch 2674, Loss 8.702038\n",
      "Params: tensor([  4.4973, -12.0577])\n",
      "Grad:   tensor([-0.0040,  0.0224])\n",
      "Epoch 2675, Loss 8.702032\n",
      "Params: tensor([  4.4974, -12.0579])\n",
      "Grad:   tensor([-0.0040,  0.0224])\n",
      "Epoch 2676, Loss 8.702027\n",
      "Params: tensor([  4.4974, -12.0581])\n",
      "Grad:   tensor([-0.0040,  0.0223])\n",
      "Epoch 2677, Loss 8.702023\n",
      "Params: tensor([  4.4974, -12.0584])\n",
      "Grad:   tensor([-0.0039,  0.0223])\n",
      "Epoch 2678, Loss 8.702020\n",
      "Params: tensor([  4.4975, -12.0586])\n",
      "Grad:   tensor([-0.0039,  0.0223])\n",
      "Epoch 2679, Loss 8.702014\n",
      "Params: tensor([  4.4975, -12.0588])\n",
      "Grad:   tensor([-0.0039,  0.0222])\n",
      "Epoch 2680, Loss 8.702009\n",
      "Params: tensor([  4.4976, -12.0590])\n",
      "Grad:   tensor([-0.0039,  0.0222])\n",
      "Epoch 2681, Loss 8.702004\n",
      "Params: tensor([  4.4976, -12.0592])\n",
      "Grad:   tensor([-0.0039,  0.0222])\n",
      "Epoch 2682, Loss 8.702000\n",
      "Params: tensor([  4.4976, -12.0595])\n",
      "Grad:   tensor([-0.0039,  0.0221])\n",
      "Epoch 2683, Loss 8.701994\n",
      "Params: tensor([  4.4977, -12.0597])\n",
      "Grad:   tensor([-0.0039,  0.0221])\n",
      "Epoch 2684, Loss 8.701989\n",
      "Params: tensor([  4.4977, -12.0599])\n",
      "Grad:   tensor([-0.0039,  0.0220])\n",
      "Epoch 2685, Loss 8.701982\n",
      "Params: tensor([  4.4978, -12.0601])\n",
      "Grad:   tensor([-0.0039,  0.0220])\n",
      "Epoch 2686, Loss 8.701977\n",
      "Params: tensor([  4.4978, -12.0603])\n",
      "Grad:   tensor([-0.0039,  0.0220])\n",
      "Epoch 2687, Loss 8.701974\n",
      "Params: tensor([  4.4978, -12.0606])\n",
      "Grad:   tensor([-0.0039,  0.0219])\n",
      "Epoch 2688, Loss 8.701966\n",
      "Params: tensor([  4.4979, -12.0608])\n",
      "Grad:   tensor([-0.0039,  0.0219])\n",
      "Epoch 2689, Loss 8.701963\n",
      "Params: tensor([  4.4979, -12.0610])\n",
      "Grad:   tensor([-0.0039,  0.0219])\n",
      "Epoch 2690, Loss 8.701959\n",
      "Params: tensor([  4.4980, -12.0612])\n",
      "Grad:   tensor([-0.0038,  0.0218])\n",
      "Epoch 2691, Loss 8.701953\n",
      "Params: tensor([  4.4980, -12.0614])\n",
      "Grad:   tensor([-0.0038,  0.0218])\n",
      "Epoch 2692, Loss 8.701947\n",
      "Params: tensor([  4.4980, -12.0617])\n",
      "Grad:   tensor([-0.0038,  0.0217])\n",
      "Epoch 2693, Loss 8.701941\n",
      "Params: tensor([  4.4981, -12.0619])\n",
      "Grad:   tensor([-0.0038,  0.0217])\n",
      "Epoch 2694, Loss 8.701939\n",
      "Params: tensor([  4.4981, -12.0621])\n",
      "Grad:   tensor([-0.0038,  0.0217])\n",
      "Epoch 2695, Loss 8.701934\n",
      "Params: tensor([  4.4981, -12.0623])\n",
      "Grad:   tensor([-0.0038,  0.0216])\n",
      "Epoch 2696, Loss 8.701931\n",
      "Params: tensor([  4.4982, -12.0625])\n",
      "Grad:   tensor([-0.0038,  0.0216])\n",
      "Epoch 2697, Loss 8.701923\n",
      "Params: tensor([  4.4982, -12.0627])\n",
      "Grad:   tensor([-0.0038,  0.0216])\n",
      "Epoch 2698, Loss 8.701921\n",
      "Params: tensor([  4.4983, -12.0630])\n",
      "Grad:   tensor([-0.0038,  0.0215])\n",
      "Epoch 2699, Loss 8.701914\n",
      "Params: tensor([  4.4983, -12.0632])\n",
      "Grad:   tensor([-0.0038,  0.0215])\n",
      "Epoch 2700, Loss 8.701910\n",
      "Params: tensor([  4.4983, -12.0634])\n",
      "Grad:   tensor([-0.0038,  0.0215])\n",
      "Epoch 2701, Loss 8.701905\n",
      "Params: tensor([  4.4984, -12.0636])\n",
      "Grad:   tensor([-0.0038,  0.0214])\n",
      "Epoch 2702, Loss 8.701899\n",
      "Params: tensor([  4.4984, -12.0638])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad:   tensor([-0.0038,  0.0214])\n",
      "Epoch 2703, Loss 8.701898\n",
      "Params: tensor([  4.4984, -12.0640])\n",
      "Grad:   tensor([-0.0038,  0.0213])\n",
      "Epoch 2704, Loss 8.701892\n",
      "Params: tensor([  4.4985, -12.0642])\n",
      "Grad:   tensor([-0.0038,  0.0213])\n",
      "Epoch 2705, Loss 8.701886\n",
      "Params: tensor([  4.4985, -12.0645])\n",
      "Grad:   tensor([-0.0038,  0.0213])\n",
      "Epoch 2706, Loss 8.701880\n",
      "Params: tensor([  4.4986, -12.0647])\n",
      "Grad:   tensor([-0.0037,  0.0212])\n",
      "Epoch 2707, Loss 8.701877\n",
      "Params: tensor([  4.4986, -12.0649])\n",
      "Grad:   tensor([-0.0037,  0.0212])\n",
      "Epoch 2708, Loss 8.701872\n",
      "Params: tensor([  4.4986, -12.0651])\n",
      "Grad:   tensor([-0.0037,  0.0212])\n",
      "Epoch 2709, Loss 8.701866\n",
      "Params: tensor([  4.4987, -12.0653])\n",
      "Grad:   tensor([-0.0037,  0.0211])\n",
      "Epoch 2710, Loss 8.701864\n",
      "Params: tensor([  4.4987, -12.0655])\n",
      "Grad:   tensor([-0.0037,  0.0211])\n",
      "Epoch 2711, Loss 8.701859\n",
      "Params: tensor([  4.4987, -12.0657])\n",
      "Grad:   tensor([-0.0037,  0.0211])\n",
      "Epoch 2712, Loss 8.701855\n",
      "Params: tensor([  4.4988, -12.0659])\n",
      "Grad:   tensor([-0.0037,  0.0210])\n",
      "Epoch 2713, Loss 8.701850\n",
      "Params: tensor([  4.4988, -12.0661])\n",
      "Grad:   tensor([-0.0037,  0.0210])\n",
      "Epoch 2714, Loss 8.701844\n",
      "Params: tensor([  4.4989, -12.0663])\n",
      "Grad:   tensor([-0.0037,  0.0209])\n",
      "Epoch 2715, Loss 8.701839\n",
      "Params: tensor([  4.4989, -12.0666])\n",
      "Grad:   tensor([-0.0037,  0.0209])\n",
      "Epoch 2716, Loss 8.701837\n",
      "Params: tensor([  4.4989, -12.0668])\n",
      "Grad:   tensor([-0.0037,  0.0209])\n",
      "Epoch 2717, Loss 8.701834\n",
      "Params: tensor([  4.4990, -12.0670])\n",
      "Grad:   tensor([-0.0037,  0.0208])\n",
      "Epoch 2718, Loss 8.701827\n",
      "Params: tensor([  4.4990, -12.0672])\n",
      "Grad:   tensor([-0.0037,  0.0208])\n",
      "Epoch 2719, Loss 8.701821\n",
      "Params: tensor([  4.4990, -12.0674])\n",
      "Grad:   tensor([-0.0037,  0.0208])\n",
      "Epoch 2720, Loss 8.701818\n",
      "Params: tensor([  4.4991, -12.0676])\n",
      "Grad:   tensor([-0.0037,  0.0207])\n",
      "Epoch 2721, Loss 8.701814\n",
      "Params: tensor([  4.4991, -12.0678])\n",
      "Grad:   tensor([-0.0037,  0.0207])\n",
      "Epoch 2722, Loss 8.701809\n",
      "Params: tensor([  4.4992, -12.0680])\n",
      "Grad:   tensor([-0.0036,  0.0207])\n",
      "Epoch 2723, Loss 8.701807\n",
      "Params: tensor([  4.4992, -12.0682])\n",
      "Grad:   tensor([-0.0037,  0.0206])\n",
      "Epoch 2724, Loss 8.701801\n",
      "Params: tensor([  4.4992, -12.0684])\n",
      "Grad:   tensor([-0.0036,  0.0206])\n",
      "Epoch 2725, Loss 8.701797\n",
      "Params: tensor([  4.4993, -12.0686])\n",
      "Grad:   tensor([-0.0036,  0.0206])\n",
      "Epoch 2726, Loss 8.701792\n",
      "Params: tensor([  4.4993, -12.0688])\n",
      "Grad:   tensor([-0.0036,  0.0205])\n",
      "Epoch 2727, Loss 8.701788\n",
      "Params: tensor([  4.4993, -12.0690])\n",
      "Grad:   tensor([-0.0036,  0.0205])\n",
      "Epoch 2728, Loss 8.701785\n",
      "Params: tensor([  4.4994, -12.0692])\n",
      "Grad:   tensor([-0.0036,  0.0205])\n",
      "Epoch 2729, Loss 8.701780\n",
      "Params: tensor([  4.4994, -12.0694])\n",
      "Grad:   tensor([-0.0036,  0.0204])\n",
      "Epoch 2730, Loss 8.701776\n",
      "Params: tensor([  4.4994, -12.0697])\n",
      "Grad:   tensor([-0.0036,  0.0204])\n",
      "Epoch 2731, Loss 8.701768\n",
      "Params: tensor([  4.4995, -12.0699])\n",
      "Grad:   tensor([-0.0036,  0.0203])\n",
      "Epoch 2732, Loss 8.701764\n",
      "Params: tensor([  4.4995, -12.0701])\n",
      "Grad:   tensor([-0.0036,  0.0203])\n",
      "Epoch 2733, Loss 8.701762\n",
      "Params: tensor([  4.4995, -12.0703])\n",
      "Grad:   tensor([-0.0036,  0.0203])\n",
      "Epoch 2734, Loss 8.701756\n",
      "Params: tensor([  4.4996, -12.0705])\n",
      "Grad:   tensor([-0.0036,  0.0202])\n",
      "Epoch 2735, Loss 8.701755\n",
      "Params: tensor([  4.4996, -12.0707])\n",
      "Grad:   tensor([-0.0036,  0.0202])\n",
      "Epoch 2736, Loss 8.701750\n",
      "Params: tensor([  4.4997, -12.0709])\n",
      "Grad:   tensor([-0.0036,  0.0202])\n",
      "Epoch 2737, Loss 8.701743\n",
      "Params: tensor([  4.4997, -12.0711])\n",
      "Grad:   tensor([-0.0035,  0.0201])\n",
      "Epoch 2738, Loss 8.701743\n",
      "Params: tensor([  4.4997, -12.0713])\n",
      "Grad:   tensor([-0.0036,  0.0201])\n",
      "Epoch 2739, Loss 8.701737\n",
      "Params: tensor([  4.4998, -12.0715])\n",
      "Grad:   tensor([-0.0035,  0.0201])\n",
      "Epoch 2740, Loss 8.701732\n",
      "Params: tensor([  4.4998, -12.0717])\n",
      "Grad:   tensor([-0.0035,  0.0200])\n",
      "Epoch 2741, Loss 8.701727\n",
      "Params: tensor([  4.4998, -12.0719])\n",
      "Grad:   tensor([-0.0035,  0.0200])\n",
      "Epoch 2742, Loss 8.701724\n",
      "Params: tensor([  4.4999, -12.0721])\n",
      "Grad:   tensor([-0.0035,  0.0200])\n",
      "Epoch 2743, Loss 8.701720\n",
      "Params: tensor([  4.4999, -12.0723])\n",
      "Grad:   tensor([-0.0035,  0.0199])\n",
      "Epoch 2744, Loss 8.701716\n",
      "Params: tensor([  4.4999, -12.0725])\n",
      "Grad:   tensor([-0.0035,  0.0199])\n",
      "Epoch 2745, Loss 8.701712\n",
      "Params: tensor([  4.5000, -12.0727])\n",
      "Grad:   tensor([-0.0035,  0.0199])\n",
      "Epoch 2746, Loss 8.701707\n",
      "Params: tensor([  4.5000, -12.0729])\n",
      "Grad:   tensor([-0.0035,  0.0198])\n",
      "Epoch 2747, Loss 8.701705\n",
      "Params: tensor([  4.5000, -12.0731])\n",
      "Grad:   tensor([-0.0035,  0.0198])\n",
      "Epoch 2748, Loss 8.701698\n",
      "Params: tensor([  4.5001, -12.0733])\n",
      "Grad:   tensor([-0.0035,  0.0198])\n",
      "Epoch 2749, Loss 8.701694\n",
      "Params: tensor([  4.5001, -12.0735])\n",
      "Grad:   tensor([-0.0035,  0.0197])\n",
      "Epoch 2750, Loss 8.701694\n",
      "Params: tensor([  4.5001, -12.0737])\n",
      "Grad:   tensor([-0.0035,  0.0197])\n",
      "Epoch 2751, Loss 8.701687\n",
      "Params: tensor([  4.5002, -12.0739])\n",
      "Grad:   tensor([-0.0035,  0.0197])\n",
      "Epoch 2752, Loss 8.701684\n",
      "Params: tensor([  4.5002, -12.0741])\n",
      "Grad:   tensor([-0.0035,  0.0196])\n",
      "Epoch 2753, Loss 8.701678\n",
      "Params: tensor([  4.5003, -12.0742])\n",
      "Grad:   tensor([-0.0034,  0.0196])\n",
      "Epoch 2754, Loss 8.701677\n",
      "Params: tensor([  4.5003, -12.0744])\n",
      "Grad:   tensor([-0.0035,  0.0196])\n",
      "Epoch 2755, Loss 8.701672\n",
      "Params: tensor([  4.5003, -12.0746])\n",
      "Grad:   tensor([-0.0034,  0.0195])\n",
      "Epoch 2756, Loss 8.701667\n",
      "Params: tensor([  4.5004, -12.0748])\n",
      "Grad:   tensor([-0.0034,  0.0195])\n",
      "Epoch 2757, Loss 8.701664\n",
      "Params: tensor([  4.5004, -12.0750])\n",
      "Grad:   tensor([-0.0035,  0.0195])\n",
      "Epoch 2758, Loss 8.701660\n",
      "Params: tensor([  4.5004, -12.0752])\n",
      "Grad:   tensor([-0.0034,  0.0194])\n",
      "Epoch 2759, Loss 8.701654\n",
      "Params: tensor([  4.5005, -12.0754])\n",
      "Grad:   tensor([-0.0034,  0.0194])\n",
      "Epoch 2760, Loss 8.701651\n",
      "Params: tensor([  4.5005, -12.0756])\n",
      "Grad:   tensor([-0.0034,  0.0194])\n",
      "Epoch 2761, Loss 8.701649\n",
      "Params: tensor([  4.5005, -12.0758])\n",
      "Grad:   tensor([-0.0034,  0.0193])\n",
      "Epoch 2762, Loss 8.701644\n",
      "Params: tensor([  4.5006, -12.0760])\n",
      "Grad:   tensor([-0.0034,  0.0193])\n",
      "Epoch 2763, Loss 8.701639\n",
      "Params: tensor([  4.5006, -12.0762])\n",
      "Grad:   tensor([-0.0034,  0.0193])\n",
      "Epoch 2764, Loss 8.701638\n",
      "Params: tensor([  4.5006, -12.0764])\n",
      "Grad:   tensor([-0.0034,  0.0192])\n",
      "Epoch 2765, Loss 8.701632\n",
      "Params: tensor([  4.5007, -12.0766])\n",
      "Grad:   tensor([-0.0034,  0.0192])\n",
      "Epoch 2766, Loss 8.701629\n",
      "Params: tensor([  4.5007, -12.0768])\n",
      "Grad:   tensor([-0.0034,  0.0192])\n",
      "Epoch 2767, Loss 8.701627\n",
      "Params: tensor([  4.5007, -12.0770])\n",
      "Grad:   tensor([-0.0034,  0.0191])\n",
      "Epoch 2768, Loss 8.701621\n",
      "Params: tensor([  4.5008, -12.0771])\n",
      "Grad:   tensor([-0.0034,  0.0191])\n",
      "Epoch 2769, Loss 8.701618\n",
      "Params: tensor([  4.5008, -12.0773])\n",
      "Grad:   tensor([-0.0034,  0.0191])\n",
      "Epoch 2770, Loss 8.701613\n",
      "Params: tensor([  4.5008, -12.0775])\n",
      "Grad:   tensor([-0.0033,  0.0190])\n",
      "Epoch 2771, Loss 8.701611\n",
      "Params: tensor([  4.5009, -12.0777])\n",
      "Grad:   tensor([-0.0034,  0.0190])\n",
      "Epoch 2772, Loss 8.701607\n",
      "Params: tensor([  4.5009, -12.0779])\n",
      "Grad:   tensor([-0.0033,  0.0190])\n",
      "Epoch 2773, Loss 8.701600\n",
      "Params: tensor([  4.5009, -12.0781])\n",
      "Grad:   tensor([-0.0033,  0.0189])\n",
      "Epoch 2774, Loss 8.701598\n",
      "Params: tensor([  4.5010, -12.0783])\n",
      "Grad:   tensor([-0.0033,  0.0189])\n",
      "Epoch 2775, Loss 8.701595\n",
      "Params: tensor([  4.5010, -12.0785])\n",
      "Grad:   tensor([-0.0033,  0.0189])\n",
      "Epoch 2776, Loss 8.701591\n",
      "Params: tensor([  4.5010, -12.0787])\n",
      "Grad:   tensor([-0.0033,  0.0189])\n",
      "Epoch 2777, Loss 8.701588\n",
      "Params: tensor([  4.5011, -12.0789])\n",
      "Grad:   tensor([-0.0033,  0.0188])\n",
      "Epoch 2778, Loss 8.701585\n",
      "Params: tensor([  4.5011, -12.0790])\n",
      "Grad:   tensor([-0.0033,  0.0188])\n",
      "Epoch 2779, Loss 8.701583\n",
      "Params: tensor([  4.5011, -12.0792])\n",
      "Grad:   tensor([-0.0033,  0.0188])\n",
      "Epoch 2780, Loss 8.701577\n",
      "Params: tensor([  4.5012, -12.0794])\n",
      "Grad:   tensor([-0.0033,  0.0187])\n",
      "Epoch 2781, Loss 8.701572\n",
      "Params: tensor([  4.5012, -12.0796])\n",
      "Grad:   tensor([-0.0033,  0.0187])\n",
      "Epoch 2782, Loss 8.701571\n",
      "Params: tensor([  4.5012, -12.0798])\n",
      "Grad:   tensor([-0.0033,  0.0187])\n",
      "Epoch 2783, Loss 8.701568\n",
      "Params: tensor([  4.5013, -12.0800])\n",
      "Grad:   tensor([-0.0033,  0.0186])\n",
      "Epoch 2784, Loss 8.701563\n",
      "Params: tensor([  4.5013, -12.0802])\n",
      "Grad:   tensor([-0.0033,  0.0186])\n",
      "Epoch 2785, Loss 8.701560\n",
      "Params: tensor([  4.5013, -12.0803])\n",
      "Grad:   tensor([-0.0033,  0.0186])\n",
      "Epoch 2786, Loss 8.701556\n",
      "Params: tensor([  4.5014, -12.0805])\n",
      "Grad:   tensor([-0.0033,  0.0185])\n",
      "Epoch 2787, Loss 8.701550\n",
      "Params: tensor([  4.5014, -12.0807])\n",
      "Grad:   tensor([-0.0033,  0.0185])\n",
      "Epoch 2788, Loss 8.701550\n",
      "Params: tensor([  4.5014, -12.0809])\n",
      "Grad:   tensor([-0.0033,  0.0185])\n",
      "Epoch 2789, Loss 8.701545\n",
      "Params: tensor([  4.5015, -12.0811])\n",
      "Grad:   tensor([-0.0033,  0.0184])\n",
      "Epoch 2790, Loss 8.701544\n",
      "Params: tensor([  4.5015, -12.0813])\n",
      "Grad:   tensor([-0.0033,  0.0184])\n",
      "Epoch 2791, Loss 8.701539\n",
      "Params: tensor([  4.5015, -12.0815])\n",
      "Grad:   tensor([-0.0033,  0.0184])\n",
      "Epoch 2792, Loss 8.701534\n",
      "Params: tensor([  4.5016, -12.0816])\n",
      "Grad:   tensor([-0.0032,  0.0183])\n",
      "Epoch 2793, Loss 8.701533\n",
      "Params: tensor([  4.5016, -12.0818])\n",
      "Grad:   tensor([-0.0032,  0.0183])\n",
      "Epoch 2794, Loss 8.701527\n",
      "Params: tensor([  4.5016, -12.0820])\n",
      "Grad:   tensor([-0.0032,  0.0183])\n",
      "Epoch 2795, Loss 8.701523\n",
      "Params: tensor([  4.5017, -12.0822])\n",
      "Grad:   tensor([-0.0032,  0.0183])\n",
      "Epoch 2796, Loss 8.701520\n",
      "Params: tensor([  4.5017, -12.0824])\n",
      "Grad:   tensor([-0.0032,  0.0182])\n",
      "Epoch 2797, Loss 8.701517\n",
      "Params: tensor([  4.5017, -12.0826])\n",
      "Grad:   tensor([-0.0032,  0.0182])\n",
      "Epoch 2798, Loss 8.701514\n",
      "Params: tensor([  4.5018, -12.0827])\n",
      "Grad:   tensor([-0.0032,  0.0182])\n",
      "Epoch 2799, Loss 8.701511\n",
      "Params: tensor([  4.5018, -12.0829])\n",
      "Grad:   tensor([-0.0032,  0.0181])\n",
      "Epoch 2800, Loss 8.701506\n",
      "Params: tensor([  4.5018, -12.0831])\n",
      "Grad:   tensor([-0.0032,  0.0181])\n",
      "Epoch 2801, Loss 8.701505\n",
      "Params: tensor([  4.5018, -12.0833])\n",
      "Grad:   tensor([-0.0032,  0.0181])\n",
      "Epoch 2802, Loss 8.701501\n",
      "Params: tensor([  4.5019, -12.0835])\n",
      "Grad:   tensor([-0.0032,  0.0180])\n",
      "Epoch 2803, Loss 8.701499\n",
      "Params: tensor([  4.5019, -12.0836])\n",
      "Grad:   tensor([-0.0032,  0.0180])\n",
      "Epoch 2804, Loss 8.701493\n",
      "Params: tensor([  4.5019, -12.0838])\n",
      "Grad:   tensor([-0.0032,  0.0180])\n",
      "Epoch 2805, Loss 8.701491\n",
      "Params: tensor([  4.5020, -12.0840])\n",
      "Grad:   tensor([-0.0032,  0.0179])\n",
      "Epoch 2806, Loss 8.701488\n",
      "Params: tensor([  4.5020, -12.0842])\n",
      "Grad:   tensor([-0.0032,  0.0179])\n",
      "Epoch 2807, Loss 8.701483\n",
      "Params: tensor([  4.5020, -12.0844])\n",
      "Grad:   tensor([-0.0032,  0.0179])\n",
      "Epoch 2808, Loss 8.701482\n",
      "Params: tensor([  4.5021, -12.0845])\n",
      "Grad:   tensor([-0.0032,  0.0179])\n",
      "Epoch 2809, Loss 8.701476\n",
      "Params: tensor([  4.5021, -12.0847])\n",
      "Grad:   tensor([-0.0031,  0.0178])\n",
      "Epoch 2810, Loss 8.701476\n",
      "Params: tensor([  4.5021, -12.0849])\n",
      "Grad:   tensor([-0.0031,  0.0178])\n",
      "Epoch 2811, Loss 8.701471\n",
      "Params: tensor([  4.5022, -12.0851])\n",
      "Grad:   tensor([-0.0031,  0.0178])\n",
      "Epoch 2812, Loss 8.701468\n",
      "Params: tensor([  4.5022, -12.0852])\n",
      "Grad:   tensor([-0.0031,  0.0177])\n",
      "Epoch 2813, Loss 8.701465\n",
      "Params: tensor([  4.5022, -12.0854])\n",
      "Grad:   tensor([-0.0031,  0.0177])\n",
      "Epoch 2814, Loss 8.701459\n",
      "Params: tensor([  4.5023, -12.0856])\n",
      "Grad:   tensor([-0.0031,  0.0177])\n",
      "Epoch 2815, Loss 8.701457\n",
      "Params: tensor([  4.5023, -12.0858])\n",
      "Grad:   tensor([-0.0031,  0.0176])\n",
      "Epoch 2816, Loss 8.701454\n",
      "Params: tensor([  4.5023, -12.0859])\n",
      "Grad:   tensor([-0.0031,  0.0176])\n",
      "Epoch 2817, Loss 8.701450\n",
      "Params: tensor([  4.5023, -12.0861])\n",
      "Grad:   tensor([-0.0031,  0.0176])\n",
      "Epoch 2818, Loss 8.701447\n",
      "Params: tensor([  4.5024, -12.0863])\n",
      "Grad:   tensor([-0.0031,  0.0176])\n",
      "Epoch 2819, Loss 8.701446\n",
      "Params: tensor([  4.5024, -12.0865])\n",
      "Grad:   tensor([-0.0031,  0.0175])\n",
      "Epoch 2820, Loss 8.701441\n",
      "Params: tensor([  4.5024, -12.0866])\n",
      "Grad:   tensor([-0.0031,  0.0175])\n",
      "Epoch 2821, Loss 8.701440\n",
      "Params: tensor([  4.5025, -12.0868])\n",
      "Grad:   tensor([-0.0031,  0.0175])\n",
      "Epoch 2822, Loss 8.701435\n",
      "Params: tensor([  4.5025, -12.0870])\n",
      "Grad:   tensor([-0.0031,  0.0174])\n",
      "Epoch 2823, Loss 8.701432\n",
      "Params: tensor([  4.5025, -12.0872])\n",
      "Grad:   tensor([-0.0031,  0.0174])\n",
      "Epoch 2824, Loss 8.701430\n",
      "Params: tensor([  4.5026, -12.0873])\n",
      "Grad:   tensor([-0.0031,  0.0174])\n",
      "Epoch 2825, Loss 8.701426\n",
      "Params: tensor([  4.5026, -12.0875])\n",
      "Grad:   tensor([-0.0030,  0.0173])\n",
      "Epoch 2826, Loss 8.701425\n",
      "Params: tensor([  4.5026, -12.0877])\n",
      "Grad:   tensor([-0.0031,  0.0173])\n",
      "Epoch 2827, Loss 8.701420\n",
      "Params: tensor([  4.5027, -12.0879])\n",
      "Grad:   tensor([-0.0031,  0.0173])\n",
      "Epoch 2828, Loss 8.701417\n",
      "Params: tensor([  4.5027, -12.0880])\n",
      "Grad:   tensor([-0.0031,  0.0173])\n",
      "Epoch 2829, Loss 8.701415\n",
      "Params: tensor([  4.5027, -12.0882])\n",
      "Grad:   tensor([-0.0030,  0.0172])\n",
      "Epoch 2830, Loss 8.701410\n",
      "Params: tensor([  4.5027, -12.0884])\n",
      "Grad:   tensor([-0.0030,  0.0172])\n",
      "Epoch 2831, Loss 8.701406\n",
      "Params: tensor([  4.5028, -12.0886])\n",
      "Grad:   tensor([-0.0030,  0.0172])\n",
      "Epoch 2832, Loss 8.701406\n",
      "Params: tensor([  4.5028, -12.0887])\n",
      "Grad:   tensor([-0.0030,  0.0171])\n",
      "Epoch 2833, Loss 8.701402\n",
      "Params: tensor([  4.5028, -12.0889])\n",
      "Grad:   tensor([-0.0030,  0.0171])\n",
      "Epoch 2834, Loss 8.701400\n",
      "Params: tensor([  4.5029, -12.0891])\n",
      "Grad:   tensor([-0.0030,  0.0171])\n",
      "Epoch 2835, Loss 8.701395\n",
      "Params: tensor([  4.5029, -12.0892])\n",
      "Grad:   tensor([-0.0030,  0.0171])\n",
      "Epoch 2836, Loss 8.701391\n",
      "Params: tensor([  4.5029, -12.0894])\n",
      "Grad:   tensor([-0.0030,  0.0170])\n",
      "Epoch 2837, Loss 8.701388\n",
      "Params: tensor([  4.5030, -12.0896])\n",
      "Grad:   tensor([-0.0030,  0.0170])\n",
      "Epoch 2838, Loss 8.701385\n",
      "Params: tensor([  4.5030, -12.0897])\n",
      "Grad:   tensor([-0.0030,  0.0170])\n",
      "Epoch 2839, Loss 8.701384\n",
      "Params: tensor([  4.5030, -12.0899])\n",
      "Grad:   tensor([-0.0030,  0.0169])\n",
      "Epoch 2840, Loss 8.701380\n",
      "Params: tensor([  4.5030, -12.0901])\n",
      "Grad:   tensor([-0.0030,  0.0169])\n",
      "Epoch 2841, Loss 8.701377\n",
      "Params: tensor([  4.5031, -12.0903])\n",
      "Grad:   tensor([-0.0030,  0.0169])\n",
      "Epoch 2842, Loss 8.701375\n",
      "Params: tensor([  4.5031, -12.0904])\n",
      "Grad:   tensor([-0.0030,  0.0168])\n",
      "Epoch 2843, Loss 8.701370\n",
      "Params: tensor([  4.5031, -12.0906])\n",
      "Grad:   tensor([-0.0030,  0.0168])\n",
      "Epoch 2844, Loss 8.701369\n",
      "Params: tensor([  4.5032, -12.0908])\n",
      "Grad:   tensor([-0.0030,  0.0168])\n",
      "Epoch 2845, Loss 8.701366\n",
      "Params: tensor([  4.5032, -12.0909])\n",
      "Grad:   tensor([-0.0030,  0.0168])\n",
      "Epoch 2846, Loss 8.701362\n",
      "Params: tensor([  4.5032, -12.0911])\n",
      "Grad:   tensor([-0.0030,  0.0167])\n",
      "Epoch 2847, Loss 8.701359\n",
      "Params: tensor([  4.5033, -12.0913])\n",
      "Grad:   tensor([-0.0030,  0.0167])\n",
      "Epoch 2848, Loss 8.701358\n",
      "Params: tensor([  4.5033, -12.0914])\n",
      "Grad:   tensor([-0.0029,  0.0167])\n",
      "Epoch 2849, Loss 8.701355\n",
      "Params: tensor([  4.5033, -12.0916])\n",
      "Grad:   tensor([-0.0029,  0.0167])\n",
      "Epoch 2850, Loss 8.701351\n",
      "Params: tensor([  4.5033, -12.0918])\n",
      "Grad:   tensor([-0.0029,  0.0166])\n",
      "Epoch 2851, Loss 8.701350\n",
      "Params: tensor([  4.5034, -12.0919])\n",
      "Grad:   tensor([-0.0029,  0.0166])\n",
      "Epoch 2852, Loss 8.701345\n",
      "Params: tensor([  4.5034, -12.0921])\n",
      "Grad:   tensor([-0.0029,  0.0166])\n",
      "Epoch 2853, Loss 8.701345\n",
      "Params: tensor([  4.5034, -12.0923])\n",
      "Grad:   tensor([-0.0029,  0.0165])\n",
      "Epoch 2854, Loss 8.701340\n",
      "Params: tensor([  4.5035, -12.0924])\n",
      "Grad:   tensor([-0.0029,  0.0165])\n",
      "Epoch 2855, Loss 8.701341\n",
      "Params: tensor([  4.5035, -12.0926])\n",
      "Grad:   tensor([-0.0029,  0.0165])\n",
      "Epoch 2856, Loss 8.701332\n",
      "Params: tensor([  4.5035, -12.0928])\n",
      "Grad:   tensor([-0.0029,  0.0165])\n",
      "Epoch 2857, Loss 8.701331\n",
      "Params: tensor([  4.5035, -12.0929])\n",
      "Grad:   tensor([-0.0029,  0.0164])\n",
      "Epoch 2858, Loss 8.701327\n",
      "Params: tensor([  4.5036, -12.0931])\n",
      "Grad:   tensor([-0.0029,  0.0164])\n",
      "Epoch 2859, Loss 8.701325\n",
      "Params: tensor([  4.5036, -12.0932])\n",
      "Grad:   tensor([-0.0029,  0.0164])\n",
      "Epoch 2860, Loss 8.701325\n",
      "Params: tensor([  4.5036, -12.0934])\n",
      "Grad:   tensor([-0.0029,  0.0163])\n",
      "Epoch 2861, Loss 8.701321\n",
      "Params: tensor([  4.5037, -12.0936])\n",
      "Grad:   tensor([-0.0029,  0.0163])\n",
      "Epoch 2862, Loss 8.701318\n",
      "Params: tensor([  4.5037, -12.0937])\n",
      "Grad:   tensor([-0.0029,  0.0163])\n",
      "Epoch 2863, Loss 8.701318\n",
      "Params: tensor([  4.5037, -12.0939])\n",
      "Grad:   tensor([-0.0029,  0.0163])\n",
      "Epoch 2864, Loss 8.701311\n",
      "Params: tensor([  4.5038, -12.0941])\n",
      "Grad:   tensor([-0.0029,  0.0162])\n",
      "Epoch 2865, Loss 8.701310\n",
      "Params: tensor([  4.5038, -12.0942])\n",
      "Grad:   tensor([-0.0029,  0.0162])\n",
      "Epoch 2866, Loss 8.701308\n",
      "Params: tensor([  4.5038, -12.0944])\n",
      "Grad:   tensor([-0.0029,  0.0162])\n",
      "Epoch 2867, Loss 8.701305\n",
      "Params: tensor([  4.5038, -12.0945])\n",
      "Grad:   tensor([-0.0029,  0.0161])\n",
      "Epoch 2868, Loss 8.701303\n",
      "Params: tensor([  4.5039, -12.0947])\n",
      "Grad:   tensor([-0.0028,  0.0161])\n",
      "Epoch 2869, Loss 8.701298\n",
      "Params: tensor([  4.5039, -12.0949])\n",
      "Grad:   tensor([-0.0028,  0.0161])\n",
      "Epoch 2870, Loss 8.701295\n",
      "Params: tensor([  4.5039, -12.0950])\n",
      "Grad:   tensor([-0.0028,  0.0161])\n",
      "Epoch 2871, Loss 8.701295\n",
      "Params: tensor([  4.5040, -12.0952])\n",
      "Grad:   tensor([-0.0028,  0.0160])\n",
      "Epoch 2872, Loss 8.701289\n",
      "Params: tensor([  4.5040, -12.0953])\n",
      "Grad:   tensor([-0.0028,  0.0160])\n",
      "Epoch 2873, Loss 8.701287\n",
      "Params: tensor([  4.5040, -12.0955])\n",
      "Grad:   tensor([-0.0028,  0.0160])\n",
      "Epoch 2874, Loss 8.701288\n",
      "Params: tensor([  4.5040, -12.0957])\n",
      "Grad:   tensor([-0.0028,  0.0160])\n",
      "Epoch 2875, Loss 8.701282\n",
      "Params: tensor([  4.5041, -12.0958])\n",
      "Grad:   tensor([-0.0028,  0.0159])\n",
      "Epoch 2876, Loss 8.701281\n",
      "Params: tensor([  4.5041, -12.0960])\n",
      "Grad:   tensor([-0.0028,  0.0159])\n",
      "Epoch 2877, Loss 8.701279\n",
      "Params: tensor([  4.5041, -12.0961])\n",
      "Grad:   tensor([-0.0028,  0.0159])\n",
      "Epoch 2878, Loss 8.701276\n",
      "Params: tensor([  4.5041, -12.0963])\n",
      "Grad:   tensor([-0.0028,  0.0159])\n",
      "Epoch 2879, Loss 8.701275\n",
      "Params: tensor([  4.5042, -12.0965])\n",
      "Grad:   tensor([-0.0028,  0.0158])\n",
      "Epoch 2880, Loss 8.701270\n",
      "Params: tensor([  4.5042, -12.0966])\n",
      "Grad:   tensor([-0.0028,  0.0158])\n",
      "Epoch 2881, Loss 8.701269\n",
      "Params: tensor([  4.5042, -12.0968])\n",
      "Grad:   tensor([-0.0028,  0.0158])\n",
      "Epoch 2882, Loss 8.701264\n",
      "Params: tensor([  4.5043, -12.0969])\n",
      "Grad:   tensor([-0.0028,  0.0157])\n",
      "Epoch 2883, Loss 8.701263\n",
      "Params: tensor([  4.5043, -12.0971])\n",
      "Grad:   tensor([-0.0028,  0.0157])\n",
      "Epoch 2884, Loss 8.701261\n",
      "Params: tensor([  4.5043, -12.0972])\n",
      "Grad:   tensor([-0.0028,  0.0157])\n",
      "Epoch 2885, Loss 8.701257\n",
      "Params: tensor([  4.5043, -12.0974])\n",
      "Grad:   tensor([-0.0028,  0.0157])\n",
      "Epoch 2886, Loss 8.701255\n",
      "Params: tensor([  4.5044, -12.0976])\n",
      "Grad:   tensor([-0.0028,  0.0156])\n",
      "Epoch 2887, Loss 8.701254\n",
      "Params: tensor([  4.5044, -12.0977])\n",
      "Grad:   tensor([-0.0028,  0.0156])\n",
      "Epoch 2888, Loss 8.701249\n",
      "Params: tensor([  4.5044, -12.0979])\n",
      "Grad:   tensor([-0.0028,  0.0156])\n",
      "Epoch 2889, Loss 8.701248\n",
      "Params: tensor([  4.5045, -12.0980])\n",
      "Grad:   tensor([-0.0027,  0.0156])\n",
      "Epoch 2890, Loss 8.701243\n",
      "Params: tensor([  4.5045, -12.0982])\n",
      "Grad:   tensor([-0.0027,  0.0155])\n",
      "Epoch 2891, Loss 8.701242\n",
      "Params: tensor([  4.5045, -12.0983])\n",
      "Grad:   tensor([-0.0027,  0.0155])\n",
      "Epoch 2892, Loss 8.701241\n",
      "Params: tensor([  4.5045, -12.0985])\n",
      "Grad:   tensor([-0.0027,  0.0155])\n",
      "Epoch 2893, Loss 8.701237\n",
      "Params: tensor([  4.5046, -12.0986])\n",
      "Grad:   tensor([-0.0027,  0.0155])\n",
      "Epoch 2894, Loss 8.701236\n",
      "Params: tensor([  4.5046, -12.0988])\n",
      "Grad:   tensor([-0.0027,  0.0154])\n",
      "Epoch 2895, Loss 8.701234\n",
      "Params: tensor([  4.5046, -12.0990])\n",
      "Grad:   tensor([-0.0027,  0.0154])\n",
      "Epoch 2896, Loss 8.701229\n",
      "Params: tensor([  4.5046, -12.0991])\n",
      "Grad:   tensor([-0.0027,  0.0154])\n",
      "Epoch 2897, Loss 8.701227\n",
      "Params: tensor([  4.5047, -12.0993])\n",
      "Grad:   tensor([-0.0027,  0.0153])\n",
      "Epoch 2898, Loss 8.701226\n",
      "Params: tensor([  4.5047, -12.0994])\n",
      "Grad:   tensor([-0.0027,  0.0153])\n",
      "Epoch 2899, Loss 8.701221\n",
      "Params: tensor([  4.5047, -12.0996])\n",
      "Grad:   tensor([-0.0027,  0.0153])\n",
      "Epoch 2900, Loss 8.701221\n",
      "Params: tensor([  4.5048, -12.0997])\n",
      "Grad:   tensor([-0.0027,  0.0153])\n",
      "Epoch 2901, Loss 8.701219\n",
      "Params: tensor([  4.5048, -12.0999])\n",
      "Grad:   tensor([-0.0027,  0.0152])\n",
      "Epoch 2902, Loss 8.701216\n",
      "Params: tensor([  4.5048, -12.1000])\n",
      "Grad:   tensor([-0.0027,  0.0152])\n",
      "Epoch 2903, Loss 8.701214\n",
      "Params: tensor([  4.5048, -12.1002])\n",
      "Grad:   tensor([-0.0027,  0.0152])\n",
      "Epoch 2904, Loss 8.701212\n",
      "Params: tensor([  4.5049, -12.1003])\n",
      "Grad:   tensor([-0.0027,  0.0152])\n",
      "Epoch 2905, Loss 8.701209\n",
      "Params: tensor([  4.5049, -12.1005])\n",
      "Grad:   tensor([-0.0027,  0.0151])\n",
      "Epoch 2906, Loss 8.701206\n",
      "Params: tensor([  4.5049, -12.1006])\n",
      "Grad:   tensor([-0.0027,  0.0151])\n",
      "Epoch 2907, Loss 8.701205\n",
      "Params: tensor([  4.5049, -12.1008])\n",
      "Grad:   tensor([-0.0027,  0.0151])\n",
      "Epoch 2908, Loss 8.701201\n",
      "Params: tensor([  4.5050, -12.1009])\n",
      "Grad:   tensor([-0.0027,  0.0151])\n",
      "Epoch 2909, Loss 8.701200\n",
      "Params: tensor([  4.5050, -12.1011])\n",
      "Grad:   tensor([-0.0027,  0.0150])\n",
      "Epoch 2910, Loss 8.701199\n",
      "Params: tensor([  4.5050, -12.1012])\n",
      "Grad:   tensor([-0.0027,  0.0150])\n",
      "Epoch 2911, Loss 8.701196\n",
      "Params: tensor([  4.5050, -12.1014])\n",
      "Grad:   tensor([-0.0026,  0.0150])\n",
      "Epoch 2912, Loss 8.701194\n",
      "Params: tensor([  4.5051, -12.1015])\n",
      "Grad:   tensor([-0.0026,  0.0150])\n",
      "Epoch 2913, Loss 8.701191\n",
      "Params: tensor([  4.5051, -12.1017])\n",
      "Grad:   tensor([-0.0026,  0.0149])\n",
      "Epoch 2914, Loss 8.701188\n",
      "Params: tensor([  4.5051, -12.1018])\n",
      "Grad:   tensor([-0.0026,  0.0149])\n",
      "Epoch 2915, Loss 8.701186\n",
      "Params: tensor([  4.5052, -12.1020])\n",
      "Grad:   tensor([-0.0026,  0.0149])\n",
      "Epoch 2916, Loss 8.701184\n",
      "Params: tensor([  4.5052, -12.1021])\n",
      "Grad:   tensor([-0.0026,  0.0149])\n",
      "Epoch 2917, Loss 8.701180\n",
      "Params: tensor([  4.5052, -12.1023])\n",
      "Grad:   tensor([-0.0026,  0.0148])\n",
      "Epoch 2918, Loss 8.701178\n",
      "Params: tensor([  4.5052, -12.1024])\n",
      "Grad:   tensor([-0.0026,  0.0148])\n",
      "Epoch 2919, Loss 8.701176\n",
      "Params: tensor([  4.5053, -12.1026])\n",
      "Grad:   tensor([-0.0026,  0.0148])\n",
      "Epoch 2920, Loss 8.701173\n",
      "Params: tensor([  4.5053, -12.1027])\n",
      "Grad:   tensor([-0.0026,  0.0148])\n",
      "Epoch 2921, Loss 8.701172\n",
      "Params: tensor([  4.5053, -12.1029])\n",
      "Grad:   tensor([-0.0026,  0.0147])\n",
      "Epoch 2922, Loss 8.701172\n",
      "Params: tensor([  4.5053, -12.1030])\n",
      "Grad:   tensor([-0.0026,  0.0147])\n",
      "Epoch 2923, Loss 8.701168\n",
      "Params: tensor([  4.5054, -12.1032])\n",
      "Grad:   tensor([-0.0026,  0.0147])\n",
      "Epoch 2924, Loss 8.701165\n",
      "Params: tensor([  4.5054, -12.1033])\n",
      "Grad:   tensor([-0.0026,  0.0147])\n",
      "Epoch 2925, Loss 8.701163\n",
      "Params: tensor([  4.5054, -12.1035])\n",
      "Grad:   tensor([-0.0026,  0.0146])\n",
      "Epoch 2926, Loss 8.701159\n",
      "Params: tensor([  4.5054, -12.1036])\n",
      "Grad:   tensor([-0.0026,  0.0146])\n",
      "Epoch 2927, Loss 8.701157\n",
      "Params: tensor([  4.5055, -12.1037])\n",
      "Grad:   tensor([-0.0026,  0.0146])\n",
      "Epoch 2928, Loss 8.701157\n",
      "Params: tensor([  4.5055, -12.1039])\n",
      "Grad:   tensor([-0.0026,  0.0146])\n",
      "Epoch 2929, Loss 8.701153\n",
      "Params: tensor([  4.5055, -12.1040])\n",
      "Grad:   tensor([-0.0026,  0.0145])\n",
      "Epoch 2930, Loss 8.701153\n",
      "Params: tensor([  4.5055, -12.1042])\n",
      "Grad:   tensor([-0.0026,  0.0145])\n",
      "Epoch 2931, Loss 8.701148\n",
      "Params: tensor([  4.5056, -12.1043])\n",
      "Grad:   tensor([-0.0025,  0.0145])\n",
      "Epoch 2932, Loss 8.701147\n",
      "Params: tensor([  4.5056, -12.1045])\n",
      "Grad:   tensor([-0.0026,  0.0145])\n",
      "Epoch 2933, Loss 8.701147\n",
      "Params: tensor([  4.5056, -12.1046])\n",
      "Grad:   tensor([-0.0025,  0.0144])\n",
      "Epoch 2934, Loss 8.701143\n",
      "Params: tensor([  4.5056, -12.1048])\n",
      "Grad:   tensor([-0.0025,  0.0144])\n",
      "Epoch 2935, Loss 8.701140\n",
      "Params: tensor([  4.5057, -12.1049])\n",
      "Grad:   tensor([-0.0025,  0.0144])\n",
      "Epoch 2936, Loss 8.701138\n",
      "Params: tensor([  4.5057, -12.1050])\n",
      "Grad:   tensor([-0.0026,  0.0144])\n",
      "Epoch 2937, Loss 8.701138\n",
      "Params: tensor([  4.5057, -12.1052])\n",
      "Grad:   tensor([-0.0025,  0.0143])\n",
      "Epoch 2938, Loss 8.701133\n",
      "Params: tensor([  4.5057, -12.1053])\n",
      "Grad:   tensor([-0.0025,  0.0143])\n",
      "Epoch 2939, Loss 8.701131\n",
      "Params: tensor([  4.5058, -12.1055])\n",
      "Grad:   tensor([-0.0025,  0.0143])\n",
      "Epoch 2940, Loss 8.701132\n",
      "Params: tensor([  4.5058, -12.1056])\n",
      "Grad:   tensor([-0.0025,  0.0143])\n",
      "Epoch 2941, Loss 8.701130\n",
      "Params: tensor([  4.5058, -12.1058])\n",
      "Grad:   tensor([-0.0025,  0.0142])\n",
      "Epoch 2942, Loss 8.701125\n",
      "Params: tensor([  4.5058, -12.1059])\n",
      "Grad:   tensor([-0.0025,  0.0142])\n",
      "Epoch 2943, Loss 8.701124\n",
      "Params: tensor([  4.5059, -12.1060])\n",
      "Grad:   tensor([-0.0025,  0.0142])\n",
      "Epoch 2944, Loss 8.701122\n",
      "Params: tensor([  4.5059, -12.1062])\n",
      "Grad:   tensor([-0.0025,  0.0142])\n",
      "Epoch 2945, Loss 8.701122\n",
      "Params: tensor([  4.5059, -12.1063])\n",
      "Grad:   tensor([-0.0025,  0.0141])\n",
      "Epoch 2946, Loss 8.701118\n",
      "Params: tensor([  4.5059, -12.1065])\n",
      "Grad:   tensor([-0.0025,  0.0141])\n",
      "Epoch 2947, Loss 8.701117\n",
      "Params: tensor([  4.5060, -12.1066])\n",
      "Grad:   tensor([-0.0025,  0.0141])\n",
      "Epoch 2948, Loss 8.701115\n",
      "Params: tensor([  4.5060, -12.1068])\n",
      "Grad:   tensor([-0.0025,  0.0141])\n",
      "Epoch 2949, Loss 8.701114\n",
      "Params: tensor([  4.5060, -12.1069])\n",
      "Grad:   tensor([-0.0025,  0.0140])\n",
      "Epoch 2950, Loss 8.701109\n",
      "Params: tensor([  4.5060, -12.1070])\n",
      "Grad:   tensor([-0.0025,  0.0140])\n",
      "Epoch 2951, Loss 8.701108\n",
      "Params: tensor([  4.5061, -12.1072])\n",
      "Grad:   tensor([-0.0025,  0.0140])\n",
      "Epoch 2952, Loss 8.701105\n",
      "Params: tensor([  4.5061, -12.1073])\n",
      "Grad:   tensor([-0.0025,  0.0140])\n",
      "Epoch 2953, Loss 8.701104\n",
      "Params: tensor([  4.5061, -12.1075])\n",
      "Grad:   tensor([-0.0025,  0.0139])\n",
      "Epoch 2954, Loss 8.701102\n",
      "Params: tensor([  4.5061, -12.1076])\n",
      "Grad:   tensor([-0.0025,  0.0139])\n",
      "Epoch 2955, Loss 8.701099\n",
      "Params: tensor([  4.5062, -12.1077])\n",
      "Grad:   tensor([-0.0024,  0.0139])\n",
      "Epoch 2956, Loss 8.701098\n",
      "Params: tensor([  4.5062, -12.1079])\n",
      "Grad:   tensor([-0.0025,  0.0139])\n",
      "Epoch 2957, Loss 8.701096\n",
      "Params: tensor([  4.5062, -12.1080])\n",
      "Grad:   tensor([-0.0024,  0.0139])\n",
      "Epoch 2958, Loss 8.701096\n",
      "Params: tensor([  4.5062, -12.1081])\n",
      "Grad:   tensor([-0.0024,  0.0138])\n",
      "Epoch 2959, Loss 8.701090\n",
      "Params: tensor([  4.5063, -12.1083])\n",
      "Grad:   tensor([-0.0024,  0.0138])\n",
      "Epoch 2960, Loss 8.701089\n",
      "Params: tensor([  4.5063, -12.1084])\n",
      "Grad:   tensor([-0.0025,  0.0138])\n",
      "Epoch 2961, Loss 8.701087\n",
      "Params: tensor([  4.5063, -12.1086])\n",
      "Grad:   tensor([-0.0025,  0.0138])\n",
      "Epoch 2962, Loss 8.701087\n",
      "Params: tensor([  4.5063, -12.1087])\n",
      "Grad:   tensor([-0.0024,  0.0137])\n",
      "Epoch 2963, Loss 8.701084\n",
      "Params: tensor([  4.5064, -12.1088])\n",
      "Grad:   tensor([-0.0024,  0.0137])\n",
      "Epoch 2964, Loss 8.701081\n",
      "Params: tensor([  4.5064, -12.1090])\n",
      "Grad:   tensor([-0.0024,  0.0137])\n",
      "Epoch 2965, Loss 8.701079\n",
      "Params: tensor([  4.5064, -12.1091])\n",
      "Grad:   tensor([-0.0024,  0.0137])\n",
      "Epoch 2966, Loss 8.701079\n",
      "Params: tensor([  4.5064, -12.1092])\n",
      "Grad:   tensor([-0.0024,  0.0136])\n",
      "Epoch 2967, Loss 8.701077\n",
      "Params: tensor([  4.5065, -12.1094])\n",
      "Grad:   tensor([-0.0024,  0.0136])\n",
      "Epoch 2968, Loss 8.701075\n",
      "Params: tensor([  4.5065, -12.1095])\n",
      "Grad:   tensor([-0.0024,  0.0136])\n",
      "Epoch 2969, Loss 8.701074\n",
      "Params: tensor([  4.5065, -12.1097])\n",
      "Grad:   tensor([-0.0024,  0.0136])\n",
      "Epoch 2970, Loss 8.701069\n",
      "Params: tensor([  4.5065, -12.1098])\n",
      "Grad:   tensor([-0.0024,  0.0136])\n",
      "Epoch 2971, Loss 8.701069\n",
      "Params: tensor([  4.5066, -12.1099])\n",
      "Grad:   tensor([-0.0024,  0.0135])\n",
      "Epoch 2972, Loss 8.701066\n",
      "Params: tensor([  4.5066, -12.1101])\n",
      "Grad:   tensor([-0.0024,  0.0135])\n",
      "Epoch 2973, Loss 8.701066\n",
      "Params: tensor([  4.5066, -12.1102])\n",
      "Grad:   tensor([-0.0024,  0.0135])\n",
      "Epoch 2974, Loss 8.701061\n",
      "Params: tensor([  4.5066, -12.1103])\n",
      "Grad:   tensor([-0.0024,  0.0135])\n",
      "Epoch 2975, Loss 8.701059\n",
      "Params: tensor([  4.5066, -12.1105])\n",
      "Grad:   tensor([-0.0024,  0.0134])\n",
      "Epoch 2976, Loss 8.701059\n",
      "Params: tensor([  4.5067, -12.1106])\n",
      "Grad:   tensor([-0.0024,  0.0134])\n",
      "Epoch 2977, Loss 8.701059\n",
      "Params: tensor([  4.5067, -12.1107])\n",
      "Grad:   tensor([-0.0024,  0.0134])\n",
      "Epoch 2978, Loss 8.701056\n",
      "Params: tensor([  4.5067, -12.1109])\n",
      "Grad:   tensor([-0.0024,  0.0134])\n",
      "Epoch 2979, Loss 8.701056\n",
      "Params: tensor([  4.5067, -12.1110])\n",
      "Grad:   tensor([-0.0024,  0.0133])\n",
      "Epoch 2980, Loss 8.701051\n",
      "Params: tensor([  4.5068, -12.1111])\n",
      "Grad:   tensor([-0.0023,  0.0133])\n",
      "Epoch 2981, Loss 8.701049\n",
      "Params: tensor([  4.5068, -12.1113])\n",
      "Grad:   tensor([-0.0024,  0.0133])\n",
      "Epoch 2982, Loss 8.701048\n",
      "Params: tensor([  4.5068, -12.1114])\n",
      "Grad:   tensor([-0.0024,  0.0133])\n",
      "Epoch 2983, Loss 8.701046\n",
      "Params: tensor([  4.5068, -12.1115])\n",
      "Grad:   tensor([-0.0024,  0.0133])\n",
      "Epoch 2984, Loss 8.701045\n",
      "Params: tensor([  4.5069, -12.1117])\n",
      "Grad:   tensor([-0.0024,  0.0132])\n",
      "Epoch 2985, Loss 8.701044\n",
      "Params: tensor([  4.5069, -12.1118])\n",
      "Grad:   tensor([-0.0024,  0.0132])\n",
      "Epoch 2986, Loss 8.701042\n",
      "Params: tensor([  4.5069, -12.1119])\n",
      "Grad:   tensor([-0.0024,  0.0132])\n",
      "Epoch 2987, Loss 8.701037\n",
      "Params: tensor([  4.5069, -12.1121])\n",
      "Grad:   tensor([-0.0023,  0.0132])\n",
      "Epoch 2988, Loss 8.701040\n",
      "Params: tensor([  4.5070, -12.1122])\n",
      "Grad:   tensor([-0.0023,  0.0131])\n",
      "Epoch 2989, Loss 8.701035\n",
      "Params: tensor([  4.5070, -12.1123])\n",
      "Grad:   tensor([-0.0023,  0.0131])\n",
      "Epoch 2990, Loss 8.701035\n",
      "Params: tensor([  4.5070, -12.1125])\n",
      "Grad:   tensor([-0.0023,  0.0131])\n",
      "Epoch 2991, Loss 8.701035\n",
      "Params: tensor([  4.5070, -12.1126])\n",
      "Grad:   tensor([-0.0023,  0.0131])\n",
      "Epoch 2992, Loss 8.701032\n",
      "Params: tensor([  4.5070, -12.1127])\n",
      "Grad:   tensor([-0.0023,  0.0131])\n",
      "Epoch 2993, Loss 8.701028\n",
      "Params: tensor([  4.5071, -12.1128])\n",
      "Grad:   tensor([-0.0023,  0.0130])\n",
      "Epoch 2994, Loss 8.701028\n",
      "Params: tensor([  4.5071, -12.1130])\n",
      "Grad:   tensor([-0.0023,  0.0130])\n",
      "Epoch 2995, Loss 8.701026\n",
      "Params: tensor([  4.5071, -12.1131])\n",
      "Grad:   tensor([-0.0023,  0.0130])\n",
      "Epoch 2996, Loss 8.701026\n",
      "Params: tensor([  4.5071, -12.1132])\n",
      "Grad:   tensor([-0.0023,  0.0130])\n",
      "Epoch 2997, Loss 8.701023\n",
      "Params: tensor([  4.5072, -12.1134])\n",
      "Grad:   tensor([-0.0023,  0.0129])\n",
      "Epoch 2998, Loss 8.701022\n",
      "Params: tensor([  4.5072, -12.1135])\n",
      "Grad:   tensor([-0.0023,  0.0129])\n",
      "Epoch 2999, Loss 8.701018\n",
      "Params: tensor([  4.5072, -12.1136])\n",
      "Grad:   tensor([-0.0023,  0.0129])\n",
      "Epoch 3000, Loss 8.701015\n",
      "Params: tensor([  4.5072, -12.1138])\n",
      "Grad:   tensor([-0.0023,  0.0129])\n",
      "Epoch 3001, Loss 8.701014\n",
      "Params: tensor([  4.5073, -12.1139])\n",
      "Grad:   tensor([-0.0023,  0.0129])\n",
      "Epoch 3002, Loss 8.701013\n",
      "Params: tensor([  4.5073, -12.1140])\n",
      "Grad:   tensor([-0.0023,  0.0128])\n",
      "Epoch 3003, Loss 8.701013\n",
      "Params: tensor([  4.5073, -12.1141])\n",
      "Grad:   tensor([-0.0023,  0.0128])\n",
      "Epoch 3004, Loss 8.701011\n",
      "Params: tensor([  4.5073, -12.1143])\n",
      "Grad:   tensor([-0.0023,  0.0128])\n",
      "Epoch 3005, Loss 8.701008\n",
      "Params: tensor([  4.5073, -12.1144])\n",
      "Grad:   tensor([-0.0023,  0.0128])\n",
      "Epoch 3006, Loss 8.701005\n",
      "Params: tensor([  4.5074, -12.1145])\n",
      "Grad:   tensor([-0.0023,  0.0127])\n",
      "Epoch 3007, Loss 8.701004\n",
      "Params: tensor([  4.5074, -12.1146])\n",
      "Grad:   tensor([-0.0023,  0.0127])\n",
      "Epoch 3008, Loss 8.701004\n",
      "Params: tensor([  4.5074, -12.1148])\n",
      "Grad:   tensor([-0.0022,  0.0127])\n",
      "Epoch 3009, Loss 8.700998\n",
      "Params: tensor([  4.5074, -12.1149])\n",
      "Grad:   tensor([-0.0022,  0.0127])\n",
      "Epoch 3010, Loss 8.701000\n",
      "Params: tensor([  4.5075, -12.1150])\n",
      "Grad:   tensor([-0.0022,  0.0127])\n",
      "Epoch 3011, Loss 8.700997\n",
      "Params: tensor([  4.5075, -12.1152])\n",
      "Grad:   tensor([-0.0022,  0.0126])\n",
      "Epoch 3012, Loss 8.700997\n",
      "Params: tensor([  4.5075, -12.1153])\n",
      "Grad:   tensor([-0.0022,  0.0126])\n",
      "Epoch 3013, Loss 8.700995\n",
      "Params: tensor([  4.5075, -12.1154])\n",
      "Grad:   tensor([-0.0022,  0.0126])\n",
      "Epoch 3014, Loss 8.700993\n",
      "Params: tensor([  4.5075, -12.1155])\n",
      "Grad:   tensor([-0.0022,  0.0126])\n",
      "Epoch 3015, Loss 8.700991\n",
      "Params: tensor([  4.5076, -12.1157])\n",
      "Grad:   tensor([-0.0022,  0.0126])\n",
      "Epoch 3016, Loss 8.700988\n",
      "Params: tensor([  4.5076, -12.1158])\n",
      "Grad:   tensor([-0.0022,  0.0125])\n",
      "Epoch 3017, Loss 8.700989\n",
      "Params: tensor([  4.5076, -12.1159])\n",
      "Grad:   tensor([-0.0022,  0.0125])\n",
      "Epoch 3018, Loss 8.700986\n",
      "Params: tensor([  4.5076, -12.1160])\n",
      "Grad:   tensor([-0.0022,  0.0125])\n",
      "Epoch 3019, Loss 8.700985\n",
      "Params: tensor([  4.5077, -12.1162])\n",
      "Grad:   tensor([-0.0022,  0.0125])\n",
      "Epoch 3020, Loss 8.700983\n",
      "Params: tensor([  4.5077, -12.1163])\n",
      "Grad:   tensor([-0.0022,  0.0124])\n",
      "Epoch 3021, Loss 8.700983\n",
      "Params: tensor([  4.5077, -12.1164])\n",
      "Grad:   tensor([-0.0022,  0.0124])\n",
      "Epoch 3022, Loss 8.700980\n",
      "Params: tensor([  4.5077, -12.1165])\n",
      "Grad:   tensor([-0.0022,  0.0124])\n",
      "Epoch 3023, Loss 8.700980\n",
      "Params: tensor([  4.5077, -12.1167])\n",
      "Grad:   tensor([-0.0022,  0.0124])\n",
      "Epoch 3024, Loss 8.700977\n",
      "Params: tensor([  4.5078, -12.1168])\n",
      "Grad:   tensor([-0.0022,  0.0124])\n",
      "Epoch 3025, Loss 8.700977\n",
      "Params: tensor([  4.5078, -12.1169])\n",
      "Grad:   tensor([-0.0022,  0.0123])\n",
      "Epoch 3026, Loss 8.700974\n",
      "Params: tensor([  4.5078, -12.1170])\n",
      "Grad:   tensor([-0.0022,  0.0123])\n",
      "Epoch 3027, Loss 8.700971\n",
      "Params: tensor([  4.5078, -12.1171])\n",
      "Grad:   tensor([-0.0022,  0.0123])\n",
      "Epoch 3028, Loss 8.700970\n",
      "Params: tensor([  4.5079, -12.1173])\n",
      "Grad:   tensor([-0.0022,  0.0123])\n",
      "Epoch 3029, Loss 8.700971\n",
      "Params: tensor([  4.5079, -12.1174])\n",
      "Grad:   tensor([-0.0022,  0.0123])\n",
      "Epoch 3030, Loss 8.700967\n",
      "Params: tensor([  4.5079, -12.1175])\n",
      "Grad:   tensor([-0.0022,  0.0122])\n",
      "Epoch 3031, Loss 8.700967\n",
      "Params: tensor([  4.5079, -12.1176])\n",
      "Grad:   tensor([-0.0022,  0.0122])\n",
      "Epoch 3032, Loss 8.700965\n",
      "Params: tensor([  4.5079, -12.1178])\n",
      "Grad:   tensor([-0.0021,  0.0122])\n",
      "Epoch 3033, Loss 8.700962\n",
      "Params: tensor([  4.5080, -12.1179])\n",
      "Grad:   tensor([-0.0021,  0.0122])\n",
      "Epoch 3034, Loss 8.700963\n",
      "Params: tensor([  4.5080, -12.1180])\n",
      "Grad:   tensor([-0.0022,  0.0122])\n",
      "Epoch 3035, Loss 8.700961\n",
      "Params: tensor([  4.5080, -12.1181])\n",
      "Grad:   tensor([-0.0021,  0.0121])\n",
      "Epoch 3036, Loss 8.700959\n",
      "Params: tensor([  4.5080, -12.1182])\n",
      "Grad:   tensor([-0.0021,  0.0121])\n",
      "Epoch 3037, Loss 8.700958\n",
      "Params: tensor([  4.5080, -12.1184])\n",
      "Grad:   tensor([-0.0021,  0.0121])\n",
      "Epoch 3038, Loss 8.700955\n",
      "Params: tensor([  4.5081, -12.1185])\n",
      "Grad:   tensor([-0.0021,  0.0121])\n",
      "Epoch 3039, Loss 8.700954\n",
      "Params: tensor([  4.5081, -12.1186])\n",
      "Grad:   tensor([-0.0021,  0.0121])\n",
      "Epoch 3040, Loss 8.700952\n",
      "Params: tensor([  4.5081, -12.1187])\n",
      "Grad:   tensor([-0.0021,  0.0120])\n",
      "Epoch 3041, Loss 8.700952\n",
      "Params: tensor([  4.5081, -12.1188])\n",
      "Grad:   tensor([-0.0021,  0.0120])\n",
      "Epoch 3042, Loss 8.700949\n",
      "Params: tensor([  4.5082, -12.1190])\n",
      "Grad:   tensor([-0.0021,  0.0120])\n",
      "Epoch 3043, Loss 8.700949\n",
      "Params: tensor([  4.5082, -12.1191])\n",
      "Grad:   tensor([-0.0021,  0.0120])\n",
      "Epoch 3044, Loss 8.700946\n",
      "Params: tensor([  4.5082, -12.1192])\n",
      "Grad:   tensor([-0.0021,  0.0120])\n",
      "Epoch 3045, Loss 8.700946\n",
      "Params: tensor([  4.5082, -12.1193])\n",
      "Grad:   tensor([-0.0021,  0.0119])\n",
      "Epoch 3046, Loss 8.700944\n",
      "Params: tensor([  4.5082, -12.1194])\n",
      "Grad:   tensor([-0.0021,  0.0119])\n",
      "Epoch 3047, Loss 8.700942\n",
      "Params: tensor([  4.5083, -12.1196])\n",
      "Grad:   tensor([-0.0021,  0.0119])\n",
      "Epoch 3048, Loss 8.700942\n",
      "Params: tensor([  4.5083, -12.1197])\n",
      "Grad:   tensor([-0.0021,  0.0119])\n",
      "Epoch 3049, Loss 8.700939\n",
      "Params: tensor([  4.5083, -12.1198])\n",
      "Grad:   tensor([-0.0021,  0.0118])\n",
      "Epoch 3050, Loss 8.700937\n",
      "Params: tensor([  4.5083, -12.1199])\n",
      "Grad:   tensor([-0.0021,  0.0118])\n",
      "Epoch 3051, Loss 8.700936\n",
      "Params: tensor([  4.5083, -12.1200])\n",
      "Grad:   tensor([-0.0021,  0.0118])\n",
      "Epoch 3052, Loss 8.700934\n",
      "Params: tensor([  4.5084, -12.1202])\n",
      "Grad:   tensor([-0.0021,  0.0118])\n",
      "Epoch 3053, Loss 8.700933\n",
      "Params: tensor([  4.5084, -12.1203])\n",
      "Grad:   tensor([-0.0021,  0.0118])\n",
      "Epoch 3054, Loss 8.700933\n",
      "Params: tensor([  4.5084, -12.1204])\n",
      "Grad:   tensor([-0.0021,  0.0118])\n",
      "Epoch 3055, Loss 8.700933\n",
      "Params: tensor([  4.5084, -12.1205])\n",
      "Grad:   tensor([-0.0021,  0.0117])\n",
      "Epoch 3056, Loss 8.700931\n",
      "Params: tensor([  4.5084, -12.1206])\n",
      "Grad:   tensor([-0.0021,  0.0117])\n",
      "Epoch 3057, Loss 8.700928\n",
      "Params: tensor([  4.5085, -12.1207])\n",
      "Grad:   tensor([-0.0021,  0.0117])\n",
      "Epoch 3058, Loss 8.700927\n",
      "Params: tensor([  4.5085, -12.1209])\n",
      "Grad:   tensor([-0.0021,  0.0117])\n",
      "Epoch 3059, Loss 8.700927\n",
      "Params: tensor([  4.5085, -12.1210])\n",
      "Grad:   tensor([-0.0021,  0.0117])\n",
      "Epoch 3060, Loss 8.700924\n",
      "Params: tensor([  4.5085, -12.1211])\n",
      "Grad:   tensor([-0.0021,  0.0116])\n",
      "Epoch 3061, Loss 8.700925\n",
      "Params: tensor([  4.5085, -12.1212])\n",
      "Grad:   tensor([-0.0021,  0.0116])\n",
      "Epoch 3062, Loss 8.700922\n",
      "Params: tensor([  4.5086, -12.1213])\n",
      "Grad:   tensor([-0.0021,  0.0116])\n",
      "Epoch 3063, Loss 8.700922\n",
      "Params: tensor([  4.5086, -12.1214])\n",
      "Grad:   tensor([-0.0021,  0.0116])\n",
      "Epoch 3064, Loss 8.700918\n",
      "Params: tensor([  4.5086, -12.1216])\n",
      "Grad:   tensor([-0.0021,  0.0116])\n",
      "Epoch 3065, Loss 8.700914\n",
      "Params: tensor([  4.5086, -12.1217])\n",
      "Grad:   tensor([-0.0020,  0.0115])\n",
      "Epoch 3066, Loss 8.700913\n",
      "Params: tensor([  4.5086, -12.1218])\n",
      "Grad:   tensor([-0.0020,  0.0115])\n",
      "Epoch 3067, Loss 8.700912\n",
      "Params: tensor([  4.5087, -12.1219])\n",
      "Grad:   tensor([-0.0020,  0.0115])\n",
      "Epoch 3068, Loss 8.700913\n",
      "Params: tensor([  4.5087, -12.1220])\n",
      "Grad:   tensor([-0.0020,  0.0115])\n",
      "Epoch 3069, Loss 8.700911\n",
      "Params: tensor([  4.5087, -12.1221])\n",
      "Grad:   tensor([-0.0020,  0.0115])\n",
      "Epoch 3070, Loss 8.700909\n",
      "Params: tensor([  4.5087, -12.1222])\n",
      "Grad:   tensor([-0.0020,  0.0114])\n",
      "Epoch 3071, Loss 8.700908\n",
      "Params: tensor([  4.5088, -12.1224])\n",
      "Grad:   tensor([-0.0020,  0.0114])\n",
      "Epoch 3072, Loss 8.700907\n",
      "Params: tensor([  4.5088, -12.1225])\n",
      "Grad:   tensor([-0.0020,  0.0114])\n",
      "Epoch 3073, Loss 8.700906\n",
      "Params: tensor([  4.5088, -12.1226])\n",
      "Grad:   tensor([-0.0020,  0.0114])\n",
      "Epoch 3074, Loss 8.700904\n",
      "Params: tensor([  4.5088, -12.1227])\n",
      "Grad:   tensor([-0.0020,  0.0114])\n",
      "Epoch 3075, Loss 8.700901\n",
      "Params: tensor([  4.5088, -12.1228])\n",
      "Grad:   tensor([-0.0020,  0.0113])\n",
      "Epoch 3076, Loss 8.700901\n",
      "Params: tensor([  4.5089, -12.1229])\n",
      "Grad:   tensor([-0.0020,  0.0113])\n",
      "Epoch 3077, Loss 8.700900\n",
      "Params: tensor([  4.5089, -12.1230])\n",
      "Grad:   tensor([-0.0020,  0.0113])\n",
      "Epoch 3078, Loss 8.700898\n",
      "Params: tensor([  4.5089, -12.1232])\n",
      "Grad:   tensor([-0.0020,  0.0113])\n",
      "Epoch 3079, Loss 8.700896\n",
      "Params: tensor([  4.5089, -12.1233])\n",
      "Grad:   tensor([-0.0020,  0.0113])\n",
      "Epoch 3080, Loss 8.700896\n",
      "Params: tensor([  4.5089, -12.1234])\n",
      "Grad:   tensor([-0.0020,  0.0112])\n",
      "Epoch 3081, Loss 8.700894\n",
      "Params: tensor([  4.5090, -12.1235])\n",
      "Grad:   tensor([-0.0020,  0.0112])\n",
      "Epoch 3082, Loss 8.700896\n",
      "Params: tensor([  4.5090, -12.1236])\n",
      "Grad:   tensor([-0.0020,  0.0112])\n",
      "Epoch 3083, Loss 8.700893\n",
      "Params: tensor([  4.5090, -12.1237])\n",
      "Grad:   tensor([-0.0020,  0.0112])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3084, Loss 8.700889\n",
      "Params: tensor([  4.5090, -12.1238])\n",
      "Grad:   tensor([-0.0020,  0.0112])\n",
      "Epoch 3085, Loss 8.700891\n",
      "Params: tensor([  4.5090, -12.1239])\n",
      "Grad:   tensor([-0.0020,  0.0111])\n",
      "Epoch 3086, Loss 8.700891\n",
      "Params: tensor([  4.5090, -12.1240])\n",
      "Grad:   tensor([-0.0020,  0.0111])\n",
      "Epoch 3087, Loss 8.700889\n",
      "Params: tensor([  4.5091, -12.1242])\n",
      "Grad:   tensor([-0.0020,  0.0111])\n",
      "Epoch 3088, Loss 8.700888\n",
      "Params: tensor([  4.5091, -12.1243])\n",
      "Grad:   tensor([-0.0020,  0.0111])\n",
      "Epoch 3089, Loss 8.700885\n",
      "Params: tensor([  4.5091, -12.1244])\n",
      "Grad:   tensor([-0.0020,  0.0111])\n",
      "Epoch 3090, Loss 8.700885\n",
      "Params: tensor([  4.5091, -12.1245])\n",
      "Grad:   tensor([-0.0020,  0.0111])\n",
      "Epoch 3091, Loss 8.700882\n",
      "Params: tensor([  4.5091, -12.1246])\n",
      "Grad:   tensor([-0.0020,  0.0110])\n",
      "Epoch 3092, Loss 8.700881\n",
      "Params: tensor([  4.5092, -12.1247])\n",
      "Grad:   tensor([-0.0019,  0.0110])\n",
      "Epoch 3093, Loss 8.700881\n",
      "Params: tensor([  4.5092, -12.1248])\n",
      "Grad:   tensor([-0.0019,  0.0110])\n",
      "Epoch 3094, Loss 8.700879\n",
      "Params: tensor([  4.5092, -12.1249])\n",
      "Grad:   tensor([-0.0019,  0.0110])\n",
      "Epoch 3095, Loss 8.700879\n",
      "Params: tensor([  4.5092, -12.1250])\n",
      "Grad:   tensor([-0.0019,  0.0110])\n",
      "Epoch 3096, Loss 8.700877\n",
      "Params: tensor([  4.5092, -12.1251])\n",
      "Grad:   tensor([-0.0019,  0.0109])\n",
      "Epoch 3097, Loss 8.700875\n",
      "Params: tensor([  4.5093, -12.1253])\n",
      "Grad:   tensor([-0.0019,  0.0109])\n",
      "Epoch 3098, Loss 8.700875\n",
      "Params: tensor([  4.5093, -12.1254])\n",
      "Grad:   tensor([-0.0019,  0.0109])\n",
      "Epoch 3099, Loss 8.700872\n",
      "Params: tensor([  4.5093, -12.1255])\n",
      "Grad:   tensor([-0.0019,  0.0109])\n",
      "Epoch 3100, Loss 8.700871\n",
      "Params: tensor([  4.5093, -12.1256])\n",
      "Grad:   tensor([-0.0019,  0.0109])\n",
      "Epoch 3101, Loss 8.700871\n",
      "Params: tensor([  4.5093, -12.1257])\n",
      "Grad:   tensor([-0.0019,  0.0108])\n",
      "Epoch 3102, Loss 8.700868\n",
      "Params: tensor([  4.5094, -12.1258])\n",
      "Grad:   tensor([-0.0019,  0.0108])\n",
      "Epoch 3103, Loss 8.700868\n",
      "Params: tensor([  4.5094, -12.1259])\n",
      "Grad:   tensor([-0.0019,  0.0108])\n",
      "Epoch 3104, Loss 8.700867\n",
      "Params: tensor([  4.5094, -12.1260])\n",
      "Grad:   tensor([-0.0019,  0.0108])\n",
      "Epoch 3105, Loss 8.700863\n",
      "Params: tensor([  4.5094, -12.1261])\n",
      "Grad:   tensor([-0.0019,  0.0108])\n",
      "Epoch 3106, Loss 8.700864\n",
      "Params: tensor([  4.5094, -12.1262])\n",
      "Grad:   tensor([-0.0019,  0.0108])\n",
      "Epoch 3107, Loss 8.700862\n",
      "Params: tensor([  4.5095, -12.1263])\n",
      "Grad:   tensor([-0.0019,  0.0107])\n",
      "Epoch 3108, Loss 8.700863\n",
      "Params: tensor([  4.5095, -12.1264])\n",
      "Grad:   tensor([-0.0019,  0.0107])\n",
      "Epoch 3109, Loss 8.700860\n",
      "Params: tensor([  4.5095, -12.1266])\n",
      "Grad:   tensor([-0.0019,  0.0107])\n",
      "Epoch 3110, Loss 8.700858\n",
      "Params: tensor([  4.5095, -12.1267])\n",
      "Grad:   tensor([-0.0019,  0.0107])\n",
      "Epoch 3111, Loss 8.700860\n",
      "Params: tensor([  4.5095, -12.1268])\n",
      "Grad:   tensor([-0.0019,  0.0107])\n",
      "Epoch 3112, Loss 8.700858\n",
      "Params: tensor([  4.5095, -12.1269])\n",
      "Grad:   tensor([-0.0019,  0.0106])\n",
      "Epoch 3113, Loss 8.700857\n",
      "Params: tensor([  4.5096, -12.1270])\n",
      "Grad:   tensor([-0.0019,  0.0106])\n",
      "Epoch 3114, Loss 8.700854\n",
      "Params: tensor([  4.5096, -12.1271])\n",
      "Grad:   tensor([-0.0019,  0.0106])\n",
      "Epoch 3115, Loss 8.700854\n",
      "Params: tensor([  4.5096, -12.1272])\n",
      "Grad:   tensor([-0.0019,  0.0106])\n",
      "Epoch 3116, Loss 8.700852\n",
      "Params: tensor([  4.5096, -12.1273])\n",
      "Grad:   tensor([-0.0019,  0.0106])\n",
      "Epoch 3117, Loss 8.700854\n",
      "Params: tensor([  4.5096, -12.1274])\n",
      "Grad:   tensor([-0.0019,  0.0106])\n",
      "Epoch 3118, Loss 8.700850\n",
      "Params: tensor([  4.5097, -12.1275])\n",
      "Grad:   tensor([-0.0019,  0.0105])\n",
      "Epoch 3119, Loss 8.700849\n",
      "Params: tensor([  4.5097, -12.1276])\n",
      "Grad:   tensor([-0.0019,  0.0105])\n",
      "Epoch 3120, Loss 8.700849\n",
      "Params: tensor([  4.5097, -12.1277])\n",
      "Grad:   tensor([-0.0019,  0.0105])\n",
      "Epoch 3121, Loss 8.700846\n",
      "Params: tensor([  4.5097, -12.1278])\n",
      "Grad:   tensor([-0.0019,  0.0105])\n",
      "Epoch 3122, Loss 8.700845\n",
      "Params: tensor([  4.5097, -12.1279])\n",
      "Grad:   tensor([-0.0019,  0.0105])\n",
      "Epoch 3123, Loss 8.700843\n",
      "Params: tensor([  4.5098, -12.1280])\n",
      "Grad:   tensor([-0.0018,  0.0105])\n",
      "Epoch 3124, Loss 8.700843\n",
      "Params: tensor([  4.5098, -12.1281])\n",
      "Grad:   tensor([-0.0018,  0.0104])\n",
      "Epoch 3125, Loss 8.700845\n",
      "Params: tensor([  4.5098, -12.1282])\n",
      "Grad:   tensor([-0.0019,  0.0104])\n",
      "Epoch 3126, Loss 8.700842\n",
      "Params: tensor([  4.5098, -12.1283])\n",
      "Grad:   tensor([-0.0018,  0.0104])\n",
      "Epoch 3127, Loss 8.700842\n",
      "Params: tensor([  4.5098, -12.1285])\n",
      "Grad:   tensor([-0.0018,  0.0104])\n",
      "Epoch 3128, Loss 8.700841\n",
      "Params: tensor([  4.5098, -12.1286])\n",
      "Grad:   tensor([-0.0018,  0.0104])\n",
      "Epoch 3129, Loss 8.700838\n",
      "Params: tensor([  4.5099, -12.1287])\n",
      "Grad:   tensor([-0.0018,  0.0103])\n",
      "Epoch 3130, Loss 8.700836\n",
      "Params: tensor([  4.5099, -12.1288])\n",
      "Grad:   tensor([-0.0018,  0.0103])\n",
      "Epoch 3131, Loss 8.700835\n",
      "Params: tensor([  4.5099, -12.1289])\n",
      "Grad:   tensor([-0.0018,  0.0103])\n",
      "Epoch 3132, Loss 8.700833\n",
      "Params: tensor([  4.5099, -12.1290])\n",
      "Grad:   tensor([-0.0018,  0.0103])\n",
      "Epoch 3133, Loss 8.700832\n",
      "Params: tensor([  4.5099, -12.1291])\n",
      "Grad:   tensor([-0.0018,  0.0103])\n",
      "Epoch 3134, Loss 8.700832\n",
      "Params: tensor([  4.5100, -12.1292])\n",
      "Grad:   tensor([-0.0018,  0.0103])\n",
      "Epoch 3135, Loss 8.700830\n",
      "Params: tensor([  4.5100, -12.1293])\n",
      "Grad:   tensor([-0.0018,  0.0102])\n",
      "Epoch 3136, Loss 8.700833\n",
      "Params: tensor([  4.5100, -12.1294])\n",
      "Grad:   tensor([-0.0018,  0.0102])\n",
      "Epoch 3137, Loss 8.700830\n",
      "Params: tensor([  4.5100, -12.1295])\n",
      "Grad:   tensor([-0.0018,  0.0102])\n",
      "Epoch 3138, Loss 8.700830\n",
      "Params: tensor([  4.5100, -12.1296])\n",
      "Grad:   tensor([-0.0018,  0.0102])\n",
      "Epoch 3139, Loss 8.700829\n",
      "Params: tensor([  4.5100, -12.1297])\n",
      "Grad:   tensor([-0.0018,  0.0102])\n",
      "Epoch 3140, Loss 8.700828\n",
      "Params: tensor([  4.5101, -12.1298])\n",
      "Grad:   tensor([-0.0018,  0.0102])\n",
      "Epoch 3141, Loss 8.700827\n",
      "Params: tensor([  4.5101, -12.1299])\n",
      "Grad:   tensor([-0.0018,  0.0101])\n",
      "Epoch 3142, Loss 8.700825\n",
      "Params: tensor([  4.5101, -12.1300])\n",
      "Grad:   tensor([-0.0018,  0.0101])\n",
      "Epoch 3143, Loss 8.700822\n",
      "Params: tensor([  4.5101, -12.1301])\n",
      "Grad:   tensor([-0.0018,  0.0101])\n",
      "Epoch 3144, Loss 8.700822\n",
      "Params: tensor([  4.5101, -12.1302])\n",
      "Grad:   tensor([-0.0018,  0.0101])\n",
      "Epoch 3145, Loss 8.700821\n",
      "Params: tensor([  4.5102, -12.1303])\n",
      "Grad:   tensor([-0.0018,  0.0101])\n",
      "Epoch 3146, Loss 8.700820\n",
      "Params: tensor([  4.5102, -12.1304])\n",
      "Grad:   tensor([-0.0018,  0.0100])\n",
      "Epoch 3147, Loss 8.700821\n",
      "Params: tensor([  4.5102, -12.1305])\n",
      "Grad:   tensor([-0.0018,  0.0100])\n",
      "Epoch 3148, Loss 8.700817\n",
      "Params: tensor([  4.5102, -12.1306])\n",
      "Grad:   tensor([-0.0018,  0.0100])\n",
      "Epoch 3149, Loss 8.700817\n",
      "Params: tensor([  4.5102, -12.1307])\n",
      "Grad:   tensor([-0.0018,  0.0100])\n",
      "Epoch 3150, Loss 8.700817\n",
      "Params: tensor([  4.5102, -12.1308])\n",
      "Grad:   tensor([-0.0018,  0.0100])\n",
      "Epoch 3151, Loss 8.700814\n",
      "Params: tensor([  4.5103, -12.1309])\n",
      "Grad:   tensor([-0.0018,  0.0100])\n",
      "Epoch 3152, Loss 8.700814\n",
      "Params: tensor([  4.5103, -12.1310])\n",
      "Grad:   tensor([-0.0018,  0.0099])\n",
      "Epoch 3153, Loss 8.700812\n",
      "Params: tensor([  4.5103, -12.1311])\n",
      "Grad:   tensor([-0.0017,  0.0099])\n",
      "Epoch 3154, Loss 8.700812\n",
      "Params: tensor([  4.5103, -12.1312])\n",
      "Grad:   tensor([-0.0017,  0.0099])\n",
      "Epoch 3155, Loss 8.700812\n",
      "Params: tensor([  4.5103, -12.1313])\n",
      "Grad:   tensor([-0.0017,  0.0099])\n",
      "Epoch 3156, Loss 8.700809\n",
      "Params: tensor([  4.5103, -12.1314])\n",
      "Grad:   tensor([-0.0018,  0.0099])\n",
      "Epoch 3157, Loss 8.700809\n",
      "Params: tensor([  4.5104, -12.1315])\n",
      "Grad:   tensor([-0.0017,  0.0099])\n",
      "Epoch 3158, Loss 8.700809\n",
      "Params: tensor([  4.5104, -12.1316])\n",
      "Grad:   tensor([-0.0017,  0.0098])\n",
      "Epoch 3159, Loss 8.700806\n",
      "Params: tensor([  4.5104, -12.1317])\n",
      "Grad:   tensor([-0.0017,  0.0098])\n",
      "Epoch 3160, Loss 8.700803\n",
      "Params: tensor([  4.5104, -12.1318])\n",
      "Grad:   tensor([-0.0017,  0.0098])\n",
      "Epoch 3161, Loss 8.700806\n",
      "Params: tensor([  4.5104, -12.1319])\n",
      "Grad:   tensor([-0.0017,  0.0098])\n",
      "Epoch 3162, Loss 8.700805\n",
      "Params: tensor([  4.5104, -12.1320])\n",
      "Grad:   tensor([-0.0017,  0.0098])\n",
      "Epoch 3163, Loss 8.700803\n",
      "Params: tensor([  4.5105, -12.1321])\n",
      "Grad:   tensor([-0.0017,  0.0098])\n",
      "Epoch 3164, Loss 8.700803\n",
      "Params: tensor([  4.5105, -12.1322])\n",
      "Grad:   tensor([-0.0017,  0.0097])\n",
      "Epoch 3165, Loss 8.700801\n",
      "Params: tensor([  4.5105, -12.1323])\n",
      "Grad:   tensor([-0.0017,  0.0097])\n",
      "Epoch 3166, Loss 8.700799\n",
      "Params: tensor([  4.5105, -12.1324])\n",
      "Grad:   tensor([-0.0017,  0.0097])\n",
      "Epoch 3167, Loss 8.700796\n",
      "Params: tensor([  4.5105, -12.1325])\n",
      "Grad:   tensor([-0.0017,  0.0097])\n",
      "Epoch 3168, Loss 8.700799\n",
      "Params: tensor([  4.5106, -12.1326])\n",
      "Grad:   tensor([-0.0017,  0.0097])\n",
      "Epoch 3169, Loss 8.700797\n",
      "Params: tensor([  4.5106, -12.1327])\n",
      "Grad:   tensor([-0.0017,  0.0097])\n",
      "Epoch 3170, Loss 8.700796\n",
      "Params: tensor([  4.5106, -12.1328])\n",
      "Grad:   tensor([-0.0017,  0.0096])\n",
      "Epoch 3171, Loss 8.700794\n",
      "Params: tensor([  4.5106, -12.1328])\n",
      "Grad:   tensor([-0.0017,  0.0096])\n",
      "Epoch 3172, Loss 8.700794\n",
      "Params: tensor([  4.5106, -12.1329])\n",
      "Grad:   tensor([-0.0017,  0.0096])\n",
      "Epoch 3173, Loss 8.700791\n",
      "Params: tensor([  4.5106, -12.1330])\n",
      "Grad:   tensor([-0.0017,  0.0096])\n",
      "Epoch 3174, Loss 8.700790\n",
      "Params: tensor([  4.5107, -12.1331])\n",
      "Grad:   tensor([-0.0017,  0.0096])\n",
      "Epoch 3175, Loss 8.700790\n",
      "Params: tensor([  4.5107, -12.1332])\n",
      "Grad:   tensor([-0.0017,  0.0096])\n",
      "Epoch 3176, Loss 8.700791\n",
      "Params: tensor([  4.5107, -12.1333])\n",
      "Grad:   tensor([-0.0017,  0.0095])\n",
      "Epoch 3177, Loss 8.700789\n",
      "Params: tensor([  4.5107, -12.1334])\n",
      "Grad:   tensor([-0.0017,  0.0095])\n",
      "Epoch 3178, Loss 8.700788\n",
      "Params: tensor([  4.5107, -12.1335])\n",
      "Grad:   tensor([-0.0017,  0.0095])\n",
      "Epoch 3179, Loss 8.700787\n",
      "Params: tensor([  4.5107, -12.1336])\n",
      "Grad:   tensor([-0.0017,  0.0095])\n",
      "Epoch 3180, Loss 8.700785\n",
      "Params: tensor([  4.5108, -12.1337])\n",
      "Grad:   tensor([-0.0017,  0.0095])\n",
      "Epoch 3181, Loss 8.700785\n",
      "Params: tensor([  4.5108, -12.1338])\n",
      "Grad:   tensor([-0.0017,  0.0095])\n",
      "Epoch 3182, Loss 8.700787\n",
      "Params: tensor([  4.5108, -12.1339])\n",
      "Grad:   tensor([-0.0017,  0.0095])\n",
      "Epoch 3183, Loss 8.700784\n",
      "Params: tensor([  4.5108, -12.1340])\n",
      "Grad:   tensor([-0.0017,  0.0094])\n",
      "Epoch 3184, Loss 8.700782\n",
      "Params: tensor([  4.5108, -12.1341])\n",
      "Grad:   tensor([-0.0017,  0.0094])\n",
      "Epoch 3185, Loss 8.700781\n",
      "Params: tensor([  4.5108, -12.1342])\n",
      "Grad:   tensor([-0.0017,  0.0094])\n",
      "Epoch 3186, Loss 8.700779\n",
      "Params: tensor([  4.5109, -12.1343])\n",
      "Grad:   tensor([-0.0017,  0.0094])\n",
      "Epoch 3187, Loss 8.700780\n",
      "Params: tensor([  4.5109, -12.1344])\n",
      "Grad:   tensor([-0.0017,  0.0094])\n",
      "Epoch 3188, Loss 8.700779\n",
      "Params: tensor([  4.5109, -12.1345])\n",
      "Grad:   tensor([-0.0016,  0.0094])\n",
      "Epoch 3189, Loss 8.700777\n",
      "Params: tensor([  4.5109, -12.1346])\n",
      "Grad:   tensor([-0.0017,  0.0093])\n",
      "Epoch 3190, Loss 8.700776\n",
      "Params: tensor([  4.5109, -12.1346])\n",
      "Grad:   tensor([-0.0016,  0.0093])\n",
      "Epoch 3191, Loss 8.700776\n",
      "Params: tensor([  4.5109, -12.1347])\n",
      "Grad:   tensor([-0.0017,  0.0093])\n",
      "Epoch 3192, Loss 8.700774\n",
      "Params: tensor([  4.5110, -12.1348])\n",
      "Grad:   tensor([-0.0016,  0.0093])\n",
      "Epoch 3193, Loss 8.700778\n",
      "Params: tensor([  4.5110, -12.1349])\n",
      "Grad:   tensor([-0.0017,  0.0093])\n",
      "Epoch 3194, Loss 8.700772\n",
      "Params: tensor([  4.5110, -12.1350])\n",
      "Grad:   tensor([-0.0016,  0.0093])\n",
      "Epoch 3195, Loss 8.700772\n",
      "Params: tensor([  4.5110, -12.1351])\n",
      "Grad:   tensor([-0.0016,  0.0092])\n",
      "Epoch 3196, Loss 8.700771\n",
      "Params: tensor([  4.5110, -12.1352])\n",
      "Grad:   tensor([-0.0016,  0.0092])\n",
      "Epoch 3197, Loss 8.700769\n",
      "Params: tensor([  4.5110, -12.1353])\n",
      "Grad:   tensor([-0.0016,  0.0092])\n",
      "Epoch 3198, Loss 8.700771\n",
      "Params: tensor([  4.5111, -12.1354])\n",
      "Grad:   tensor([-0.0016,  0.0092])\n",
      "Epoch 3199, Loss 8.700768\n",
      "Params: tensor([  4.5111, -12.1355])\n",
      "Grad:   tensor([-0.0016,  0.0092])\n",
      "Epoch 3200, Loss 8.700768\n",
      "Params: tensor([  4.5111, -12.1356])\n",
      "Grad:   tensor([-0.0016,  0.0092])\n",
      "Epoch 3201, Loss 8.700767\n",
      "Params: tensor([  4.5111, -12.1357])\n",
      "Grad:   tensor([-0.0016,  0.0092])\n",
      "Epoch 3202, Loss 8.700767\n",
      "Params: tensor([  4.5111, -12.1358])\n",
      "Grad:   tensor([-0.0016,  0.0091])\n",
      "Epoch 3203, Loss 8.700768\n",
      "Params: tensor([  4.5111, -12.1358])\n",
      "Grad:   tensor([-0.0016,  0.0091])\n",
      "Epoch 3204, Loss 8.700766\n",
      "Params: tensor([  4.5111, -12.1359])\n",
      "Grad:   tensor([-0.0016,  0.0091])\n",
      "Epoch 3205, Loss 8.700766\n",
      "Params: tensor([  4.5112, -12.1360])\n",
      "Grad:   tensor([-0.0016,  0.0091])\n",
      "Epoch 3206, Loss 8.700763\n",
      "Params: tensor([  4.5112, -12.1361])\n",
      "Grad:   tensor([-0.0016,  0.0091])\n",
      "Epoch 3207, Loss 8.700761\n",
      "Params: tensor([  4.5112, -12.1362])\n",
      "Grad:   tensor([-0.0016,  0.0091])\n",
      "Epoch 3208, Loss 8.700764\n",
      "Params: tensor([  4.5112, -12.1363])\n",
      "Grad:   tensor([-0.0016,  0.0090])\n",
      "Epoch 3209, Loss 8.700760\n",
      "Params: tensor([  4.5112, -12.1364])\n",
      "Grad:   tensor([-0.0016,  0.0090])\n",
      "Epoch 3210, Loss 8.700761\n",
      "Params: tensor([  4.5112, -12.1365])\n",
      "Grad:   tensor([-0.0016,  0.0090])\n",
      "Epoch 3211, Loss 8.700759\n",
      "Params: tensor([  4.5113, -12.1366])\n",
      "Grad:   tensor([-0.0016,  0.0090])\n",
      "Epoch 3212, Loss 8.700759\n",
      "Params: tensor([  4.5113, -12.1367])\n",
      "Grad:   tensor([-0.0016,  0.0090])\n",
      "Epoch 3213, Loss 8.700759\n",
      "Params: tensor([  4.5113, -12.1367])\n",
      "Grad:   tensor([-0.0016,  0.0090])\n",
      "Epoch 3214, Loss 8.700756\n",
      "Params: tensor([  4.5113, -12.1368])\n",
      "Grad:   tensor([-0.0016,  0.0090])\n",
      "Epoch 3215, Loss 8.700756\n",
      "Params: tensor([  4.5113, -12.1369])\n",
      "Grad:   tensor([-0.0016,  0.0089])\n",
      "Epoch 3216, Loss 8.700754\n",
      "Params: tensor([  4.5113, -12.1370])\n",
      "Grad:   tensor([-0.0016,  0.0089])\n",
      "Epoch 3217, Loss 8.700754\n",
      "Params: tensor([  4.5114, -12.1371])\n",
      "Grad:   tensor([-0.0016,  0.0089])\n",
      "Epoch 3218, Loss 8.700754\n",
      "Params: tensor([  4.5114, -12.1372])\n",
      "Grad:   tensor([-0.0016,  0.0089])\n",
      "Epoch 3219, Loss 8.700753\n",
      "Params: tensor([  4.5114, -12.1373])\n",
      "Grad:   tensor([-0.0016,  0.0089])\n",
      "Epoch 3220, Loss 8.700751\n",
      "Params: tensor([  4.5114, -12.1374])\n",
      "Grad:   tensor([-0.0016,  0.0089])\n",
      "Epoch 3221, Loss 8.700750\n",
      "Params: tensor([  4.5114, -12.1375])\n",
      "Grad:   tensor([-0.0015,  0.0088])\n",
      "Epoch 3222, Loss 8.700750\n",
      "Params: tensor([  4.5114, -12.1375])\n",
      "Grad:   tensor([-0.0016,  0.0088])\n",
      "Epoch 3223, Loss 8.700749\n",
      "Params: tensor([  4.5114, -12.1376])\n",
      "Grad:   tensor([-0.0016,  0.0088])\n",
      "Epoch 3224, Loss 8.700747\n",
      "Params: tensor([  4.5115, -12.1377])\n",
      "Grad:   tensor([-0.0015,  0.0088])\n",
      "Epoch 3225, Loss 8.700746\n",
      "Params: tensor([  4.5115, -12.1378])\n",
      "Grad:   tensor([-0.0015,  0.0088])\n",
      "Epoch 3226, Loss 8.700746\n",
      "Params: tensor([  4.5115, -12.1379])\n",
      "Grad:   tensor([-0.0015,  0.0088])\n",
      "Epoch 3227, Loss 8.700746\n",
      "Params: tensor([  4.5115, -12.1380])\n",
      "Grad:   tensor([-0.0016,  0.0088])\n",
      "Epoch 3228, Loss 8.700746\n",
      "Params: tensor([  4.5115, -12.1381])\n",
      "Grad:   tensor([-0.0015,  0.0087])\n",
      "Epoch 3229, Loss 8.700744\n",
      "Params: tensor([  4.5115, -12.1382])\n",
      "Grad:   tensor([-0.0015,  0.0087])\n",
      "Epoch 3230, Loss 8.700743\n",
      "Params: tensor([  4.5116, -12.1382])\n",
      "Grad:   tensor([-0.0016,  0.0087])\n",
      "Epoch 3231, Loss 8.700745\n",
      "Params: tensor([  4.5116, -12.1383])\n",
      "Grad:   tensor([-0.0015,  0.0087])\n",
      "Epoch 3232, Loss 8.700743\n",
      "Params: tensor([  4.5116, -12.1384])\n",
      "Grad:   tensor([-0.0015,  0.0087])\n",
      "Epoch 3233, Loss 8.700741\n",
      "Params: tensor([  4.5116, -12.1385])\n",
      "Grad:   tensor([-0.0015,  0.0087])\n",
      "Epoch 3234, Loss 8.700740\n",
      "Params: tensor([  4.5116, -12.1386])\n",
      "Grad:   tensor([-0.0015,  0.0087])\n",
      "Epoch 3235, Loss 8.700741\n",
      "Params: tensor([  4.5116, -12.1387])\n",
      "Grad:   tensor([-0.0015,  0.0086])\n",
      "Epoch 3236, Loss 8.700741\n",
      "Params: tensor([  4.5116, -12.1388])\n",
      "Grad:   tensor([-0.0015,  0.0086])\n",
      "Epoch 3237, Loss 8.700738\n",
      "Params: tensor([  4.5117, -12.1389])\n",
      "Grad:   tensor([-0.0015,  0.0086])\n",
      "Epoch 3238, Loss 8.700736\n",
      "Params: tensor([  4.5117, -12.1389])\n",
      "Grad:   tensor([-0.0015,  0.0086])\n",
      "Epoch 3239, Loss 8.700738\n",
      "Params: tensor([  4.5117, -12.1390])\n",
      "Grad:   tensor([-0.0015,  0.0086])\n",
      "Epoch 3240, Loss 8.700737\n",
      "Params: tensor([  4.5117, -12.1391])\n",
      "Grad:   tensor([-0.0015,  0.0086])\n",
      "Epoch 3241, Loss 8.700734\n",
      "Params: tensor([  4.5117, -12.1392])\n",
      "Grad:   tensor([-0.0015,  0.0086])\n",
      "Epoch 3242, Loss 8.700733\n",
      "Params: tensor([  4.5117, -12.1393])\n",
      "Grad:   tensor([-0.0015,  0.0085])\n",
      "Epoch 3243, Loss 8.700730\n",
      "Params: tensor([  4.5118, -12.1394])\n",
      "Grad:   tensor([-0.0015,  0.0085])\n",
      "Epoch 3244, Loss 8.700732\n",
      "Params: tensor([  4.5118, -12.1395])\n",
      "Grad:   tensor([-0.0015,  0.0085])\n",
      "Epoch 3245, Loss 8.700733\n",
      "Params: tensor([  4.5118, -12.1395])\n",
      "Grad:   tensor([-0.0015,  0.0085])\n",
      "Epoch 3246, Loss 8.700730\n",
      "Params: tensor([  4.5118, -12.1396])\n",
      "Grad:   tensor([-0.0015,  0.0085])\n",
      "Epoch 3247, Loss 8.700732\n",
      "Params: tensor([  4.5118, -12.1397])\n",
      "Grad:   tensor([-0.0015,  0.0085])\n",
      "Epoch 3248, Loss 8.700729\n",
      "Params: tensor([  4.5118, -12.1398])\n",
      "Grad:   tensor([-0.0015,  0.0084])\n",
      "Epoch 3249, Loss 8.700728\n",
      "Params: tensor([  4.5118, -12.1399])\n",
      "Grad:   tensor([-0.0015,  0.0084])\n",
      "Epoch 3250, Loss 8.700728\n",
      "Params: tensor([  4.5119, -12.1400])\n",
      "Grad:   tensor([-0.0015,  0.0084])\n",
      "Epoch 3251, Loss 8.700728\n",
      "Params: tensor([  4.5119, -12.1400])\n",
      "Grad:   tensor([-0.0015,  0.0084])\n",
      "Epoch 3252, Loss 8.700727\n",
      "Params: tensor([  4.5119, -12.1401])\n",
      "Grad:   tensor([-0.0015,  0.0084])\n",
      "Epoch 3253, Loss 8.700727\n",
      "Params: tensor([  4.5119, -12.1402])\n",
      "Grad:   tensor([-0.0015,  0.0084])\n",
      "Epoch 3254, Loss 8.700726\n",
      "Params: tensor([  4.5119, -12.1403])\n",
      "Grad:   tensor([-0.0015,  0.0084])\n",
      "Epoch 3255, Loss 8.700726\n",
      "Params: tensor([  4.5119, -12.1404])\n",
      "Grad:   tensor([-0.0015,  0.0083])\n",
      "Epoch 3256, Loss 8.700726\n",
      "Params: tensor([  4.5119, -12.1405])\n",
      "Grad:   tensor([-0.0015,  0.0083])\n",
      "Epoch 3257, Loss 8.700721\n",
      "Params: tensor([  4.5120, -12.1405])\n",
      "Grad:   tensor([-0.0015,  0.0083])\n",
      "Epoch 3258, Loss 8.700723\n",
      "Params: tensor([  4.5120, -12.1406])\n",
      "Grad:   tensor([-0.0015,  0.0083])\n",
      "Epoch 3259, Loss 8.700723\n",
      "Params: tensor([  4.5120, -12.1407])\n",
      "Grad:   tensor([-0.0015,  0.0083])\n",
      "Epoch 3260, Loss 8.700723\n",
      "Params: tensor([  4.5120, -12.1408])\n",
      "Grad:   tensor([-0.0015,  0.0083])\n",
      "Epoch 3261, Loss 8.700720\n",
      "Params: tensor([  4.5120, -12.1409])\n",
      "Grad:   tensor([-0.0015,  0.0083])\n",
      "Epoch 3262, Loss 8.700720\n",
      "Params: tensor([  4.5120, -12.1410])\n",
      "Grad:   tensor([-0.0015,  0.0083])\n",
      "Epoch 3263, Loss 8.700720\n",
      "Params: tensor([  4.5121, -12.1410])\n",
      "Grad:   tensor([-0.0015,  0.0082])\n",
      "Epoch 3264, Loss 8.700716\n",
      "Params: tensor([  4.5121, -12.1411])\n",
      "Grad:   tensor([-0.0015,  0.0082])\n",
      "Epoch 3265, Loss 8.700717\n",
      "Params: tensor([  4.5121, -12.1412])\n",
      "Grad:   tensor([-0.0014,  0.0082])\n",
      "Epoch 3266, Loss 8.700717\n",
      "Params: tensor([  4.5121, -12.1413])\n",
      "Grad:   tensor([-0.0014,  0.0082])\n",
      "Epoch 3267, Loss 8.700717\n",
      "Params: tensor([  4.5121, -12.1414])\n",
      "Grad:   tensor([-0.0015,  0.0082])\n",
      "Epoch 3268, Loss 8.700715\n",
      "Params: tensor([  4.5121, -12.1415])\n",
      "Grad:   tensor([-0.0015,  0.0082])\n",
      "Epoch 3269, Loss 8.700715\n",
      "Params: tensor([  4.5121, -12.1415])\n",
      "Grad:   tensor([-0.0014,  0.0082])\n",
      "Epoch 3270, Loss 8.700715\n",
      "Params: tensor([  4.5122, -12.1416])\n",
      "Grad:   tensor([-0.0014,  0.0081])\n",
      "Epoch 3271, Loss 8.700713\n",
      "Params: tensor([  4.5122, -12.1417])\n",
      "Grad:   tensor([-0.0014,  0.0081])\n",
      "Epoch 3272, Loss 8.700711\n",
      "Params: tensor([  4.5122, -12.1418])\n",
      "Grad:   tensor([-0.0014,  0.0081])\n",
      "Epoch 3273, Loss 8.700712\n",
      "Params: tensor([  4.5122, -12.1419])\n",
      "Grad:   tensor([-0.0014,  0.0081])\n",
      "Epoch 3274, Loss 8.700712\n",
      "Params: tensor([  4.5122, -12.1419])\n",
      "Grad:   tensor([-0.0014,  0.0081])\n",
      "Epoch 3275, Loss 8.700710\n",
      "Params: tensor([  4.5122, -12.1420])\n",
      "Grad:   tensor([-0.0014,  0.0081])\n",
      "Epoch 3276, Loss 8.700708\n",
      "Params: tensor([  4.5122, -12.1421])\n",
      "Grad:   tensor([-0.0014,  0.0081])\n",
      "Epoch 3277, Loss 8.700710\n",
      "Params: tensor([  4.5123, -12.1422])\n",
      "Grad:   tensor([-0.0014,  0.0080])\n",
      "Epoch 3278, Loss 8.700708\n",
      "Params: tensor([  4.5123, -12.1423])\n",
      "Grad:   tensor([-0.0014,  0.0080])\n",
      "Epoch 3279, Loss 8.700707\n",
      "Params: tensor([  4.5123, -12.1423])\n",
      "Grad:   tensor([-0.0014,  0.0080])\n",
      "Epoch 3280, Loss 8.700709\n",
      "Params: tensor([  4.5123, -12.1424])\n",
      "Grad:   tensor([-0.0014,  0.0080])\n",
      "Epoch 3281, Loss 8.700707\n",
      "Params: tensor([  4.5123, -12.1425])\n",
      "Grad:   tensor([-0.0014,  0.0080])\n",
      "Epoch 3282, Loss 8.700707\n",
      "Params: tensor([  4.5123, -12.1426])\n",
      "Grad:   tensor([-0.0014,  0.0080])\n",
      "Epoch 3283, Loss 8.700704\n",
      "Params: tensor([  4.5123, -12.1427])\n",
      "Grad:   tensor([-0.0014,  0.0080])\n",
      "Epoch 3284, Loss 8.700706\n",
      "Params: tensor([  4.5124, -12.1427])\n",
      "Grad:   tensor([-0.0014,  0.0079])\n",
      "Epoch 3285, Loss 8.700705\n",
      "Params: tensor([  4.5124, -12.1428])\n",
      "Grad:   tensor([-0.0014,  0.0079])\n",
      "Epoch 3286, Loss 8.700705\n",
      "Params: tensor([  4.5124, -12.1429])\n",
      "Grad:   tensor([-0.0014,  0.0079])\n",
      "Epoch 3287, Loss 8.700703\n",
      "Params: tensor([  4.5124, -12.1430])\n",
      "Grad:   tensor([-0.0014,  0.0079])\n",
      "Epoch 3288, Loss 8.700701\n",
      "Params: tensor([  4.5124, -12.1431])\n",
      "Grad:   tensor([-0.0014,  0.0079])\n",
      "Epoch 3289, Loss 8.700700\n",
      "Params: tensor([  4.5124, -12.1431])\n",
      "Grad:   tensor([-0.0014,  0.0079])\n",
      "Epoch 3290, Loss 8.700702\n",
      "Params: tensor([  4.5124, -12.1432])\n",
      "Grad:   tensor([-0.0014,  0.0079])\n",
      "Epoch 3291, Loss 8.700700\n",
      "Params: tensor([  4.5124, -12.1433])\n",
      "Grad:   tensor([-0.0014,  0.0079])\n",
      "Epoch 3292, Loss 8.700702\n",
      "Params: tensor([  4.5125, -12.1434])\n",
      "Grad:   tensor([-0.0014,  0.0078])\n",
      "Epoch 3293, Loss 8.700699\n",
      "Params: tensor([  4.5125, -12.1434])\n",
      "Grad:   tensor([-0.0014,  0.0078])\n",
      "Epoch 3294, Loss 8.700699\n",
      "Params: tensor([  4.5125, -12.1435])\n",
      "Grad:   tensor([-0.0014,  0.0078])\n",
      "Epoch 3295, Loss 8.700697\n",
      "Params: tensor([  4.5125, -12.1436])\n",
      "Grad:   tensor([-0.0014,  0.0078])\n",
      "Epoch 3296, Loss 8.700696\n",
      "Params: tensor([  4.5125, -12.1437])\n",
      "Grad:   tensor([-0.0014,  0.0078])\n",
      "Epoch 3297, Loss 8.700697\n",
      "Params: tensor([  4.5125, -12.1438])\n",
      "Grad:   tensor([-0.0014,  0.0078])\n",
      "Epoch 3298, Loss 8.700698\n",
      "Params: tensor([  4.5125, -12.1438])\n",
      "Grad:   tensor([-0.0014,  0.0078])\n",
      "Epoch 3299, Loss 8.700694\n",
      "Params: tensor([  4.5126, -12.1439])\n",
      "Grad:   tensor([-0.0014,  0.0078])\n",
      "Epoch 3300, Loss 8.700696\n",
      "Params: tensor([  4.5126, -12.1440])\n",
      "Grad:   tensor([-0.0014,  0.0077])\n",
      "Epoch 3301, Loss 8.700695\n",
      "Params: tensor([  4.5126, -12.1441])\n",
      "Grad:   tensor([-0.0014,  0.0077])\n",
      "Epoch 3302, Loss 8.700695\n",
      "Params: tensor([  4.5126, -12.1441])\n",
      "Grad:   tensor([-0.0013,  0.0077])\n",
      "Epoch 3303, Loss 8.700695\n",
      "Params: tensor([  4.5126, -12.1442])\n",
      "Grad:   tensor([-0.0014,  0.0077])\n",
      "Epoch 3304, Loss 8.700692\n",
      "Params: tensor([  4.5126, -12.1443])\n",
      "Grad:   tensor([-0.0013,  0.0077])\n",
      "Epoch 3305, Loss 8.700691\n",
      "Params: tensor([  4.5126, -12.1444])\n",
      "Grad:   tensor([-0.0014,  0.0077])\n",
      "Epoch 3306, Loss 8.700691\n",
      "Params: tensor([  4.5127, -12.1445])\n",
      "Grad:   tensor([-0.0013,  0.0077])\n",
      "Epoch 3307, Loss 8.700692\n",
      "Params: tensor([  4.5127, -12.1445])\n",
      "Grad:   tensor([-0.0013,  0.0076])\n",
      "Epoch 3308, Loss 8.700689\n",
      "Params: tensor([  4.5127, -12.1446])\n",
      "Grad:   tensor([-0.0014,  0.0076])\n",
      "Epoch 3309, Loss 8.700689\n",
      "Params: tensor([  4.5127, -12.1447])\n",
      "Grad:   tensor([-0.0014,  0.0076])\n",
      "Epoch 3310, Loss 8.700688\n",
      "Params: tensor([  4.5127, -12.1448])\n",
      "Grad:   tensor([-0.0013,  0.0076])\n",
      "Epoch 3311, Loss 8.700687\n",
      "Params: tensor([  4.5127, -12.1448])\n",
      "Grad:   tensor([-0.0013,  0.0076])\n",
      "Epoch 3312, Loss 8.700687\n",
      "Params: tensor([  4.5127, -12.1449])\n",
      "Grad:   tensor([-0.0013,  0.0076])\n",
      "Epoch 3313, Loss 8.700685\n",
      "Params: tensor([  4.5127, -12.1450])\n",
      "Grad:   tensor([-0.0013,  0.0076])\n",
      "Epoch 3314, Loss 8.700685\n",
      "Params: tensor([  4.5128, -12.1451])\n",
      "Grad:   tensor([-0.0013,  0.0076])\n",
      "Epoch 3315, Loss 8.700687\n",
      "Params: tensor([  4.5128, -12.1451])\n",
      "Grad:   tensor([-0.0013,  0.0075])\n",
      "Epoch 3316, Loss 8.700685\n",
      "Params: tensor([  4.5128, -12.1452])\n",
      "Grad:   tensor([-0.0013,  0.0075])\n",
      "Epoch 3317, Loss 8.700684\n",
      "Params: tensor([  4.5128, -12.1453])\n",
      "Grad:   tensor([-0.0013,  0.0075])\n",
      "Epoch 3318, Loss 8.700684\n",
      "Params: tensor([  4.5128, -12.1454])\n",
      "Grad:   tensor([-0.0013,  0.0075])\n",
      "Epoch 3319, Loss 8.700685\n",
      "Params: tensor([  4.5128, -12.1454])\n",
      "Grad:   tensor([-0.0013,  0.0075])\n",
      "Epoch 3320, Loss 8.700681\n",
      "Params: tensor([  4.5128, -12.1455])\n",
      "Grad:   tensor([-0.0013,  0.0075])\n",
      "Epoch 3321, Loss 8.700683\n",
      "Params: tensor([  4.5129, -12.1456])\n",
      "Grad:   tensor([-0.0013,  0.0075])\n",
      "Epoch 3322, Loss 8.700683\n",
      "Params: tensor([  4.5129, -12.1457])\n",
      "Grad:   tensor([-0.0013,  0.0075])\n",
      "Epoch 3323, Loss 8.700681\n",
      "Params: tensor([  4.5129, -12.1457])\n",
      "Grad:   tensor([-0.0013,  0.0074])\n",
      "Epoch 3324, Loss 8.700681\n",
      "Params: tensor([  4.5129, -12.1458])\n",
      "Grad:   tensor([-0.0013,  0.0074])\n",
      "Epoch 3325, Loss 8.700678\n",
      "Params: tensor([  4.5129, -12.1459])\n",
      "Grad:   tensor([-0.0013,  0.0074])\n",
      "Epoch 3326, Loss 8.700678\n",
      "Params: tensor([  4.5129, -12.1460])\n",
      "Grad:   tensor([-0.0013,  0.0074])\n",
      "Epoch 3327, Loss 8.700681\n",
      "Params: tensor([  4.5129, -12.1460])\n",
      "Grad:   tensor([-0.0013,  0.0074])\n",
      "Epoch 3328, Loss 8.700678\n",
      "Params: tensor([  4.5129, -12.1461])\n",
      "Grad:   tensor([-0.0013,  0.0074])\n",
      "Epoch 3329, Loss 8.700677\n",
      "Params: tensor([  4.5130, -12.1462])\n",
      "Grad:   tensor([-0.0013,  0.0074])\n",
      "Epoch 3330, Loss 8.700679\n",
      "Params: tensor([  4.5130, -12.1463])\n",
      "Grad:   tensor([-0.0013,  0.0074])\n",
      "Epoch 3331, Loss 8.700677\n",
      "Params: tensor([  4.5130, -12.1463])\n",
      "Grad:   tensor([-0.0013,  0.0073])\n",
      "Epoch 3332, Loss 8.700675\n",
      "Params: tensor([  4.5130, -12.1464])\n",
      "Grad:   tensor([-0.0013,  0.0073])\n",
      "Epoch 3333, Loss 8.700676\n",
      "Params: tensor([  4.5130, -12.1465])\n",
      "Grad:   tensor([-0.0013,  0.0073])\n",
      "Epoch 3334, Loss 8.700675\n",
      "Params: tensor([  4.5130, -12.1465])\n",
      "Grad:   tensor([-0.0013,  0.0073])\n",
      "Epoch 3335, Loss 8.700675\n",
      "Params: tensor([  4.5130, -12.1466])\n",
      "Grad:   tensor([-0.0013,  0.0073])\n",
      "Epoch 3336, Loss 8.700674\n",
      "Params: tensor([  4.5130, -12.1467])\n",
      "Grad:   tensor([-0.0013,  0.0073])\n",
      "Epoch 3337, Loss 8.700672\n",
      "Params: tensor([  4.5131, -12.1468])\n",
      "Grad:   tensor([-0.0013,  0.0073])\n",
      "Epoch 3338, Loss 8.700673\n",
      "Params: tensor([  4.5131, -12.1468])\n",
      "Grad:   tensor([-0.0013,  0.0073])\n",
      "Epoch 3339, Loss 8.700671\n",
      "Params: tensor([  4.5131, -12.1469])\n",
      "Grad:   tensor([-0.0013,  0.0072])\n",
      "Epoch 3340, Loss 8.700672\n",
      "Params: tensor([  4.5131, -12.1470])\n",
      "Grad:   tensor([-0.0013,  0.0072])\n",
      "Epoch 3341, Loss 8.700672\n",
      "Params: tensor([  4.5131, -12.1471])\n",
      "Grad:   tensor([-0.0013,  0.0072])\n",
      "Epoch 3342, Loss 8.700671\n",
      "Params: tensor([  4.5131, -12.1471])\n",
      "Grad:   tensor([-0.0013,  0.0072])\n",
      "Epoch 3343, Loss 8.700670\n",
      "Params: tensor([  4.5131, -12.1472])\n",
      "Grad:   tensor([-0.0013,  0.0072])\n",
      "Epoch 3344, Loss 8.700669\n",
      "Params: tensor([  4.5132, -12.1473])\n",
      "Grad:   tensor([-0.0013,  0.0072])\n",
      "Epoch 3345, Loss 8.700669\n",
      "Params: tensor([  4.5132, -12.1473])\n",
      "Grad:   tensor([-0.0013,  0.0072])\n",
      "Epoch 3346, Loss 8.700669\n",
      "Params: tensor([  4.5132, -12.1474])\n",
      "Grad:   tensor([-0.0013,  0.0072])\n",
      "Epoch 3347, Loss 8.700668\n",
      "Params: tensor([  4.5132, -12.1475])\n",
      "Grad:   tensor([-0.0013,  0.0071])\n",
      "Epoch 3348, Loss 8.700667\n",
      "Params: tensor([  4.5132, -12.1476])\n",
      "Grad:   tensor([-0.0013,  0.0071])\n",
      "Epoch 3349, Loss 8.700667\n",
      "Params: tensor([  4.5132, -12.1476])\n",
      "Grad:   tensor([-0.0013,  0.0071])\n",
      "Epoch 3350, Loss 8.700665\n",
      "Params: tensor([  4.5132, -12.1477])\n",
      "Grad:   tensor([-0.0013,  0.0071])\n",
      "Epoch 3351, Loss 8.700665\n",
      "Params: tensor([  4.5132, -12.1478])\n",
      "Grad:   tensor([-0.0013,  0.0071])\n",
      "Epoch 3352, Loss 8.700665\n",
      "Params: tensor([  4.5133, -12.1478])\n",
      "Grad:   tensor([-0.0012,  0.0071])\n",
      "Epoch 3353, Loss 8.700665\n",
      "Params: tensor([  4.5133, -12.1479])\n",
      "Grad:   tensor([-0.0012,  0.0071])\n",
      "Epoch 3354, Loss 8.700666\n",
      "Params: tensor([  4.5133, -12.1480])\n",
      "Grad:   tensor([-0.0012,  0.0071])\n",
      "Epoch 3355, Loss 8.700663\n",
      "Params: tensor([  4.5133, -12.1480])\n",
      "Grad:   tensor([-0.0012,  0.0070])\n",
      "Epoch 3356, Loss 8.700662\n",
      "Params: tensor([  4.5133, -12.1481])\n",
      "Grad:   tensor([-0.0012,  0.0070])\n",
      "Epoch 3357, Loss 8.700665\n",
      "Params: tensor([  4.5133, -12.1482])\n",
      "Grad:   tensor([-0.0013,  0.0070])\n",
      "Epoch 3358, Loss 8.700662\n",
      "Params: tensor([  4.5133, -12.1483])\n",
      "Grad:   tensor([-0.0012,  0.0070])\n",
      "Epoch 3359, Loss 8.700664\n",
      "Params: tensor([  4.5133, -12.1483])\n",
      "Grad:   tensor([-0.0012,  0.0070])\n",
      "Epoch 3360, Loss 8.700662\n",
      "Params: tensor([  4.5134, -12.1484])\n",
      "Grad:   tensor([-0.0012,  0.0070])\n",
      "Epoch 3361, Loss 8.700660\n",
      "Params: tensor([  4.5134, -12.1485])\n",
      "Grad:   tensor([-0.0012,  0.0070])\n",
      "Epoch 3362, Loss 8.700660\n",
      "Params: tensor([  4.5134, -12.1485])\n",
      "Grad:   tensor([-0.0012,  0.0070])\n",
      "Epoch 3363, Loss 8.700662\n",
      "Params: tensor([  4.5134, -12.1486])\n",
      "Grad:   tensor([-0.0012,  0.0070])\n",
      "Epoch 3364, Loss 8.700659\n",
      "Params: tensor([  4.5134, -12.1487])\n",
      "Grad:   tensor([-0.0012,  0.0069])\n",
      "Epoch 3365, Loss 8.700659\n",
      "Params: tensor([  4.5134, -12.1487])\n",
      "Grad:   tensor([-0.0012,  0.0069])\n",
      "Epoch 3366, Loss 8.700657\n",
      "Params: tensor([  4.5134, -12.1488])\n",
      "Grad:   tensor([-0.0012,  0.0069])\n",
      "Epoch 3367, Loss 8.700659\n",
      "Params: tensor([  4.5134, -12.1489])\n",
      "Grad:   tensor([-0.0012,  0.0069])\n",
      "Epoch 3368, Loss 8.700658\n",
      "Params: tensor([  4.5134, -12.1490])\n",
      "Grad:   tensor([-0.0012,  0.0069])\n",
      "Epoch 3369, Loss 8.700656\n",
      "Params: tensor([  4.5135, -12.1490])\n",
      "Grad:   tensor([-0.0012,  0.0069])\n",
      "Epoch 3370, Loss 8.700654\n",
      "Params: tensor([  4.5135, -12.1491])\n",
      "Grad:   tensor([-0.0012,  0.0069])\n",
      "Epoch 3371, Loss 8.700654\n",
      "Params: tensor([  4.5135, -12.1492])\n",
      "Grad:   tensor([-0.0012,  0.0069])\n",
      "Epoch 3372, Loss 8.700656\n",
      "Params: tensor([  4.5135, -12.1492])\n",
      "Grad:   tensor([-0.0012,  0.0068])\n",
      "Epoch 3373, Loss 8.700654\n",
      "Params: tensor([  4.5135, -12.1493])\n",
      "Grad:   tensor([-0.0012,  0.0068])\n",
      "Epoch 3374, Loss 8.700652\n",
      "Params: tensor([  4.5135, -12.1494])\n",
      "Grad:   tensor([-0.0012,  0.0068])\n",
      "Epoch 3375, Loss 8.700656\n",
      "Params: tensor([  4.5135, -12.1494])\n",
      "Grad:   tensor([-0.0012,  0.0068])\n",
      "Epoch 3376, Loss 8.700652\n",
      "Params: tensor([  4.5135, -12.1495])\n",
      "Grad:   tensor([-0.0012,  0.0068])\n",
      "Epoch 3377, Loss 8.700652\n",
      "Params: tensor([  4.5136, -12.1496])\n",
      "Grad:   tensor([-0.0012,  0.0068])\n",
      "Epoch 3378, Loss 8.700653\n",
      "Params: tensor([  4.5136, -12.1496])\n",
      "Grad:   tensor([-0.0012,  0.0068])\n",
      "Epoch 3379, Loss 8.700652\n",
      "Params: tensor([  4.5136, -12.1497])\n",
      "Grad:   tensor([-0.0012,  0.0068])\n",
      "Epoch 3380, Loss 8.700652\n",
      "Params: tensor([  4.5136, -12.1498])\n",
      "Grad:   tensor([-0.0012,  0.0067])\n",
      "Epoch 3381, Loss 8.700649\n",
      "Params: tensor([  4.5136, -12.1498])\n",
      "Grad:   tensor([-0.0012,  0.0067])\n",
      "Epoch 3382, Loss 8.700652\n",
      "Params: tensor([  4.5136, -12.1499])\n",
      "Grad:   tensor([-0.0012,  0.0067])\n",
      "Epoch 3383, Loss 8.700650\n",
      "Params: tensor([  4.5136, -12.1500])\n",
      "Grad:   tensor([-0.0012,  0.0067])\n",
      "Epoch 3384, Loss 8.700649\n",
      "Params: tensor([  4.5136, -12.1500])\n",
      "Grad:   tensor([-0.0012,  0.0067])\n",
      "Epoch 3385, Loss 8.700648\n",
      "Params: tensor([  4.5137, -12.1501])\n",
      "Grad:   tensor([-0.0012,  0.0067])\n",
      "Epoch 3386, Loss 8.700647\n",
      "Params: tensor([  4.5137, -12.1502])\n",
      "Grad:   tensor([-0.0012,  0.0067])\n",
      "Epoch 3387, Loss 8.700648\n",
      "Params: tensor([  4.5137, -12.1502])\n",
      "Grad:   tensor([-0.0012,  0.0067])\n",
      "Epoch 3388, Loss 8.700649\n",
      "Params: tensor([  4.5137, -12.1503])\n",
      "Grad:   tensor([-0.0012,  0.0067])\n",
      "Epoch 3389, Loss 8.700646\n",
      "Params: tensor([  4.5137, -12.1504])\n",
      "Grad:   tensor([-0.0012,  0.0066])\n",
      "Epoch 3390, Loss 8.700648\n",
      "Params: tensor([  4.5137, -12.1504])\n",
      "Grad:   tensor([-0.0012,  0.0066])\n",
      "Epoch 3391, Loss 8.700646\n",
      "Params: tensor([  4.5137, -12.1505])\n",
      "Grad:   tensor([-0.0012,  0.0066])\n",
      "Epoch 3392, Loss 8.700646\n",
      "Params: tensor([  4.5137, -12.1506])\n",
      "Grad:   tensor([-0.0012,  0.0066])\n",
      "Epoch 3393, Loss 8.700645\n",
      "Params: tensor([  4.5137, -12.1506])\n",
      "Grad:   tensor([-0.0011,  0.0066])\n",
      "Epoch 3394, Loss 8.700646\n",
      "Params: tensor([  4.5138, -12.1507])\n",
      "Grad:   tensor([-0.0012,  0.0066])\n",
      "Epoch 3395, Loss 8.700644\n",
      "Params: tensor([  4.5138, -12.1508])\n",
      "Grad:   tensor([-0.0012,  0.0066])\n",
      "Epoch 3396, Loss 8.700644\n",
      "Params: tensor([  4.5138, -12.1508])\n",
      "Grad:   tensor([-0.0012,  0.0066])\n",
      "Epoch 3397, Loss 8.700644\n",
      "Params: tensor([  4.5138, -12.1509])\n",
      "Grad:   tensor([-0.0012,  0.0066])\n",
      "Epoch 3398, Loss 8.700642\n",
      "Params: tensor([  4.5138, -12.1510])\n",
      "Grad:   tensor([-0.0012,  0.0065])\n",
      "Epoch 3399, Loss 8.700644\n",
      "Params: tensor([  4.5138, -12.1510])\n",
      "Grad:   tensor([-0.0012,  0.0065])\n",
      "Epoch 3400, Loss 8.700642\n",
      "Params: tensor([  4.5138, -12.1511])\n",
      "Grad:   tensor([-0.0012,  0.0065])\n",
      "Epoch 3401, Loss 8.700644\n",
      "Params: tensor([  4.5138, -12.1512])\n",
      "Grad:   tensor([-0.0012,  0.0065])\n",
      "Epoch 3402, Loss 8.700644\n",
      "Params: tensor([  4.5139, -12.1512])\n",
      "Grad:   tensor([-0.0012,  0.0065])\n",
      "Epoch 3403, Loss 8.700641\n",
      "Params: tensor([  4.5139, -12.1513])\n",
      "Grad:   tensor([-0.0011,  0.0065])\n",
      "Epoch 3404, Loss 8.700643\n",
      "Params: tensor([  4.5139, -12.1514])\n",
      "Grad:   tensor([-0.0012,  0.0065])\n",
      "Epoch 3405, Loss 8.700640\n",
      "Params: tensor([  4.5139, -12.1514])\n",
      "Grad:   tensor([-0.0012,  0.0065])\n",
      "Epoch 3406, Loss 8.700642\n",
      "Params: tensor([  4.5139, -12.1515])\n",
      "Grad:   tensor([-0.0012,  0.0065])\n",
      "Epoch 3407, Loss 8.700641\n",
      "Params: tensor([  4.5139, -12.1516])\n",
      "Grad:   tensor([-0.0011,  0.0064])\n",
      "Epoch 3408, Loss 8.700639\n",
      "Params: tensor([  4.5139, -12.1516])\n",
      "Grad:   tensor([-0.0011,  0.0064])\n",
      "Epoch 3409, Loss 8.700638\n",
      "Params: tensor([  4.5139, -12.1517])\n",
      "Grad:   tensor([-0.0011,  0.0064])\n",
      "Epoch 3410, Loss 8.700638\n",
      "Params: tensor([  4.5139, -12.1517])\n",
      "Grad:   tensor([-0.0011,  0.0064])\n",
      "Epoch 3411, Loss 8.700638\n",
      "Params: tensor([  4.5140, -12.1518])\n",
      "Grad:   tensor([-0.0011,  0.0064])\n",
      "Epoch 3412, Loss 8.700637\n",
      "Params: tensor([  4.5140, -12.1519])\n",
      "Grad:   tensor([-0.0011,  0.0064])\n",
      "Epoch 3413, Loss 8.700638\n",
      "Params: tensor([  4.5140, -12.1519])\n",
      "Grad:   tensor([-0.0011,  0.0064])\n",
      "Epoch 3414, Loss 8.700635\n",
      "Params: tensor([  4.5140, -12.1520])\n",
      "Grad:   tensor([-0.0011,  0.0064])\n",
      "Epoch 3415, Loss 8.700638\n",
      "Params: tensor([  4.5140, -12.1521])\n",
      "Grad:   tensor([-0.0011,  0.0064])\n",
      "Epoch 3416, Loss 8.700636\n",
      "Params: tensor([  4.5140, -12.1521])\n",
      "Grad:   tensor([-0.0011,  0.0064])\n",
      "Epoch 3417, Loss 8.700635\n",
      "Params: tensor([  4.5140, -12.1522])\n",
      "Grad:   tensor([-0.0011,  0.0063])\n",
      "Epoch 3418, Loss 8.700636\n",
      "Params: tensor([  4.5140, -12.1523])\n",
      "Grad:   tensor([-0.0011,  0.0063])\n",
      "Epoch 3419, Loss 8.700635\n",
      "Params: tensor([  4.5140, -12.1523])\n",
      "Grad:   tensor([-0.0011,  0.0063])\n",
      "Epoch 3420, Loss 8.700635\n",
      "Params: tensor([  4.5141, -12.1524])\n",
      "Grad:   tensor([-0.0011,  0.0063])\n",
      "Epoch 3421, Loss 8.700633\n",
      "Params: tensor([  4.5141, -12.1524])\n",
      "Grad:   tensor([-0.0011,  0.0063])\n",
      "Epoch 3422, Loss 8.700632\n",
      "Params: tensor([  4.5141, -12.1525])\n",
      "Grad:   tensor([-0.0011,  0.0063])\n",
      "Epoch 3423, Loss 8.700631\n",
      "Params: tensor([  4.5141, -12.1526])\n",
      "Grad:   tensor([-0.0011,  0.0063])\n",
      "Epoch 3424, Loss 8.700634\n",
      "Params: tensor([  4.5141, -12.1526])\n",
      "Grad:   tensor([-0.0011,  0.0063])\n",
      "Epoch 3425, Loss 8.700631\n",
      "Params: tensor([  4.5141, -12.1527])\n",
      "Grad:   tensor([-0.0011,  0.0063])\n",
      "Epoch 3426, Loss 8.700631\n",
      "Params: tensor([  4.5141, -12.1528])\n",
      "Grad:   tensor([-0.0011,  0.0062])\n",
      "Epoch 3427, Loss 8.700632\n",
      "Params: tensor([  4.5141, -12.1528])\n",
      "Grad:   tensor([-0.0011,  0.0062])\n",
      "Epoch 3428, Loss 8.700629\n",
      "Params: tensor([  4.5141, -12.1529])\n",
      "Grad:   tensor([-0.0011,  0.0062])\n",
      "Epoch 3429, Loss 8.700631\n",
      "Params: tensor([  4.5142, -12.1529])\n",
      "Grad:   tensor([-0.0011,  0.0062])\n",
      "Epoch 3430, Loss 8.700628\n",
      "Params: tensor([  4.5142, -12.1530])\n",
      "Grad:   tensor([-0.0011,  0.0062])\n",
      "Epoch 3431, Loss 8.700630\n",
      "Params: tensor([  4.5142, -12.1531])\n",
      "Grad:   tensor([-0.0011,  0.0062])\n",
      "Epoch 3432, Loss 8.700628\n",
      "Params: tensor([  4.5142, -12.1531])\n",
      "Grad:   tensor([-0.0011,  0.0062])\n",
      "Epoch 3433, Loss 8.700631\n",
      "Params: tensor([  4.5142, -12.1532])\n",
      "Grad:   tensor([-0.0011,  0.0062])\n",
      "Epoch 3434, Loss 8.700628\n",
      "Params: tensor([  4.5142, -12.1533])\n",
      "Grad:   tensor([-0.0011,  0.0062])\n",
      "Epoch 3435, Loss 8.700626\n",
      "Params: tensor([  4.5142, -12.1533])\n",
      "Grad:   tensor([-0.0011,  0.0061])\n",
      "Epoch 3436, Loss 8.700626\n",
      "Params: tensor([  4.5142, -12.1534])\n",
      "Grad:   tensor([-0.0011,  0.0061])\n",
      "Epoch 3437, Loss 8.700625\n",
      "Params: tensor([  4.5142, -12.1534])\n",
      "Grad:   tensor([-0.0011,  0.0061])\n",
      "Epoch 3438, Loss 8.700626\n",
      "Params: tensor([  4.5143, -12.1535])\n",
      "Grad:   tensor([-0.0011,  0.0061])\n",
      "Epoch 3439, Loss 8.700624\n",
      "Params: tensor([  4.5143, -12.1536])\n",
      "Grad:   tensor([-0.0011,  0.0061])\n",
      "Epoch 3440, Loss 8.700626\n",
      "Params: tensor([  4.5143, -12.1536])\n",
      "Grad:   tensor([-0.0011,  0.0061])\n",
      "Epoch 3441, Loss 8.700624\n",
      "Params: tensor([  4.5143, -12.1537])\n",
      "Grad:   tensor([-0.0011,  0.0061])\n",
      "Epoch 3442, Loss 8.700624\n",
      "Params: tensor([  4.5143, -12.1537])\n",
      "Grad:   tensor([-0.0011,  0.0061])\n",
      "Epoch 3443, Loss 8.700624\n",
      "Params: tensor([  4.5143, -12.1538])\n",
      "Grad:   tensor([-0.0011,  0.0061])\n",
      "Epoch 3444, Loss 8.700624\n",
      "Params: tensor([  4.5143, -12.1539])\n",
      "Grad:   tensor([-0.0011,  0.0061])\n",
      "Epoch 3445, Loss 8.700624\n",
      "Params: tensor([  4.5143, -12.1539])\n",
      "Grad:   tensor([-0.0011,  0.0060])\n",
      "Epoch 3446, Loss 8.700624\n",
      "Params: tensor([  4.5143, -12.1540])\n",
      "Grad:   tensor([-0.0011,  0.0060])\n",
      "Epoch 3447, Loss 8.700622\n",
      "Params: tensor([  4.5143, -12.1540])\n",
      "Grad:   tensor([-0.0011,  0.0060])\n",
      "Epoch 3448, Loss 8.700624\n",
      "Params: tensor([  4.5144, -12.1541])\n",
      "Grad:   tensor([-0.0011,  0.0060])\n",
      "Epoch 3449, Loss 8.700622\n",
      "Params: tensor([  4.5144, -12.1542])\n",
      "Grad:   tensor([-0.0010,  0.0060])\n",
      "Epoch 3450, Loss 8.700624\n",
      "Params: tensor([  4.5144, -12.1542])\n",
      "Grad:   tensor([-0.0011,  0.0060])\n",
      "Epoch 3451, Loss 8.700621\n",
      "Params: tensor([  4.5144, -12.1543])\n",
      "Grad:   tensor([-0.0011,  0.0060])\n",
      "Epoch 3452, Loss 8.700622\n",
      "Params: tensor([  4.5144, -12.1543])\n",
      "Grad:   tensor([-0.0011,  0.0060])\n",
      "Epoch 3453, Loss 8.700622\n",
      "Params: tensor([  4.5144, -12.1544])\n",
      "Grad:   tensor([-0.0011,  0.0060])\n",
      "Epoch 3454, Loss 8.700620\n",
      "Params: tensor([  4.5144, -12.1545])\n",
      "Grad:   tensor([-0.0011,  0.0059])\n",
      "Epoch 3455, Loss 8.700620\n",
      "Params: tensor([  4.5144, -12.1545])\n",
      "Grad:   tensor([-0.0010,  0.0059])\n",
      "Epoch 3456, Loss 8.700620\n",
      "Params: tensor([  4.5144, -12.1546])\n",
      "Grad:   tensor([-0.0010,  0.0059])\n",
      "Epoch 3457, Loss 8.700621\n",
      "Params: tensor([  4.5145, -12.1546])\n",
      "Grad:   tensor([-0.0010,  0.0059])\n",
      "Epoch 3458, Loss 8.700617\n",
      "Params: tensor([  4.5145, -12.1547])\n",
      "Grad:   tensor([-0.0010,  0.0059])\n",
      "Epoch 3459, Loss 8.700619\n",
      "Params: tensor([  4.5145, -12.1548])\n",
      "Grad:   tensor([-0.0010,  0.0059])\n",
      "Epoch 3460, Loss 8.700619\n",
      "Params: tensor([  4.5145, -12.1548])\n",
      "Grad:   tensor([-0.0010,  0.0059])\n",
      "Epoch 3461, Loss 8.700619\n",
      "Params: tensor([  4.5145, -12.1549])\n",
      "Grad:   tensor([-0.0010,  0.0059])\n",
      "Epoch 3462, Loss 8.700618\n",
      "Params: tensor([  4.5145, -12.1549])\n",
      "Grad:   tensor([-0.0010,  0.0059])\n",
      "Epoch 3463, Loss 8.700619\n",
      "Params: tensor([  4.5145, -12.1550])\n",
      "Grad:   tensor([-0.0010,  0.0059])\n",
      "Epoch 3464, Loss 8.700617\n",
      "Params: tensor([  4.5145, -12.1551])\n",
      "Grad:   tensor([-0.0010,  0.0059])\n",
      "Epoch 3465, Loss 8.700616\n",
      "Params: tensor([  4.5145, -12.1551])\n",
      "Grad:   tensor([-0.0010,  0.0058])\n",
      "Epoch 3466, Loss 8.700616\n",
      "Params: tensor([  4.5145, -12.1552])\n",
      "Grad:   tensor([-0.0010,  0.0058])\n",
      "Epoch 3467, Loss 8.700617\n",
      "Params: tensor([  4.5146, -12.1552])\n",
      "Grad:   tensor([-0.0010,  0.0058])\n",
      "Epoch 3468, Loss 8.700616\n",
      "Params: tensor([  4.5146, -12.1553])\n",
      "Grad:   tensor([-0.0010,  0.0058])\n",
      "Epoch 3469, Loss 8.700616\n",
      "Params: tensor([  4.5146, -12.1553])\n",
      "Grad:   tensor([-0.0010,  0.0058])\n",
      "Epoch 3470, Loss 8.700614\n",
      "Params: tensor([  4.5146, -12.1554])\n",
      "Grad:   tensor([-0.0010,  0.0058])\n",
      "Epoch 3471, Loss 8.700615\n",
      "Params: tensor([  4.5146, -12.1555])\n",
      "Grad:   tensor([-0.0010,  0.0058])\n",
      "Epoch 3472, Loss 8.700614\n",
      "Params: tensor([  4.5146, -12.1555])\n",
      "Grad:   tensor([-0.0010,  0.0058])\n",
      "Epoch 3473, Loss 8.700615\n",
      "Params: tensor([  4.5146, -12.1556])\n",
      "Grad:   tensor([-0.0010,  0.0058])\n",
      "Epoch 3474, Loss 8.700614\n",
      "Params: tensor([  4.5146, -12.1556])\n",
      "Grad:   tensor([-0.0010,  0.0058])\n",
      "Epoch 3475, Loss 8.700614\n",
      "Params: tensor([  4.5146, -12.1557])\n",
      "Grad:   tensor([-0.0010,  0.0057])\n",
      "Epoch 3476, Loss 8.700614\n",
      "Params: tensor([  4.5146, -12.1557])\n",
      "Grad:   tensor([-0.0010,  0.0057])\n",
      "Epoch 3477, Loss 8.700614\n",
      "Params: tensor([  4.5147, -12.1558])\n",
      "Grad:   tensor([-0.0010,  0.0057])\n",
      "Epoch 3478, Loss 8.700611\n",
      "Params: tensor([  4.5147, -12.1559])\n",
      "Grad:   tensor([-0.0010,  0.0057])\n",
      "Epoch 3479, Loss 8.700613\n",
      "Params: tensor([  4.5147, -12.1559])\n",
      "Grad:   tensor([-0.0010,  0.0057])\n",
      "Epoch 3480, Loss 8.700613\n",
      "Params: tensor([  4.5147, -12.1560])\n",
      "Grad:   tensor([-0.0010,  0.0057])\n",
      "Epoch 3481, Loss 8.700614\n",
      "Params: tensor([  4.5147, -12.1560])\n",
      "Grad:   tensor([-0.0010,  0.0057])\n",
      "Epoch 3482, Loss 8.700610\n",
      "Params: tensor([  4.5147, -12.1561])\n",
      "Grad:   tensor([-0.0010,  0.0057])\n",
      "Epoch 3483, Loss 8.700612\n",
      "Params: tensor([  4.5147, -12.1561])\n",
      "Grad:   tensor([-0.0010,  0.0057])\n",
      "Epoch 3484, Loss 8.700610\n",
      "Params: tensor([  4.5147, -12.1562])\n",
      "Grad:   tensor([-0.0010,  0.0057])\n",
      "Epoch 3485, Loss 8.700611\n",
      "Params: tensor([  4.5147, -12.1563])\n",
      "Grad:   tensor([-0.0010,  0.0056])\n",
      "Epoch 3486, Loss 8.700610\n",
      "Params: tensor([  4.5147, -12.1563])\n",
      "Grad:   tensor([-0.0010,  0.0056])\n",
      "Epoch 3487, Loss 8.700610\n",
      "Params: tensor([  4.5148, -12.1564])\n",
      "Grad:   tensor([-0.0010,  0.0056])\n",
      "Epoch 3488, Loss 8.700608\n",
      "Params: tensor([  4.5148, -12.1564])\n",
      "Grad:   tensor([-0.0010,  0.0056])\n",
      "Epoch 3489, Loss 8.700611\n",
      "Params: tensor([  4.5148, -12.1565])\n",
      "Grad:   tensor([-0.0010,  0.0056])\n",
      "Epoch 3490, Loss 8.700607\n",
      "Params: tensor([  4.5148, -12.1565])\n",
      "Grad:   tensor([-0.0010,  0.0056])\n",
      "Epoch 3491, Loss 8.700608\n",
      "Params: tensor([  4.5148, -12.1566])\n",
      "Grad:   tensor([-0.0010,  0.0056])\n",
      "Epoch 3492, Loss 8.700607\n",
      "Params: tensor([  4.5148, -12.1567])\n",
      "Grad:   tensor([-0.0010,  0.0056])\n",
      "Epoch 3493, Loss 8.700608\n",
      "Params: tensor([  4.5148, -12.1567])\n",
      "Grad:   tensor([-0.0010,  0.0056])\n",
      "Epoch 3494, Loss 8.700606\n",
      "Params: tensor([  4.5148, -12.1568])\n",
      "Grad:   tensor([-0.0010,  0.0056])\n",
      "Epoch 3495, Loss 8.700605\n",
      "Params: tensor([  4.5148, -12.1568])\n",
      "Grad:   tensor([-0.0010,  0.0056])\n",
      "Epoch 3496, Loss 8.700607\n",
      "Params: tensor([  4.5148, -12.1569])\n",
      "Grad:   tensor([-0.0010,  0.0055])\n",
      "Epoch 3497, Loss 8.700606\n",
      "Params: tensor([  4.5149, -12.1569])\n",
      "Grad:   tensor([-0.0010,  0.0055])\n",
      "Epoch 3498, Loss 8.700606\n",
      "Params: tensor([  4.5149, -12.1570])\n",
      "Grad:   tensor([-0.0010,  0.0055])\n",
      "Epoch 3499, Loss 8.700606\n",
      "Params: tensor([  4.5149, -12.1570])\n",
      "Grad:   tensor([-0.0010,  0.0055])\n",
      "Epoch 3500, Loss 8.700603\n",
      "Params: tensor([  4.5149, -12.1571])\n",
      "Grad:   tensor([-0.0010,  0.0055])\n",
      "Epoch 3501, Loss 8.700604\n",
      "Params: tensor([  4.5149, -12.1571])\n",
      "Grad:   tensor([-0.0010,  0.0055])\n",
      "Epoch 3502, Loss 8.700604\n",
      "Params: tensor([  4.5149, -12.1572])\n",
      "Grad:   tensor([-0.0010,  0.0055])\n",
      "Epoch 3503, Loss 8.700606\n",
      "Params: tensor([  4.5149, -12.1573])\n",
      "Grad:   tensor([-0.0010,  0.0055])\n",
      "Epoch 3504, Loss 8.700602\n",
      "Params: tensor([  4.5149, -12.1573])\n",
      "Grad:   tensor([-0.0010,  0.0055])\n",
      "Epoch 3505, Loss 8.700603\n",
      "Params: tensor([  4.5149, -12.1574])\n",
      "Grad:   tensor([-0.0010,  0.0055])\n",
      "Epoch 3506, Loss 8.700603\n",
      "Params: tensor([  4.5149, -12.1574])\n",
      "Grad:   tensor([-0.0010,  0.0054])\n",
      "Epoch 3507, Loss 8.700603\n",
      "Params: tensor([  4.5150, -12.1575])\n",
      "Grad:   tensor([-0.0010,  0.0054])\n",
      "Epoch 3508, Loss 8.700602\n",
      "Params: tensor([  4.5150, -12.1575])\n",
      "Grad:   tensor([-0.0010,  0.0054])\n",
      "Epoch 3509, Loss 8.700603\n",
      "Params: tensor([  4.5150, -12.1576])\n",
      "Grad:   tensor([-0.0010,  0.0054])\n",
      "Epoch 3510, Loss 8.700602\n",
      "Params: tensor([  4.5150, -12.1576])\n",
      "Grad:   tensor([-0.0010,  0.0054])\n",
      "Epoch 3511, Loss 8.700601\n",
      "Params: tensor([  4.5150, -12.1577])\n",
      "Grad:   tensor([-0.0010,  0.0054])\n",
      "Epoch 3512, Loss 8.700602\n",
      "Params: tensor([  4.5150, -12.1577])\n",
      "Grad:   tensor([-0.0010,  0.0054])\n",
      "Epoch 3513, Loss 8.700602\n",
      "Params: tensor([  4.5150, -12.1578])\n",
      "Grad:   tensor([-0.0010,  0.0054])\n",
      "Epoch 3514, Loss 8.700603\n",
      "Params: tensor([  4.5150, -12.1579])\n",
      "Grad:   tensor([-0.0009,  0.0054])\n",
      "Epoch 3515, Loss 8.700601\n",
      "Params: tensor([  4.5150, -12.1579])\n",
      "Grad:   tensor([-0.0009,  0.0054])\n",
      "Epoch 3516, Loss 8.700602\n",
      "Params: tensor([  4.5150, -12.1580])\n",
      "Grad:   tensor([-0.0009,  0.0054])\n",
      "Epoch 3517, Loss 8.700600\n",
      "Params: tensor([  4.5150, -12.1580])\n",
      "Grad:   tensor([-0.0009,  0.0053])\n",
      "Epoch 3518, Loss 8.700602\n",
      "Params: tensor([  4.5151, -12.1581])\n",
      "Grad:   tensor([-0.0009,  0.0053])\n",
      "Epoch 3519, Loss 8.700599\n",
      "Params: tensor([  4.5151, -12.1581])\n",
      "Grad:   tensor([-0.0009,  0.0053])\n",
      "Epoch 3520, Loss 8.700599\n",
      "Params: tensor([  4.5151, -12.1582])\n",
      "Grad:   tensor([-0.0009,  0.0053])\n",
      "Epoch 3521, Loss 8.700598\n",
      "Params: tensor([  4.5151, -12.1582])\n",
      "Grad:   tensor([-0.0009,  0.0053])\n",
      "Epoch 3522, Loss 8.700600\n",
      "Params: tensor([  4.5151, -12.1583])\n",
      "Grad:   tensor([-0.0009,  0.0053])\n",
      "Epoch 3523, Loss 8.700599\n",
      "Params: tensor([  4.5151, -12.1583])\n",
      "Grad:   tensor([-0.0009,  0.0053])\n",
      "Epoch 3524, Loss 8.700599\n",
      "Params: tensor([  4.5151, -12.1584])\n",
      "Grad:   tensor([-0.0010,  0.0053])\n",
      "Epoch 3525, Loss 8.700596\n",
      "Params: tensor([  4.5151, -12.1584])\n",
      "Grad:   tensor([-0.0009,  0.0053])\n",
      "Epoch 3526, Loss 8.700598\n",
      "Params: tensor([  4.5151, -12.1585])\n",
      "Grad:   tensor([-0.0009,  0.0053])\n",
      "Epoch 3527, Loss 8.700596\n",
      "Params: tensor([  4.5151, -12.1585])\n",
      "Grad:   tensor([-0.0009,  0.0053])\n",
      "Epoch 3528, Loss 8.700597\n",
      "Params: tensor([  4.5152, -12.1586])\n",
      "Grad:   tensor([-0.0009,  0.0052])\n",
      "Epoch 3529, Loss 8.700596\n",
      "Params: tensor([  4.5152, -12.1586])\n",
      "Grad:   tensor([-0.0009,  0.0052])\n",
      "Epoch 3530, Loss 8.700596\n",
      "Params: tensor([  4.5152, -12.1587])\n",
      "Grad:   tensor([-0.0009,  0.0052])\n",
      "Epoch 3531, Loss 8.700597\n",
      "Params: tensor([  4.5152, -12.1588])\n",
      "Grad:   tensor([-0.0009,  0.0052])\n",
      "Epoch 3532, Loss 8.700596\n",
      "Params: tensor([  4.5152, -12.1588])\n",
      "Grad:   tensor([-0.0009,  0.0052])\n",
      "Epoch 3533, Loss 8.700596\n",
      "Params: tensor([  4.5152, -12.1589])\n",
      "Grad:   tensor([-0.0009,  0.0052])\n",
      "Epoch 3534, Loss 8.700594\n",
      "Params: tensor([  4.5152, -12.1589])\n",
      "Grad:   tensor([-0.0009,  0.0052])\n",
      "Epoch 3535, Loss 8.700596\n",
      "Params: tensor([  4.5152, -12.1590])\n",
      "Grad:   tensor([-0.0009,  0.0052])\n",
      "Epoch 3536, Loss 8.700595\n",
      "Params: tensor([  4.5152, -12.1590])\n",
      "Grad:   tensor([-0.0009,  0.0052])\n",
      "Epoch 3537, Loss 8.700596\n",
      "Params: tensor([  4.5152, -12.1591])\n",
      "Grad:   tensor([-0.0009,  0.0052])\n",
      "Epoch 3538, Loss 8.700593\n",
      "Params: tensor([  4.5152, -12.1591])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad:   tensor([-0.0009,  0.0052])\n",
      "Epoch 3539, Loss 8.700592\n",
      "Params: tensor([  4.5153, -12.1592])\n",
      "Grad:   tensor([-0.0009,  0.0052])\n",
      "Epoch 3540, Loss 8.700593\n",
      "Params: tensor([  4.5153, -12.1592])\n",
      "Grad:   tensor([-0.0009,  0.0051])\n",
      "Epoch 3541, Loss 8.700591\n",
      "Params: tensor([  4.5153, -12.1593])\n",
      "Grad:   tensor([-0.0009,  0.0051])\n",
      "Epoch 3542, Loss 8.700593\n",
      "Params: tensor([  4.5153, -12.1593])\n",
      "Grad:   tensor([-0.0009,  0.0051])\n",
      "Epoch 3543, Loss 8.700591\n",
      "Params: tensor([  4.5153, -12.1594])\n",
      "Grad:   tensor([-0.0009,  0.0051])\n",
      "Epoch 3544, Loss 8.700592\n",
      "Params: tensor([  4.5153, -12.1594])\n",
      "Grad:   tensor([-0.0009,  0.0051])\n",
      "Epoch 3545, Loss 8.700591\n",
      "Params: tensor([  4.5153, -12.1595])\n",
      "Grad:   tensor([-0.0009,  0.0051])\n",
      "Epoch 3546, Loss 8.700591\n",
      "Params: tensor([  4.5153, -12.1595])\n",
      "Grad:   tensor([-0.0009,  0.0051])\n",
      "Epoch 3547, Loss 8.700590\n",
      "Params: tensor([  4.5153, -12.1596])\n",
      "Grad:   tensor([-0.0009,  0.0051])\n",
      "Epoch 3548, Loss 8.700589\n",
      "Params: tensor([  4.5153, -12.1596])\n",
      "Grad:   tensor([-0.0009,  0.0051])\n",
      "Epoch 3549, Loss 8.700591\n",
      "Params: tensor([  4.5153, -12.1597])\n",
      "Grad:   tensor([-0.0009,  0.0051])\n",
      "Epoch 3550, Loss 8.700591\n",
      "Params: tensor([  4.5154, -12.1597])\n",
      "Grad:   tensor([-0.0009,  0.0051])\n",
      "Epoch 3551, Loss 8.700591\n",
      "Params: tensor([  4.5154, -12.1598])\n",
      "Grad:   tensor([-0.0009,  0.0050])\n",
      "Epoch 3552, Loss 8.700590\n",
      "Params: tensor([  4.5154, -12.1598])\n",
      "Grad:   tensor([-0.0009,  0.0050])\n",
      "Epoch 3553, Loss 8.700590\n",
      "Params: tensor([  4.5154, -12.1599])\n",
      "Grad:   tensor([-0.0009,  0.0050])\n",
      "Epoch 3554, Loss 8.700588\n",
      "Params: tensor([  4.5154, -12.1599])\n",
      "Grad:   tensor([-0.0009,  0.0050])\n",
      "Epoch 3555, Loss 8.700591\n",
      "Params: tensor([  4.5154, -12.1600])\n",
      "Grad:   tensor([-0.0009,  0.0050])\n",
      "Epoch 3556, Loss 8.700589\n",
      "Params: tensor([  4.5154, -12.1600])\n",
      "Grad:   tensor([-0.0009,  0.0050])\n",
      "Epoch 3557, Loss 8.700589\n",
      "Params: tensor([  4.5154, -12.1601])\n",
      "Grad:   tensor([-0.0009,  0.0050])\n",
      "Epoch 3558, Loss 8.700589\n",
      "Params: tensor([  4.5154, -12.1601])\n",
      "Grad:   tensor([-0.0009,  0.0050])\n",
      "Epoch 3559, Loss 8.700588\n",
      "Params: tensor([  4.5154, -12.1602])\n",
      "Grad:   tensor([-0.0009,  0.0050])\n",
      "Epoch 3560, Loss 8.700589\n",
      "Params: tensor([  4.5154, -12.1602])\n",
      "Grad:   tensor([-0.0009,  0.0050])\n",
      "Epoch 3561, Loss 8.700588\n",
      "Params: tensor([  4.5154, -12.1603])\n",
      "Grad:   tensor([-0.0009,  0.0050])\n",
      "Epoch 3562, Loss 8.700588\n",
      "Params: tensor([  4.5155, -12.1603])\n",
      "Grad:   tensor([-0.0009,  0.0050])\n",
      "Epoch 3563, Loss 8.700586\n",
      "Params: tensor([  4.5155, -12.1604])\n",
      "Grad:   tensor([-0.0009,  0.0049])\n",
      "Epoch 3564, Loss 8.700588\n",
      "Params: tensor([  4.5155, -12.1604])\n",
      "Grad:   tensor([-0.0009,  0.0049])\n",
      "Epoch 3565, Loss 8.700585\n",
      "Params: tensor([  4.5155, -12.1605])\n",
      "Grad:   tensor([-0.0009,  0.0049])\n",
      "Epoch 3566, Loss 8.700587\n",
      "Params: tensor([  4.5155, -12.1605])\n",
      "Grad:   tensor([-0.0009,  0.0049])\n",
      "Epoch 3567, Loss 8.700586\n",
      "Params: tensor([  4.5155, -12.1606])\n",
      "Grad:   tensor([-0.0009,  0.0049])\n",
      "Epoch 3568, Loss 8.700585\n",
      "Params: tensor([  4.5155, -12.1606])\n",
      "Grad:   tensor([-0.0009,  0.0049])\n",
      "Epoch 3569, Loss 8.700586\n",
      "Params: tensor([  4.5155, -12.1607])\n",
      "Grad:   tensor([-0.0009,  0.0049])\n",
      "Epoch 3570, Loss 8.700584\n",
      "Params: tensor([  4.5155, -12.1607])\n",
      "Grad:   tensor([-0.0009,  0.0049])\n",
      "Epoch 3571, Loss 8.700585\n",
      "Params: tensor([  4.5155, -12.1608])\n",
      "Grad:   tensor([-0.0009,  0.0049])\n",
      "Epoch 3572, Loss 8.700584\n",
      "Params: tensor([  4.5155, -12.1608])\n",
      "Grad:   tensor([-0.0009,  0.0049])\n",
      "Epoch 3573, Loss 8.700585\n",
      "Params: tensor([  4.5156, -12.1609])\n",
      "Grad:   tensor([-0.0009,  0.0049])\n",
      "Epoch 3574, Loss 8.700588\n",
      "Params: tensor([  4.5156, -12.1609])\n",
      "Grad:   tensor([-0.0009,  0.0049])\n",
      "Epoch 3575, Loss 8.700583\n",
      "Params: tensor([  4.5156, -12.1610])\n",
      "Grad:   tensor([-0.0009,  0.0048])\n",
      "Epoch 3576, Loss 8.700583\n",
      "Params: tensor([  4.5156, -12.1610])\n",
      "Grad:   tensor([-0.0009,  0.0048])\n",
      "Epoch 3577, Loss 8.700584\n",
      "Params: tensor([  4.5156, -12.1611])\n",
      "Grad:   tensor([-0.0009,  0.0048])\n",
      "Epoch 3578, Loss 8.700585\n",
      "Params: tensor([  4.5156, -12.1611])\n",
      "Grad:   tensor([-0.0009,  0.0048])\n",
      "Epoch 3579, Loss 8.700583\n",
      "Params: tensor([  4.5156, -12.1612])\n",
      "Grad:   tensor([-0.0009,  0.0048])\n",
      "Epoch 3580, Loss 8.700583\n",
      "Params: tensor([  4.5156, -12.1612])\n",
      "Grad:   tensor([-0.0009,  0.0048])\n",
      "Epoch 3581, Loss 8.700583\n",
      "Params: tensor([  4.5156, -12.1613])\n",
      "Grad:   tensor([-0.0008,  0.0048])\n",
      "Epoch 3582, Loss 8.700583\n",
      "Params: tensor([  4.5156, -12.1613])\n",
      "Grad:   tensor([-0.0008,  0.0048])\n",
      "Epoch 3583, Loss 8.700583\n",
      "Params: tensor([  4.5156, -12.1614])\n",
      "Grad:   tensor([-0.0008,  0.0048])\n",
      "Epoch 3584, Loss 8.700580\n",
      "Params: tensor([  4.5156, -12.1614])\n",
      "Grad:   tensor([-0.0008,  0.0048])\n",
      "Epoch 3585, Loss 8.700583\n",
      "Params: tensor([  4.5157, -12.1614])\n",
      "Grad:   tensor([-0.0008,  0.0048])\n",
      "Epoch 3586, Loss 8.700581\n",
      "Params: tensor([  4.5157, -12.1615])\n",
      "Grad:   tensor([-0.0008,  0.0048])\n",
      "Epoch 3587, Loss 8.700582\n",
      "Params: tensor([  4.5157, -12.1615])\n",
      "Grad:   tensor([-0.0008,  0.0048])\n",
      "Epoch 3588, Loss 8.700582\n",
      "Params: tensor([  4.5157, -12.1616])\n",
      "Grad:   tensor([-0.0008,  0.0047])\n",
      "Epoch 3589, Loss 8.700581\n",
      "Params: tensor([  4.5157, -12.1616])\n",
      "Grad:   tensor([-0.0008,  0.0047])\n",
      "Epoch 3590, Loss 8.700583\n",
      "Params: tensor([  4.5157, -12.1617])\n",
      "Grad:   tensor([-0.0008,  0.0047])\n",
      "Epoch 3591, Loss 8.700580\n",
      "Params: tensor([  4.5157, -12.1617])\n",
      "Grad:   tensor([-0.0008,  0.0047])\n",
      "Epoch 3592, Loss 8.700581\n",
      "Params: tensor([  4.5157, -12.1618])\n",
      "Grad:   tensor([-0.0008,  0.0047])\n",
      "Epoch 3593, Loss 8.700581\n",
      "Params: tensor([  4.5157, -12.1618])\n",
      "Grad:   tensor([-0.0008,  0.0047])\n",
      "Epoch 3594, Loss 8.700581\n",
      "Params: tensor([  4.5157, -12.1619])\n",
      "Grad:   tensor([-0.0008,  0.0047])\n",
      "Epoch 3595, Loss 8.700581\n",
      "Params: tensor([  4.5157, -12.1619])\n",
      "Grad:   tensor([-0.0008,  0.0047])\n",
      "Epoch 3596, Loss 8.700577\n",
      "Params: tensor([  4.5157, -12.1620])\n",
      "Grad:   tensor([-0.0008,  0.0047])\n",
      "Epoch 3597, Loss 8.700580\n",
      "Params: tensor([  4.5158, -12.1620])\n",
      "Grad:   tensor([-0.0008,  0.0047])\n",
      "Epoch 3598, Loss 8.700580\n",
      "Params: tensor([  4.5158, -12.1621])\n",
      "Grad:   tensor([-0.0008,  0.0047])\n",
      "Epoch 3599, Loss 8.700578\n",
      "Params: tensor([  4.5158, -12.1621])\n",
      "Grad:   tensor([-0.0008,  0.0047])\n",
      "Epoch 3600, Loss 8.700580\n",
      "Params: tensor([  4.5158, -12.1622])\n",
      "Grad:   tensor([-0.0008,  0.0046])\n",
      "Epoch 3601, Loss 8.700578\n",
      "Params: tensor([  4.5158, -12.1622])\n",
      "Grad:   tensor([-0.0008,  0.0046])\n",
      "Epoch 3602, Loss 8.700577\n",
      "Params: tensor([  4.5158, -12.1622])\n",
      "Grad:   tensor([-0.0008,  0.0046])\n",
      "Epoch 3603, Loss 8.700577\n",
      "Params: tensor([  4.5158, -12.1623])\n",
      "Grad:   tensor([-0.0008,  0.0046])\n",
      "Epoch 3604, Loss 8.700577\n",
      "Params: tensor([  4.5158, -12.1623])\n",
      "Grad:   tensor([-0.0008,  0.0046])\n",
      "Epoch 3605, Loss 8.700578\n",
      "Params: tensor([  4.5158, -12.1624])\n",
      "Grad:   tensor([-0.0008,  0.0046])\n",
      "Epoch 3606, Loss 8.700576\n",
      "Params: tensor([  4.5158, -12.1624])\n",
      "Grad:   tensor([-0.0008,  0.0046])\n",
      "Epoch 3607, Loss 8.700578\n",
      "Params: tensor([  4.5158, -12.1625])\n",
      "Grad:   tensor([-0.0008,  0.0046])\n",
      "Epoch 3608, Loss 8.700577\n",
      "Params: tensor([  4.5158, -12.1625])\n",
      "Grad:   tensor([-0.0008,  0.0046])\n",
      "Epoch 3609, Loss 8.700576\n",
      "Params: tensor([  4.5159, -12.1626])\n",
      "Grad:   tensor([-0.0008,  0.0046])\n",
      "Epoch 3610, Loss 8.700578\n",
      "Params: tensor([  4.5159, -12.1626])\n",
      "Grad:   tensor([-0.0008,  0.0046])\n",
      "Epoch 3611, Loss 8.700575\n",
      "Params: tensor([  4.5159, -12.1627])\n",
      "Grad:   tensor([-0.0008,  0.0046])\n",
      "Epoch 3612, Loss 8.700576\n",
      "Params: tensor([  4.5159, -12.1627])\n",
      "Grad:   tensor([-0.0008,  0.0046])\n",
      "Epoch 3613, Loss 8.700576\n",
      "Params: tensor([  4.5159, -12.1627])\n",
      "Grad:   tensor([-0.0008,  0.0045])\n",
      "Epoch 3614, Loss 8.700576\n",
      "Params: tensor([  4.5159, -12.1628])\n",
      "Grad:   tensor([-0.0008,  0.0045])\n",
      "Epoch 3615, Loss 8.700577\n",
      "Params: tensor([  4.5159, -12.1628])\n",
      "Grad:   tensor([-0.0008,  0.0045])\n",
      "Epoch 3616, Loss 8.700573\n",
      "Params: tensor([  4.5159, -12.1629])\n",
      "Grad:   tensor([-0.0008,  0.0045])\n",
      "Epoch 3617, Loss 8.700576\n",
      "Params: tensor([  4.5159, -12.1629])\n",
      "Grad:   tensor([-0.0008,  0.0045])\n",
      "Epoch 3618, Loss 8.700576\n",
      "Params: tensor([  4.5159, -12.1630])\n",
      "Grad:   tensor([-0.0008,  0.0045])\n",
      "Epoch 3619, Loss 8.700574\n",
      "Params: tensor([  4.5159, -12.1630])\n",
      "Grad:   tensor([-0.0008,  0.0045])\n",
      "Epoch 3620, Loss 8.700576\n",
      "Params: tensor([  4.5159, -12.1631])\n",
      "Grad:   tensor([-0.0008,  0.0045])\n",
      "Epoch 3621, Loss 8.700573\n",
      "Params: tensor([  4.5159, -12.1631])\n",
      "Grad:   tensor([-0.0008,  0.0045])\n",
      "Epoch 3622, Loss 8.700574\n",
      "Params: tensor([  4.5160, -12.1632])\n",
      "Grad:   tensor([-0.0008,  0.0045])\n",
      "Epoch 3623, Loss 8.700574\n",
      "Params: tensor([  4.5160, -12.1632])\n",
      "Grad:   tensor([-0.0008,  0.0045])\n",
      "Epoch 3624, Loss 8.700572\n",
      "Params: tensor([  4.5160, -12.1632])\n",
      "Grad:   tensor([-0.0008,  0.0045])\n",
      "Epoch 3625, Loss 8.700574\n",
      "Params: tensor([  4.5160, -12.1633])\n",
      "Grad:   tensor([-0.0008,  0.0045])\n",
      "Epoch 3626, Loss 8.700573\n",
      "Params: tensor([  4.5160, -12.1633])\n",
      "Grad:   tensor([-0.0008,  0.0044])\n",
      "Epoch 3627, Loss 8.700574\n",
      "Params: tensor([  4.5160, -12.1634])\n",
      "Grad:   tensor([-0.0008,  0.0044])\n",
      "Epoch 3628, Loss 8.700573\n",
      "Params: tensor([  4.5160, -12.1634])\n",
      "Grad:   tensor([-0.0008,  0.0044])\n",
      "Epoch 3629, Loss 8.700571\n",
      "Params: tensor([  4.5160, -12.1635])\n",
      "Grad:   tensor([-0.0008,  0.0044])\n",
      "Epoch 3630, Loss 8.700573\n",
      "Params: tensor([  4.5160, -12.1635])\n",
      "Grad:   tensor([-0.0008,  0.0044])\n",
      "Epoch 3631, Loss 8.700573\n",
      "Params: tensor([  4.5160, -12.1636])\n",
      "Grad:   tensor([-0.0008,  0.0044])\n",
      "Epoch 3632, Loss 8.700573\n",
      "Params: tensor([  4.5160, -12.1636])\n",
      "Grad:   tensor([-0.0008,  0.0044])\n",
      "Epoch 3633, Loss 8.700573\n",
      "Params: tensor([  4.5160, -12.1636])\n",
      "Grad:   tensor([-0.0008,  0.0044])\n",
      "Epoch 3634, Loss 8.700568\n",
      "Params: tensor([  4.5161, -12.1637])\n",
      "Grad:   tensor([-0.0008,  0.0044])\n",
      "Epoch 3635, Loss 8.700574\n",
      "Params: tensor([  4.5161, -12.1637])\n",
      "Grad:   tensor([-0.0008,  0.0044])\n",
      "Epoch 3636, Loss 8.700569\n",
      "Params: tensor([  4.5161, -12.1638])\n",
      "Grad:   tensor([-0.0008,  0.0044])\n",
      "Epoch 3637, Loss 8.700573\n",
      "Params: tensor([  4.5161, -12.1638])\n",
      "Grad:   tensor([-0.0008,  0.0044])\n",
      "Epoch 3638, Loss 8.700571\n",
      "Params: tensor([  4.5161, -12.1639])\n",
      "Grad:   tensor([-0.0008,  0.0044])\n",
      "Epoch 3639, Loss 8.700571\n",
      "Params: tensor([  4.5161, -12.1639])\n",
      "Grad:   tensor([-0.0008,  0.0043])\n",
      "Epoch 3640, Loss 8.700569\n",
      "Params: tensor([  4.5161, -12.1639])\n",
      "Grad:   tensor([-0.0008,  0.0043])\n",
      "Epoch 3641, Loss 8.700568\n",
      "Params: tensor([  4.5161, -12.1640])\n",
      "Grad:   tensor([-0.0008,  0.0043])\n",
      "Epoch 3642, Loss 8.700570\n",
      "Params: tensor([  4.5161, -12.1640])\n",
      "Grad:   tensor([-0.0008,  0.0043])\n",
      "Epoch 3643, Loss 8.700570\n",
      "Params: tensor([  4.5161, -12.1641])\n",
      "Grad:   tensor([-0.0008,  0.0043])\n",
      "Epoch 3644, Loss 8.700568\n",
      "Params: tensor([  4.5161, -12.1641])\n",
      "Grad:   tensor([-0.0008,  0.0043])\n",
      "Epoch 3645, Loss 8.700568\n",
      "Params: tensor([  4.5161, -12.1642])\n",
      "Grad:   tensor([-0.0008,  0.0043])\n",
      "Epoch 3646, Loss 8.700573\n",
      "Params: tensor([  4.5161, -12.1642])\n",
      "Grad:   tensor([-0.0008,  0.0043])\n",
      "Epoch 3647, Loss 8.700568\n",
      "Params: tensor([  4.5162, -12.1642])\n",
      "Grad:   tensor([-0.0008,  0.0043])\n",
      "Epoch 3648, Loss 8.700570\n",
      "Params: tensor([  4.5162, -12.1643])\n",
      "Grad:   tensor([-0.0007,  0.0043])\n",
      "Epoch 3649, Loss 8.700567\n",
      "Params: tensor([  4.5162, -12.1643])\n",
      "Grad:   tensor([-0.0007,  0.0043])\n",
      "Epoch 3650, Loss 8.700568\n",
      "Params: tensor([  4.5162, -12.1644])\n",
      "Grad:   tensor([-0.0007,  0.0043])\n",
      "Epoch 3651, Loss 8.700570\n",
      "Params: tensor([  4.5162, -12.1644])\n",
      "Grad:   tensor([-0.0007,  0.0043])\n",
      "Epoch 3652, Loss 8.700566\n",
      "Params: tensor([  4.5162, -12.1645])\n",
      "Grad:   tensor([-0.0007,  0.0043])\n",
      "Epoch 3653, Loss 8.700568\n",
      "Params: tensor([  4.5162, -12.1645])\n",
      "Grad:   tensor([-0.0008,  0.0042])\n",
      "Epoch 3654, Loss 8.700568\n",
      "Params: tensor([  4.5162, -12.1645])\n",
      "Grad:   tensor([-0.0007,  0.0042])\n",
      "Epoch 3655, Loss 8.700567\n",
      "Params: tensor([  4.5162, -12.1646])\n",
      "Grad:   tensor([-0.0007,  0.0042])\n",
      "Epoch 3656, Loss 8.700567\n",
      "Params: tensor([  4.5162, -12.1646])\n",
      "Grad:   tensor([-0.0007,  0.0042])\n",
      "Epoch 3657, Loss 8.700566\n",
      "Params: tensor([  4.5162, -12.1647])\n",
      "Grad:   tensor([-0.0007,  0.0042])\n",
      "Epoch 3658, Loss 8.700567\n",
      "Params: tensor([  4.5162, -12.1647])\n",
      "Grad:   tensor([-0.0007,  0.0042])\n",
      "Epoch 3659, Loss 8.700567\n",
      "Params: tensor([  4.5162, -12.1648])\n",
      "Grad:   tensor([-0.0007,  0.0042])\n",
      "Epoch 3660, Loss 8.700564\n",
      "Params: tensor([  4.5162, -12.1648])\n",
      "Grad:   tensor([-0.0007,  0.0042])\n",
      "Epoch 3661, Loss 8.700566\n",
      "Params: tensor([  4.5163, -12.1648])\n",
      "Grad:   tensor([-0.0007,  0.0042])\n",
      "Epoch 3662, Loss 8.700567\n",
      "Params: tensor([  4.5163, -12.1649])\n",
      "Grad:   tensor([-0.0007,  0.0042])\n",
      "Epoch 3663, Loss 8.700565\n",
      "Params: tensor([  4.5163, -12.1649])\n",
      "Grad:   tensor([-0.0007,  0.0042])\n",
      "Epoch 3664, Loss 8.700565\n",
      "Params: tensor([  4.5163, -12.1650])\n",
      "Grad:   tensor([-0.0007,  0.0042])\n",
      "Epoch 3665, Loss 8.700567\n",
      "Params: tensor([  4.5163, -12.1650])\n",
      "Grad:   tensor([-0.0007,  0.0042])\n",
      "Epoch 3666, Loss 8.700565\n",
      "Params: tensor([  4.5163, -12.1650])\n",
      "Grad:   tensor([-0.0007,  0.0042])\n",
      "Epoch 3667, Loss 8.700565\n",
      "Params: tensor([  4.5163, -12.1651])\n",
      "Grad:   tensor([-0.0007,  0.0041])\n",
      "Epoch 3668, Loss 8.700564\n",
      "Params: tensor([  4.5163, -12.1651])\n",
      "Grad:   tensor([-0.0007,  0.0041])\n",
      "Epoch 3669, Loss 8.700563\n",
      "Params: tensor([  4.5163, -12.1652])\n",
      "Grad:   tensor([-0.0007,  0.0041])\n",
      "Epoch 3670, Loss 8.700565\n",
      "Params: tensor([  4.5163, -12.1652])\n",
      "Grad:   tensor([-0.0007,  0.0041])\n",
      "Epoch 3671, Loss 8.700565\n",
      "Params: tensor([  4.5163, -12.1653])\n",
      "Grad:   tensor([-0.0007,  0.0041])\n",
      "Epoch 3672, Loss 8.700562\n",
      "Params: tensor([  4.5163, -12.1653])\n",
      "Grad:   tensor([-0.0007,  0.0041])\n",
      "Epoch 3673, Loss 8.700564\n",
      "Params: tensor([  4.5163, -12.1653])\n",
      "Grad:   tensor([-0.0007,  0.0041])\n",
      "Epoch 3674, Loss 8.700564\n",
      "Params: tensor([  4.5163, -12.1654])\n",
      "Grad:   tensor([-0.0007,  0.0041])\n",
      "Epoch 3675, Loss 8.700564\n",
      "Params: tensor([  4.5164, -12.1654])\n",
      "Grad:   tensor([-0.0007,  0.0041])\n",
      "Epoch 3676, Loss 8.700565\n",
      "Params: tensor([  4.5164, -12.1655])\n",
      "Grad:   tensor([-0.0007,  0.0041])\n",
      "Epoch 3677, Loss 8.700563\n",
      "Params: tensor([  4.5164, -12.1655])\n",
      "Grad:   tensor([-0.0007,  0.0041])\n",
      "Epoch 3678, Loss 8.700565\n",
      "Params: tensor([  4.5164, -12.1655])\n",
      "Grad:   tensor([-0.0007,  0.0041])\n",
      "Epoch 3679, Loss 8.700562\n",
      "Params: tensor([  4.5164, -12.1656])\n",
      "Grad:   tensor([-0.0007,  0.0041])\n",
      "Epoch 3680, Loss 8.700562\n",
      "Params: tensor([  4.5164, -12.1656])\n",
      "Grad:   tensor([-0.0007,  0.0041])\n",
      "Epoch 3681, Loss 8.700563\n",
      "Params: tensor([  4.5164, -12.1657])\n",
      "Grad:   tensor([-0.0007,  0.0040])\n",
      "Epoch 3682, Loss 8.700562\n",
      "Params: tensor([  4.5164, -12.1657])\n",
      "Grad:   tensor([-0.0007,  0.0040])\n",
      "Epoch 3683, Loss 8.700562\n",
      "Params: tensor([  4.5164, -12.1657])\n",
      "Grad:   tensor([-0.0007,  0.0040])\n",
      "Epoch 3684, Loss 8.700562\n",
      "Params: tensor([  4.5164, -12.1658])\n",
      "Grad:   tensor([-0.0007,  0.0040])\n",
      "Epoch 3685, Loss 8.700562\n",
      "Params: tensor([  4.5164, -12.1658])\n",
      "Grad:   tensor([-0.0007,  0.0040])\n",
      "Epoch 3686, Loss 8.700562\n",
      "Params: tensor([  4.5164, -12.1659])\n",
      "Grad:   tensor([-0.0007,  0.0040])\n",
      "Epoch 3687, Loss 8.700562\n",
      "Params: tensor([  4.5164, -12.1659])\n",
      "Grad:   tensor([-0.0007,  0.0040])\n",
      "Epoch 3688, Loss 8.700562\n",
      "Params: tensor([  4.5164, -12.1659])\n",
      "Grad:   tensor([-0.0007,  0.0040])\n",
      "Epoch 3689, Loss 8.700562\n",
      "Params: tensor([  4.5165, -12.1660])\n",
      "Grad:   tensor([-0.0007,  0.0040])\n",
      "Epoch 3690, Loss 8.700562\n",
      "Params: tensor([  4.5165, -12.1660])\n",
      "Grad:   tensor([-0.0007,  0.0040])\n",
      "Epoch 3691, Loss 8.700562\n",
      "Params: tensor([  4.5165, -12.1661])\n",
      "Grad:   tensor([-0.0007,  0.0040])\n",
      "Epoch 3692, Loss 8.700561\n",
      "Params: tensor([  4.5165, -12.1661])\n",
      "Grad:   tensor([-0.0007,  0.0040])\n",
      "Epoch 3693, Loss 8.700562\n",
      "Params: tensor([  4.5165, -12.1661])\n",
      "Grad:   tensor([-0.0007,  0.0040])\n",
      "Epoch 3694, Loss 8.700562\n",
      "Params: tensor([  4.5165, -12.1662])\n",
      "Grad:   tensor([-0.0007,  0.0040])\n",
      "Epoch 3695, Loss 8.700561\n",
      "Params: tensor([  4.5165, -12.1662])\n",
      "Grad:   tensor([-0.0007,  0.0040])\n",
      "Epoch 3696, Loss 8.700559\n",
      "Params: tensor([  4.5165, -12.1663])\n",
      "Grad:   tensor([-0.0007,  0.0039])\n",
      "Epoch 3697, Loss 8.700560\n",
      "Params: tensor([  4.5165, -12.1663])\n",
      "Grad:   tensor([-0.0007,  0.0039])\n",
      "Epoch 3698, Loss 8.700562\n",
      "Params: tensor([  4.5165, -12.1663])\n",
      "Grad:   tensor([-0.0007,  0.0039])\n",
      "Epoch 3699, Loss 8.700561\n",
      "Params: tensor([  4.5165, -12.1664])\n",
      "Grad:   tensor([-0.0007,  0.0039])\n",
      "Epoch 3700, Loss 8.700559\n",
      "Params: tensor([  4.5165, -12.1664])\n",
      "Grad:   tensor([-0.0007,  0.0039])\n",
      "Epoch 3701, Loss 8.700559\n",
      "Params: tensor([  4.5165, -12.1665])\n",
      "Grad:   tensor([-0.0007,  0.0039])\n",
      "Epoch 3702, Loss 8.700559\n",
      "Params: tensor([  4.5165, -12.1665])\n",
      "Grad:   tensor([-0.0007,  0.0039])\n",
      "Epoch 3703, Loss 8.700561\n",
      "Params: tensor([  4.5166, -12.1665])\n",
      "Grad:   tensor([-0.0007,  0.0039])\n",
      "Epoch 3704, Loss 8.700562\n",
      "Params: tensor([  4.5166, -12.1666])\n",
      "Grad:   tensor([-0.0007,  0.0039])\n",
      "Epoch 3705, Loss 8.700558\n",
      "Params: tensor([  4.5166, -12.1666])\n",
      "Grad:   tensor([-0.0007,  0.0039])\n",
      "Epoch 3706, Loss 8.700559\n",
      "Params: tensor([  4.5166, -12.1667])\n",
      "Grad:   tensor([-0.0007,  0.0039])\n",
      "Epoch 3707, Loss 8.700559\n",
      "Params: tensor([  4.5166, -12.1667])\n",
      "Grad:   tensor([-0.0007,  0.0039])\n",
      "Epoch 3708, Loss 8.700558\n",
      "Params: tensor([  4.5166, -12.1667])\n",
      "Grad:   tensor([-0.0007,  0.0039])\n",
      "Epoch 3709, Loss 8.700558\n",
      "Params: tensor([  4.5166, -12.1668])\n",
      "Grad:   tensor([-0.0007,  0.0039])\n",
      "Epoch 3710, Loss 8.700559\n",
      "Params: tensor([  4.5166, -12.1668])\n",
      "Grad:   tensor([-0.0007,  0.0039])\n",
      "Epoch 3711, Loss 8.700558\n",
      "Params: tensor([  4.5166, -12.1668])\n",
      "Grad:   tensor([-0.0007,  0.0038])\n",
      "Epoch 3712, Loss 8.700558\n",
      "Params: tensor([  4.5166, -12.1669])\n",
      "Grad:   tensor([-0.0007,  0.0038])\n",
      "Epoch 3713, Loss 8.700557\n",
      "Params: tensor([  4.5166, -12.1669])\n",
      "Grad:   tensor([-0.0007,  0.0038])\n",
      "Epoch 3714, Loss 8.700557\n",
      "Params: tensor([  4.5166, -12.1670])\n",
      "Grad:   tensor([-0.0007,  0.0038])\n",
      "Epoch 3715, Loss 8.700557\n",
      "Params: tensor([  4.5166, -12.1670])\n",
      "Grad:   tensor([-0.0007,  0.0038])\n",
      "Epoch 3716, Loss 8.700558\n",
      "Params: tensor([  4.5166, -12.1670])\n",
      "Grad:   tensor([-0.0007,  0.0038])\n",
      "Epoch 3717, Loss 8.700558\n",
      "Params: tensor([  4.5166, -12.1671])\n",
      "Grad:   tensor([-0.0007,  0.0038])\n",
      "Epoch 3718, Loss 8.700559\n",
      "Params: tensor([  4.5167, -12.1671])\n",
      "Grad:   tensor([-0.0007,  0.0038])\n",
      "Epoch 3719, Loss 8.700558\n",
      "Params: tensor([  4.5167, -12.1671])\n",
      "Grad:   tensor([-0.0007,  0.0038])\n",
      "Epoch 3720, Loss 8.700556\n",
      "Params: tensor([  4.5167, -12.1672])\n",
      "Grad:   tensor([-0.0007,  0.0038])\n",
      "Epoch 3721, Loss 8.700558\n",
      "Params: tensor([  4.5167, -12.1672])\n",
      "Grad:   tensor([-0.0007,  0.0038])\n",
      "Epoch 3722, Loss 8.700558\n",
      "Params: tensor([  4.5167, -12.1673])\n",
      "Grad:   tensor([-0.0007,  0.0038])\n",
      "Epoch 3723, Loss 8.700555\n",
      "Params: tensor([  4.5167, -12.1673])\n",
      "Grad:   tensor([-0.0007,  0.0038])\n",
      "Epoch 3724, Loss 8.700556\n",
      "Params: tensor([  4.5167, -12.1673])\n",
      "Grad:   tensor([-0.0007,  0.0038])\n",
      "Epoch 3725, Loss 8.700557\n",
      "Params: tensor([  4.5167, -12.1674])\n",
      "Grad:   tensor([-0.0007,  0.0038])\n",
      "Epoch 3726, Loss 8.700556\n",
      "Params: tensor([  4.5167, -12.1674])\n",
      "Grad:   tensor([-0.0007,  0.0038])\n",
      "Epoch 3727, Loss 8.700555\n",
      "Params: tensor([  4.5167, -12.1674])\n",
      "Grad:   tensor([-0.0007,  0.0037])\n",
      "Epoch 3728, Loss 8.700555\n",
      "Params: tensor([  4.5167, -12.1675])\n",
      "Grad:   tensor([-0.0007,  0.0037])\n",
      "Epoch 3729, Loss 8.700556\n",
      "Params: tensor([  4.5167, -12.1675])\n",
      "Grad:   tensor([-0.0006,  0.0037])\n",
      "Epoch 3730, Loss 8.700556\n",
      "Params: tensor([  4.5167, -12.1676])\n",
      "Grad:   tensor([-0.0007,  0.0037])\n",
      "Epoch 3731, Loss 8.700556\n",
      "Params: tensor([  4.5167, -12.1676])\n",
      "Grad:   tensor([-0.0007,  0.0037])\n",
      "Epoch 3732, Loss 8.700555\n",
      "Params: tensor([  4.5167, -12.1676])\n",
      "Grad:   tensor([-0.0006,  0.0037])\n",
      "Epoch 3733, Loss 8.700555\n",
      "Params: tensor([  4.5168, -12.1677])\n",
      "Grad:   tensor([-0.0007,  0.0037])\n",
      "Epoch 3734, Loss 8.700557\n",
      "Params: tensor([  4.5168, -12.1677])\n",
      "Grad:   tensor([-0.0007,  0.0037])\n",
      "Epoch 3735, Loss 8.700553\n",
      "Params: tensor([  4.5168, -12.1677])\n",
      "Grad:   tensor([-0.0006,  0.0037])\n",
      "Epoch 3736, Loss 8.700553\n",
      "Params: tensor([  4.5168, -12.1678])\n",
      "Grad:   tensor([-0.0006,  0.0037])\n",
      "Epoch 3737, Loss 8.700555\n",
      "Params: tensor([  4.5168, -12.1678])\n",
      "Grad:   tensor([-0.0006,  0.0037])\n",
      "Epoch 3738, Loss 8.700555\n",
      "Params: tensor([  4.5168, -12.1679])\n",
      "Grad:   tensor([-0.0007,  0.0037])\n",
      "Epoch 3739, Loss 8.700553\n",
      "Params: tensor([  4.5168, -12.1679])\n",
      "Grad:   tensor([-0.0006,  0.0037])\n",
      "Epoch 3740, Loss 8.700555\n",
      "Params: tensor([  4.5168, -12.1679])\n",
      "Grad:   tensor([-0.0006,  0.0037])\n",
      "Epoch 3741, Loss 8.700552\n",
      "Params: tensor([  4.5168, -12.1680])\n",
      "Grad:   tensor([-0.0006,  0.0037])\n",
      "Epoch 3742, Loss 8.700554\n",
      "Params: tensor([  4.5168, -12.1680])\n",
      "Grad:   tensor([-0.0007,  0.0036])\n",
      "Epoch 3743, Loss 8.700553\n",
      "Params: tensor([  4.5168, -12.1680])\n",
      "Grad:   tensor([-0.0006,  0.0036])\n",
      "Epoch 3744, Loss 8.700552\n",
      "Params: tensor([  4.5168, -12.1681])\n",
      "Grad:   tensor([-0.0006,  0.0036])\n",
      "Epoch 3745, Loss 8.700553\n",
      "Params: tensor([  4.5168, -12.1681])\n",
      "Grad:   tensor([-0.0006,  0.0036])\n",
      "Epoch 3746, Loss 8.700553\n",
      "Params: tensor([  4.5168, -12.1681])\n",
      "Grad:   tensor([-0.0006,  0.0036])\n",
      "Epoch 3747, Loss 8.700552\n",
      "Params: tensor([  4.5168, -12.1682])\n",
      "Grad:   tensor([-0.0006,  0.0036])\n",
      "Epoch 3748, Loss 8.700553\n",
      "Params: tensor([  4.5169, -12.1682])\n",
      "Grad:   tensor([-0.0006,  0.0036])\n",
      "Epoch 3749, Loss 8.700553\n",
      "Params: tensor([  4.5169, -12.1683])\n",
      "Grad:   tensor([-0.0006,  0.0036])\n",
      "Epoch 3750, Loss 8.700555\n",
      "Params: tensor([  4.5169, -12.1683])\n",
      "Grad:   tensor([-0.0007,  0.0036])\n",
      "Epoch 3751, Loss 8.700550\n",
      "Params: tensor([  4.5169, -12.1683])\n",
      "Grad:   tensor([-0.0006,  0.0036])\n",
      "Epoch 3752, Loss 8.700555\n",
      "Params: tensor([  4.5169, -12.1684])\n",
      "Grad:   tensor([-0.0007,  0.0036])\n",
      "Epoch 3753, Loss 8.700553\n",
      "Params: tensor([  4.5169, -12.1684])\n",
      "Grad:   tensor([-0.0006,  0.0036])\n",
      "Epoch 3754, Loss 8.700553\n",
      "Params: tensor([  4.5169, -12.1684])\n",
      "Grad:   tensor([-0.0006,  0.0036])\n",
      "Epoch 3755, Loss 8.700552\n",
      "Params: tensor([  4.5169, -12.1685])\n",
      "Grad:   tensor([-0.0006,  0.0036])\n",
      "Epoch 3756, Loss 8.700553\n",
      "Params: tensor([  4.5169, -12.1685])\n",
      "Grad:   tensor([-0.0006,  0.0036])\n",
      "Epoch 3757, Loss 8.700550\n",
      "Params: tensor([  4.5169, -12.1685])\n",
      "Grad:   tensor([-0.0006,  0.0036])\n",
      "Epoch 3758, Loss 8.700553\n",
      "Params: tensor([  4.5169, -12.1686])\n",
      "Grad:   tensor([-0.0006,  0.0036])\n",
      "Epoch 3759, Loss 8.700553\n",
      "Params: tensor([  4.5169, -12.1686])\n",
      "Grad:   tensor([-0.0006,  0.0035])\n",
      "Epoch 3760, Loss 8.700550\n",
      "Params: tensor([  4.5169, -12.1686])\n",
      "Grad:   tensor([-0.0006,  0.0035])\n",
      "Epoch 3761, Loss 8.700549\n",
      "Params: tensor([  4.5169, -12.1687])\n",
      "Grad:   tensor([-0.0006,  0.0035])\n",
      "Epoch 3762, Loss 8.700553\n",
      "Params: tensor([  4.5169, -12.1687])\n",
      "Grad:   tensor([-0.0006,  0.0035])\n",
      "Epoch 3763, Loss 8.700551\n",
      "Params: tensor([  4.5169, -12.1688])\n",
      "Grad:   tensor([-0.0006,  0.0035])\n",
      "Epoch 3764, Loss 8.700549\n",
      "Params: tensor([  4.5170, -12.1688])\n",
      "Grad:   tensor([-0.0006,  0.0035])\n",
      "Epoch 3765, Loss 8.700550\n",
      "Params: tensor([  4.5170, -12.1688])\n",
      "Grad:   tensor([-0.0006,  0.0035])\n",
      "Epoch 3766, Loss 8.700553\n",
      "Params: tensor([  4.5170, -12.1689])\n",
      "Grad:   tensor([-0.0006,  0.0035])\n",
      "Epoch 3767, Loss 8.700550\n",
      "Params: tensor([  4.5170, -12.1689])\n",
      "Grad:   tensor([-0.0006,  0.0035])\n",
      "Epoch 3768, Loss 8.700550\n",
      "Params: tensor([  4.5170, -12.1689])\n",
      "Grad:   tensor([-0.0006,  0.0035])\n",
      "Epoch 3769, Loss 8.700550\n",
      "Params: tensor([  4.5170, -12.1690])\n",
      "Grad:   tensor([-0.0006,  0.0035])\n",
      "Epoch 3770, Loss 8.700550\n",
      "Params: tensor([  4.5170, -12.1690])\n",
      "Grad:   tensor([-0.0006,  0.0035])\n",
      "Epoch 3771, Loss 8.700551\n",
      "Params: tensor([  4.5170, -12.1690])\n",
      "Grad:   tensor([-0.0006,  0.0035])\n",
      "Epoch 3772, Loss 8.700550\n",
      "Params: tensor([  4.5170, -12.1691])\n",
      "Grad:   tensor([-0.0006,  0.0035])\n",
      "Epoch 3773, Loss 8.700550\n",
      "Params: tensor([  4.5170, -12.1691])\n",
      "Grad:   tensor([-0.0006,  0.0035])\n",
      "Epoch 3774, Loss 8.700550\n",
      "Params: tensor([  4.5170, -12.1691])\n",
      "Grad:   tensor([-0.0006,  0.0035])\n",
      "Epoch 3775, Loss 8.700549\n",
      "Params: tensor([  4.5170, -12.1692])\n",
      "Grad:   tensor([-0.0006,  0.0034])\n",
      "Epoch 3776, Loss 8.700547\n",
      "Params: tensor([  4.5170, -12.1692])\n",
      "Grad:   tensor([-0.0006,  0.0034])\n",
      "Epoch 3777, Loss 8.700550\n",
      "Params: tensor([  4.5170, -12.1692])\n",
      "Grad:   tensor([-0.0006,  0.0034])\n",
      "Epoch 3778, Loss 8.700549\n",
      "Params: tensor([  4.5170, -12.1693])\n",
      "Grad:   tensor([-0.0006,  0.0034])\n",
      "Epoch 3779, Loss 8.700551\n",
      "Params: tensor([  4.5170, -12.1693])\n",
      "Grad:   tensor([-0.0006,  0.0034])\n",
      "Epoch 3780, Loss 8.700547\n",
      "Params: tensor([  4.5171, -12.1693])\n",
      "Grad:   tensor([-0.0006,  0.0034])\n",
      "Epoch 3781, Loss 8.700549\n",
      "Params: tensor([  4.5171, -12.1694])\n",
      "Grad:   tensor([-0.0006,  0.0034])\n",
      "Epoch 3782, Loss 8.700550\n",
      "Params: tensor([  4.5171, -12.1694])\n",
      "Grad:   tensor([-0.0006,  0.0034])\n",
      "Epoch 3783, Loss 8.700549\n",
      "Params: tensor([  4.5171, -12.1694])\n",
      "Grad:   tensor([-0.0006,  0.0034])\n",
      "Epoch 3784, Loss 8.700547\n",
      "Params: tensor([  4.5171, -12.1695])\n",
      "Grad:   tensor([-0.0006,  0.0034])\n",
      "Epoch 3785, Loss 8.700550\n",
      "Params: tensor([  4.5171, -12.1695])\n",
      "Grad:   tensor([-0.0006,  0.0034])\n",
      "Epoch 3786, Loss 8.700547\n",
      "Params: tensor([  4.5171, -12.1696])\n",
      "Grad:   tensor([-0.0006,  0.0034])\n",
      "Epoch 3787, Loss 8.700549\n",
      "Params: tensor([  4.5171, -12.1696])\n",
      "Grad:   tensor([-0.0006,  0.0034])\n",
      "Epoch 3788, Loss 8.700549\n",
      "Params: tensor([  4.5171, -12.1696])\n",
      "Grad:   tensor([-0.0006,  0.0034])\n",
      "Epoch 3789, Loss 8.700547\n",
      "Params: tensor([  4.5171, -12.1697])\n",
      "Grad:   tensor([-0.0006,  0.0034])\n",
      "Epoch 3790, Loss 8.700547\n",
      "Params: tensor([  4.5171, -12.1697])\n",
      "Grad:   tensor([-0.0006,  0.0034])\n",
      "Epoch 3791, Loss 8.700548\n",
      "Params: tensor([  4.5171, -12.1697])\n",
      "Grad:   tensor([-0.0006,  0.0034])\n",
      "Epoch 3792, Loss 8.700547\n",
      "Params: tensor([  4.5171, -12.1698])\n",
      "Grad:   tensor([-0.0006,  0.0034])\n",
      "Epoch 3793, Loss 8.700546\n",
      "Params: tensor([  4.5171, -12.1698])\n",
      "Grad:   tensor([-0.0006,  0.0033])\n",
      "Epoch 3794, Loss 8.700547\n",
      "Params: tensor([  4.5171, -12.1698])\n",
      "Grad:   tensor([-0.0006,  0.0033])\n",
      "Epoch 3795, Loss 8.700548\n",
      "Params: tensor([  4.5171, -12.1699])\n",
      "Grad:   tensor([-0.0006,  0.0033])\n",
      "Epoch 3796, Loss 8.700547\n",
      "Params: tensor([  4.5171, -12.1699])\n",
      "Grad:   tensor([-0.0006,  0.0033])\n",
      "Epoch 3797, Loss 8.700547\n",
      "Params: tensor([  4.5172, -12.1699])\n",
      "Grad:   tensor([-0.0006,  0.0033])\n",
      "Epoch 3798, Loss 8.700547\n",
      "Params: tensor([  4.5172, -12.1700])\n",
      "Grad:   tensor([-0.0006,  0.0033])\n",
      "Epoch 3799, Loss 8.700548\n",
      "Params: tensor([  4.5172, -12.1700])\n",
      "Grad:   tensor([-0.0006,  0.0033])\n",
      "Epoch 3800, Loss 8.700545\n",
      "Params: tensor([  4.5172, -12.1700])\n",
      "Grad:   tensor([-0.0006,  0.0033])\n",
      "Epoch 3801, Loss 8.700545\n",
      "Params: tensor([  4.5172, -12.1701])\n",
      "Grad:   tensor([-0.0006,  0.0033])\n",
      "Epoch 3802, Loss 8.700546\n",
      "Params: tensor([  4.5172, -12.1701])\n",
      "Grad:   tensor([-0.0006,  0.0033])\n",
      "Epoch 3803, Loss 8.700545\n",
      "Params: tensor([  4.5172, -12.1701])\n",
      "Grad:   tensor([-0.0006,  0.0033])\n",
      "Epoch 3804, Loss 8.700543\n",
      "Params: tensor([  4.5172, -12.1701])\n",
      "Grad:   tensor([-0.0006,  0.0033])\n",
      "Epoch 3805, Loss 8.700547\n",
      "Params: tensor([  4.5172, -12.1702])\n",
      "Grad:   tensor([-0.0006,  0.0033])\n",
      "Epoch 3806, Loss 8.700546\n",
      "Params: tensor([  4.5172, -12.1702])\n",
      "Grad:   tensor([-0.0006,  0.0033])\n",
      "Epoch 3807, Loss 8.700545\n",
      "Params: tensor([  4.5172, -12.1702])\n",
      "Grad:   tensor([-0.0006,  0.0033])\n",
      "Epoch 3808, Loss 8.700545\n",
      "Params: tensor([  4.5172, -12.1703])\n",
      "Grad:   tensor([-0.0006,  0.0033])\n",
      "Epoch 3809, Loss 8.700546\n",
      "Params: tensor([  4.5172, -12.1703])\n",
      "Grad:   tensor([-0.0006,  0.0033])\n",
      "Epoch 3810, Loss 8.700545\n",
      "Params: tensor([  4.5172, -12.1703])\n",
      "Grad:   tensor([-0.0006,  0.0033])\n",
      "Epoch 3811, Loss 8.700545\n",
      "Params: tensor([  4.5172, -12.1704])\n",
      "Grad:   tensor([-0.0006,  0.0032])\n",
      "Epoch 3812, Loss 8.700545\n",
      "Params: tensor([  4.5172, -12.1704])\n",
      "Grad:   tensor([-0.0006,  0.0032])\n",
      "Epoch 3813, Loss 8.700545\n",
      "Params: tensor([  4.5172, -12.1704])\n",
      "Grad:   tensor([-0.0006,  0.0032])\n",
      "Epoch 3814, Loss 8.700543\n",
      "Params: tensor([  4.5173, -12.1705])\n",
      "Grad:   tensor([-0.0006,  0.0032])\n",
      "Epoch 3815, Loss 8.700545\n",
      "Params: tensor([  4.5173, -12.1705])\n",
      "Grad:   tensor([-0.0006,  0.0032])\n",
      "Epoch 3816, Loss 8.700545\n",
      "Params: tensor([  4.5173, -12.1705])\n",
      "Grad:   tensor([-0.0006,  0.0032])\n",
      "Epoch 3817, Loss 8.700543\n",
      "Params: tensor([  4.5173, -12.1706])\n",
      "Grad:   tensor([-0.0006,  0.0032])\n",
      "Epoch 3818, Loss 8.700545\n",
      "Params: tensor([  4.5173, -12.1706])\n",
      "Grad:   tensor([-0.0006,  0.0032])\n",
      "Epoch 3819, Loss 8.700545\n",
      "Params: tensor([  4.5173, -12.1706])\n",
      "Grad:   tensor([-0.0006,  0.0032])\n",
      "Epoch 3820, Loss 8.700545\n",
      "Params: tensor([  4.5173, -12.1707])\n",
      "Grad:   tensor([-0.0006,  0.0032])\n",
      "Epoch 3821, Loss 8.700542\n",
      "Params: tensor([  4.5173, -12.1707])\n",
      "Grad:   tensor([-0.0006,  0.0032])\n",
      "Epoch 3822, Loss 8.700544\n",
      "Params: tensor([  4.5173, -12.1707])\n",
      "Grad:   tensor([-0.0006,  0.0032])\n",
      "Epoch 3823, Loss 8.700543\n",
      "Params: tensor([  4.5173, -12.1708])\n",
      "Grad:   tensor([-0.0005,  0.0032])\n",
      "Epoch 3824, Loss 8.700545\n",
      "Params: tensor([  4.5173, -12.1708])\n",
      "Grad:   tensor([-0.0006,  0.0032])\n",
      "Epoch 3825, Loss 8.700542\n",
      "Params: tensor([  4.5173, -12.1708])\n",
      "Grad:   tensor([-0.0005,  0.0032])\n",
      "Epoch 3826, Loss 8.700542\n",
      "Params: tensor([  4.5173, -12.1709])\n",
      "Grad:   tensor([-0.0006,  0.0032])\n",
      "Epoch 3827, Loss 8.700543\n",
      "Params: tensor([  4.5173, -12.1709])\n",
      "Grad:   tensor([-0.0006,  0.0032])\n",
      "Epoch 3828, Loss 8.700543\n",
      "Params: tensor([  4.5173, -12.1709])\n",
      "Grad:   tensor([-0.0005,  0.0032])\n",
      "Epoch 3829, Loss 8.700542\n",
      "Params: tensor([  4.5173, -12.1710])\n",
      "Grad:   tensor([-0.0006,  0.0031])\n",
      "Epoch 3830, Loss 8.700543\n",
      "Params: tensor([  4.5173, -12.1710])\n",
      "Grad:   tensor([-0.0006,  0.0031])\n",
      "Epoch 3831, Loss 8.700545\n",
      "Params: tensor([  4.5173, -12.1710])\n",
      "Grad:   tensor([-0.0005,  0.0031])\n",
      "Epoch 3832, Loss 8.700541\n",
      "Params: tensor([  4.5174, -12.1710])\n",
      "Grad:   tensor([-0.0006,  0.0031])\n",
      "Epoch 3833, Loss 8.700543\n",
      "Params: tensor([  4.5174, -12.1711])\n",
      "Grad:   tensor([-0.0006,  0.0031])\n",
      "Epoch 3834, Loss 8.700542\n",
      "Params: tensor([  4.5174, -12.1711])\n",
      "Grad:   tensor([-0.0005,  0.0031])\n",
      "Epoch 3835, Loss 8.700541\n",
      "Params: tensor([  4.5174, -12.1711])\n",
      "Grad:   tensor([-0.0005,  0.0031])\n",
      "Epoch 3836, Loss 8.700542\n",
      "Params: tensor([  4.5174, -12.1712])\n",
      "Grad:   tensor([-0.0006,  0.0031])\n",
      "Epoch 3837, Loss 8.700542\n",
      "Params: tensor([  4.5174, -12.1712])\n",
      "Grad:   tensor([-0.0006,  0.0031])\n",
      "Epoch 3838, Loss 8.700543\n",
      "Params: tensor([  4.5174, -12.1712])\n",
      "Grad:   tensor([-0.0006,  0.0031])\n",
      "Epoch 3839, Loss 8.700542\n",
      "Params: tensor([  4.5174, -12.1713])\n",
      "Grad:   tensor([-0.0005,  0.0031])\n",
      "Epoch 3840, Loss 8.700543\n",
      "Params: tensor([  4.5174, -12.1713])\n",
      "Grad:   tensor([-0.0005,  0.0031])\n",
      "Epoch 3841, Loss 8.700542\n",
      "Params: tensor([  4.5174, -12.1713])\n",
      "Grad:   tensor([-0.0005,  0.0031])\n",
      "Epoch 3842, Loss 8.700543\n",
      "Params: tensor([  4.5174, -12.1714])\n",
      "Grad:   tensor([-0.0006,  0.0031])\n",
      "Epoch 3843, Loss 8.700542\n",
      "Params: tensor([  4.5174, -12.1714])\n",
      "Grad:   tensor([-0.0005,  0.0031])\n",
      "Epoch 3844, Loss 8.700542\n",
      "Params: tensor([  4.5174, -12.1714])\n",
      "Grad:   tensor([-0.0005,  0.0031])\n",
      "Epoch 3845, Loss 8.700542\n",
      "Params: tensor([  4.5174, -12.1714])\n",
      "Grad:   tensor([-0.0006,  0.0031])\n",
      "Epoch 3846, Loss 8.700541\n",
      "Params: tensor([  4.5174, -12.1715])\n",
      "Grad:   tensor([-0.0005,  0.0031])\n",
      "Epoch 3847, Loss 8.700540\n",
      "Params: tensor([  4.5174, -12.1715])\n",
      "Grad:   tensor([-0.0005,  0.0031])\n",
      "Epoch 3848, Loss 8.700542\n",
      "Params: tensor([  4.5174, -12.1715])\n",
      "Grad:   tensor([-0.0005,  0.0030])\n",
      "Epoch 3849, Loss 8.700542\n",
      "Params: tensor([  4.5174, -12.1716])\n",
      "Grad:   tensor([-0.0006,  0.0030])\n",
      "Epoch 3850, Loss 8.700540\n",
      "Params: tensor([  4.5174, -12.1716])\n",
      "Grad:   tensor([-0.0005,  0.0030])\n",
      "Epoch 3851, Loss 8.700541\n",
      "Params: tensor([  4.5175, -12.1716])\n",
      "Grad:   tensor([-0.0005,  0.0030])\n",
      "Epoch 3852, Loss 8.700541\n",
      "Params: tensor([  4.5175, -12.1717])\n",
      "Grad:   tensor([-0.0005,  0.0030])\n",
      "Epoch 3853, Loss 8.700543\n",
      "Params: tensor([  4.5175, -12.1717])\n",
      "Grad:   tensor([-0.0005,  0.0030])\n",
      "Epoch 3854, Loss 8.700541\n",
      "Params: tensor([  4.5175, -12.1717])\n",
      "Grad:   tensor([-0.0005,  0.0030])\n",
      "Epoch 3855, Loss 8.700540\n",
      "Params: tensor([  4.5175, -12.1718])\n",
      "Grad:   tensor([-0.0005,  0.0030])\n",
      "Epoch 3856, Loss 8.700541\n",
      "Params: tensor([  4.5175, -12.1718])\n",
      "Grad:   tensor([-0.0005,  0.0030])\n",
      "Epoch 3857, Loss 8.700542\n",
      "Params: tensor([  4.5175, -12.1718])\n",
      "Grad:   tensor([-0.0005,  0.0030])\n",
      "Epoch 3858, Loss 8.700540\n",
      "Params: tensor([  4.5175, -12.1718])\n",
      "Grad:   tensor([-0.0005,  0.0030])\n",
      "Epoch 3859, Loss 8.700541\n",
      "Params: tensor([  4.5175, -12.1719])\n",
      "Grad:   tensor([-0.0005,  0.0030])\n",
      "Epoch 3860, Loss 8.700541\n",
      "Params: tensor([  4.5175, -12.1719])\n",
      "Grad:   tensor([-0.0005,  0.0030])\n",
      "Epoch 3861, Loss 8.700540\n",
      "Params: tensor([  4.5175, -12.1719])\n",
      "Grad:   tensor([-0.0005,  0.0030])\n",
      "Epoch 3862, Loss 8.700541\n",
      "Params: tensor([  4.5175, -12.1720])\n",
      "Grad:   tensor([-0.0005,  0.0030])\n",
      "Epoch 3863, Loss 8.700540\n",
      "Params: tensor([  4.5175, -12.1720])\n",
      "Grad:   tensor([-0.0005,  0.0030])\n",
      "Epoch 3864, Loss 8.700541\n",
      "Params: tensor([  4.5175, -12.1720])\n",
      "Grad:   tensor([-0.0005,  0.0030])\n",
      "Epoch 3865, Loss 8.700541\n",
      "Params: tensor([  4.5175, -12.1720])\n",
      "Grad:   tensor([-0.0005,  0.0030])\n",
      "Epoch 3866, Loss 8.700539\n",
      "Params: tensor([  4.5175, -12.1721])\n",
      "Grad:   tensor([-0.0005,  0.0030])\n",
      "Epoch 3867, Loss 8.700541\n",
      "Params: tensor([  4.5175, -12.1721])\n",
      "Grad:   tensor([-0.0005,  0.0029])\n",
      "Epoch 3868, Loss 8.700540\n",
      "Params: tensor([  4.5175, -12.1721])\n",
      "Grad:   tensor([-0.0005,  0.0029])\n",
      "Epoch 3869, Loss 8.700540\n",
      "Params: tensor([  4.5175, -12.1722])\n",
      "Grad:   tensor([-0.0005,  0.0029])\n",
      "Epoch 3870, Loss 8.700540\n",
      "Params: tensor([  4.5176, -12.1722])\n",
      "Grad:   tensor([-0.0005,  0.0029])\n",
      "Epoch 3871, Loss 8.700541\n",
      "Params: tensor([  4.5176, -12.1722])\n",
      "Grad:   tensor([-0.0005,  0.0029])\n",
      "Epoch 3872, Loss 8.700540\n",
      "Params: tensor([  4.5176, -12.1723])\n",
      "Grad:   tensor([-0.0005,  0.0029])\n",
      "Epoch 3873, Loss 8.700541\n",
      "Params: tensor([  4.5176, -12.1723])\n",
      "Grad:   tensor([-0.0005,  0.0029])\n",
      "Epoch 3874, Loss 8.700539\n",
      "Params: tensor([  4.5176, -12.1723])\n",
      "Grad:   tensor([-0.0005,  0.0029])\n",
      "Epoch 3875, Loss 8.700539\n",
      "Params: tensor([  4.5176, -12.1723])\n",
      "Grad:   tensor([-0.0005,  0.0029])\n",
      "Epoch 3876, Loss 8.700541\n",
      "Params: tensor([  4.5176, -12.1724])\n",
      "Grad:   tensor([-0.0005,  0.0029])\n",
      "Epoch 3877, Loss 8.700538\n",
      "Params: tensor([  4.5176, -12.1724])\n",
      "Grad:   tensor([-0.0005,  0.0029])\n",
      "Epoch 3878, Loss 8.700538\n",
      "Params: tensor([  4.5176, -12.1724])\n",
      "Grad:   tensor([-0.0005,  0.0029])\n",
      "Epoch 3879, Loss 8.700538\n",
      "Params: tensor([  4.5176, -12.1725])\n",
      "Grad:   tensor([-0.0005,  0.0029])\n",
      "Epoch 3880, Loss 8.700539\n",
      "Params: tensor([  4.5176, -12.1725])\n",
      "Grad:   tensor([-0.0005,  0.0029])\n",
      "Epoch 3881, Loss 8.700540\n",
      "Params: tensor([  4.5176, -12.1725])\n",
      "Grad:   tensor([-0.0005,  0.0029])\n",
      "Epoch 3882, Loss 8.700540\n",
      "Params: tensor([  4.5176, -12.1725])\n",
      "Grad:   tensor([-0.0005,  0.0029])\n",
      "Epoch 3883, Loss 8.700538\n",
      "Params: tensor([  4.5176, -12.1726])\n",
      "Grad:   tensor([-0.0005,  0.0029])\n",
      "Epoch 3884, Loss 8.700540\n",
      "Params: tensor([  4.5176, -12.1726])\n",
      "Grad:   tensor([-0.0005,  0.0029])\n",
      "Epoch 3885, Loss 8.700538\n",
      "Params: tensor([  4.5176, -12.1726])\n",
      "Grad:   tensor([-0.0005,  0.0029])\n",
      "Epoch 3886, Loss 8.700538\n",
      "Params: tensor([  4.5176, -12.1727])\n",
      "Grad:   tensor([-0.0005,  0.0029])\n",
      "Epoch 3887, Loss 8.700539\n",
      "Params: tensor([  4.5176, -12.1727])\n",
      "Grad:   tensor([-0.0005,  0.0029])\n",
      "Epoch 3888, Loss 8.700538\n",
      "Params: tensor([  4.5176, -12.1727])\n",
      "Grad:   tensor([-0.0005,  0.0028])\n",
      "Epoch 3889, Loss 8.700538\n",
      "Params: tensor([  4.5177, -12.1727])\n",
      "Grad:   tensor([-0.0005,  0.0028])\n",
      "Epoch 3890, Loss 8.700540\n",
      "Params: tensor([  4.5177, -12.1728])\n",
      "Grad:   tensor([-0.0005,  0.0028])\n",
      "Epoch 3891, Loss 8.700538\n",
      "Params: tensor([  4.5177, -12.1728])\n",
      "Grad:   tensor([-0.0005,  0.0028])\n",
      "Epoch 3892, Loss 8.700538\n",
      "Params: tensor([  4.5177, -12.1728])\n",
      "Grad:   tensor([-0.0005,  0.0028])\n",
      "Epoch 3893, Loss 8.700538\n",
      "Params: tensor([  4.5177, -12.1729])\n",
      "Grad:   tensor([-0.0005,  0.0028])\n",
      "Epoch 3894, Loss 8.700538\n",
      "Params: tensor([  4.5177, -12.1729])\n",
      "Grad:   tensor([-0.0005,  0.0028])\n",
      "Epoch 3895, Loss 8.700539\n",
      "Params: tensor([  4.5177, -12.1729])\n",
      "Grad:   tensor([-0.0005,  0.0028])\n",
      "Epoch 3896, Loss 8.700539\n",
      "Params: tensor([  4.5177, -12.1729])\n",
      "Grad:   tensor([-0.0005,  0.0028])\n",
      "Epoch 3897, Loss 8.700537\n",
      "Params: tensor([  4.5177, -12.1730])\n",
      "Grad:   tensor([-0.0005,  0.0028])\n",
      "Epoch 3898, Loss 8.700537\n",
      "Params: tensor([  4.5177, -12.1730])\n",
      "Grad:   tensor([-0.0005,  0.0028])\n",
      "Epoch 3899, Loss 8.700539\n",
      "Params: tensor([  4.5177, -12.1730])\n",
      "Grad:   tensor([-0.0005,  0.0028])\n",
      "Epoch 3900, Loss 8.700539\n",
      "Params: tensor([  4.5177, -12.1731])\n",
      "Grad:   tensor([-0.0005,  0.0028])\n",
      "Epoch 3901, Loss 8.700536\n",
      "Params: tensor([  4.5177, -12.1731])\n",
      "Grad:   tensor([-0.0005,  0.0028])\n",
      "Epoch 3902, Loss 8.700535\n",
      "Params: tensor([  4.5177, -12.1731])\n",
      "Grad:   tensor([-0.0005,  0.0028])\n",
      "Epoch 3903, Loss 8.700537\n",
      "Params: tensor([  4.5177, -12.1731])\n",
      "Grad:   tensor([-0.0005,  0.0028])\n",
      "Epoch 3904, Loss 8.700538\n",
      "Params: tensor([  4.5177, -12.1732])\n",
      "Grad:   tensor([-0.0005,  0.0028])\n",
      "Epoch 3905, Loss 8.700535\n",
      "Params: tensor([  4.5177, -12.1732])\n",
      "Grad:   tensor([-0.0005,  0.0028])\n",
      "Epoch 3906, Loss 8.700536\n",
      "Params: tensor([  4.5177, -12.1732])\n",
      "Grad:   tensor([-0.0005,  0.0028])\n",
      "Epoch 3907, Loss 8.700538\n",
      "Params: tensor([  4.5177, -12.1732])\n",
      "Grad:   tensor([-0.0005,  0.0028])\n",
      "Epoch 3908, Loss 8.700538\n",
      "Params: tensor([  4.5177, -12.1733])\n",
      "Grad:   tensor([-0.0005,  0.0028])\n",
      "Epoch 3909, Loss 8.700535\n",
      "Params: tensor([  4.5177, -12.1733])\n",
      "Grad:   tensor([-0.0005,  0.0027])\n",
      "Epoch 3910, Loss 8.700535\n",
      "Params: tensor([  4.5178, -12.1733])\n",
      "Grad:   tensor([-0.0005,  0.0027])\n",
      "Epoch 3911, Loss 8.700535\n",
      "Params: tensor([  4.5178, -12.1734])\n",
      "Grad:   tensor([-0.0005,  0.0027])\n",
      "Epoch 3912, Loss 8.700537\n",
      "Params: tensor([  4.5178, -12.1734])\n",
      "Grad:   tensor([-0.0005,  0.0027])\n",
      "Epoch 3913, Loss 8.700535\n",
      "Params: tensor([  4.5178, -12.1734])\n",
      "Grad:   tensor([-0.0005,  0.0027])\n",
      "Epoch 3914, Loss 8.700535\n",
      "Params: tensor([  4.5178, -12.1734])\n",
      "Grad:   tensor([-0.0005,  0.0027])\n",
      "Epoch 3915, Loss 8.700535\n",
      "Params: tensor([  4.5178, -12.1735])\n",
      "Grad:   tensor([-0.0005,  0.0027])\n",
      "Epoch 3916, Loss 8.700537\n",
      "Params: tensor([  4.5178, -12.1735])\n",
      "Grad:   tensor([-0.0005,  0.0027])\n",
      "Epoch 3917, Loss 8.700535\n",
      "Params: tensor([  4.5178, -12.1735])\n",
      "Grad:   tensor([-0.0005,  0.0027])\n",
      "Epoch 3918, Loss 8.700537\n",
      "Params: tensor([  4.5178, -12.1735])\n",
      "Grad:   tensor([-0.0005,  0.0027])\n",
      "Epoch 3919, Loss 8.700537\n",
      "Params: tensor([  4.5178, -12.1736])\n",
      "Grad:   tensor([-0.0005,  0.0027])\n",
      "Epoch 3920, Loss 8.700537\n",
      "Params: tensor([  4.5178, -12.1736])\n",
      "Grad:   tensor([-0.0005,  0.0027])\n",
      "Epoch 3921, Loss 8.700538\n",
      "Params: tensor([  4.5178, -12.1736])\n",
      "Grad:   tensor([-0.0005,  0.0027])\n",
      "Epoch 3922, Loss 8.700535\n",
      "Params: tensor([  4.5178, -12.1737])\n",
      "Grad:   tensor([-0.0005,  0.0027])\n",
      "Epoch 3923, Loss 8.700535\n",
      "Params: tensor([  4.5178, -12.1737])\n",
      "Grad:   tensor([-0.0005,  0.0027])\n",
      "Epoch 3924, Loss 8.700535\n",
      "Params: tensor([  4.5178, -12.1737])\n",
      "Grad:   tensor([-0.0005,  0.0027])\n",
      "Epoch 3925, Loss 8.700535\n",
      "Params: tensor([  4.5178, -12.1737])\n",
      "Grad:   tensor([-0.0005,  0.0027])\n",
      "Epoch 3926, Loss 8.700532\n",
      "Params: tensor([  4.5178, -12.1738])\n",
      "Grad:   tensor([-0.0005,  0.0027])\n",
      "Epoch 3927, Loss 8.700535\n",
      "Params: tensor([  4.5178, -12.1738])\n",
      "Grad:   tensor([-0.0005,  0.0027])\n",
      "Epoch 3928, Loss 8.700535\n",
      "Params: tensor([  4.5178, -12.1738])\n",
      "Grad:   tensor([-0.0005,  0.0027])\n",
      "Epoch 3929, Loss 8.700535\n",
      "Params: tensor([  4.5178, -12.1738])\n",
      "Grad:   tensor([-0.0005,  0.0027])\n",
      "Epoch 3930, Loss 8.700532\n",
      "Params: tensor([  4.5178, -12.1739])\n",
      "Grad:   tensor([-0.0004,  0.0027])\n",
      "Epoch 3931, Loss 8.700532\n",
      "Params: tensor([  4.5179, -12.1739])\n",
      "Grad:   tensor([-0.0005,  0.0026])\n",
      "Epoch 3932, Loss 8.700534\n",
      "Params: tensor([  4.5179, -12.1739])\n",
      "Grad:   tensor([-0.0005,  0.0026])\n",
      "Epoch 3933, Loss 8.700535\n",
      "Params: tensor([  4.5179, -12.1739])\n",
      "Grad:   tensor([-0.0005,  0.0026])\n",
      "Epoch 3934, Loss 8.700534\n",
      "Params: tensor([  4.5179, -12.1740])\n",
      "Grad:   tensor([-0.0005,  0.0026])\n",
      "Epoch 3935, Loss 8.700532\n",
      "Params: tensor([  4.5179, -12.1740])\n",
      "Grad:   tensor([-0.0005,  0.0026])\n",
      "Epoch 3936, Loss 8.700534\n",
      "Params: tensor([  4.5179, -12.1740])\n",
      "Grad:   tensor([-0.0005,  0.0026])\n",
      "Epoch 3937, Loss 8.700536\n",
      "Params: tensor([  4.5179, -12.1741])\n",
      "Grad:   tensor([-0.0004,  0.0026])\n",
      "Epoch 3938, Loss 8.700537\n",
      "Params: tensor([  4.5179, -12.1741])\n",
      "Grad:   tensor([-0.0005,  0.0026])\n",
      "Epoch 3939, Loss 8.700533\n",
      "Params: tensor([  4.5179, -12.1741])\n",
      "Grad:   tensor([-0.0005,  0.0026])\n",
      "Epoch 3940, Loss 8.700535\n",
      "Params: tensor([  4.5179, -12.1741])\n",
      "Grad:   tensor([-0.0005,  0.0026])\n",
      "Epoch 3941, Loss 8.700534\n",
      "Params: tensor([  4.5179, -12.1742])\n",
      "Grad:   tensor([-0.0005,  0.0026])\n",
      "Epoch 3942, Loss 8.700532\n",
      "Params: tensor([  4.5179, -12.1742])\n",
      "Grad:   tensor([-0.0004,  0.0026])\n",
      "Epoch 3943, Loss 8.700532\n",
      "Params: tensor([  4.5179, -12.1742])\n",
      "Grad:   tensor([-0.0005,  0.0026])\n",
      "Epoch 3944, Loss 8.700532\n",
      "Params: tensor([  4.5179, -12.1742])\n",
      "Grad:   tensor([-0.0005,  0.0026])\n",
      "Epoch 3945, Loss 8.700535\n",
      "Params: tensor([  4.5179, -12.1743])\n",
      "Grad:   tensor([-0.0005,  0.0026])\n",
      "Epoch 3946, Loss 8.700535\n",
      "Params: tensor([  4.5179, -12.1743])\n",
      "Grad:   tensor([-0.0004,  0.0026])\n",
      "Epoch 3947, Loss 8.700534\n",
      "Params: tensor([  4.5179, -12.1743])\n",
      "Grad:   tensor([-0.0005,  0.0026])\n",
      "Epoch 3948, Loss 8.700532\n",
      "Params: tensor([  4.5179, -12.1743])\n",
      "Grad:   tensor([-0.0004,  0.0026])\n",
      "Epoch 3949, Loss 8.700532\n",
      "Params: tensor([  4.5179, -12.1744])\n",
      "Grad:   tensor([-0.0005,  0.0026])\n",
      "Epoch 3950, Loss 8.700532\n",
      "Params: tensor([  4.5179, -12.1744])\n",
      "Grad:   tensor([-0.0004,  0.0026])\n",
      "Epoch 3951, Loss 8.700535\n",
      "Params: tensor([  4.5179, -12.1744])\n",
      "Grad:   tensor([-0.0005,  0.0026])\n",
      "Epoch 3952, Loss 8.700534\n",
      "Params: tensor([  4.5180, -12.1744])\n",
      "Grad:   tensor([-0.0004,  0.0026])\n",
      "Epoch 3953, Loss 8.700531\n",
      "Params: tensor([  4.5180, -12.1745])\n",
      "Grad:   tensor([-0.0005,  0.0025])\n",
      "Epoch 3954, Loss 8.700533\n",
      "Params: tensor([  4.5180, -12.1745])\n",
      "Grad:   tensor([-0.0004,  0.0025])\n",
      "Epoch 3955, Loss 8.700534\n",
      "Params: tensor([  4.5180, -12.1745])\n",
      "Grad:   tensor([-0.0005,  0.0025])\n",
      "Epoch 3956, Loss 8.700531\n",
      "Params: tensor([  4.5180, -12.1745])\n",
      "Grad:   tensor([-0.0004,  0.0025])\n",
      "Epoch 3957, Loss 8.700533\n",
      "Params: tensor([  4.5180, -12.1746])\n",
      "Grad:   tensor([-0.0005,  0.0025])\n",
      "Epoch 3958, Loss 8.700532\n",
      "Params: tensor([  4.5180, -12.1746])\n",
      "Grad:   tensor([-0.0004,  0.0025])\n",
      "Epoch 3959, Loss 8.700534\n",
      "Params: tensor([  4.5180, -12.1746])\n",
      "Grad:   tensor([-0.0005,  0.0025])\n",
      "Epoch 3960, Loss 8.700534\n",
      "Params: tensor([  4.5180, -12.1746])\n",
      "Grad:   tensor([-0.0004,  0.0025])\n",
      "Epoch 3961, Loss 8.700531\n",
      "Params: tensor([  4.5180, -12.1747])\n",
      "Grad:   tensor([-0.0004,  0.0025])\n",
      "Epoch 3962, Loss 8.700532\n",
      "Params: tensor([  4.5180, -12.1747])\n",
      "Grad:   tensor([-0.0004,  0.0025])\n",
      "Epoch 3963, Loss 8.700532\n",
      "Params: tensor([  4.5180, -12.1747])\n",
      "Grad:   tensor([-0.0005,  0.0025])\n",
      "Epoch 3964, Loss 8.700532\n",
      "Params: tensor([  4.5180, -12.1747])\n",
      "Grad:   tensor([-0.0005,  0.0025])\n",
      "Epoch 3965, Loss 8.700532\n",
      "Params: tensor([  4.5180, -12.1748])\n",
      "Grad:   tensor([-0.0004,  0.0025])\n",
      "Epoch 3966, Loss 8.700532\n",
      "Params: tensor([  4.5180, -12.1748])\n",
      "Grad:   tensor([-0.0004,  0.0025])\n",
      "Epoch 3967, Loss 8.700531\n",
      "Params: tensor([  4.5180, -12.1748])\n",
      "Grad:   tensor([-0.0004,  0.0025])\n",
      "Epoch 3968, Loss 8.700532\n",
      "Params: tensor([  4.5180, -12.1748])\n",
      "Grad:   tensor([-0.0004,  0.0025])\n",
      "Epoch 3969, Loss 8.700533\n",
      "Params: tensor([  4.5180, -12.1749])\n",
      "Grad:   tensor([-0.0005,  0.0025])\n",
      "Epoch 3970, Loss 8.700531\n",
      "Params: tensor([  4.5180, -12.1749])\n",
      "Grad:   tensor([-0.0004,  0.0025])\n",
      "Epoch 3971, Loss 8.700533\n",
      "Params: tensor([  4.5180, -12.1749])\n",
      "Grad:   tensor([-0.0005,  0.0025])\n",
      "Epoch 3972, Loss 8.700532\n",
      "Params: tensor([  4.5180, -12.1749])\n",
      "Grad:   tensor([-0.0004,  0.0025])\n",
      "Epoch 3973, Loss 8.700532\n",
      "Params: tensor([  4.5180, -12.1750])\n",
      "Grad:   tensor([-0.0004,  0.0025])\n",
      "Epoch 3974, Loss 8.700533\n",
      "Params: tensor([  4.5180, -12.1750])\n",
      "Grad:   tensor([-0.0004,  0.0025])\n",
      "Epoch 3975, Loss 8.700532\n",
      "Params: tensor([  4.5181, -12.1750])\n",
      "Grad:   tensor([-0.0004,  0.0025])\n",
      "Epoch 3976, Loss 8.700530\n",
      "Params: tensor([  4.5181, -12.1750])\n",
      "Grad:   tensor([-0.0005,  0.0024])\n",
      "Epoch 3977, Loss 8.700531\n",
      "Params: tensor([  4.5181, -12.1751])\n",
      "Grad:   tensor([-0.0005,  0.0024])\n",
      "Epoch 3978, Loss 8.700532\n",
      "Params: tensor([  4.5181, -12.1751])\n",
      "Grad:   tensor([-0.0004,  0.0024])\n",
      "Epoch 3979, Loss 8.700530\n",
      "Params: tensor([  4.5181, -12.1751])\n",
      "Grad:   tensor([-0.0004,  0.0024])\n",
      "Epoch 3980, Loss 8.700530\n",
      "Params: tensor([  4.5181, -12.1751])\n",
      "Grad:   tensor([-0.0004,  0.0024])\n",
      "Epoch 3981, Loss 8.700530\n",
      "Params: tensor([  4.5181, -12.1752])\n",
      "Grad:   tensor([-0.0004,  0.0024])\n",
      "Epoch 3982, Loss 8.700530\n",
      "Params: tensor([  4.5181, -12.1752])\n",
      "Grad:   tensor([-0.0004,  0.0024])\n",
      "Epoch 3983, Loss 8.700532\n",
      "Params: tensor([  4.5181, -12.1752])\n",
      "Grad:   tensor([-0.0004,  0.0024])\n",
      "Epoch 3984, Loss 8.700530\n",
      "Params: tensor([  4.5181, -12.1752])\n",
      "Grad:   tensor([-0.0004,  0.0024])\n",
      "Epoch 3985, Loss 8.700531\n",
      "Params: tensor([  4.5181, -12.1753])\n",
      "Grad:   tensor([-0.0004,  0.0024])\n",
      "Epoch 3986, Loss 8.700531\n",
      "Params: tensor([  4.5181, -12.1753])\n",
      "Grad:   tensor([-0.0004,  0.0024])\n",
      "Epoch 3987, Loss 8.700532\n",
      "Params: tensor([  4.5181, -12.1753])\n",
      "Grad:   tensor([-0.0004,  0.0024])\n",
      "Epoch 3988, Loss 8.700534\n",
      "Params: tensor([  4.5181, -12.1753])\n",
      "Grad:   tensor([-0.0004,  0.0024])\n",
      "Epoch 3989, Loss 8.700530\n",
      "Params: tensor([  4.5181, -12.1754])\n",
      "Grad:   tensor([-0.0004,  0.0024])\n",
      "Epoch 3990, Loss 8.700530\n",
      "Params: tensor([  4.5181, -12.1754])\n",
      "Grad:   tensor([-0.0004,  0.0024])\n",
      "Epoch 3991, Loss 8.700531\n",
      "Params: tensor([  4.5181, -12.1754])\n",
      "Grad:   tensor([-0.0004,  0.0024])\n",
      "Epoch 3992, Loss 8.700533\n",
      "Params: tensor([  4.5181, -12.1754])\n",
      "Grad:   tensor([-0.0004,  0.0024])\n",
      "Epoch 3993, Loss 8.700530\n",
      "Params: tensor([  4.5181, -12.1755])\n",
      "Grad:   tensor([-0.0004,  0.0024])\n",
      "Epoch 3994, Loss 8.700529\n",
      "Params: tensor([  4.5181, -12.1755])\n",
      "Grad:   tensor([-0.0004,  0.0024])\n",
      "Epoch 3995, Loss 8.700531\n",
      "Params: tensor([  4.5181, -12.1755])\n",
      "Grad:   tensor([-0.0004,  0.0024])\n",
      "Epoch 3996, Loss 8.700532\n",
      "Params: tensor([  4.5181, -12.1755])\n",
      "Grad:   tensor([-0.0004,  0.0024])\n",
      "Epoch 3997, Loss 8.700531\n",
      "Params: tensor([  4.5181, -12.1755])\n",
      "Grad:   tensor([-0.0004,  0.0024])\n",
      "Epoch 3998, Loss 8.700530\n",
      "Params: tensor([  4.5182, -12.1756])\n",
      "Grad:   tensor([-0.0004,  0.0024])\n",
      "Epoch 3999, Loss 8.700530\n",
      "Params: tensor([  4.5182, -12.1756])\n",
      "Grad:   tensor([-0.0004,  0.0024])\n",
      "Epoch 4000, Loss 8.700530\n",
      "Params: tensor([  4.5182, -12.1756])\n",
      "Grad:   tensor([-0.0004,  0.0024])\n",
      "Epoch 4001, Loss 8.700530\n",
      "Params: tensor([  4.5182, -12.1756])\n",
      "Grad:   tensor([-0.0004,  0.0023])\n",
      "Epoch 4002, Loss 8.700530\n",
      "Params: tensor([  4.5182, -12.1757])\n",
      "Grad:   tensor([-0.0004,  0.0023])\n",
      "Epoch 4003, Loss 8.700528\n",
      "Params: tensor([  4.5182, -12.1757])\n",
      "Grad:   tensor([-0.0004,  0.0023])\n",
      "Epoch 4004, Loss 8.700529\n",
      "Params: tensor([  4.5182, -12.1757])\n",
      "Grad:   tensor([-0.0004,  0.0023])\n",
      "Epoch 4005, Loss 8.700530\n",
      "Params: tensor([  4.5182, -12.1757])\n",
      "Grad:   tensor([-0.0004,  0.0023])\n",
      "Epoch 4006, Loss 8.700530\n",
      "Params: tensor([  4.5182, -12.1758])\n",
      "Grad:   tensor([-0.0004,  0.0023])\n",
      "Epoch 4007, Loss 8.700530\n",
      "Params: tensor([  4.5182, -12.1758])\n",
      "Grad:   tensor([-0.0004,  0.0023])\n",
      "Epoch 4008, Loss 8.700528\n",
      "Params: tensor([  4.5182, -12.1758])\n",
      "Grad:   tensor([-0.0004,  0.0023])\n",
      "Epoch 4009, Loss 8.700529\n",
      "Params: tensor([  4.5182, -12.1758])\n",
      "Grad:   tensor([-0.0004,  0.0023])\n",
      "Epoch 4010, Loss 8.700530\n",
      "Params: tensor([  4.5182, -12.1758])\n",
      "Grad:   tensor([-0.0004,  0.0023])\n",
      "Epoch 4011, Loss 8.700530\n",
      "Params: tensor([  4.5182, -12.1759])\n",
      "Grad:   tensor([-0.0004,  0.0023])\n",
      "Epoch 4012, Loss 8.700530\n",
      "Params: tensor([  4.5182, -12.1759])\n",
      "Grad:   tensor([-0.0004,  0.0023])\n",
      "Epoch 4013, Loss 8.700528\n",
      "Params: tensor([  4.5182, -12.1759])\n",
      "Grad:   tensor([-0.0004,  0.0023])\n",
      "Epoch 4014, Loss 8.700530\n",
      "Params: tensor([  4.5182, -12.1759])\n",
      "Grad:   tensor([-0.0004,  0.0023])\n",
      "Epoch 4015, Loss 8.700529\n",
      "Params: tensor([  4.5182, -12.1760])\n",
      "Grad:   tensor([-0.0004,  0.0023])\n",
      "Epoch 4016, Loss 8.700528\n",
      "Params: tensor([  4.5182, -12.1760])\n",
      "Grad:   tensor([-0.0004,  0.0023])\n",
      "Epoch 4017, Loss 8.700531\n",
      "Params: tensor([  4.5182, -12.1760])\n",
      "Grad:   tensor([-0.0004,  0.0023])\n",
      "Epoch 4018, Loss 8.700529\n",
      "Params: tensor([  4.5182, -12.1760])\n",
      "Grad:   tensor([-0.0004,  0.0023])\n",
      "Epoch 4019, Loss 8.700530\n",
      "Params: tensor([  4.5182, -12.1761])\n",
      "Grad:   tensor([-0.0004,  0.0023])\n",
      "Epoch 4020, Loss 8.700529\n",
      "Params: tensor([  4.5182, -12.1761])\n",
      "Grad:   tensor([-0.0004,  0.0023])\n",
      "Epoch 4021, Loss 8.700529\n",
      "Params: tensor([  4.5182, -12.1761])\n",
      "Grad:   tensor([-0.0004,  0.0023])\n",
      "Epoch 4022, Loss 8.700531\n",
      "Params: tensor([  4.5182, -12.1761])\n",
      "Grad:   tensor([-0.0004,  0.0023])\n",
      "Epoch 4023, Loss 8.700528\n",
      "Params: tensor([  4.5183, -12.1761])\n",
      "Grad:   tensor([-0.0004,  0.0023])\n",
      "Epoch 4024, Loss 8.700528\n",
      "Params: tensor([  4.5183, -12.1762])\n",
      "Grad:   tensor([-0.0004,  0.0023])\n",
      "Epoch 4025, Loss 8.700527\n",
      "Params: tensor([  4.5183, -12.1762])\n",
      "Grad:   tensor([-0.0004,  0.0023])\n",
      "Epoch 4026, Loss 8.700530\n",
      "Params: tensor([  4.5183, -12.1762])\n",
      "Grad:   tensor([-0.0004,  0.0022])\n",
      "Epoch 4027, Loss 8.700530\n",
      "Params: tensor([  4.5183, -12.1762])\n",
      "Grad:   tensor([-0.0004,  0.0022])\n",
      "Epoch 4028, Loss 8.700529\n",
      "Params: tensor([  4.5183, -12.1763])\n",
      "Grad:   tensor([-0.0004,  0.0022])\n",
      "Epoch 4029, Loss 8.700528\n",
      "Params: tensor([  4.5183, -12.1763])\n",
      "Grad:   tensor([-0.0004,  0.0022])\n",
      "Epoch 4030, Loss 8.700530\n",
      "Params: tensor([  4.5183, -12.1763])\n",
      "Grad:   tensor([-0.0004,  0.0022])\n",
      "Epoch 4031, Loss 8.700530\n",
      "Params: tensor([  4.5183, -12.1763])\n",
      "Grad:   tensor([-0.0004,  0.0022])\n",
      "Epoch 4032, Loss 8.700529\n",
      "Params: tensor([  4.5183, -12.1763])\n",
      "Grad:   tensor([-0.0004,  0.0022])\n",
      "Epoch 4033, Loss 8.700527\n",
      "Params: tensor([  4.5183, -12.1764])\n",
      "Grad:   tensor([-0.0004,  0.0022])\n",
      "Epoch 4034, Loss 8.700528\n",
      "Params: tensor([  4.5183, -12.1764])\n",
      "Grad:   tensor([-0.0004,  0.0022])\n",
      "Epoch 4035, Loss 8.700529\n",
      "Params: tensor([  4.5183, -12.1764])\n",
      "Grad:   tensor([-0.0004,  0.0022])\n",
      "Epoch 4036, Loss 8.700528\n",
      "Params: tensor([  4.5183, -12.1764])\n",
      "Grad:   tensor([-0.0004,  0.0022])\n",
      "Epoch 4037, Loss 8.700530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: tensor([  4.5183, -12.1765])\n",
      "Grad:   tensor([-0.0004,  0.0022])\n",
      "Epoch 4038, Loss 8.700528\n",
      "Params: tensor([  4.5183, -12.1765])\n",
      "Grad:   tensor([-0.0004,  0.0022])\n",
      "Epoch 4039, Loss 8.700528\n",
      "Params: tensor([  4.5183, -12.1765])\n",
      "Grad:   tensor([-0.0004,  0.0022])\n",
      "Epoch 4040, Loss 8.700525\n",
      "Params: tensor([  4.5183, -12.1765])\n",
      "Grad:   tensor([-0.0004,  0.0022])\n",
      "Epoch 4041, Loss 8.700528\n",
      "Params: tensor([  4.5183, -12.1765])\n",
      "Grad:   tensor([-0.0004,  0.0022])\n",
      "Epoch 4042, Loss 8.700530\n",
      "Params: tensor([  4.5183, -12.1766])\n",
      "Grad:   tensor([-0.0004,  0.0022])\n",
      "Epoch 4043, Loss 8.700525\n",
      "Params: tensor([  4.5183, -12.1766])\n",
      "Grad:   tensor([-0.0004,  0.0022])\n",
      "Epoch 4044, Loss 8.700527\n",
      "Params: tensor([  4.5183, -12.1766])\n",
      "Grad:   tensor([-0.0004,  0.0022])\n",
      "Epoch 4045, Loss 8.700531\n",
      "Params: tensor([  4.5183, -12.1766])\n",
      "Grad:   tensor([-0.0004,  0.0022])\n",
      "Epoch 4046, Loss 8.700528\n",
      "Params: tensor([  4.5183, -12.1767])\n",
      "Grad:   tensor([-0.0004,  0.0022])\n",
      "Epoch 4047, Loss 8.700527\n",
      "Params: tensor([  4.5183, -12.1767])\n",
      "Grad:   tensor([-0.0004,  0.0022])\n",
      "Epoch 4048, Loss 8.700525\n",
      "Params: tensor([  4.5184, -12.1767])\n",
      "Grad:   tensor([-0.0004,  0.0022])\n",
      "Epoch 4049, Loss 8.700527\n",
      "Params: tensor([  4.5184, -12.1767])\n",
      "Grad:   tensor([-0.0004,  0.0022])\n",
      "Epoch 4050, Loss 8.700527\n",
      "Params: tensor([  4.5184, -12.1767])\n",
      "Grad:   tensor([-0.0004,  0.0022])\n",
      "Epoch 4051, Loss 8.700527\n",
      "Params: tensor([  4.5184, -12.1768])\n",
      "Grad:   tensor([-0.0004,  0.0022])\n",
      "Epoch 4052, Loss 8.700527\n",
      "Params: tensor([  4.5184, -12.1768])\n",
      "Grad:   tensor([-0.0004,  0.0022])\n",
      "Epoch 4053, Loss 8.700527\n",
      "Params: tensor([  4.5184, -12.1768])\n",
      "Grad:   tensor([-0.0004,  0.0022])\n",
      "Epoch 4054, Loss 8.700527\n",
      "Params: tensor([  4.5184, -12.1768])\n",
      "Grad:   tensor([-0.0004,  0.0021])\n",
      "Epoch 4055, Loss 8.700527\n",
      "Params: tensor([  4.5184, -12.1769])\n",
      "Grad:   tensor([-0.0004,  0.0021])\n",
      "Epoch 4056, Loss 8.700527\n",
      "Params: tensor([  4.5184, -12.1769])\n",
      "Grad:   tensor([-0.0004,  0.0021])\n",
      "Epoch 4057, Loss 8.700527\n",
      "Params: tensor([  4.5184, -12.1769])\n",
      "Grad:   tensor([-0.0004,  0.0021])\n",
      "Epoch 4058, Loss 8.700527\n",
      "Params: tensor([  4.5184, -12.1769])\n",
      "Grad:   tensor([-0.0004,  0.0021])\n",
      "Epoch 4059, Loss 8.700525\n",
      "Params: tensor([  4.5184, -12.1769])\n",
      "Grad:   tensor([-0.0004,  0.0021])\n",
      "Epoch 4060, Loss 8.700528\n",
      "Params: tensor([  4.5184, -12.1770])\n",
      "Grad:   tensor([-0.0004,  0.0021])\n",
      "Epoch 4061, Loss 8.700528\n",
      "Params: tensor([  4.5184, -12.1770])\n",
      "Grad:   tensor([-0.0004,  0.0021])\n",
      "Epoch 4062, Loss 8.700527\n",
      "Params: tensor([  4.5184, -12.1770])\n",
      "Grad:   tensor([-0.0004,  0.0021])\n",
      "Epoch 4063, Loss 8.700528\n",
      "Params: tensor([  4.5184, -12.1770])\n",
      "Grad:   tensor([-0.0004,  0.0021])\n",
      "Epoch 4064, Loss 8.700525\n",
      "Params: tensor([  4.5184, -12.1770])\n",
      "Grad:   tensor([-0.0004,  0.0021])\n",
      "Epoch 4065, Loss 8.700526\n",
      "Params: tensor([  4.5184, -12.1771])\n",
      "Grad:   tensor([-0.0004,  0.0021])\n",
      "Epoch 4066, Loss 8.700527\n",
      "Params: tensor([  4.5184, -12.1771])\n",
      "Grad:   tensor([-0.0004,  0.0021])\n",
      "Epoch 4067, Loss 8.700527\n",
      "Params: tensor([  4.5184, -12.1771])\n",
      "Grad:   tensor([-0.0004,  0.0021])\n",
      "Epoch 4068, Loss 8.700526\n",
      "Params: tensor([  4.5184, -12.1771])\n",
      "Grad:   tensor([-0.0004,  0.0021])\n",
      "Epoch 4069, Loss 8.700528\n",
      "Params: tensor([  4.5184, -12.1771])\n",
      "Grad:   tensor([-0.0004,  0.0021])\n",
      "Epoch 4070, Loss 8.700525\n",
      "Params: tensor([  4.5184, -12.1772])\n",
      "Grad:   tensor([-0.0004,  0.0021])\n",
      "Epoch 4071, Loss 8.700525\n",
      "Params: tensor([  4.5184, -12.1772])\n",
      "Grad:   tensor([-0.0004,  0.0021])\n",
      "Epoch 4072, Loss 8.700527\n",
      "Params: tensor([  4.5184, -12.1772])\n",
      "Grad:   tensor([-0.0004,  0.0021])\n",
      "Epoch 4073, Loss 8.700528\n",
      "Params: tensor([  4.5184, -12.1772])\n",
      "Grad:   tensor([-0.0004,  0.0021])\n",
      "Epoch 4074, Loss 8.700528\n",
      "Params: tensor([  4.5184, -12.1773])\n",
      "Grad:   tensor([-0.0004,  0.0021])\n",
      "Epoch 4075, Loss 8.700524\n",
      "Params: tensor([  4.5185, -12.1773])\n",
      "Grad:   tensor([-0.0004,  0.0021])\n",
      "Epoch 4076, Loss 8.700524\n",
      "Params: tensor([  4.5185, -12.1773])\n",
      "Grad:   tensor([-0.0004,  0.0021])\n",
      "Epoch 4077, Loss 8.700527\n",
      "Params: tensor([  4.5185, -12.1773])\n",
      "Grad:   tensor([-0.0004,  0.0021])\n",
      "Epoch 4078, Loss 8.700524\n",
      "Params: tensor([  4.5185, -12.1773])\n",
      "Grad:   tensor([-0.0004,  0.0021])\n",
      "Epoch 4079, Loss 8.700527\n",
      "Params: tensor([  4.5185, -12.1774])\n",
      "Grad:   tensor([-0.0004,  0.0021])\n",
      "Epoch 4080, Loss 8.700525\n",
      "Params: tensor([  4.5185, -12.1774])\n",
      "Grad:   tensor([-0.0003,  0.0021])\n",
      "Epoch 4081, Loss 8.700524\n",
      "Params: tensor([  4.5185, -12.1774])\n",
      "Grad:   tensor([-0.0004,  0.0020])\n",
      "Epoch 4082, Loss 8.700525\n",
      "Params: tensor([  4.5185, -12.1774])\n",
      "Grad:   tensor([-0.0004,  0.0020])\n",
      "Epoch 4083, Loss 8.700526\n",
      "Params: tensor([  4.5185, -12.1774])\n",
      "Grad:   tensor([-0.0003,  0.0020])\n",
      "Epoch 4084, Loss 8.700527\n",
      "Params: tensor([  4.5185, -12.1775])\n",
      "Grad:   tensor([-0.0004,  0.0020])\n",
      "Epoch 4085, Loss 8.700526\n",
      "Params: tensor([  4.5185, -12.1775])\n",
      "Grad:   tensor([-0.0004,  0.0020])\n",
      "Epoch 4086, Loss 8.700525\n",
      "Params: tensor([  4.5185, -12.1775])\n",
      "Grad:   tensor([-0.0003,  0.0020])\n",
      "Epoch 4087, Loss 8.700525\n",
      "Params: tensor([  4.5185, -12.1775])\n",
      "Grad:   tensor([-0.0004,  0.0020])\n",
      "Epoch 4088, Loss 8.700525\n",
      "Params: tensor([  4.5185, -12.1775])\n",
      "Grad:   tensor([-0.0004,  0.0020])\n",
      "Epoch 4089, Loss 8.700527\n",
      "Params: tensor([  4.5185, -12.1776])\n",
      "Grad:   tensor([-0.0004,  0.0020])\n",
      "Epoch 4090, Loss 8.700525\n",
      "Params: tensor([  4.5185, -12.1776])\n",
      "Grad:   tensor([-0.0004,  0.0020])\n",
      "Epoch 4091, Loss 8.700525\n",
      "Params: tensor([  4.5185, -12.1776])\n",
      "Grad:   tensor([-0.0004,  0.0020])\n",
      "Epoch 4092, Loss 8.700523\n",
      "Params: tensor([  4.5185, -12.1776])\n",
      "Grad:   tensor([-0.0004,  0.0020])\n",
      "Epoch 4093, Loss 8.700525\n",
      "Params: tensor([  4.5185, -12.1776])\n",
      "Grad:   tensor([-0.0004,  0.0020])\n",
      "Epoch 4094, Loss 8.700527\n",
      "Params: tensor([  4.5185, -12.1777])\n",
      "Grad:   tensor([-0.0004,  0.0020])\n",
      "Epoch 4095, Loss 8.700526\n",
      "Params: tensor([  4.5185, -12.1777])\n",
      "Grad:   tensor([-0.0004,  0.0020])\n",
      "Epoch 4096, Loss 8.700524\n",
      "Params: tensor([  4.5185, -12.1777])\n",
      "Grad:   tensor([-0.0003,  0.0020])\n",
      "Epoch 4097, Loss 8.700522\n",
      "Params: tensor([  4.5185, -12.1777])\n",
      "Grad:   tensor([-0.0004,  0.0020])\n",
      "Epoch 4098, Loss 8.700525\n",
      "Params: tensor([  4.5185, -12.1777])\n",
      "Grad:   tensor([-0.0004,  0.0020])\n",
      "Epoch 4099, Loss 8.700524\n",
      "Params: tensor([  4.5185, -12.1778])\n",
      "Grad:   tensor([-0.0004,  0.0020])\n",
      "Epoch 4100, Loss 8.700524\n",
      "Params: tensor([  4.5185, -12.1778])\n",
      "Grad:   tensor([-0.0004,  0.0020])\n",
      "Epoch 4101, Loss 8.700525\n",
      "Params: tensor([  4.5185, -12.1778])\n",
      "Grad:   tensor([-0.0003,  0.0020])\n",
      "Epoch 4102, Loss 8.700525\n",
      "Params: tensor([  4.5185, -12.1778])\n",
      "Grad:   tensor([-0.0004,  0.0020])\n",
      "Epoch 4103, Loss 8.700524\n",
      "Params: tensor([  4.5186, -12.1778])\n",
      "Grad:   tensor([-0.0003,  0.0020])\n",
      "Epoch 4104, Loss 8.700525\n",
      "Params: tensor([  4.5186, -12.1779])\n",
      "Grad:   tensor([-0.0003,  0.0020])\n",
      "Epoch 4105, Loss 8.700524\n",
      "Params: tensor([  4.5186, -12.1779])\n",
      "Grad:   tensor([-0.0004,  0.0020])\n",
      "Epoch 4106, Loss 8.700526\n",
      "Params: tensor([  4.5186, -12.1779])\n",
      "Grad:   tensor([-0.0003,  0.0020])\n",
      "Epoch 4107, Loss 8.700526\n",
      "Params: tensor([  4.5186, -12.1779])\n",
      "Grad:   tensor([-0.0004,  0.0020])\n",
      "Epoch 4108, Loss 8.700524\n",
      "Params: tensor([  4.5186, -12.1779])\n",
      "Grad:   tensor([-0.0004,  0.0020])\n",
      "Epoch 4109, Loss 8.700522\n",
      "Params: tensor([  4.5186, -12.1780])\n",
      "Grad:   tensor([-0.0003,  0.0020])\n",
      "Epoch 4110, Loss 8.700522\n",
      "Params: tensor([  4.5186, -12.1780])\n",
      "Grad:   tensor([-0.0004,  0.0020])\n",
      "Epoch 4111, Loss 8.700524\n",
      "Params: tensor([  4.5186, -12.1780])\n",
      "Grad:   tensor([-0.0004,  0.0019])\n",
      "Epoch 4112, Loss 8.700524\n",
      "Params: tensor([  4.5186, -12.1780])\n",
      "Grad:   tensor([-0.0004,  0.0019])\n",
      "Epoch 4113, Loss 8.700525\n",
      "Params: tensor([  4.5186, -12.1780])\n",
      "Grad:   tensor([-0.0004,  0.0019])\n",
      "Epoch 4114, Loss 8.700524\n",
      "Params: tensor([  4.5186, -12.1781])\n",
      "Grad:   tensor([-0.0004,  0.0019])\n",
      "Epoch 4115, Loss 8.700522\n",
      "Params: tensor([  4.5186, -12.1781])\n",
      "Grad:   tensor([-0.0003,  0.0019])\n",
      "Epoch 4116, Loss 8.700524\n",
      "Params: tensor([  4.5186, -12.1781])\n",
      "Grad:   tensor([-0.0003,  0.0019])\n",
      "Epoch 4117, Loss 8.700524\n",
      "Params: tensor([  4.5186, -12.1781])\n",
      "Grad:   tensor([-0.0003,  0.0019])\n",
      "Epoch 4118, Loss 8.700525\n",
      "Params: tensor([  4.5186, -12.1781])\n",
      "Grad:   tensor([-0.0003,  0.0019])\n",
      "Epoch 4119, Loss 8.700527\n",
      "Params: tensor([  4.5186, -12.1781])\n",
      "Grad:   tensor([-0.0003,  0.0019])\n",
      "Epoch 4120, Loss 8.700524\n",
      "Params: tensor([  4.5186, -12.1782])\n",
      "Grad:   tensor([-0.0003,  0.0019])\n",
      "Epoch 4121, Loss 8.700525\n",
      "Params: tensor([  4.5186, -12.1782])\n",
      "Grad:   tensor([-0.0003,  0.0019])\n",
      "Epoch 4122, Loss 8.700522\n",
      "Params: tensor([  4.5186, -12.1782])\n",
      "Grad:   tensor([-0.0003,  0.0019])\n",
      "Epoch 4123, Loss 8.700524\n",
      "Params: tensor([  4.5186, -12.1782])\n",
      "Grad:   tensor([-0.0003,  0.0019])\n",
      "Epoch 4124, Loss 8.700523\n",
      "Params: tensor([  4.5186, -12.1782])\n",
      "Grad:   tensor([-0.0003,  0.0019])\n",
      "Epoch 4125, Loss 8.700526\n",
      "Params: tensor([  4.5186, -12.1783])\n",
      "Grad:   tensor([-0.0003,  0.0019])\n",
      "Epoch 4126, Loss 8.700526\n",
      "Params: tensor([  4.5186, -12.1783])\n",
      "Grad:   tensor([-0.0003,  0.0019])\n",
      "Epoch 4127, Loss 8.700522\n",
      "Params: tensor([  4.5186, -12.1783])\n",
      "Grad:   tensor([-0.0003,  0.0019])\n",
      "Epoch 4128, Loss 8.700523\n",
      "Params: tensor([  4.5186, -12.1783])\n",
      "Grad:   tensor([-0.0003,  0.0019])\n",
      "Epoch 4129, Loss 8.700524\n",
      "Params: tensor([  4.5186, -12.1783])\n",
      "Grad:   tensor([-0.0004,  0.0019])\n",
      "Epoch 4130, Loss 8.700525\n",
      "Params: tensor([  4.5186, -12.1784])\n",
      "Grad:   tensor([-0.0003,  0.0019])\n",
      "Epoch 4131, Loss 8.700523\n",
      "Params: tensor([  4.5186, -12.1784])\n",
      "Grad:   tensor([-0.0004,  0.0019])\n",
      "Epoch 4132, Loss 8.700525\n",
      "Params: tensor([  4.5186, -12.1784])\n",
      "Grad:   tensor([-0.0004,  0.0019])\n",
      "Epoch 4133, Loss 8.700521\n",
      "Params: tensor([  4.5187, -12.1784])\n",
      "Grad:   tensor([-0.0004,  0.0019])\n",
      "Epoch 4134, Loss 8.700524\n",
      "Params: tensor([  4.5187, -12.1784])\n",
      "Grad:   tensor([-0.0004,  0.0019])\n",
      "Epoch 4135, Loss 8.700523\n",
      "Params: tensor([  4.5187, -12.1785])\n",
      "Grad:   tensor([-0.0004,  0.0019])\n",
      "Epoch 4136, Loss 8.700523\n",
      "Params: tensor([  4.5187, -12.1785])\n",
      "Grad:   tensor([-0.0004,  0.0019])\n",
      "Epoch 4137, Loss 8.700525\n",
      "Params: tensor([  4.5187, -12.1785])\n",
      "Grad:   tensor([-0.0003,  0.0019])\n",
      "Epoch 4138, Loss 8.700525\n",
      "Params: tensor([  4.5187, -12.1785])\n",
      "Grad:   tensor([-0.0003,  0.0019])\n",
      "Epoch 4139, Loss 8.700522\n",
      "Params: tensor([  4.5187, -12.1785])\n",
      "Grad:   tensor([-0.0003,  0.0019])\n",
      "Epoch 4140, Loss 8.700523\n",
      "Params: tensor([  4.5187, -12.1785])\n",
      "Grad:   tensor([-0.0003,  0.0019])\n",
      "Epoch 4141, Loss 8.700524\n",
      "Params: tensor([  4.5187, -12.1786])\n",
      "Grad:   tensor([-0.0003,  0.0019])\n",
      "Epoch 4142, Loss 8.700524\n",
      "Params: tensor([  4.5187, -12.1786])\n",
      "Grad:   tensor([-0.0003,  0.0019])\n",
      "Epoch 4143, Loss 8.700524\n",
      "Params: tensor([  4.5187, -12.1786])\n",
      "Grad:   tensor([-0.0003,  0.0018])\n",
      "Epoch 4144, Loss 8.700522\n",
      "Params: tensor([  4.5187, -12.1786])\n",
      "Grad:   tensor([-0.0003,  0.0018])\n",
      "Epoch 4145, Loss 8.700524\n",
      "Params: tensor([  4.5187, -12.1786])\n",
      "Grad:   tensor([-0.0003,  0.0018])\n",
      "Epoch 4146, Loss 8.700521\n",
      "Params: tensor([  4.5187, -12.1787])\n",
      "Grad:   tensor([-0.0003,  0.0018])\n",
      "Epoch 4147, Loss 8.700522\n",
      "Params: tensor([  4.5187, -12.1787])\n",
      "Grad:   tensor([-0.0003,  0.0018])\n",
      "Epoch 4148, Loss 8.700524\n",
      "Params: tensor([  4.5187, -12.1787])\n",
      "Grad:   tensor([-0.0003,  0.0018])\n",
      "Epoch 4149, Loss 8.700524\n",
      "Params: tensor([  4.5187, -12.1787])\n",
      "Grad:   tensor([-0.0003,  0.0018])\n",
      "Epoch 4150, Loss 8.700524\n",
      "Params: tensor([  4.5187, -12.1787])\n",
      "Grad:   tensor([-0.0003,  0.0018])\n",
      "Epoch 4151, Loss 8.700521\n",
      "Params: tensor([  4.5187, -12.1787])\n",
      "Grad:   tensor([-0.0003,  0.0018])\n",
      "Epoch 4152, Loss 8.700522\n",
      "Params: tensor([  4.5187, -12.1788])\n",
      "Grad:   tensor([-0.0003,  0.0018])\n",
      "Epoch 4153, Loss 8.700523\n",
      "Params: tensor([  4.5187, -12.1788])\n",
      "Grad:   tensor([-0.0003,  0.0018])\n",
      "Epoch 4154, Loss 8.700522\n",
      "Params: tensor([  4.5187, -12.1788])\n",
      "Grad:   tensor([-0.0003,  0.0018])\n",
      "Epoch 4155, Loss 8.700523\n",
      "Params: tensor([  4.5187, -12.1788])\n",
      "Grad:   tensor([-0.0003,  0.0018])\n",
      "Epoch 4156, Loss 8.700524\n",
      "Params: tensor([  4.5187, -12.1788])\n",
      "Grad:   tensor([-0.0003,  0.0018])\n",
      "Epoch 4157, Loss 8.700522\n",
      "Params: tensor([  4.5187, -12.1789])\n",
      "Grad:   tensor([-0.0003,  0.0018])\n",
      "Epoch 4158, Loss 8.700522\n",
      "Params: tensor([  4.5187, -12.1789])\n",
      "Grad:   tensor([-0.0003,  0.0018])\n",
      "Epoch 4159, Loss 8.700523\n",
      "Params: tensor([  4.5187, -12.1789])\n",
      "Grad:   tensor([-0.0003,  0.0018])\n",
      "Epoch 4160, Loss 8.700522\n",
      "Params: tensor([  4.5187, -12.1789])\n",
      "Grad:   tensor([-0.0003,  0.0018])\n",
      "Epoch 4161, Loss 8.700522\n",
      "Params: tensor([  4.5187, -12.1789])\n",
      "Grad:   tensor([-0.0003,  0.0018])\n",
      "Epoch 4162, Loss 8.700523\n",
      "Params: tensor([  4.5187, -12.1789])\n",
      "Grad:   tensor([-0.0003,  0.0018])\n",
      "Epoch 4163, Loss 8.700525\n",
      "Params: tensor([  4.5188, -12.1790])\n",
      "Grad:   tensor([-0.0003,  0.0018])\n",
      "Epoch 4164, Loss 8.700521\n",
      "Params: tensor([  4.5188, -12.1790])\n",
      "Grad:   tensor([-0.0003,  0.0018])\n",
      "Epoch 4165, Loss 8.700522\n",
      "Params: tensor([  4.5188, -12.1790])\n",
      "Grad:   tensor([-0.0003,  0.0018])\n",
      "Epoch 4166, Loss 8.700524\n",
      "Params: tensor([  4.5188, -12.1790])\n",
      "Grad:   tensor([-0.0003,  0.0018])\n",
      "Epoch 4167, Loss 8.700522\n",
      "Params: tensor([  4.5188, -12.1790])\n",
      "Grad:   tensor([-0.0003,  0.0018])\n",
      "Epoch 4168, Loss 8.700521\n",
      "Params: tensor([  4.5188, -12.1791])\n",
      "Grad:   tensor([-0.0003,  0.0018])\n",
      "Epoch 4169, Loss 8.700523\n",
      "Params: tensor([  4.5188, -12.1791])\n",
      "Grad:   tensor([-0.0003,  0.0018])\n",
      "Epoch 4170, Loss 8.700522\n",
      "Params: tensor([  4.5188, -12.1791])\n",
      "Grad:   tensor([-0.0003,  0.0018])\n",
      "Epoch 4171, Loss 8.700522\n",
      "Params: tensor([  4.5188, -12.1791])\n",
      "Grad:   tensor([-0.0003,  0.0018])\n",
      "Epoch 4172, Loss 8.700521\n",
      "Params: tensor([  4.5188, -12.1791])\n",
      "Grad:   tensor([-0.0003,  0.0018])\n",
      "Epoch 4173, Loss 8.700523\n",
      "Params: tensor([  4.5188, -12.1791])\n",
      "Grad:   tensor([-0.0003,  0.0018])\n",
      "Epoch 4174, Loss 8.700522\n",
      "Params: tensor([  4.5188, -12.1792])\n",
      "Grad:   tensor([-0.0003,  0.0017])\n",
      "Epoch 4175, Loss 8.700524\n",
      "Params: tensor([  4.5188, -12.1792])\n",
      "Grad:   tensor([-0.0003,  0.0017])\n",
      "Epoch 4176, Loss 8.700521\n",
      "Params: tensor([  4.5188, -12.1792])\n",
      "Grad:   tensor([-0.0003,  0.0017])\n",
      "Epoch 4177, Loss 8.700522\n",
      "Params: tensor([  4.5188, -12.1792])\n",
      "Grad:   tensor([-0.0003,  0.0017])\n",
      "Epoch 4178, Loss 8.700524\n",
      "Params: tensor([  4.5188, -12.1792])\n",
      "Grad:   tensor([-0.0003,  0.0017])\n",
      "Epoch 4179, Loss 8.700522\n",
      "Params: tensor([  4.5188, -12.1792])\n",
      "Grad:   tensor([-0.0003,  0.0017])\n",
      "Epoch 4180, Loss 8.700521\n",
      "Params: tensor([  4.5188, -12.1793])\n",
      "Grad:   tensor([-0.0003,  0.0017])\n",
      "Epoch 4181, Loss 8.700522\n",
      "Params: tensor([  4.5188, -12.1793])\n",
      "Grad:   tensor([-0.0003,  0.0017])\n",
      "Epoch 4182, Loss 8.700523\n",
      "Params: tensor([  4.5188, -12.1793])\n",
      "Grad:   tensor([-0.0003,  0.0017])\n",
      "Epoch 4183, Loss 8.700521\n",
      "Params: tensor([  4.5188, -12.1793])\n",
      "Grad:   tensor([-0.0003,  0.0017])\n",
      "Epoch 4184, Loss 8.700522\n",
      "Params: tensor([  4.5188, -12.1793])\n",
      "Grad:   tensor([-0.0003,  0.0017])\n",
      "Epoch 4185, Loss 8.700521\n",
      "Params: tensor([  4.5188, -12.1793])\n",
      "Grad:   tensor([-0.0003,  0.0017])\n",
      "Epoch 4186, Loss 8.700522\n",
      "Params: tensor([  4.5188, -12.1794])\n",
      "Grad:   tensor([-0.0003,  0.0017])\n",
      "Epoch 4187, Loss 8.700522\n",
      "Params: tensor([  4.5188, -12.1794])\n",
      "Grad:   tensor([-0.0003,  0.0017])\n",
      "Epoch 4188, Loss 8.700521\n",
      "Params: tensor([  4.5188, -12.1794])\n",
      "Grad:   tensor([-0.0003,  0.0017])\n",
      "Epoch 4189, Loss 8.700523\n",
      "Params: tensor([  4.5188, -12.1794])\n",
      "Grad:   tensor([-0.0003,  0.0017])\n",
      "Epoch 4190, Loss 8.700521\n",
      "Params: tensor([  4.5188, -12.1794])\n",
      "Grad:   tensor([-0.0003,  0.0017])\n",
      "Epoch 4191, Loss 8.700521\n",
      "Params: tensor([  4.5188, -12.1794])\n",
      "Grad:   tensor([-0.0003,  0.0017])\n",
      "Epoch 4192, Loss 8.700521\n",
      "Params: tensor([  4.5188, -12.1795])\n",
      "Grad:   tensor([-0.0003,  0.0017])\n",
      "Epoch 4193, Loss 8.700522\n",
      "Params: tensor([  4.5188, -12.1795])\n",
      "Grad:   tensor([-0.0003,  0.0017])\n",
      "Epoch 4194, Loss 8.700522\n",
      "Params: tensor([  4.5188, -12.1795])\n",
      "Grad:   tensor([-0.0003,  0.0017])\n",
      "Epoch 4195, Loss 8.700522\n",
      "Params: tensor([  4.5188, -12.1795])\n",
      "Grad:   tensor([-0.0003,  0.0017])\n",
      "Epoch 4196, Loss 8.700521\n",
      "Params: tensor([  4.5189, -12.1795])\n",
      "Grad:   tensor([-0.0003,  0.0017])\n",
      "Epoch 4197, Loss 8.700521\n",
      "Params: tensor([  4.5189, -12.1796])\n",
      "Grad:   tensor([-0.0003,  0.0017])\n",
      "Epoch 4198, Loss 8.700521\n",
      "Params: tensor([  4.5189, -12.1796])\n",
      "Grad:   tensor([-0.0003,  0.0017])\n",
      "Epoch 4199, Loss 8.700521\n",
      "Params: tensor([  4.5189, -12.1796])\n",
      "Grad:   tensor([-0.0003,  0.0017])\n",
      "Epoch 4200, Loss 8.700521\n",
      "Params: tensor([  4.5189, -12.1796])\n",
      "Grad:   tensor([-0.0003,  0.0017])\n",
      "Epoch 4201, Loss 8.700521\n",
      "Params: tensor([  4.5189, -12.1796])\n",
      "Grad:   tensor([-0.0003,  0.0017])\n",
      "Epoch 4202, Loss 8.700522\n",
      "Params: tensor([  4.5189, -12.1796])\n",
      "Grad:   tensor([-0.0003,  0.0017])\n",
      "Epoch 4203, Loss 8.700521\n",
      "Params: tensor([  4.5189, -12.1797])\n",
      "Grad:   tensor([-0.0003,  0.0017])\n",
      "Epoch 4204, Loss 8.700520\n",
      "Params: tensor([  4.5189, -12.1797])\n",
      "Grad:   tensor([-0.0003,  0.0017])\n",
      "Epoch 4205, Loss 8.700522\n",
      "Params: tensor([  4.5189, -12.1797])\n",
      "Grad:   tensor([-0.0003,  0.0017])\n",
      "Epoch 4206, Loss 8.700522\n",
      "Params: tensor([  4.5189, -12.1797])\n",
      "Grad:   tensor([-0.0003,  0.0017])\n",
      "Epoch 4207, Loss 8.700521\n",
      "Params: tensor([  4.5189, -12.1797])\n",
      "Grad:   tensor([-0.0003,  0.0017])\n",
      "Epoch 4208, Loss 8.700522\n",
      "Params: tensor([  4.5189, -12.1797])\n",
      "Grad:   tensor([-0.0003,  0.0017])\n",
      "Epoch 4209, Loss 8.700522\n",
      "Params: tensor([  4.5189, -12.1798])\n",
      "Grad:   tensor([-0.0003,  0.0017])\n",
      "Epoch 4210, Loss 8.700521\n",
      "Params: tensor([  4.5189, -12.1798])\n",
      "Grad:   tensor([-0.0003,  0.0016])\n",
      "Epoch 4211, Loss 8.700521\n",
      "Params: tensor([  4.5189, -12.1798])\n",
      "Grad:   tensor([-0.0003,  0.0016])\n",
      "Epoch 4212, Loss 8.700520\n",
      "Params: tensor([  4.5189, -12.1798])\n",
      "Grad:   tensor([-0.0003,  0.0016])\n",
      "Epoch 4213, Loss 8.700521\n",
      "Params: tensor([  4.5189, -12.1798])\n",
      "Grad:   tensor([-0.0003,  0.0016])\n",
      "Epoch 4214, Loss 8.700522\n",
      "Params: tensor([  4.5189, -12.1798])\n",
      "Grad:   tensor([-0.0003,  0.0016])\n",
      "Epoch 4215, Loss 8.700521\n",
      "Params: tensor([  4.5189, -12.1798])\n",
      "Grad:   tensor([-0.0003,  0.0016])\n",
      "Epoch 4216, Loss 8.700522\n",
      "Params: tensor([  4.5189, -12.1799])\n",
      "Grad:   tensor([-0.0003,  0.0016])\n",
      "Epoch 4217, Loss 8.700520\n",
      "Params: tensor([  4.5189, -12.1799])\n",
      "Grad:   tensor([-0.0003,  0.0016])\n",
      "Epoch 4218, Loss 8.700521\n",
      "Params: tensor([  4.5189, -12.1799])\n",
      "Grad:   tensor([-0.0003,  0.0016])\n",
      "Epoch 4219, Loss 8.700520\n",
      "Params: tensor([  4.5189, -12.1799])\n",
      "Grad:   tensor([-0.0003,  0.0016])\n",
      "Epoch 4220, Loss 8.700520\n",
      "Params: tensor([  4.5189, -12.1799])\n",
      "Grad:   tensor([-0.0003,  0.0016])\n",
      "Epoch 4221, Loss 8.700521\n",
      "Params: tensor([  4.5189, -12.1799])\n",
      "Grad:   tensor([-0.0003,  0.0016])\n",
      "Epoch 4222, Loss 8.700522\n",
      "Params: tensor([  4.5189, -12.1800])\n",
      "Grad:   tensor([-0.0003,  0.0016])\n",
      "Epoch 4223, Loss 8.700521\n",
      "Params: tensor([  4.5189, -12.1800])\n",
      "Grad:   tensor([-0.0003,  0.0016])\n",
      "Epoch 4224, Loss 8.700520\n",
      "Params: tensor([  4.5189, -12.1800])\n",
      "Grad:   tensor([-0.0003,  0.0016])\n",
      "Epoch 4225, Loss 8.700521\n",
      "Params: tensor([  4.5189, -12.1800])\n",
      "Grad:   tensor([-0.0003,  0.0016])\n",
      "Epoch 4226, Loss 8.700521\n",
      "Params: tensor([  4.5189, -12.1800])\n",
      "Grad:   tensor([-0.0003,  0.0016])\n",
      "Epoch 4227, Loss 8.700521\n",
      "Params: tensor([  4.5189, -12.1800])\n",
      "Grad:   tensor([-0.0003,  0.0016])\n",
      "Epoch 4228, Loss 8.700520\n",
      "Params: tensor([  4.5189, -12.1801])\n",
      "Grad:   tensor([-0.0003,  0.0016])\n",
      "Epoch 4229, Loss 8.700522\n",
      "Params: tensor([  4.5189, -12.1801])\n",
      "Grad:   tensor([-0.0003,  0.0016])\n",
      "Epoch 4230, Loss 8.700522\n",
      "Params: tensor([  4.5189, -12.1801])\n",
      "Grad:   tensor([-0.0003,  0.0016])\n",
      "Epoch 4231, Loss 8.700520\n",
      "Params: tensor([  4.5190, -12.1801])\n",
      "Grad:   tensor([-0.0003,  0.0016])\n",
      "Epoch 4232, Loss 8.700520\n",
      "Params: tensor([  4.5190, -12.1801])\n",
      "Grad:   tensor([-0.0003,  0.0016])\n",
      "Epoch 4233, Loss 8.700520\n",
      "Params: tensor([  4.5190, -12.1801])\n",
      "Grad:   tensor([-0.0003,  0.0016])\n",
      "Epoch 4234, Loss 8.700520\n",
      "Params: tensor([  4.5190, -12.1802])\n",
      "Grad:   tensor([-0.0003,  0.0016])\n",
      "Epoch 4235, Loss 8.700520\n",
      "Params: tensor([  4.5190, -12.1802])\n",
      "Grad:   tensor([-0.0003,  0.0016])\n",
      "Epoch 4236, Loss 8.700521\n",
      "Params: tensor([  4.5190, -12.1802])\n",
      "Grad:   tensor([-0.0003,  0.0016])\n",
      "Epoch 4237, Loss 8.700521\n",
      "Params: tensor([  4.5190, -12.1802])\n",
      "Grad:   tensor([-0.0003,  0.0016])\n",
      "Epoch 4238, Loss 8.700521\n",
      "Params: tensor([  4.5190, -12.1802])\n",
      "Grad:   tensor([-0.0003,  0.0016])\n",
      "Epoch 4239, Loss 8.700520\n",
      "Params: tensor([  4.5190, -12.1802])\n",
      "Grad:   tensor([-0.0003,  0.0016])\n",
      "Epoch 4240, Loss 8.700520\n",
      "Params: tensor([  4.5190, -12.1803])\n",
      "Grad:   tensor([-0.0003,  0.0016])\n",
      "Epoch 4241, Loss 8.700521\n",
      "Params: tensor([  4.5190, -12.1803])\n",
      "Grad:   tensor([-0.0003,  0.0016])\n",
      "Epoch 4242, Loss 8.700520\n",
      "Params: tensor([  4.5190, -12.1803])\n",
      "Grad:   tensor([-0.0003,  0.0016])\n",
      "Epoch 4243, Loss 8.700521\n",
      "Params: tensor([  4.5190, -12.1803])\n",
      "Grad:   tensor([-0.0003,  0.0016])\n",
      "Epoch 4244, Loss 8.700522\n",
      "Params: tensor([  4.5190, -12.1803])\n",
      "Grad:   tensor([-0.0003,  0.0016])\n",
      "Epoch 4245, Loss 8.700520\n",
      "Params: tensor([  4.5190, -12.1803])\n",
      "Grad:   tensor([-0.0002,  0.0016])\n",
      "Epoch 4246, Loss 8.700521\n",
      "Params: tensor([  4.5190, -12.1803])\n",
      "Grad:   tensor([-0.0003,  0.0016])\n",
      "Epoch 4247, Loss 8.700520\n",
      "Params: tensor([  4.5190, -12.1804])\n",
      "Grad:   tensor([-0.0003,  0.0015])\n",
      "Epoch 4248, Loss 8.700521\n",
      "Params: tensor([  4.5190, -12.1804])\n",
      "Grad:   tensor([-0.0003,  0.0015])\n",
      "Epoch 4249, Loss 8.700520\n",
      "Params: tensor([  4.5190, -12.1804])\n",
      "Grad:   tensor([-0.0003,  0.0015])\n",
      "Epoch 4250, Loss 8.700521\n",
      "Params: tensor([  4.5190, -12.1804])\n",
      "Grad:   tensor([-0.0003,  0.0015])\n",
      "Epoch 4251, Loss 8.700522\n",
      "Params: tensor([  4.5190, -12.1804])\n",
      "Grad:   tensor([-0.0003,  0.0015])\n",
      "Epoch 4252, Loss 8.700521\n",
      "Params: tensor([  4.5190, -12.1804])\n",
      "Grad:   tensor([-0.0003,  0.0015])\n",
      "Epoch 4253, Loss 8.700519\n",
      "Params: tensor([  4.5190, -12.1804])\n",
      "Grad:   tensor([-0.0002,  0.0015])\n",
      "Epoch 4254, Loss 8.700521\n",
      "Params: tensor([  4.5190, -12.1805])\n",
      "Grad:   tensor([-0.0003,  0.0015])\n",
      "Epoch 4255, Loss 8.700520\n",
      "Params: tensor([  4.5190, -12.1805])\n",
      "Grad:   tensor([-0.0003,  0.0015])\n",
      "Epoch 4256, Loss 8.700520\n",
      "Params: tensor([  4.5190, -12.1805])\n",
      "Grad:   tensor([-0.0003,  0.0015])\n",
      "Epoch 4257, Loss 8.700521\n",
      "Params: tensor([  4.5190, -12.1805])\n",
      "Grad:   tensor([-0.0003,  0.0015])\n",
      "Epoch 4258, Loss 8.700521\n",
      "Params: tensor([  4.5190, -12.1805])\n",
      "Grad:   tensor([-0.0003,  0.0015])\n",
      "Epoch 4259, Loss 8.700520\n",
      "Params: tensor([  4.5190, -12.1805])\n",
      "Grad:   tensor([-0.0003,  0.0015])\n",
      "Epoch 4260, Loss 8.700520\n",
      "Params: tensor([  4.5190, -12.1806])\n",
      "Grad:   tensor([-0.0003,  0.0015])\n",
      "Epoch 4261, Loss 8.700521\n",
      "Params: tensor([  4.5190, -12.1806])\n",
      "Grad:   tensor([-0.0003,  0.0015])\n",
      "Epoch 4262, Loss 8.700521\n",
      "Params: tensor([  4.5190, -12.1806])\n",
      "Grad:   tensor([-0.0003,  0.0015])\n",
      "Epoch 4263, Loss 8.700520\n",
      "Params: tensor([  4.5190, -12.1806])\n",
      "Grad:   tensor([-0.0003,  0.0015])\n",
      "Epoch 4264, Loss 8.700521\n",
      "Params: tensor([  4.5190, -12.1806])\n",
      "Grad:   tensor([-0.0003,  0.0015])\n",
      "Epoch 4265, Loss 8.700521\n",
      "Params: tensor([  4.5190, -12.1806])\n",
      "Grad:   tensor([-0.0003,  0.0015])\n",
      "Epoch 4266, Loss 8.700521\n",
      "Params: tensor([  4.5190, -12.1806])\n",
      "Grad:   tensor([-0.0003,  0.0015])\n",
      "Epoch 4267, Loss 8.700521\n",
      "Params: tensor([  4.5191, -12.1807])\n",
      "Grad:   tensor([-0.0003,  0.0015])\n",
      "Epoch 4268, Loss 8.700520\n",
      "Params: tensor([  4.5191, -12.1807])\n",
      "Grad:   tensor([-0.0003,  0.0015])\n",
      "Epoch 4269, Loss 8.700520\n",
      "Params: tensor([  4.5191, -12.1807])\n",
      "Grad:   tensor([-0.0003,  0.0015])\n",
      "Epoch 4270, Loss 8.700520\n",
      "Params: tensor([  4.5191, -12.1807])\n",
      "Grad:   tensor([-0.0003,  0.0015])\n",
      "Epoch 4271, Loss 8.700521\n",
      "Params: tensor([  4.5191, -12.1807])\n",
      "Grad:   tensor([-0.0003,  0.0015])\n",
      "Epoch 4272, Loss 8.700520\n",
      "Params: tensor([  4.5191, -12.1807])\n",
      "Grad:   tensor([-0.0003,  0.0015])\n",
      "Epoch 4273, Loss 8.700521\n",
      "Params: tensor([  4.5191, -12.1808])\n",
      "Grad:   tensor([-0.0003,  0.0015])\n",
      "Epoch 4274, Loss 8.700521\n",
      "Params: tensor([  4.5191, -12.1808])\n",
      "Grad:   tensor([-0.0003,  0.0015])\n",
      "Epoch 4275, Loss 8.700519\n",
      "Params: tensor([  4.5191, -12.1808])\n",
      "Grad:   tensor([-0.0003,  0.0015])\n",
      "Epoch 4276, Loss 8.700521\n",
      "Params: tensor([  4.5191, -12.1808])\n",
      "Grad:   tensor([-0.0003,  0.0015])\n",
      "Epoch 4277, Loss 8.700519\n",
      "Params: tensor([  4.5191, -12.1808])\n",
      "Grad:   tensor([-0.0003,  0.0015])\n",
      "Epoch 4278, Loss 8.700520\n",
      "Params: tensor([  4.5191, -12.1808])\n",
      "Grad:   tensor([-0.0003,  0.0015])\n",
      "Epoch 4279, Loss 8.700519\n",
      "Params: tensor([  4.5191, -12.1808])\n",
      "Grad:   tensor([-0.0003,  0.0015])\n",
      "Epoch 4280, Loss 8.700522\n",
      "Params: tensor([  4.5191, -12.1809])\n",
      "Grad:   tensor([-0.0002,  0.0015])\n",
      "Epoch 4281, Loss 8.700521\n",
      "Params: tensor([  4.5191, -12.1809])\n",
      "Grad:   tensor([-0.0003,  0.0015])\n",
      "Epoch 4282, Loss 8.700521\n",
      "Params: tensor([  4.5191, -12.1809])\n",
      "Grad:   tensor([-0.0003,  0.0015])\n",
      "Epoch 4283, Loss 8.700520\n",
      "Params: tensor([  4.5191, -12.1809])\n",
      "Grad:   tensor([-0.0002,  0.0015])\n",
      "Epoch 4284, Loss 8.700520\n",
      "Params: tensor([  4.5191, -12.1809])\n",
      "Grad:   tensor([-0.0003,  0.0015])\n",
      "Epoch 4285, Loss 8.700520\n",
      "Params: tensor([  4.5191, -12.1809])\n",
      "Grad:   tensor([-0.0003,  0.0015])\n",
      "Epoch 4286, Loss 8.700519\n",
      "Params: tensor([  4.5191, -12.1809])\n",
      "Grad:   tensor([-0.0003,  0.0014])\n",
      "Epoch 4287, Loss 8.700519\n",
      "Params: tensor([  4.5191, -12.1810])\n",
      "Grad:   tensor([-0.0003,  0.0014])\n",
      "Epoch 4288, Loss 8.700520\n",
      "Params: tensor([  4.5191, -12.1810])\n",
      "Grad:   tensor([-0.0003,  0.0014])\n",
      "Epoch 4289, Loss 8.700520\n",
      "Params: tensor([  4.5191, -12.1810])\n",
      "Grad:   tensor([-0.0003,  0.0014])\n",
      "Epoch 4290, Loss 8.700521\n",
      "Params: tensor([  4.5191, -12.1810])\n",
      "Grad:   tensor([-0.0002,  0.0014])\n",
      "Epoch 4291, Loss 8.700518\n",
      "Params: tensor([  4.5191, -12.1810])\n",
      "Grad:   tensor([-0.0002,  0.0014])\n",
      "Epoch 4292, Loss 8.700520\n",
      "Params: tensor([  4.5191, -12.1810])\n",
      "Grad:   tensor([-0.0003,  0.0014])\n",
      "Epoch 4293, Loss 8.700519\n",
      "Params: tensor([  4.5191, -12.1810])\n",
      "Grad:   tensor([-0.0003,  0.0014])\n",
      "Epoch 4294, Loss 8.700519\n",
      "Params: tensor([  4.5191, -12.1811])\n",
      "Grad:   tensor([-0.0002,  0.0014])\n",
      "Epoch 4295, Loss 8.700520\n",
      "Params: tensor([  4.5191, -12.1811])\n",
      "Grad:   tensor([-0.0003,  0.0014])\n",
      "Epoch 4296, Loss 8.700520\n",
      "Params: tensor([  4.5191, -12.1811])\n",
      "Grad:   tensor([-0.0003,  0.0014])\n",
      "Epoch 4297, Loss 8.700519\n",
      "Params: tensor([  4.5191, -12.1811])\n",
      "Grad:   tensor([-0.0002,  0.0014])\n",
      "Epoch 4298, Loss 8.700520\n",
      "Params: tensor([  4.5191, -12.1811])\n",
      "Grad:   tensor([-0.0003,  0.0014])\n",
      "Epoch 4299, Loss 8.700520\n",
      "Params: tensor([  4.5191, -12.1811])\n",
      "Grad:   tensor([-0.0003,  0.0014])\n",
      "Epoch 4300, Loss 8.700519\n",
      "Params: tensor([  4.5191, -12.1811])\n",
      "Grad:   tensor([-0.0003,  0.0014])\n",
      "Epoch 4301, Loss 8.700519\n",
      "Params: tensor([  4.5191, -12.1812])\n",
      "Grad:   tensor([-0.0002,  0.0014])\n",
      "Epoch 4302, Loss 8.700520\n",
      "Params: tensor([  4.5191, -12.1812])\n",
      "Grad:   tensor([-0.0002,  0.0014])\n",
      "Epoch 4303, Loss 8.700519\n",
      "Params: tensor([  4.5191, -12.1812])\n",
      "Grad:   tensor([-0.0003,  0.0014])\n",
      "Epoch 4304, Loss 8.700520\n",
      "Params: tensor([  4.5191, -12.1812])\n",
      "Grad:   tensor([-0.0003,  0.0014])\n",
      "Epoch 4305, Loss 8.700519\n",
      "Params: tensor([  4.5191, -12.1812])\n",
      "Grad:   tensor([-0.0003,  0.0014])\n",
      "Epoch 4306, Loss 8.700520\n",
      "Params: tensor([  4.5191, -12.1812])\n",
      "Grad:   tensor([-0.0003,  0.0014])\n",
      "Epoch 4307, Loss 8.700519\n",
      "Params: tensor([  4.5192, -12.1812])\n",
      "Grad:   tensor([-0.0003,  0.0014])\n",
      "Epoch 4308, Loss 8.700519\n",
      "Params: tensor([  4.5192, -12.1813])\n",
      "Grad:   tensor([-0.0002,  0.0014])\n",
      "Epoch 4309, Loss 8.700520\n",
      "Params: tensor([  4.5192, -12.1813])\n",
      "Grad:   tensor([-0.0002,  0.0014])\n",
      "Epoch 4310, Loss 8.700517\n",
      "Params: tensor([  4.5192, -12.1813])\n",
      "Grad:   tensor([-0.0003,  0.0014])\n",
      "Epoch 4311, Loss 8.700520\n",
      "Params: tensor([  4.5192, -12.1813])\n",
      "Grad:   tensor([-0.0003,  0.0014])\n",
      "Epoch 4312, Loss 8.700520\n",
      "Params: tensor([  4.5192, -12.1813])\n",
      "Grad:   tensor([-0.0002,  0.0014])\n",
      "Epoch 4313, Loss 8.700520\n",
      "Params: tensor([  4.5192, -12.1813])\n",
      "Grad:   tensor([-0.0003,  0.0014])\n",
      "Epoch 4314, Loss 8.700520\n",
      "Params: tensor([  4.5192, -12.1813])\n",
      "Grad:   tensor([-0.0003,  0.0014])\n",
      "Epoch 4315, Loss 8.700517\n",
      "Params: tensor([  4.5192, -12.1814])\n",
      "Grad:   tensor([-0.0002,  0.0014])\n",
      "Epoch 4316, Loss 8.700519\n",
      "Params: tensor([  4.5192, -12.1814])\n",
      "Grad:   tensor([-0.0002,  0.0014])\n",
      "Epoch 4317, Loss 8.700517\n",
      "Params: tensor([  4.5192, -12.1814])\n",
      "Grad:   tensor([-0.0003,  0.0014])\n",
      "Epoch 4318, Loss 8.700519\n",
      "Params: tensor([  4.5192, -12.1814])\n",
      "Grad:   tensor([-0.0002,  0.0014])\n",
      "Epoch 4319, Loss 8.700517\n",
      "Params: tensor([  4.5192, -12.1814])\n",
      "Grad:   tensor([-0.0002,  0.0014])\n",
      "Epoch 4320, Loss 8.700519\n",
      "Params: tensor([  4.5192, -12.1814])\n",
      "Grad:   tensor([-0.0002,  0.0014])\n",
      "Epoch 4321, Loss 8.700520\n",
      "Params: tensor([  4.5192, -12.1814])\n",
      "Grad:   tensor([-0.0002,  0.0014])\n",
      "Epoch 4322, Loss 8.700520\n",
      "Params: tensor([  4.5192, -12.1814])\n",
      "Grad:   tensor([-0.0002,  0.0014])\n",
      "Epoch 4323, Loss 8.700520\n",
      "Params: tensor([  4.5192, -12.1815])\n",
      "Grad:   tensor([-0.0002,  0.0014])\n",
      "Epoch 4324, Loss 8.700519\n",
      "Params: tensor([  4.5192, -12.1815])\n",
      "Grad:   tensor([-0.0002,  0.0014])\n",
      "Epoch 4325, Loss 8.700519\n",
      "Params: tensor([  4.5192, -12.1815])\n",
      "Grad:   tensor([-0.0002,  0.0014])\n",
      "Epoch 4326, Loss 8.700519\n",
      "Params: tensor([  4.5192, -12.1815])\n",
      "Grad:   tensor([-0.0002,  0.0014])\n",
      "Epoch 4327, Loss 8.700519\n",
      "Params: tensor([  4.5192, -12.1815])\n",
      "Grad:   tensor([-0.0002,  0.0014])\n",
      "Epoch 4328, Loss 8.700519\n",
      "Params: tensor([  4.5192, -12.1815])\n",
      "Grad:   tensor([-0.0002,  0.0014])\n",
      "Epoch 4329, Loss 8.700520\n",
      "Params: tensor([  4.5192, -12.1815])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4330, Loss 8.700519\n",
      "Params: tensor([  4.5192, -12.1816])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4331, Loss 8.700520\n",
      "Params: tensor([  4.5192, -12.1816])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4332, Loss 8.700517\n",
      "Params: tensor([  4.5192, -12.1816])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4333, Loss 8.700517\n",
      "Params: tensor([  4.5192, -12.1816])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4334, Loss 8.700517\n",
      "Params: tensor([  4.5192, -12.1816])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4335, Loss 8.700517\n",
      "Params: tensor([  4.5192, -12.1816])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4336, Loss 8.700518\n",
      "Params: tensor([  4.5192, -12.1816])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4337, Loss 8.700517\n",
      "Params: tensor([  4.5192, -12.1816])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4338, Loss 8.700519\n",
      "Params: tensor([  4.5192, -12.1817])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4339, Loss 8.700519\n",
      "Params: tensor([  4.5192, -12.1817])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4340, Loss 8.700520\n",
      "Params: tensor([  4.5192, -12.1817])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4341, Loss 8.700517\n",
      "Params: tensor([  4.5192, -12.1817])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4342, Loss 8.700517\n",
      "Params: tensor([  4.5192, -12.1817])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4343, Loss 8.700519\n",
      "Params: tensor([  4.5192, -12.1817])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4344, Loss 8.700517\n",
      "Params: tensor([  4.5192, -12.1817])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4345, Loss 8.700520\n",
      "Params: tensor([  4.5192, -12.1818])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4346, Loss 8.700519\n",
      "Params: tensor([  4.5192, -12.1818])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4347, Loss 8.700519\n",
      "Params: tensor([  4.5192, -12.1818])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4348, Loss 8.700519\n",
      "Params: tensor([  4.5192, -12.1818])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4349, Loss 8.700519\n",
      "Params: tensor([  4.5193, -12.1818])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4350, Loss 8.700517\n",
      "Params: tensor([  4.5193, -12.1818])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4351, Loss 8.700517\n",
      "Params: tensor([  4.5193, -12.1818])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4352, Loss 8.700519\n",
      "Params: tensor([  4.5193, -12.1818])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4353, Loss 8.700517\n",
      "Params: tensor([  4.5193, -12.1819])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4354, Loss 8.700519\n",
      "Params: tensor([  4.5193, -12.1819])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4355, Loss 8.700518\n",
      "Params: tensor([  4.5193, -12.1819])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4356, Loss 8.700520\n",
      "Params: tensor([  4.5193, -12.1819])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4357, Loss 8.700519\n",
      "Params: tensor([  4.5193, -12.1819])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4358, Loss 8.700517\n",
      "Params: tensor([  4.5193, -12.1819])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4359, Loss 8.700517\n",
      "Params: tensor([  4.5193, -12.1819])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4360, Loss 8.700519\n",
      "Params: tensor([  4.5193, -12.1819])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4361, Loss 8.700519\n",
      "Params: tensor([  4.5193, -12.1820])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4362, Loss 8.700517\n",
      "Params: tensor([  4.5193, -12.1820])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4363, Loss 8.700518\n",
      "Params: tensor([  4.5193, -12.1820])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4364, Loss 8.700519\n",
      "Params: tensor([  4.5193, -12.1820])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4365, Loss 8.700517\n",
      "Params: tensor([  4.5193, -12.1820])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4366, Loss 8.700520\n",
      "Params: tensor([  4.5193, -12.1820])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4367, Loss 8.700517\n",
      "Params: tensor([  4.5193, -12.1820])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4368, Loss 8.700518\n",
      "Params: tensor([  4.5193, -12.1820])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4369, Loss 8.700517\n",
      "Params: tensor([  4.5193, -12.1821])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4370, Loss 8.700517\n",
      "Params: tensor([  4.5193, -12.1821])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4371, Loss 8.700517\n",
      "Params: tensor([  4.5193, -12.1821])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4372, Loss 8.700520\n",
      "Params: tensor([  4.5193, -12.1821])\n",
      "Grad:   tensor([-0.0002,  0.0013])\n",
      "Epoch 4373, Loss 8.700518\n",
      "Params: tensor([  4.5193, -12.1821])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4374, Loss 8.700517\n",
      "Params: tensor([  4.5193, -12.1821])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4375, Loss 8.700518\n",
      "Params: tensor([  4.5193, -12.1821])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4376, Loss 8.700517\n",
      "Params: tensor([  4.5193, -12.1821])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4377, Loss 8.700517\n",
      "Params: tensor([  4.5193, -12.1822])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4378, Loss 8.700517\n",
      "Params: tensor([  4.5193, -12.1822])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4379, Loss 8.700517\n",
      "Params: tensor([  4.5193, -12.1822])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4380, Loss 8.700519\n",
      "Params: tensor([  4.5193, -12.1822])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4381, Loss 8.700517\n",
      "Params: tensor([  4.5193, -12.1822])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4382, Loss 8.700519\n",
      "Params: tensor([  4.5193, -12.1822])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4383, Loss 8.700519\n",
      "Params: tensor([  4.5193, -12.1822])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4384, Loss 8.700519\n",
      "Params: tensor([  4.5193, -12.1822])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4385, Loss 8.700519\n",
      "Params: tensor([  4.5193, -12.1823])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4386, Loss 8.700516\n",
      "Params: tensor([  4.5193, -12.1823])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4387, Loss 8.700516\n",
      "Params: tensor([  4.5193, -12.1823])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4388, Loss 8.700519\n",
      "Params: tensor([  4.5193, -12.1823])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4389, Loss 8.700517\n",
      "Params: tensor([  4.5193, -12.1823])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4390, Loss 8.700518\n",
      "Params: tensor([  4.5193, -12.1823])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4391, Loss 8.700518\n",
      "Params: tensor([  4.5193, -12.1823])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4392, Loss 8.700519\n",
      "Params: tensor([  4.5193, -12.1823])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4393, Loss 8.700518\n",
      "Params: tensor([  4.5193, -12.1824])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4394, Loss 8.700519\n",
      "Params: tensor([  4.5194, -12.1824])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4395, Loss 8.700515\n",
      "Params: tensor([  4.5194, -12.1824])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4396, Loss 8.700517\n",
      "Params: tensor([  4.5194, -12.1824])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4397, Loss 8.700517\n",
      "Params: tensor([  4.5194, -12.1824])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4398, Loss 8.700515\n",
      "Params: tensor([  4.5194, -12.1824])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4399, Loss 8.700517\n",
      "Params: tensor([  4.5194, -12.1824])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4400, Loss 8.700519\n",
      "Params: tensor([  4.5194, -12.1824])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4401, Loss 8.700519\n",
      "Params: tensor([  4.5194, -12.1825])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4402, Loss 8.700519\n",
      "Params: tensor([  4.5194, -12.1825])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4403, Loss 8.700519\n",
      "Params: tensor([  4.5194, -12.1825])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4404, Loss 8.700517\n",
      "Params: tensor([  4.5194, -12.1825])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4405, Loss 8.700519\n",
      "Params: tensor([  4.5194, -12.1825])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4406, Loss 8.700516\n",
      "Params: tensor([  4.5194, -12.1825])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4407, Loss 8.700517\n",
      "Params: tensor([  4.5194, -12.1825])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4408, Loss 8.700518\n",
      "Params: tensor([  4.5194, -12.1825])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4409, Loss 8.700517\n",
      "Params: tensor([  4.5194, -12.1825])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4410, Loss 8.700518\n",
      "Params: tensor([  4.5194, -12.1826])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4411, Loss 8.700518\n",
      "Params: tensor([  4.5194, -12.1826])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4412, Loss 8.700517\n",
      "Params: tensor([  4.5194, -12.1826])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4413, Loss 8.700520\n",
      "Params: tensor([  4.5194, -12.1826])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4414, Loss 8.700517\n",
      "Params: tensor([  4.5194, -12.1826])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4415, Loss 8.700517\n",
      "Params: tensor([  4.5194, -12.1826])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4416, Loss 8.700517\n",
      "Params: tensor([  4.5194, -12.1826])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4417, Loss 8.700517\n",
      "Params: tensor([  4.5194, -12.1826])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4418, Loss 8.700519\n",
      "Params: tensor([  4.5194, -12.1826])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4419, Loss 8.700517\n",
      "Params: tensor([  4.5194, -12.1827])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4420, Loss 8.700517\n",
      "Params: tensor([  4.5194, -12.1827])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4421, Loss 8.700518\n",
      "Params: tensor([  4.5194, -12.1827])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4422, Loss 8.700518\n",
      "Params: tensor([  4.5194, -12.1827])\n",
      "Grad:   tensor([-0.0002,  0.0012])\n",
      "Epoch 4423, Loss 8.700519\n",
      "Params: tensor([  4.5194, -12.1827])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4424, Loss 8.700516\n",
      "Params: tensor([  4.5194, -12.1827])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4425, Loss 8.700518\n",
      "Params: tensor([  4.5194, -12.1827])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4426, Loss 8.700517\n",
      "Params: tensor([  4.5194, -12.1827])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4427, Loss 8.700516\n",
      "Params: tensor([  4.5194, -12.1828])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4428, Loss 8.700517\n",
      "Params: tensor([  4.5194, -12.1828])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4429, Loss 8.700519\n",
      "Params: tensor([  4.5194, -12.1828])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4430, Loss 8.700517\n",
      "Params: tensor([  4.5194, -12.1828])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4431, Loss 8.700517\n",
      "Params: tensor([  4.5194, -12.1828])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4432, Loss 8.700517\n",
      "Params: tensor([  4.5194, -12.1828])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4433, Loss 8.700518\n",
      "Params: tensor([  4.5194, -12.1828])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4434, Loss 8.700517\n",
      "Params: tensor([  4.5194, -12.1828])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4435, Loss 8.700516\n",
      "Params: tensor([  4.5194, -12.1828])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4436, Loss 8.700517\n",
      "Params: tensor([  4.5194, -12.1829])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4437, Loss 8.700516\n",
      "Params: tensor([  4.5194, -12.1829])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4438, Loss 8.700517\n",
      "Params: tensor([  4.5194, -12.1829])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4439, Loss 8.700517\n",
      "Params: tensor([  4.5194, -12.1829])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4440, Loss 8.700518\n",
      "Params: tensor([  4.5194, -12.1829])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4441, Loss 8.700518\n",
      "Params: tensor([  4.5194, -12.1829])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4442, Loss 8.700519\n",
      "Params: tensor([  4.5194, -12.1829])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4443, Loss 8.700517\n",
      "Params: tensor([  4.5195, -12.1829])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4444, Loss 8.700517\n",
      "Params: tensor([  4.5195, -12.1829])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4445, Loss 8.700515\n",
      "Params: tensor([  4.5195, -12.1830])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4446, Loss 8.700515\n",
      "Params: tensor([  4.5195, -12.1830])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4447, Loss 8.700517\n",
      "Params: tensor([  4.5195, -12.1830])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4448, Loss 8.700515\n",
      "Params: tensor([  4.5195, -12.1830])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4449, Loss 8.700517\n",
      "Params: tensor([  4.5195, -12.1830])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4450, Loss 8.700519\n",
      "Params: tensor([  4.5195, -12.1830])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4451, Loss 8.700517\n",
      "Params: tensor([  4.5195, -12.1830])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4452, Loss 8.700517\n",
      "Params: tensor([  4.5195, -12.1830])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4453, Loss 8.700517\n",
      "Params: tensor([  4.5195, -12.1830])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4454, Loss 8.700516\n",
      "Params: tensor([  4.5195, -12.1831])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4455, Loss 8.700516\n",
      "Params: tensor([  4.5195, -12.1831])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4456, Loss 8.700517\n",
      "Params: tensor([  4.5195, -12.1831])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4457, Loss 8.700515\n",
      "Params: tensor([  4.5195, -12.1831])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4458, Loss 8.700517\n",
      "Params: tensor([  4.5195, -12.1831])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4459, Loss 8.700515\n",
      "Params: tensor([  4.5195, -12.1831])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4460, Loss 8.700517\n",
      "Params: tensor([  4.5195, -12.1831])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4461, Loss 8.700520\n",
      "Params: tensor([  4.5195, -12.1831])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4462, Loss 8.700519\n",
      "Params: tensor([  4.5195, -12.1831])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4463, Loss 8.700518\n",
      "Params: tensor([  4.5195, -12.1831])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4464, Loss 8.700516\n",
      "Params: tensor([  4.5195, -12.1832])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4465, Loss 8.700515\n",
      "Params: tensor([  4.5195, -12.1832])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4466, Loss 8.700517\n",
      "Params: tensor([  4.5195, -12.1832])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4467, Loss 8.700517\n",
      "Params: tensor([  4.5195, -12.1832])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4468, Loss 8.700516\n",
      "Params: tensor([  4.5195, -12.1832])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4469, Loss 8.700517\n",
      "Params: tensor([  4.5195, -12.1832])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4470, Loss 8.700517\n",
      "Params: tensor([  4.5195, -12.1832])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4471, Loss 8.700517\n",
      "Params: tensor([  4.5195, -12.1832])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4472, Loss 8.700517\n",
      "Params: tensor([  4.5195, -12.1832])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4473, Loss 8.700518\n",
      "Params: tensor([  4.5195, -12.1833])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4474, Loss 8.700517\n",
      "Params: tensor([  4.5195, -12.1833])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4475, Loss 8.700519\n",
      "Params: tensor([  4.5195, -12.1833])\n",
      "Grad:   tensor([-0.0002,  0.0011])\n",
      "Epoch 4476, Loss 8.700515\n",
      "Params: tensor([  4.5195, -12.1833])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4477, Loss 8.700517\n",
      "Params: tensor([  4.5195, -12.1833])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4478, Loss 8.700519\n",
      "Params: tensor([  4.5195, -12.1833])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4479, Loss 8.700517\n",
      "Params: tensor([  4.5195, -12.1833])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4480, Loss 8.700516\n",
      "Params: tensor([  4.5195, -12.1833])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4481, Loss 8.700516\n",
      "Params: tensor([  4.5195, -12.1833])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4482, Loss 8.700517\n",
      "Params: tensor([  4.5195, -12.1833])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4483, Loss 8.700516\n",
      "Params: tensor([  4.5195, -12.1834])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4484, Loss 8.700517\n",
      "Params: tensor([  4.5195, -12.1834])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4485, Loss 8.700518\n",
      "Params: tensor([  4.5195, -12.1834])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4486, Loss 8.700515\n",
      "Params: tensor([  4.5195, -12.1834])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4487, Loss 8.700517\n",
      "Params: tensor([  4.5195, -12.1834])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4488, Loss 8.700516\n",
      "Params: tensor([  4.5195, -12.1834])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4489, Loss 8.700516\n",
      "Params: tensor([  4.5195, -12.1834])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4490, Loss 8.700517\n",
      "Params: tensor([  4.5195, -12.1834])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4491, Loss 8.700516\n",
      "Params: tensor([  4.5195, -12.1834])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4492, Loss 8.700518\n",
      "Params: tensor([  4.5195, -12.1835])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4493, Loss 8.700515\n",
      "Params: tensor([  4.5195, -12.1835])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4494, Loss 8.700519\n",
      "Params: tensor([  4.5195, -12.1835])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4495, Loss 8.700517\n",
      "Params: tensor([  4.5195, -12.1835])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4496, Loss 8.700515\n",
      "Params: tensor([  4.5196, -12.1835])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4497, Loss 8.700515\n",
      "Params: tensor([  4.5196, -12.1835])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4498, Loss 8.700517\n",
      "Params: tensor([  4.5196, -12.1835])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4499, Loss 8.700516\n",
      "Params: tensor([  4.5196, -12.1835])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4500, Loss 8.700515\n",
      "Params: tensor([  4.5196, -12.1835])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4501, Loss 8.700516\n",
      "Params: tensor([  4.5196, -12.1835])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4502, Loss 8.700515\n",
      "Params: tensor([  4.5196, -12.1836])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4503, Loss 8.700516\n",
      "Params: tensor([  4.5196, -12.1836])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4504, Loss 8.700517\n",
      "Params: tensor([  4.5196, -12.1836])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4505, Loss 8.700519\n",
      "Params: tensor([  4.5196, -12.1836])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4506, Loss 8.700518\n",
      "Params: tensor([  4.5196, -12.1836])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4507, Loss 8.700519\n",
      "Params: tensor([  4.5196, -12.1836])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4508, Loss 8.700515\n",
      "Params: tensor([  4.5196, -12.1836])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4509, Loss 8.700517\n",
      "Params: tensor([  4.5196, -12.1836])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4510, Loss 8.700515\n",
      "Params: tensor([  4.5196, -12.1836])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4511, Loss 8.700517\n",
      "Params: tensor([  4.5196, -12.1836])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4512, Loss 8.700515\n",
      "Params: tensor([  4.5196, -12.1837])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4513, Loss 8.700517\n",
      "Params: tensor([  4.5196, -12.1837])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4514, Loss 8.700516\n",
      "Params: tensor([  4.5196, -12.1837])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4515, Loss 8.700517\n",
      "Params: tensor([  4.5196, -12.1837])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4516, Loss 8.700517\n",
      "Params: tensor([  4.5196, -12.1837])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4517, Loss 8.700517\n",
      "Params: tensor([  4.5196, -12.1837])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4518, Loss 8.700516\n",
      "Params: tensor([  4.5196, -12.1837])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4519, Loss 8.700517\n",
      "Params: tensor([  4.5196, -12.1837])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4520, Loss 8.700513\n",
      "Params: tensor([  4.5196, -12.1837])\n",
      "Grad:   tensor([-0.0001,  0.0010])\n",
      "Epoch 4521, Loss 8.700515\n",
      "Params: tensor([  4.5196, -12.1837])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4522, Loss 8.700515\n",
      "Params: tensor([  4.5196, -12.1837])\n",
      "Grad:   tensor([-0.0001,  0.0010])\n",
      "Epoch 4523, Loss 8.700516\n",
      "Params: tensor([  4.5196, -12.1838])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4524, Loss 8.700516\n",
      "Params: tensor([  4.5196, -12.1838])\n",
      "Grad:   tensor([-0.0001,  0.0010])\n",
      "Epoch 4525, Loss 8.700517\n",
      "Params: tensor([  4.5196, -12.1838])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4526, Loss 8.700515\n",
      "Params: tensor([  4.5196, -12.1838])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4527, Loss 8.700517\n",
      "Params: tensor([  4.5196, -12.1838])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4528, Loss 8.700516\n",
      "Params: tensor([  4.5196, -12.1838])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4529, Loss 8.700517\n",
      "Params: tensor([  4.5196, -12.1838])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4530, Loss 8.700515\n",
      "Params: tensor([  4.5196, -12.1838])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4531, Loss 8.700517\n",
      "Params: tensor([  4.5196, -12.1838])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4532, Loss 8.700515\n",
      "Params: tensor([  4.5196, -12.1838])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4533, Loss 8.700515\n",
      "Params: tensor([  4.5196, -12.1839])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4534, Loss 8.700514\n",
      "Params: tensor([  4.5196, -12.1839])\n",
      "Grad:   tensor([-0.0002,  0.0010])\n",
      "Epoch 4535, Loss 8.700516\n",
      "Params: tensor([  4.5196, -12.1839])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4536, Loss 8.700515\n",
      "Params: tensor([  4.5196, -12.1839])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4537, Loss 8.700515\n",
      "Params: tensor([  4.5196, -12.1839])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4538, Loss 8.700516\n",
      "Params: tensor([  4.5196, -12.1839])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4539, Loss 8.700517\n",
      "Params: tensor([  4.5196, -12.1839])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4540, Loss 8.700515\n",
      "Params: tensor([  4.5196, -12.1839])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4541, Loss 8.700517\n",
      "Params: tensor([  4.5196, -12.1839])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4542, Loss 8.700515\n",
      "Params: tensor([  4.5196, -12.1839])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4543, Loss 8.700517\n",
      "Params: tensor([  4.5196, -12.1839])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4544, Loss 8.700512\n",
      "Params: tensor([  4.5196, -12.1840])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4545, Loss 8.700516\n",
      "Params: tensor([  4.5196, -12.1840])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4546, Loss 8.700515\n",
      "Params: tensor([  4.5196, -12.1840])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4547, Loss 8.700515\n",
      "Params: tensor([  4.5196, -12.1840])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4548, Loss 8.700514\n",
      "Params: tensor([  4.5196, -12.1840])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4549, Loss 8.700515\n",
      "Params: tensor([  4.5196, -12.1840])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4550, Loss 8.700516\n",
      "Params: tensor([  4.5196, -12.1840])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4551, Loss 8.700517\n",
      "Params: tensor([  4.5196, -12.1840])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4552, Loss 8.700514\n",
      "Params: tensor([  4.5196, -12.1840])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4553, Loss 8.700516\n",
      "Params: tensor([  4.5196, -12.1840])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4554, Loss 8.700516\n",
      "Params: tensor([  4.5196, -12.1841])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4555, Loss 8.700516\n",
      "Params: tensor([  4.5197, -12.1841])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4556, Loss 8.700513\n",
      "Params: tensor([  4.5197, -12.1841])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4557, Loss 8.700517\n",
      "Params: tensor([  4.5197, -12.1841])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4558, Loss 8.700515\n",
      "Params: tensor([  4.5197, -12.1841])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4559, Loss 8.700516\n",
      "Params: tensor([  4.5197, -12.1841])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4560, Loss 8.700515\n",
      "Params: tensor([  4.5197, -12.1841])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4561, Loss 8.700517\n",
      "Params: tensor([  4.5197, -12.1841])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4562, Loss 8.700516\n",
      "Params: tensor([  4.5197, -12.1841])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4563, Loss 8.700515\n",
      "Params: tensor([  4.5197, -12.1841])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4564, Loss 8.700517\n",
      "Params: tensor([  4.5197, -12.1841])\n",
      "Grad:   tensor([-0.0001,  0.0009])\n",
      "Epoch 4565, Loss 8.700517\n",
      "Params: tensor([  4.5197, -12.1842])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4566, Loss 8.700515\n",
      "Params: tensor([  4.5197, -12.1842])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4567, Loss 8.700516\n",
      "Params: tensor([  4.5197, -12.1842])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4568, Loss 8.700517\n",
      "Params: tensor([  4.5197, -12.1842])\n",
      "Grad:   tensor([-0.0001,  0.0009])\n",
      "Epoch 4569, Loss 8.700515\n",
      "Params: tensor([  4.5197, -12.1842])\n",
      "Grad:   tensor([-0.0001,  0.0009])\n",
      "Epoch 4570, Loss 8.700515\n",
      "Params: tensor([  4.5197, -12.1842])\n",
      "Grad:   tensor([-0.0001,  0.0009])\n",
      "Epoch 4571, Loss 8.700517\n",
      "Params: tensor([  4.5197, -12.1842])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4572, Loss 8.700515\n",
      "Params: tensor([  4.5197, -12.1842])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4573, Loss 8.700516\n",
      "Params: tensor([  4.5197, -12.1842])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4574, Loss 8.700516\n",
      "Params: tensor([  4.5197, -12.1842])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4575, Loss 8.700515\n",
      "Params: tensor([  4.5197, -12.1842])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4576, Loss 8.700515\n",
      "Params: tensor([  4.5197, -12.1842])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4577, Loss 8.700517\n",
      "Params: tensor([  4.5197, -12.1843])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4578, Loss 8.700516\n",
      "Params: tensor([  4.5197, -12.1843])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4579, Loss 8.700516\n",
      "Params: tensor([  4.5197, -12.1843])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4580, Loss 8.700517\n",
      "Params: tensor([  4.5197, -12.1843])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4581, Loss 8.700519\n",
      "Params: tensor([  4.5197, -12.1843])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4582, Loss 8.700515\n",
      "Params: tensor([  4.5197, -12.1843])\n",
      "Grad:   tensor([-0.0001,  0.0009])\n",
      "Epoch 4583, Loss 8.700513\n",
      "Params: tensor([  4.5197, -12.1843])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4584, Loss 8.700515\n",
      "Params: tensor([  4.5197, -12.1843])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4585, Loss 8.700516\n",
      "Params: tensor([  4.5197, -12.1843])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4586, Loss 8.700516\n",
      "Params: tensor([  4.5197, -12.1843])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4587, Loss 8.700515\n",
      "Params: tensor([  4.5197, -12.1843])\n",
      "Grad:   tensor([-0.0001,  0.0009])\n",
      "Epoch 4588, Loss 8.700517\n",
      "Params: tensor([  4.5197, -12.1844])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4589, Loss 8.700516\n",
      "Params: tensor([  4.5197, -12.1844])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4590, Loss 8.700515\n",
      "Params: tensor([  4.5197, -12.1844])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4591, Loss 8.700516\n",
      "Params: tensor([  4.5197, -12.1844])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4592, Loss 8.700517\n",
      "Params: tensor([  4.5197, -12.1844])\n",
      "Grad:   tensor([-0.0001,  0.0009])\n",
      "Epoch 4593, Loss 8.700516\n",
      "Params: tensor([  4.5197, -12.1844])\n",
      "Grad:   tensor([-0.0001,  0.0009])\n",
      "Epoch 4594, Loss 8.700517\n",
      "Params: tensor([  4.5197, -12.1844])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4595, Loss 8.700516\n",
      "Params: tensor([  4.5197, -12.1844])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4596, Loss 8.700515\n",
      "Params: tensor([  4.5197, -12.1844])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4597, Loss 8.700515\n",
      "Params: tensor([  4.5197, -12.1844])\n",
      "Grad:   tensor([-0.0002,  0.0009])\n",
      "Epoch 4598, Loss 8.700515\n",
      "Params: tensor([  4.5197, -12.1844])\n",
      "Grad:   tensor([-0.0002,  0.0008])\n",
      "Epoch 4599, Loss 8.700515\n",
      "Params: tensor([  4.5197, -12.1844])\n",
      "Grad:   tensor([-0.0001,  0.0009])\n",
      "Epoch 4600, Loss 8.700515\n",
      "Params: tensor([  4.5197, -12.1845])\n",
      "Grad:   tensor([-0.0002,  0.0008])\n",
      "Epoch 4601, Loss 8.700515\n",
      "Params: tensor([  4.5197, -12.1845])\n",
      "Grad:   tensor([-0.0002,  0.0008])\n",
      "Epoch 4602, Loss 8.700516\n",
      "Params: tensor([  4.5197, -12.1845])\n",
      "Grad:   tensor([-0.0002,  0.0008])\n",
      "Epoch 4603, Loss 8.700515\n",
      "Params: tensor([  4.5197, -12.1845])\n",
      "Grad:   tensor([-0.0002,  0.0008])\n",
      "Epoch 4604, Loss 8.700516\n",
      "Params: tensor([  4.5197, -12.1845])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4605, Loss 8.700517\n",
      "Params: tensor([  4.5197, -12.1845])\n",
      "Grad:   tensor([-0.0002,  0.0008])\n",
      "Epoch 4606, Loss 8.700518\n",
      "Params: tensor([  4.5197, -12.1845])\n",
      "Grad:   tensor([-0.0002,  0.0008])\n",
      "Epoch 4607, Loss 8.700515\n",
      "Params: tensor([  4.5197, -12.1845])\n",
      "Grad:   tensor([-0.0002,  0.0008])\n",
      "Epoch 4608, Loss 8.700516\n",
      "Params: tensor([  4.5197, -12.1845])\n",
      "Grad:   tensor([-0.0002,  0.0008])\n",
      "Epoch 4609, Loss 8.700517\n",
      "Params: tensor([  4.5197, -12.1845])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4610, Loss 8.700515\n",
      "Params: tensor([  4.5197, -12.1845])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4611, Loss 8.700513\n",
      "Params: tensor([  4.5197, -12.1845])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4612, Loss 8.700516\n",
      "Params: tensor([  4.5197, -12.1846])\n",
      "Grad:   tensor([-0.0002,  0.0008])\n",
      "Epoch 4613, Loss 8.700516\n",
      "Params: tensor([  4.5197, -12.1846])\n",
      "Grad:   tensor([-0.0002,  0.0008])\n",
      "Epoch 4614, Loss 8.700513\n",
      "Params: tensor([  4.5197, -12.1846])\n",
      "Grad:   tensor([-0.0002,  0.0008])\n",
      "Epoch 4615, Loss 8.700515\n",
      "Params: tensor([  4.5197, -12.1846])\n",
      "Grad:   tensor([-0.0002,  0.0008])\n",
      "Epoch 4616, Loss 8.700517\n",
      "Params: tensor([  4.5197, -12.1846])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4617, Loss 8.700515\n",
      "Params: tensor([  4.5197, -12.1846])\n",
      "Grad:   tensor([-0.0002,  0.0008])\n",
      "Epoch 4618, Loss 8.700516\n",
      "Params: tensor([  4.5197, -12.1846])\n",
      "Grad:   tensor([-0.0002,  0.0008])\n",
      "Epoch 4619, Loss 8.700517\n",
      "Params: tensor([  4.5197, -12.1846])\n",
      "Grad:   tensor([-0.0002,  0.0008])\n",
      "Epoch 4620, Loss 8.700517\n",
      "Params: tensor([  4.5198, -12.1846])\n",
      "Grad:   tensor([-0.0002,  0.0008])\n",
      "Epoch 4621, Loss 8.700516\n",
      "Params: tensor([  4.5198, -12.1846])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4622, Loss 8.700516\n",
      "Params: tensor([  4.5198, -12.1846])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4623, Loss 8.700515\n",
      "Params: tensor([  4.5198, -12.1847])\n",
      "Grad:   tensor([-0.0002,  0.0008])\n",
      "Epoch 4624, Loss 8.700516\n",
      "Params: tensor([  4.5198, -12.1847])\n",
      "Grad:   tensor([-0.0002,  0.0008])\n",
      "Epoch 4625, Loss 8.700516\n",
      "Params: tensor([  4.5198, -12.1847])\n",
      "Grad:   tensor([-0.0002,  0.0008])\n",
      "Epoch 4626, Loss 8.700516\n",
      "Params: tensor([  4.5198, -12.1847])\n",
      "Grad:   tensor([-0.0002,  0.0008])\n",
      "Epoch 4627, Loss 8.700516\n",
      "Params: tensor([  4.5198, -12.1847])\n",
      "Grad:   tensor([-0.0002,  0.0008])\n",
      "Epoch 4628, Loss 8.700515\n",
      "Params: tensor([  4.5198, -12.1847])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4629, Loss 8.700516\n",
      "Params: tensor([  4.5198, -12.1847])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4630, Loss 8.700516\n",
      "Params: tensor([  4.5198, -12.1847])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4631, Loss 8.700516\n",
      "Params: tensor([  4.5198, -12.1847])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4632, Loss 8.700517\n",
      "Params: tensor([  4.5198, -12.1847])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4633, Loss 8.700516\n",
      "Params: tensor([  4.5198, -12.1847])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4634, Loss 8.700517\n",
      "Params: tensor([  4.5198, -12.1847])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4635, Loss 8.700517\n",
      "Params: tensor([  4.5198, -12.1847])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4636, Loss 8.700515\n",
      "Params: tensor([  4.5198, -12.1848])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4637, Loss 8.700515\n",
      "Params: tensor([  4.5198, -12.1848])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4638, Loss 8.700516\n",
      "Params: tensor([  4.5198, -12.1848])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4639, Loss 8.700516\n",
      "Params: tensor([  4.5198, -12.1848])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4640, Loss 8.700515\n",
      "Params: tensor([  4.5198, -12.1848])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4641, Loss 8.700515\n",
      "Params: tensor([  4.5198, -12.1848])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4642, Loss 8.700515\n",
      "Params: tensor([  4.5198, -12.1848])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4643, Loss 8.700516\n",
      "Params: tensor([  4.5198, -12.1848])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4644, Loss 8.700515\n",
      "Params: tensor([  4.5198, -12.1848])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4645, Loss 8.700516\n",
      "Params: tensor([  4.5198, -12.1848])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4646, Loss 8.700517\n",
      "Params: tensor([  4.5198, -12.1848])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4647, Loss 8.700516\n",
      "Params: tensor([  4.5198, -12.1848])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4648, Loss 8.700516\n",
      "Params: tensor([  4.5198, -12.1848])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4649, Loss 8.700516\n",
      "Params: tensor([  4.5198, -12.1849])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4650, Loss 8.700517\n",
      "Params: tensor([  4.5198, -12.1849])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4651, Loss 8.700513\n",
      "Params: tensor([  4.5198, -12.1849])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4652, Loss 8.700515\n",
      "Params: tensor([  4.5198, -12.1849])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4653, Loss 8.700516\n",
      "Params: tensor([  4.5198, -12.1849])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4654, Loss 8.700515\n",
      "Params: tensor([  4.5198, -12.1849])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4655, Loss 8.700515\n",
      "Params: tensor([  4.5198, -12.1849])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4656, Loss 8.700516\n",
      "Params: tensor([  4.5198, -12.1849])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4657, Loss 8.700515\n",
      "Params: tensor([  4.5198, -12.1849])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4658, Loss 8.700516\n",
      "Params: tensor([  4.5198, -12.1849])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4659, Loss 8.700516\n",
      "Params: tensor([  4.5198, -12.1849])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4660, Loss 8.700515\n",
      "Params: tensor([  4.5198, -12.1849])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4661, Loss 8.700516\n",
      "Params: tensor([  4.5198, -12.1849])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4662, Loss 8.700516\n",
      "Params: tensor([  4.5198, -12.1850])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4663, Loss 8.700517\n",
      "Params: tensor([  4.5198, -12.1850])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4664, Loss 8.700517\n",
      "Params: tensor([  4.5198, -12.1850])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4665, Loss 8.700516\n",
      "Params: tensor([  4.5198, -12.1850])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4666, Loss 8.700515\n",
      "Params: tensor([  4.5198, -12.1850])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4667, Loss 8.700515\n",
      "Params: tensor([  4.5198, -12.1850])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4668, Loss 8.700515\n",
      "Params: tensor([  4.5198, -12.1850])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4669, Loss 8.700515\n",
      "Params: tensor([  4.5198, -12.1850])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4670, Loss 8.700513\n",
      "Params: tensor([  4.5198, -12.1850])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4671, Loss 8.700515\n",
      "Params: tensor([  4.5198, -12.1850])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4672, Loss 8.700516\n",
      "Params: tensor([  4.5198, -12.1850])\n",
      "Grad:   tensor([-0.0001,  0.0008])\n",
      "Epoch 4673, Loss 8.700516\n",
      "Params: tensor([  4.5198, -12.1850])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4674, Loss 8.700516\n",
      "Params: tensor([  4.5198, -12.1850])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4675, Loss 8.700515\n",
      "Params: tensor([  4.5198, -12.1851])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4676, Loss 8.700516\n",
      "Params: tensor([  4.5198, -12.1851])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4677, Loss 8.700517\n",
      "Params: tensor([  4.5198, -12.1851])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4678, Loss 8.700517\n",
      "Params: tensor([  4.5198, -12.1851])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4679, Loss 8.700516\n",
      "Params: tensor([  4.5198, -12.1851])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4680, Loss 8.700517\n",
      "Params: tensor([  4.5198, -12.1851])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4681, Loss 8.700515\n",
      "Params: tensor([  4.5198, -12.1851])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4682, Loss 8.700516\n",
      "Params: tensor([  4.5198, -12.1851])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4683, Loss 8.700515\n",
      "Params: tensor([  4.5198, -12.1851])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4684, Loss 8.700515\n",
      "Params: tensor([  4.5198, -12.1851])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4685, Loss 8.700516\n",
      "Params: tensor([  4.5198, -12.1851])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4686, Loss 8.700516\n",
      "Params: tensor([  4.5198, -12.1851])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4687, Loss 8.700515\n",
      "Params: tensor([  4.5198, -12.1851])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4688, Loss 8.700515\n",
      "Params: tensor([  4.5198, -12.1851])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4689, Loss 8.700516\n",
      "Params: tensor([  4.5198, -12.1852])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4690, Loss 8.700517\n",
      "Params: tensor([  4.5198, -12.1852])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4691, Loss 8.700515\n",
      "Params: tensor([  4.5198, -12.1852])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4692, Loss 8.700516\n",
      "Params: tensor([  4.5198, -12.1852])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4693, Loss 8.700517\n",
      "Params: tensor([  4.5198, -12.1852])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4694, Loss 8.700516\n",
      "Params: tensor([  4.5199, -12.1852])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4695, Loss 8.700517\n",
      "Params: tensor([  4.5199, -12.1852])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4696, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1852])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4697, Loss 8.700513\n",
      "Params: tensor([  4.5199, -12.1852])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4698, Loss 8.700516\n",
      "Params: tensor([  4.5199, -12.1852])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4699, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1852])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4700, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1852])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4701, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1852])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4702, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1853])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4703, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1853])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4704, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1853])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4705, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1853])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4706, Loss 8.700516\n",
      "Params: tensor([  4.5199, -12.1853])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4707, Loss 8.700513\n",
      "Params: tensor([  4.5199, -12.1853])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4708, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1853])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4709, Loss 8.700516\n",
      "Params: tensor([  4.5199, -12.1853])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4710, Loss 8.700517\n",
      "Params: tensor([  4.5199, -12.1853])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4711, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1853])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4712, Loss 8.700513\n",
      "Params: tensor([  4.5199, -12.1853])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4713, Loss 8.700513\n",
      "Params: tensor([  4.5199, -12.1853])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4714, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1853])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4715, Loss 8.700514\n",
      "Params: tensor([  4.5199, -12.1853])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4716, Loss 8.700513\n",
      "Params: tensor([  4.5199, -12.1853])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4717, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1854])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4718, Loss 8.700514\n",
      "Params: tensor([  4.5199, -12.1854])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4719, Loss 8.700513\n",
      "Params: tensor([  4.5199, -12.1854])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4720, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1854])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4721, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1854])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4722, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1854])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4723, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1854])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4724, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1854])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4725, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1854])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4726, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1854])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4727, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1854])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4728, Loss 8.700517\n",
      "Params: tensor([  4.5199, -12.1854])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4729, Loss 8.700516\n",
      "Params: tensor([  4.5199, -12.1854])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4730, Loss 8.700514\n",
      "Params: tensor([  4.5199, -12.1854])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4731, Loss 8.700513\n",
      "Params: tensor([  4.5199, -12.1854])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4732, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1855])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4733, Loss 8.700517\n",
      "Params: tensor([  4.5199, -12.1855])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4734, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1855])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4735, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1855])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4736, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1855])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4737, Loss 8.700516\n",
      "Params: tensor([  4.5199, -12.1855])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4738, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1855])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4739, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1855])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4740, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1855])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4741, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1855])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4742, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1855])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4743, Loss 8.700517\n",
      "Params: tensor([  4.5199, -12.1855])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4744, Loss 8.700516\n",
      "Params: tensor([  4.5199, -12.1855])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4745, Loss 8.700516\n",
      "Params: tensor([  4.5199, -12.1855])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4746, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1855])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4747, Loss 8.700514\n",
      "Params: tensor([  4.5199, -12.1856])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4748, Loss 8.700514\n",
      "Params: tensor([  4.5199, -12.1856])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4749, Loss 8.700514\n",
      "Params: tensor([  4.5199, -12.1856])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4750, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1856])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4751, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1856])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4752, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1856])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4753, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1856])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4754, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1856])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4755, Loss 8.700516\n",
      "Params: tensor([  4.5199, -12.1856])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4756, Loss 8.700514\n",
      "Params: tensor([  4.5199, -12.1856])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4757, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1856])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4758, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1856])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4759, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1856])\n",
      "Grad:   tensor([-0.0001,  0.0007])\n",
      "Epoch 4760, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1856])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4761, Loss 8.700516\n",
      "Params: tensor([  4.5199, -12.1856])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4762, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1857])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4763, Loss 8.700513\n",
      "Params: tensor([  4.5199, -12.1857])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4764, Loss 8.700513\n",
      "Params: tensor([  4.5199, -12.1857])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4765, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1857])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4766, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1857])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4767, Loss 8.700512\n",
      "Params: tensor([  4.5199, -12.1857])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4768, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1857])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4769, Loss 8.700513\n",
      "Params: tensor([  4.5199, -12.1857])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4770, Loss 8.700516\n",
      "Params: tensor([  4.5199, -12.1857])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4771, Loss 8.700513\n",
      "Params: tensor([  4.5199, -12.1857])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4772, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1857])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4773, Loss 8.700515\n",
      "Params: tensor([  4.5199, -12.1857])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4774, Loss 8.700516\n",
      "Params: tensor([  4.5199, -12.1857])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4775, Loss 8.700512\n",
      "Params: tensor([  4.5199, -12.1857])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4776, Loss 8.700516\n",
      "Params: tensor([  4.5199, -12.1857])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4777, Loss 8.700516\n",
      "Params: tensor([  4.5199, -12.1858])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4778, Loss 8.700517\n",
      "Params: tensor([  4.5200, -12.1858])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4779, Loss 8.700516\n",
      "Params: tensor([  4.5200, -12.1858])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4780, Loss 8.700513\n",
      "Params: tensor([  4.5200, -12.1858])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4781, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1858])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4782, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1858])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4783, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1858])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4784, Loss 8.700513\n",
      "Params: tensor([  4.5200, -12.1858])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4785, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1858])\n",
      "Grad:   tensor([-9.2745e-05,  6.2275e-04])\n",
      "Epoch 4786, Loss 8.700514\n",
      "Params: tensor([  4.5200, -12.1858])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4787, Loss 8.700513\n",
      "Params: tensor([  4.5200, -12.1858])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4788, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1858])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4789, Loss 8.700513\n",
      "Params: tensor([  4.5200, -12.1858])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4790, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1858])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4791, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1858])\n",
      "Grad:   tensor([-9.5367e-05,  6.1619e-04])\n",
      "Epoch 4792, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1858])\n",
      "Grad:   tensor([-9.9182e-05,  6.1452e-04])\n",
      "Epoch 4793, Loss 8.700516\n",
      "Params: tensor([  4.5200, -12.1859])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4794, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1859])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4795, Loss 8.700514\n",
      "Params: tensor([  4.5200, -12.1859])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4796, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1859])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4797, Loss 8.700516\n",
      "Params: tensor([  4.5200, -12.1859])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4798, Loss 8.700516\n",
      "Params: tensor([  4.5200, -12.1859])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4799, Loss 8.700513\n",
      "Params: tensor([  4.5200, -12.1859])\n",
      "Grad:   tensor([-9.1553e-05,  6.0844e-04])\n",
      "Epoch 4800, Loss 8.700512\n",
      "Params: tensor([  4.5200, -12.1859])\n",
      "Grad:   tensor([-9.2983e-05,  6.0737e-04])\n",
      "Epoch 4801, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1859])\n",
      "Grad:   tensor([-9.5129e-05,  6.0618e-04])\n",
      "Epoch 4802, Loss 8.700512\n",
      "Params: tensor([  4.5200, -12.1859])\n",
      "Grad:   tensor([-9.8705e-05,  6.0427e-04])\n",
      "Epoch 4803, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1859])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4804, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1859])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4805, Loss 8.700512\n",
      "Params: tensor([  4.5200, -12.1859])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4806, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1859])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4807, Loss 8.700513\n",
      "Params: tensor([  4.5200, -12.1859])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4808, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1859])\n",
      "Grad:   tensor([-9.3460e-05,  5.9938e-04])\n",
      "Epoch 4809, Loss 8.700514\n",
      "Params: tensor([  4.5200, -12.1859])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4810, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1859])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4811, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1860])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4812, Loss 8.700516\n",
      "Params: tensor([  4.5200, -12.1860])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4813, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1860])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4814, Loss 8.700516\n",
      "Params: tensor([  4.5200, -12.1860])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4815, Loss 8.700516\n",
      "Params: tensor([  4.5200, -12.1860])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4816, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1860])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4817, Loss 8.700516\n",
      "Params: tensor([  4.5200, -12.1860])\n",
      "Grad:   tensor([-9.8705e-05,  5.8949e-04])\n",
      "Epoch 4818, Loss 8.700516\n",
      "Params: tensor([  4.5200, -12.1860])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4819, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1860])\n",
      "Grad:   tensor([-9.7513e-05,  5.8770e-04])\n",
      "Epoch 4820, Loss 8.700514\n",
      "Params: tensor([  4.5200, -12.1860])\n",
      "Grad:   tensor([-9.9659e-05,  5.8615e-04])\n",
      "Epoch 4821, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1860])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4822, Loss 8.700513\n",
      "Params: tensor([  4.5200, -12.1860])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4823, Loss 8.700513\n",
      "Params: tensor([  4.5200, -12.1860])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4824, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1860])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4825, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1860])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4826, Loss 8.700514\n",
      "Params: tensor([  4.5200, -12.1860])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4827, Loss 8.700513\n",
      "Params: tensor([  4.5200, -12.1860])\n",
      "Grad:   tensor([-9.7752e-05,  5.7960e-04])\n",
      "Epoch 4828, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1861])\n",
      "Grad:   tensor([-9.8705e-05,  5.7840e-04])\n",
      "Epoch 4829, Loss 8.700516\n",
      "Params: tensor([  4.5200, -12.1861])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4830, Loss 8.700516\n",
      "Params: tensor([  4.5200, -12.1861])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4831, Loss 8.700514\n",
      "Params: tensor([  4.5200, -12.1861])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4832, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1861])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4833, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1861])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4834, Loss 8.700516\n",
      "Params: tensor([  4.5200, -12.1861])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4835, Loss 8.700516\n",
      "Params: tensor([  4.5200, -12.1861])\n",
      "Grad:   tensor([-9.9659e-05,  5.7137e-04])\n",
      "Epoch 4836, Loss 8.700516\n",
      "Params: tensor([  4.5200, -12.1861])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4837, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1861])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4838, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1861])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4839, Loss 8.700512\n",
      "Params: tensor([  4.5200, -12.1861])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4840, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1861])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4841, Loss 8.700513\n",
      "Params: tensor([  4.5200, -12.1861])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4842, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1861])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4843, Loss 8.700513\n",
      "Params: tensor([  4.5200, -12.1861])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4844, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1861])\n",
      "Grad:   tensor([-9.2983e-05,  5.6314e-04])\n",
      "Epoch 4845, Loss 8.700514\n",
      "Params: tensor([  4.5200, -12.1861])\n",
      "Grad:   tensor([-9.9659e-05,  5.6112e-04])\n",
      "Epoch 4846, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1862])\n",
      "Grad:   tensor([-9.9659e-05,  5.6016e-04])\n",
      "Epoch 4847, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1862])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4848, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1862])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4849, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1862])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4850, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1862])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4851, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1862])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4852, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1862])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4853, Loss 8.700514\n",
      "Params: tensor([  4.5200, -12.1862])\n",
      "Grad:   tensor([-9.8944e-05,  5.5349e-04])\n",
      "Epoch 4854, Loss 8.700514\n",
      "Params: tensor([  4.5200, -12.1862])\n",
      "Grad:   tensor([-0.0001,  0.0006])\n",
      "Epoch 4855, Loss 8.700516\n",
      "Params: tensor([  4.5200, -12.1862])\n",
      "Grad:   tensor([-0.0001,  0.0005])\n",
      "Epoch 4856, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1862])\n",
      "Grad:   tensor([-0.0001,  0.0005])\n",
      "Epoch 4857, Loss 8.700513\n",
      "Params: tensor([  4.5200, -12.1862])\n",
      "Grad:   tensor([-0.0001,  0.0005])\n",
      "Epoch 4858, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1862])\n",
      "Grad:   tensor([-0.0001,  0.0005])\n",
      "Epoch 4859, Loss 8.700514\n",
      "Params: tensor([  4.5200, -12.1862])\n",
      "Grad:   tensor([-8.0585e-05,  5.5027e-04])\n",
      "Epoch 4860, Loss 8.700513\n",
      "Params: tensor([  4.5200, -12.1862])\n",
      "Grad:   tensor([-9.0122e-05,  5.4765e-04])\n",
      "Epoch 4861, Loss 8.700513\n",
      "Params: tensor([  4.5200, -12.1862])\n",
      "Grad:   tensor([-9.6798e-05,  5.4538e-04])\n",
      "Epoch 4862, Loss 8.700514\n",
      "Params: tensor([  4.5200, -12.1862])\n",
      "Grad:   tensor([-9.7513e-05,  5.4431e-04])\n",
      "Epoch 4863, Loss 8.700513\n",
      "Params: tensor([  4.5200, -12.1863])\n",
      "Grad:   tensor([-0.0001,  0.0005])\n",
      "Epoch 4864, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1863])\n",
      "Grad:   tensor([-0.0001,  0.0005])\n",
      "Epoch 4865, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1863])\n",
      "Grad:   tensor([-0.0001,  0.0005])\n",
      "Epoch 4866, Loss 8.700513\n",
      "Params: tensor([  4.5200, -12.1863])\n",
      "Grad:   tensor([-0.0001,  0.0005])\n",
      "Epoch 4867, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1863])\n",
      "Grad:   tensor([-0.0001,  0.0005])\n",
      "Epoch 4868, Loss 8.700513\n",
      "Params: tensor([  4.5200, -12.1863])\n",
      "Grad:   tensor([-0.0001,  0.0005])\n",
      "Epoch 4869, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1863])\n",
      "Grad:   tensor([-0.0001,  0.0005])\n",
      "Epoch 4870, Loss 8.700514\n",
      "Params: tensor([  4.5200, -12.1863])\n",
      "Grad:   tensor([-0.0001,  0.0005])\n",
      "Epoch 4871, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1863])\n",
      "Grad:   tensor([-9.9182e-05,  5.3525e-04])\n",
      "Epoch 4872, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1863])\n",
      "Grad:   tensor([-0.0001,  0.0005])\n",
      "Epoch 4873, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1863])\n",
      "Grad:   tensor([-0.0001,  0.0005])\n",
      "Epoch 4874, Loss 8.700515\n",
      "Params: tensor([  4.5200, -12.1863])\n",
      "Grad:   tensor([-0.0001,  0.0005])\n",
      "Epoch 4875, Loss 8.700514\n",
      "Params: tensor([  4.5200, -12.1863])\n",
      "Grad:   tensor([-0.0001,  0.0005])\n",
      "Epoch 4876, Loss 8.700516\n",
      "Params: tensor([  4.5201, -12.1863])\n",
      "Grad:   tensor([-0.0001,  0.0005])\n",
      "Epoch 4877, Loss 8.700516\n",
      "Params: tensor([  4.5201, -12.1863])\n",
      "Grad:   tensor([-0.0001,  0.0005])\n",
      "Epoch 4878, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1863])\n",
      "Grad:   tensor([-9.3699e-05,  5.2953e-04])\n",
      "Epoch 4879, Loss 8.700512\n",
      "Params: tensor([  4.5201, -12.1863])\n",
      "Grad:   tensor([-9.6321e-05,  5.2786e-04])\n",
      "Epoch 4880, Loss 8.700513\n",
      "Params: tensor([  4.5201, -12.1863])\n",
      "Grad:   tensor([-9.5844e-05,  5.2691e-04])\n",
      "Epoch 4881, Loss 8.700512\n",
      "Params: tensor([  4.5201, -12.1864])\n",
      "Grad:   tensor([-0.0001,  0.0005])\n",
      "Epoch 4882, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1864])\n",
      "Grad:   tensor([-0.0001,  0.0005])\n",
      "Epoch 4883, Loss 8.700513\n",
      "Params: tensor([  4.5201, -12.1864])\n",
      "Grad:   tensor([-0.0001,  0.0005])\n",
      "Epoch 4884, Loss 8.700513\n",
      "Params: tensor([  4.5201, -12.1864])\n",
      "Grad:   tensor([-9.4175e-05,  5.2333e-04])\n",
      "Epoch 4885, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1864])\n",
      "Grad:   tensor([-8.6308e-05,  5.2428e-04])\n",
      "Epoch 4886, Loss 8.700513\n",
      "Params: tensor([  4.5201, -12.1864])\n",
      "Grad:   tensor([-7.9870e-05,  5.2416e-04])\n",
      "Epoch 4887, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1864])\n",
      "Grad:   tensor([-6.9380e-05,  5.2559e-04])\n",
      "Epoch 4888, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1864])\n",
      "Grad:   tensor([-0.0001,  0.0005])\n",
      "Epoch 4889, Loss 8.700513\n",
      "Params: tensor([  4.5201, -12.1864])\n",
      "Grad:   tensor([-0.0001,  0.0005])\n",
      "Epoch 4890, Loss 8.700514\n",
      "Params: tensor([  4.5201, -12.1864])\n",
      "Grad:   tensor([-9.0599e-05,  5.1892e-04])\n",
      "Epoch 4891, Loss 8.700513\n",
      "Params: tensor([  4.5201, -12.1864])\n",
      "Grad:   tensor([-8.3685e-05,  5.1916e-04])\n",
      "Epoch 4892, Loss 8.700516\n",
      "Params: tensor([  4.5201, -12.1864])\n",
      "Grad:   tensor([-8.0824e-05,  5.1939e-04])\n",
      "Epoch 4893, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1864])\n",
      "Grad:   tensor([-7.0810e-05,  5.1975e-04])\n",
      "Epoch 4894, Loss 8.700514\n",
      "Params: tensor([  4.5201, -12.1864])\n",
      "Grad:   tensor([-9.4175e-05,  5.1475e-04])\n",
      "Epoch 4895, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1864])\n",
      "Grad:   tensor([-8.5115e-05,  5.1582e-04])\n",
      "Epoch 4896, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1864])\n",
      "Grad:   tensor([-8.2493e-05,  5.1546e-04])\n",
      "Epoch 4897, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1864])\n",
      "Grad:   tensor([-7.3433e-05,  5.1630e-04])\n",
      "Epoch 4898, Loss 8.700513\n",
      "Params: tensor([  4.5201, -12.1864])\n",
      "Grad:   tensor([-6.7234e-05,  5.1653e-04])\n",
      "Epoch 4899, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1864])\n",
      "Grad:   tensor([-8.6784e-05,  5.1224e-04])\n",
      "Epoch 4900, Loss 8.700517\n",
      "Params: tensor([  4.5201, -12.1864])\n",
      "Grad:   tensor([-8.4639e-05,  5.1188e-04])\n",
      "Epoch 4901, Loss 8.700513\n",
      "Params: tensor([  4.5201, -12.1865])\n",
      "Grad:   tensor([-7.3671e-05,  5.1236e-04])\n",
      "Epoch 4902, Loss 8.700512\n",
      "Params: tensor([  4.5201, -12.1865])\n",
      "Grad:   tensor([-6.4135e-05,  5.1355e-04])\n",
      "Epoch 4903, Loss 8.700514\n",
      "Params: tensor([  4.5201, -12.1865])\n",
      "Grad:   tensor([-8.0585e-05,  5.0950e-04])\n",
      "Epoch 4904, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1865])\n",
      "Grad:   tensor([-7.7724e-05,  5.0938e-04])\n",
      "Epoch 4905, Loss 8.700513\n",
      "Params: tensor([  4.5201, -12.1865])\n",
      "Grad:   tensor([-7.2718e-05,  5.0950e-04])\n",
      "Epoch 4906, Loss 8.700513\n",
      "Params: tensor([  4.5201, -12.1865])\n",
      "Grad:   tensor([-6.6996e-05,  5.0950e-04])\n",
      "Epoch 4907, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1865])\n",
      "Grad:   tensor([-8.5115e-05,  5.0557e-04])\n",
      "Epoch 4908, Loss 8.700512\n",
      "Params: tensor([  4.5201, -12.1865])\n",
      "Grad:   tensor([-8.3923e-05,  5.0509e-04])\n",
      "Epoch 4909, Loss 8.700513\n",
      "Params: tensor([  4.5201, -12.1865])\n",
      "Grad:   tensor([-7.5817e-05,  5.0569e-04])\n",
      "Epoch 4910, Loss 8.700512\n",
      "Params: tensor([  4.5201, -12.1865])\n",
      "Grad:   tensor([-6.8188e-05,  5.0640e-04])\n",
      "Epoch 4911, Loss 8.700513\n",
      "Params: tensor([  4.5201, -12.1865])\n",
      "Grad:   tensor([-8.8215e-05,  5.0163e-04])\n",
      "Epoch 4912, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1865])\n",
      "Grad:   tensor([-8.5354e-05,  5.0163e-04])\n",
      "Epoch 4913, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1865])\n",
      "Grad:   tensor([-7.7963e-05,  5.0175e-04])\n",
      "Epoch 4914, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1865])\n",
      "Grad:   tensor([-6.7711e-05,  5.0294e-04])\n",
      "Epoch 4915, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1865])\n",
      "Grad:   tensor([-9.3460e-05,  4.9758e-04])\n",
      "Epoch 4916, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1865])\n",
      "Grad:   tensor([-8.8453e-05,  4.9770e-04])\n",
      "Epoch 4917, Loss 8.700516\n",
      "Params: tensor([  4.5201, -12.1865])\n",
      "Grad:   tensor([-7.7486e-05,  4.9889e-04])\n",
      "Epoch 4918, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1865])\n",
      "Grad:   tensor([-7.0572e-05,  4.9913e-04])\n",
      "Epoch 4919, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1865])\n",
      "Grad:   tensor([-9.7513e-05,  4.9365e-04])\n",
      "Epoch 4920, Loss 8.700516\n",
      "Params: tensor([  4.5201, -12.1865])\n",
      "Grad:   tensor([-9.0122e-05,  4.9412e-04])\n",
      "Epoch 4921, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1865])\n",
      "Grad:   tensor([-8.1539e-05,  4.9472e-04])\n",
      "Epoch 4922, Loss 8.700516\n",
      "Params: tensor([  4.5201, -12.1866])\n",
      "Grad:   tensor([-7.2718e-05,  4.9543e-04])\n",
      "Epoch 4923, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1866])\n",
      "Grad:   tensor([-6.9857e-05,  4.9543e-04])\n",
      "Epoch 4924, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1866])\n",
      "Grad:   tensor([-9.0361e-05,  4.9090e-04])\n",
      "Epoch 4925, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1866])\n",
      "Grad:   tensor([-7.7724e-05,  4.9162e-04])\n",
      "Epoch 4926, Loss 8.700512\n",
      "Params: tensor([  4.5201, -12.1866])\n",
      "Grad:   tensor([-7.2479e-05,  4.9174e-04])\n",
      "Epoch 4927, Loss 8.700514\n",
      "Params: tensor([  4.5201, -12.1866])\n",
      "Grad:   tensor([-6.3896e-05,  4.9269e-04])\n",
      "Epoch 4928, Loss 8.700514\n",
      "Params: tensor([  4.5201, -12.1866])\n",
      "Grad:   tensor([-8.7500e-05,  4.8757e-04])\n",
      "Epoch 4929, Loss 8.700512\n",
      "Params: tensor([  4.5201, -12.1866])\n",
      "Grad:   tensor([-8.2731e-05,  4.8769e-04])\n",
      "Epoch 4930, Loss 8.700512\n",
      "Params: tensor([  4.5201, -12.1866])\n",
      "Grad:   tensor([-7.2002e-05,  4.8864e-04])\n",
      "Epoch 4931, Loss 8.700513\n",
      "Params: tensor([  4.5201, -12.1866])\n",
      "Grad:   tensor([-6.9857e-05,  4.8828e-04])\n",
      "Epoch 4932, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1866])\n",
      "Grad:   tensor([-9.2745e-05,  4.8339e-04])\n",
      "Epoch 4933, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1866])\n",
      "Grad:   tensor([-8.2016e-05,  4.8447e-04])\n",
      "Epoch 4934, Loss 8.700513\n",
      "Params: tensor([  4.5201, -12.1866])\n",
      "Grad:   tensor([-7.2718e-05,  4.8518e-04])\n",
      "Epoch 4935, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1866])\n",
      "Grad:   tensor([-6.6996e-05,  4.8554e-04])\n",
      "Epoch 4936, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1866])\n",
      "Grad:   tensor([-9.3699e-05,  4.7982e-04])\n",
      "Epoch 4937, Loss 8.700513\n",
      "Params: tensor([  4.5201, -12.1866])\n",
      "Grad:   tensor([-8.6784e-05,  4.8018e-04])\n",
      "Epoch 4938, Loss 8.700514\n",
      "Params: tensor([  4.5201, -12.1866])\n",
      "Grad:   tensor([-7.5579e-05,  4.8137e-04])\n",
      "Epoch 4939, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1866])\n",
      "Grad:   tensor([-7.2241e-05,  4.8113e-04])\n",
      "Epoch 4940, Loss 8.700513\n",
      "Params: tensor([  4.5201, -12.1866])\n",
      "Grad:   tensor([-6.5088e-05,  4.8172e-04])\n",
      "Epoch 4941, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1866])\n",
      "Grad:   tensor([-8.6308e-05,  4.7708e-04])\n",
      "Epoch 4942, Loss 8.700514\n",
      "Params: tensor([  4.5201, -12.1866])\n",
      "Grad:   tensor([-8.0824e-05,  4.7731e-04])\n",
      "Epoch 4943, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1867])\n",
      "Grad:   tensor([-7.4387e-05,  4.7767e-04])\n",
      "Epoch 4944, Loss 8.700516\n",
      "Params: tensor([  4.5201, -12.1867])\n",
      "Grad:   tensor([-6.9618e-05,  4.7779e-04])\n",
      "Epoch 4945, Loss 8.700516\n",
      "Params: tensor([  4.5201, -12.1867])\n",
      "Grad:   tensor([-8.8215e-05,  4.7350e-04])\n",
      "Epoch 4946, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1867])\n",
      "Grad:   tensor([-7.9155e-05,  4.7410e-04])\n",
      "Epoch 4947, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1867])\n",
      "Grad:   tensor([-7.7486e-05,  4.7386e-04])\n",
      "Epoch 4948, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1867])\n",
      "Grad:   tensor([-7.1287e-05,  4.7421e-04])\n",
      "Epoch 4949, Loss 8.700513\n",
      "Params: tensor([  4.5201, -12.1867])\n",
      "Grad:   tensor([-8.3923e-05,  4.7076e-04])\n",
      "Epoch 4950, Loss 8.700513\n",
      "Params: tensor([  4.5201, -12.1867])\n",
      "Grad:   tensor([-7.7486e-05,  4.7112e-04])\n",
      "Epoch 4951, Loss 8.700512\n",
      "Params: tensor([  4.5201, -12.1867])\n",
      "Grad:   tensor([-7.4387e-05,  4.7052e-04])\n",
      "Epoch 4952, Loss 8.700512\n",
      "Params: tensor([  4.5201, -12.1867])\n",
      "Grad:   tensor([-6.8188e-05,  4.7112e-04])\n",
      "Epoch 4953, Loss 8.700513\n",
      "Params: tensor([  4.5201, -12.1867])\n",
      "Grad:   tensor([-8.4400e-05,  4.6730e-04])\n",
      "Epoch 4954, Loss 8.700512\n",
      "Params: tensor([  4.5201, -12.1867])\n",
      "Grad:   tensor([-7.8917e-05,  4.6730e-04])\n",
      "Epoch 4955, Loss 8.700514\n",
      "Params: tensor([  4.5201, -12.1867])\n",
      "Grad:   tensor([-7.1287e-05,  4.6802e-04])\n",
      "Epoch 4956, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1867])\n",
      "Grad:   tensor([-9.6321e-05,  4.6265e-04])\n",
      "Epoch 4957, Loss 8.700513\n",
      "Params: tensor([  4.5201, -12.1867])\n",
      "Grad:   tensor([-9.0361e-05,  4.6301e-04])\n",
      "Epoch 4958, Loss 8.700513\n",
      "Params: tensor([  4.5201, -12.1867])\n",
      "Grad:   tensor([-8.1539e-05,  4.6372e-04])\n",
      "Epoch 4959, Loss 8.700512\n",
      "Params: tensor([  4.5201, -12.1867])\n",
      "Grad:   tensor([-7.8440e-05,  4.6349e-04])\n",
      "Epoch 4960, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1867])\n",
      "Grad:   tensor([-6.8903e-05,  4.6444e-04])\n",
      "Epoch 4961, Loss 8.700513\n",
      "Params: tensor([  4.5201, -12.1867])\n",
      "Grad:   tensor([-9.0361e-05,  4.5967e-04])\n",
      "Epoch 4962, Loss 8.700512\n",
      "Params: tensor([  4.5201, -12.1867])\n",
      "Grad:   tensor([-8.5592e-05,  4.5955e-04])\n",
      "Epoch 4963, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1867])\n",
      "Grad:   tensor([-7.7724e-05,  4.6039e-04])\n",
      "Epoch 4964, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1868])\n",
      "Grad:   tensor([-7.2479e-05,  4.6039e-04])\n",
      "Epoch 4965, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1868])\n",
      "Grad:   tensor([-6.1274e-05,  4.6170e-04])\n",
      "Epoch 4966, Loss 8.700514\n",
      "Params: tensor([  4.5201, -12.1868])\n",
      "Grad:   tensor([-8.6069e-05,  4.5645e-04])\n",
      "Epoch 4967, Loss 8.700513\n",
      "Params: tensor([  4.5201, -12.1868])\n",
      "Grad:   tensor([-8.2970e-05,  4.5609e-04])\n",
      "Epoch 4968, Loss 8.700516\n",
      "Params: tensor([  4.5201, -12.1868])\n",
      "Grad:   tensor([-7.2718e-05,  4.5705e-04])\n",
      "Epoch 4969, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1868])\n",
      "Grad:   tensor([-6.7949e-05,  4.5705e-04])\n",
      "Epoch 4970, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1868])\n",
      "Grad:   tensor([-8.9645e-05,  4.5216e-04])\n",
      "Epoch 4971, Loss 8.700517\n",
      "Params: tensor([  4.5201, -12.1868])\n",
      "Grad:   tensor([-8.0824e-05,  4.5311e-04])\n",
      "Epoch 4972, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1868])\n",
      "Grad:   tensor([-8.1778e-05,  4.5216e-04])\n",
      "Epoch 4973, Loss 8.700513\n",
      "Params: tensor([  4.5201, -12.1868])\n",
      "Grad:   tensor([-6.4373e-05,  4.5419e-04])\n",
      "Epoch 4974, Loss 8.700513\n",
      "Params: tensor([  4.5201, -12.1868])\n",
      "Grad:   tensor([-8.0824e-05,  4.5002e-04])\n",
      "Epoch 4975, Loss 8.700512\n",
      "Params: tensor([  4.5201, -12.1868])\n",
      "Grad:   tensor([-7.9870e-05,  4.4966e-04])\n",
      "Epoch 4976, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1868])\n",
      "Grad:   tensor([-7.4387e-05,  4.5002e-04])\n",
      "Epoch 4977, Loss 8.700514\n",
      "Params: tensor([  4.5201, -12.1868])\n",
      "Grad:   tensor([-6.5804e-05,  4.5049e-04])\n",
      "Epoch 4978, Loss 8.700511\n",
      "Params: tensor([  4.5201, -12.1868])\n",
      "Grad:   tensor([-8.9645e-05,  4.4513e-04])\n",
      "Epoch 4979, Loss 8.700513\n",
      "Params: tensor([  4.5201, -12.1868])\n",
      "Grad:   tensor([-8.1062e-05,  4.4632e-04])\n",
      "Epoch 4980, Loss 8.700513\n",
      "Params: tensor([  4.5201, -12.1868])\n",
      "Grad:   tensor([-7.6771e-05,  4.4632e-04])\n",
      "Epoch 4981, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1868])\n",
      "Grad:   tensor([-6.6280e-05,  4.4715e-04])\n",
      "Epoch 4982, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1868])\n",
      "Grad:   tensor([-8.8692e-05,  4.4215e-04])\n",
      "Epoch 4983, Loss 8.700513\n",
      "Params: tensor([  4.5201, -12.1868])\n",
      "Grad:   tensor([-8.4639e-05,  4.4203e-04])\n",
      "Epoch 4984, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1868])\n",
      "Grad:   tensor([-7.6056e-05,  4.4310e-04])\n",
      "Epoch 4985, Loss 8.700513\n",
      "Params: tensor([  4.5201, -12.1869])\n",
      "Grad:   tensor([-6.8903e-05,  4.4334e-04])\n",
      "Epoch 4986, Loss 8.700513\n",
      "Params: tensor([  4.5201, -12.1869])\n",
      "Grad:   tensor([-9.1076e-05,  4.3845e-04])\n",
      "Epoch 4987, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1869])\n",
      "Grad:   tensor([-8.5115e-05,  4.3893e-04])\n",
      "Epoch 4988, Loss 8.700513\n",
      "Params: tensor([  4.5201, -12.1869])\n",
      "Grad:   tensor([-8.1301e-05,  4.3869e-04])\n",
      "Epoch 4989, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1869])\n",
      "Grad:   tensor([-7.2479e-05,  4.3941e-04])\n",
      "Epoch 4990, Loss 8.700512\n",
      "Params: tensor([  4.5201, -12.1869])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad:   tensor([-6.6757e-05,  4.3952e-04])\n",
      "Epoch 4991, Loss 8.700515\n",
      "Params: tensor([  4.5201, -12.1869])\n",
      "Grad:   tensor([-8.6546e-05,  4.3547e-04])\n",
      "Epoch 4992, Loss 8.700516\n",
      "Params: tensor([  4.5201, -12.1869])\n",
      "Grad:   tensor([-8.1778e-05,  4.3547e-04])\n",
      "Epoch 4993, Loss 8.700513\n",
      "Params: tensor([  4.5202, -12.1869])\n",
      "Grad:   tensor([-7.9632e-05,  4.3476e-04])\n",
      "Epoch 4994, Loss 8.700513\n",
      "Params: tensor([  4.5202, -12.1869])\n",
      "Grad:   tensor([-6.7711e-05,  4.3583e-04])\n",
      "Epoch 4995, Loss 8.700515\n",
      "Params: tensor([  4.5202, -12.1869])\n",
      "Grad:   tensor([-9.1553e-05,  4.3106e-04])\n",
      "Epoch 4996, Loss 8.700516\n",
      "Params: tensor([  4.5202, -12.1869])\n",
      "Grad:   tensor([-8.5354e-05,  4.3130e-04])\n",
      "Epoch 4997, Loss 8.700512\n",
      "Params: tensor([  4.5202, -12.1869])\n",
      "Grad:   tensor([-7.3433e-05,  4.3249e-04])\n",
      "Epoch 4998, Loss 8.700512\n",
      "Params: tensor([  4.5202, -12.1869])\n",
      "Grad:   tensor([-6.1512e-05,  4.3356e-04])\n",
      "Epoch 4999, Loss 8.700513\n",
      "Params: tensor([  4.5202, -12.1869])\n",
      "Grad:   tensor([-8.4639e-05,  4.2856e-04])\n",
      "Epoch 5000, Loss 8.700512\n",
      "Params: tensor([  4.5202, -12.1869])\n",
      "Grad:   tensor([-7.2479e-05,  4.3011e-04])\n"
     ]
    }
   ],
   "source": [
    "params = training_loop(n_epochs = 5000,\n",
    "              learning_rate = 1e-2,\n",
    "              params = torch.tensor([1.0, 0.0]),\n",
    "              t_u = t_un,\n",
    "              t_c = t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e99d7993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  4.5202, -12.1869])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4d12f2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12bcc3350>]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2560x1920 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t_p = model(t_un, *params)\n",
    "fig = plt.figure(dpi=400)\n",
    "plt.xlabel(\"Temperature (°Fahrenheit)\")\n",
    "plt.ylabel(\"Temperature (°Celsius)\")\n",
    "plt.plot(t_u.numpy(), t_p.detach().numpy())\n",
    "plt.plot(t_u.numpy(), t_c.numpy(), 'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480a2385",
   "metadata": {},
   "source": [
    "### Использование autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1039c71d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 0], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "19fb8d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.grad is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b1ef3827",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_fn(model(t_u, *params), t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3318e637",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5b63cbbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4485.5879,   81.1455])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "572ff97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, learning_rate, params, t_u, t_c):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        if params.grad is not None:\n",
    "            params.grad.zero_()\n",
    "        t_p = model(t_u, *params)\n",
    "        loss = loss_fn(t_p, t_c)\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            params -= learning_rate * params.grad\n",
    "        if epoch % 500 == 0:\n",
    "            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8c427a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Loss 11.178135\n",
      "Epoch 1000, Loss 9.153041\n",
      "Epoch 1500, Loss 8.783166\n",
      "Epoch 2000, Loss 8.715611\n",
      "Epoch 2500, Loss 8.703269\n",
      "Epoch 3000, Loss 8.701015\n",
      "Epoch 3500, Loss 8.700603\n",
      "Epoch 4000, Loss 8.700530\n",
      "Epoch 4500, Loss 8.700515\n",
      "Epoch 5000, Loss 8.700512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  4.5202, -12.1869], requires_grad=True)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs = 5000,\n",
    "    learning_rate = 1e-2,\n",
    "    params = torch.tensor([1.0, 0.0], requires_grad=True),\n",
    "    t_u = t_un,\n",
    "    t_c = t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3b644818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4a4a9c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ASGD',\n",
       " 'Adadelta',\n",
       " 'Adagrad',\n",
       " 'Adam',\n",
       " 'AdamW',\n",
       " 'Adamax',\n",
       " 'LBFGS',\n",
       " 'NAdam',\n",
       " 'Optimizer',\n",
       " 'RAdam',\n",
       " 'RMSprop',\n",
       " 'Rprop',\n",
       " 'SGD',\n",
       " 'SparseAdam',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_functional',\n",
       " '_multi_tensor',\n",
       " 'lr_scheduler',\n",
       " 'swa_utils']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(optim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3787eb40",
   "metadata": {},
   "source": [
    "### Оптимизатор на основе градиентного спуска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cdff5e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "learning_rate = 1e-5\n",
    "optimizer = optim.SGD([params], lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "10338715",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_p = model(t_u, *params)\n",
    "loss = loss_fn(t_p, t_c)\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a748aac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9.5514e-01, -8.1145e-04], requires_grad=True)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f5332c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.SGD([params], lr=learning_rate)\n",
    "t_p = model(t_un, *params)\n",
    "loss = loss_fn(t_p, t_c)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ac60b3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.8078, 0.1209], requires_grad=True)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e1a1bd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, params, t_u, t_c):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        t_p = model(t_u, *params)\n",
    "        loss = loss_fn(t_p, t_c)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 500 == 0:\n",
    "            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b44bcb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.SGD([params], lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "70d38e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Loss 11.178135\n",
      "Epoch 1000, Loss 9.153041\n",
      "Epoch 1500, Loss 8.783166\n",
      "Epoch 2000, Loss 8.715611\n",
      "Epoch 2500, Loss 8.703269\n",
      "Epoch 3000, Loss 8.701015\n",
      "Epoch 3500, Loss 8.700603\n",
      "Epoch 4000, Loss 8.700530\n",
      "Epoch 4500, Loss 8.700515\n",
      "Epoch 5000, Loss 8.700512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  4.5202, -12.1869], requires_grad=True)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs = 5000,\n",
    "    optimizer = optimizer,\n",
    "    params = params,\n",
    "    t_u = t_un,\n",
    "    t_c = t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "75b2922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "learning_rate = 1e-1\n",
    "optimizer = optim.Adam([params], lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "92df3de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Loss 10.824798\n",
      "Epoch 1000, Loss 8.762753\n",
      "Epoch 1500, Loss 8.700804\n",
      "Epoch 2000, Loss 8.700513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  0.4520, -12.1882], requires_grad=True)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs = 2000,\n",
    "    optimizer = optimizer,\n",
    "    params = params,\n",
    "    t_u = t_u,\n",
    "    t_c = t_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be885f93",
   "metadata": {},
   "source": [
    "### Разбиение набора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1210e6f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = t_u.shape[0]\n",
    "n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "475bc81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_val = int(0.2 * n_samples)\n",
    "n_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5b4179e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2,  1,  7,  0,  3,  9,  4,  5, 10,  6,  8])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_indices = torch.randperm(n_samples)\n",
    "shuffled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "114d3285",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = shuffled_indices[:-n_val]\n",
    "val_indices = shuffled_indices[-n_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "848b3e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 2,  1,  7,  0,  3,  9,  4,  5, 10]), tensor([6, 8]))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_indices, val_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bed3ef25",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_t_u = t_u[train_indices]\n",
    "train_t_c = t_c[train_indices]\n",
    "val_t_u = t_u[val_indices]\n",
    "val_t_c = t_c[val_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "50a7161a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_t_un = 0.1 * train_t_u\n",
    "val_t_un = 0.1 * val_t_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "adde03cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, params, train_t_u, val_t_u,\n",
    "              train_t_c, val_t_c):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_t_p = model(train_t_u, *params)\n",
    "        train_loss = loss_fn(train_t_p, train_t_c)\n",
    "        \n",
    "        val_t_p = model(val_t_u, *params)\n",
    "        val_loss = loss_fn(val_t_p, val_t_c)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch <= 3 or epoch % 500 == 0:\n",
    "            print(f'Epoch {epoch}, Training loss {train_loss.item():.4f},'\n",
    "                  f'Validation loss {val_loss.item():.4f}')\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "06890c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.SGD([params], lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "365f61a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 94.1811,Validation loss 0.7488\n",
      "Epoch 2, Training loss 28.6573,Validation loss 14.3298\n",
      "Epoch 3, Training loss 21.0330,Validation loss 27.0762\n",
      "Epoch 500, Training loss 11.0644,Validation loss 17.1123\n",
      "Epoch 1000, Training loss 9.3242,Validation loss 11.8782\n",
      "Epoch 1500, Training loss 8.9909,Validation loss 10.1265\n",
      "Epoch 2000, Training loss 8.9271,Validation loss 9.4631\n",
      "Epoch 2500, Training loss 8.9148,Validation loss 9.1926\n",
      "Epoch 3000, Training loss 8.9125,Validation loss 9.0780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  4.4089, -11.1527], requires_grad=True)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs = 3000,\n",
    "    optimizer = optimizer,\n",
    "    params = params,\n",
    "    train_t_u = train_t_un,\n",
    "    val_t_u = val_t_un,\n",
    "    train_t_c = train_t_c,\n",
    "    val_t_c = val_t_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa879085",
   "metadata": {},
   "source": [
    "### Упражнение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fce6cb6",
   "metadata": {},
   "source": [
    "Поменяйте модель на w2 * t_u**2 + w1 * t_u + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7b00a71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_upd(t_u, w1, w2, b):\n",
    "    return w2 * t_u**2 + w1 * t_u + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "fbfb3aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop_upd(n_epochs, optimizer, params, train_t_u, val_t_u,\n",
    "              train_t_c, val_t_c):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_t_p = model_upd(train_t_u, *params)\n",
    "        train_loss = loss_fn(train_t_p, train_t_c)\n",
    "        \n",
    "        val_t_p = model_upd(val_t_u, *params)\n",
    "        val_loss = loss_fn(val_t_p, val_t_c)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch <= 3 or epoch % 500 == 0:\n",
    "            print(f'Epoch {epoch}, Training loss {train_loss.item():.4f},'\n",
    "                  f'Validation loss {val_loss.item():.4f}')\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "2bbc1c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 1.0, 0.0], requires_grad=True)\n",
    "learning_rate = 1e-4\n",
    "optimizer = optim.SGD([params], lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "1309fada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 742.8753,Validation loss 318.4707\n",
      "Epoch 2, Training loss 398.6072,Validation loss 198.2386\n",
      "Epoch 3, Training loss 215.5660,Validation loss 128.4664\n",
      "Epoch 500, Training loss 6.8026,Validation loss 13.2513\n",
      "Epoch 1000, Training loss 6.0941,Validation loss 11.3441\n",
      "Epoch 1500, Training loss 5.5756,Validation loss 9.8495\n",
      "Epoch 2000, Training loss 5.1961,Validation loss 8.6709\n",
      "Epoch 2500, Training loss 4.9182,Validation loss 7.7359\n",
      "Epoch 3000, Training loss 4.7146,Validation loss 6.9894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0236,  0.4109, -0.3119], requires_grad=True)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop_upd(\n",
    "    n_epochs = 3000,\n",
    "    optimizer = optimizer,\n",
    "    params = params,\n",
    "    train_t_u = train_t_un,\n",
    "    val_t_u = val_t_un,\n",
    "    train_t_c = train_t_c,\n",
    "    val_t_c = val_t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643ab7c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Lineal model",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "267.59375px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
